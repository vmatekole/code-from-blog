00:00:00,098 --> 00:00:07,678
SPEAKER_0:  The great lie we tell ourselves is that people who are evil are not like us. They're a class apart. Everybody in history who has sinned is a person who's very different from me.

00:00:08,130 --> 00:00:19,102
SPEAKER_0:  Robert George, the philosopher over at Princeton, he's fond of doing a sort of thought experiment in his classes where he asks people to raise their hand if they had lived in Alabama in 1861. How many of you would be abolitionists?

00:00:19,490 --> 00:00:21,726
SPEAKER_0:  And everybody raises their hand. He says, of course, that's not true.

00:00:22,594 --> 00:00:23,390
SPEAKER_0:  Of course that's not true.

00:00:24,066 --> 00:00:26,078
SPEAKER_0:  The best protection against...

00:00:26,338 --> 00:00:31,614
SPEAKER_0:  evil is recognizing that it lies in every human heart and the possibility that it takes.

00:00:31,906 --> 00:00:32,510
SPEAKER_1:  You over.

00:00:32,962 --> 00:00:33,950
SPEAKER_1:  Did you ever sit back?

00:00:34,978 --> 00:00:35,358
SPEAKER_1:  You know.

00:00:35,682 --> 00:00:38,494
SPEAKER_1:  in the quiet of your mind and think, am I participating in evil?

00:00:41,314 --> 00:00:43,518
SPEAKER_1:  Following is a conversation with Ben Shapiro.

00:00:44,194 --> 00:00:45,854
SPEAKER_1:  conservative political commentator.

00:00:46,242 --> 00:00:47,710
SPEAKER_1:  Host of the Ben Shapiro Show.

00:00:48,098 --> 00:00:49,790
SPEAKER_1:  co-founder of The Daily Wire.

00:00:50,114 --> 00:00:52,094
SPEAKER_1:  and author of several books.

00:00:52,354 --> 00:00:54,590
SPEAKER_1:  including the authoritarian moment.

00:00:54,978 --> 00:00:56,190
SPEAKER_1:  the right side of history.

00:00:56,418 --> 00:00:56,894
SPEAKER_1:  and

00:00:57,218 --> 00:00:58,910
SPEAKER_1:  Facts don't care about your feelings.

00:00:59,778 --> 00:01:01,278
SPEAKER_1:  whatever your political leanings.

00:01:01,602 --> 00:01:02,526
SPEAKER_1:  I humbly ask.

00:01:03,010 --> 00:01:04,702
SPEAKER_1:  that you tried to put those aside.

00:01:05,154 --> 00:01:06,782
SPEAKER_1:  and listen with an open mind.

00:01:07,138 --> 00:01:10,590
SPEAKER_1:  trying to give the most charitable interpretation of the words we say.

00:01:11,458 --> 00:01:14,334
SPEAKER_1:  This is true in general for this podcast.

00:01:14,722 --> 00:01:16,958
SPEAKER_1:  whether the guest is Ben Shapiro or.

00:01:17,314 --> 00:01:19,262
SPEAKER_1:  Alexandria Ocasio-Cortez.

00:01:19,810 --> 00:01:20,478
SPEAKER_1:  Donald Trump.

00:01:20,738 --> 00:01:22,142
SPEAKER_1:  or Barack Obama.

00:01:23,042 --> 00:01:24,254
SPEAKER_1:  I will talk to everyone.

00:01:24,770 --> 00:01:25,758
SPEAKER_1:  from every side.

00:01:26,146 --> 00:01:27,006
SPEAKER_1:  from the far left.

00:01:27,522 --> 00:01:28,094
SPEAKER_1:  far right.

00:01:28,738 --> 00:01:30,206
SPEAKER_1:  from presidents to prisoners.

00:01:30,498 --> 00:01:32,062
SPEAKER_1:  from artists to scientists.

00:01:32,482 --> 00:01:33,342
SPEAKER_1:  from the powerful.

00:01:33,634 --> 00:01:34,462
SPEAKER_1:  to the powerless.

00:01:34,978 --> 00:01:36,510
SPEAKER_1:  because we are all human.

00:01:37,218 --> 00:01:39,390
SPEAKER_1:  all capable of good and evil.

00:01:39,970 --> 00:01:41,822
SPEAKER_1:  all with fascinating stories.

00:01:42,050 --> 00:01:43,678
SPEAKER_1:  and ideas to explore.

00:01:44,386 --> 00:01:45,950
SPEAKER_1:  I seek only to understand.

00:01:46,306 --> 00:01:47,198
SPEAKER_1:  and in so doing.

00:01:47,586 --> 00:01:48,126
SPEAKER_1:  Hopefully.

00:01:48,450 --> 00:01:49,886
SPEAKER_1:  Add a bit of love to the world.

00:01:51,074 --> 00:01:53,694
SPEAKER_1:  This is the Lex treatment podcast to support it.

00:01:53,954 --> 00:01:56,030
SPEAKER_1:  Please check out our sponsors in the description.

00:01:56,482 --> 00:01:56,990
SPEAKER_1:  And now...

00:01:57,282 --> 00:01:58,046
SPEAKER_1:  Dear friends.

00:01:58,562 --> 00:01:59,262
SPEAKER_1:  Here's Ben.

00:01:59,746 --> 00:02:00,318
SPEAKER_1:  Shapiro.

00:02:01,442 --> 00:02:02,782
SPEAKER_1:  Let's start with a difficult topic.

00:02:04,130 --> 00:02:05,150
SPEAKER_1:  What do you think about?

00:02:05,442 --> 00:02:09,246
SPEAKER_1:  the comments made by Yeh, formerly known as Kanye West, about Jewish people.

00:02:09,826 --> 00:02:10,558
SPEAKER_0:  They're awful.

00:02:10,850 --> 00:02:12,222
SPEAKER_0:  and anti-Semitic.

00:02:12,994 --> 00:02:15,614
SPEAKER_0:  and they seem to get worse over time. They started off with...

00:02:16,322 --> 00:02:16,990
SPEAKER_0:  The bizarre

00:02:17,218 --> 00:02:19,518
SPEAKER_0:  DEATHCON 3 tweet and then they went into...

00:02:20,482 --> 00:02:22,590
SPEAKER_0:  even more stereotypical.

00:02:23,202 --> 00:02:24,574
SPEAKER_0:  garbage about Jews and...

00:02:25,026 --> 00:02:29,022
SPEAKER_0:  being sexual manipulators, I think that's the Pete Davidson, Kim Kardashian stuff, and then...

00:02:29,506 --> 00:02:30,014
SPEAKER_0:  Jews.

00:02:30,242 --> 00:02:33,502
SPEAKER_0:  running all of the media, just being in charge of the financial sector.

00:02:34,274 --> 00:02:35,198
SPEAKER_0:  Jewish people, I mean...

00:02:35,586 --> 00:02:39,966
SPEAKER_0:  There's no, I mean, I called it on my show, there's stermonaziism, and it is. I mean, it's like.

00:02:40,514 --> 00:02:42,462
SPEAKER_0:  right from Protocols of the Elters of Zion.

00:02:42,722 --> 00:02:43,230
SPEAKER_0:  type stuff.

00:02:43,554 --> 00:02:45,502
SPEAKER_1:  Do you think those words come from pain?

00:02:45,954 --> 00:02:46,782
SPEAKER_1:  where they come from.

00:02:47,074 --> 00:02:51,134
SPEAKER_0:  And you know, it's always hard to try and read somebody's mind. What he looks like to me...

00:02:51,746 --> 00:02:55,550
SPEAKER_0:  having experience in my own family with people who are bipolar is he seems like a bipolar personality.

00:02:55,778 --> 00:02:57,470
SPEAKER_0:  He seems like somebody who is.

00:02:58,082 --> 00:02:58,814
SPEAKER_0:  in the middle of a...

00:02:59,074 --> 00:02:59,934
SPEAKER_0:  Manic episode.

00:03:00,418 --> 00:03:03,742
SPEAKER_0:  and when you're manic you tend to say a lot of things that...

00:03:04,770 --> 00:03:05,502
SPEAKER_0:  You shouldn't say.

00:03:05,730 --> 00:03:08,094
SPEAKER_0:  and you tend to believe that they're the most brilliant things ever said.

00:03:08,866 --> 00:03:12,830
SPEAKER_0:  The Washington Post an entire piece speculating about how bipolarism played into

00:03:13,090 --> 00:03:15,230
SPEAKER_0:  the kind of stuff that Ye was saying.

00:03:15,586 --> 00:03:16,286
SPEAKER_0:  And um...

00:03:17,058 --> 00:03:18,782
SPEAKER_0:  It's hard for me to think that it's not playing.

00:03:19,170 --> 00:03:19,742
SPEAKER_0:  into it.

00:03:20,194 --> 00:03:21,150
SPEAKER_0:  especially because.

00:03:22,338 --> 00:03:22,750
SPEAKER_0:  Even if-

00:03:23,330 --> 00:03:26,750
SPEAKER_0:  He is an anti-semite and I have no reason to suspect he's not given all of his comments.

00:03:27,490 --> 00:03:30,462
SPEAKER_0:  If he had an ounce of common sense, he would stop at a certain point.

00:03:30,914 --> 00:03:34,238
SPEAKER_0:  And bipolarism tends to drive you well past the point where.

00:03:34,626 --> 00:03:35,262
SPEAKER_0:  Common Sense.

00:03:36,162 --> 00:03:36,766
SPEAKER_0:  applies.

00:03:37,186 --> 00:03:40,158
SPEAKER_0:  So I would imagine it's coming from that.

00:03:40,962 --> 00:03:43,998
SPEAKER_0:  I would also imagine that he's...

00:03:44,706 --> 00:03:45,278
SPEAKER_0:  doing.

00:03:45,570 --> 00:03:49,214
SPEAKER_0:  logical mistake that a lot of anti-semites or racists or bigots do which is

00:03:50,466 --> 00:03:52,286
SPEAKER_0:  Somebody hurt me. That person is a Jew.

00:03:52,642 --> 00:03:54,078
SPEAKER_0:  Therefore, all Jews are bad.

00:03:54,530 --> 00:03:56,574
SPEAKER_0:  and that jump from a person.

00:03:56,802 --> 00:04:00,542
SPEAKER_0:  did something to me I don't like, who's a member of a particular race or class.

00:04:01,090 --> 00:04:03,262
SPEAKER_0:  And therefore, everybody of that race or class is bad.

00:04:03,682 --> 00:04:04,670
SPEAKER_0:  Man, that's textbook.

00:04:04,994 --> 00:04:05,694
SPEAKER_0:  bigotry in this.

00:04:06,050 --> 00:04:07,925
SPEAKER_0:  pretty obviously what he is engaging in here.

00:04:07,925 --> 00:04:08,675
SPEAKER_1:  Jumping from the innovation.

00:04:08,675 --> 00:04:15,934
SPEAKER_0:  That's the way he's been expressing it, right? He keeps talking about his Jewish agents. And I watched your interview with him and you kept saying, so just name the agents, right? Just name the people who are...

00:04:16,482 --> 00:04:17,182
SPEAKER_0:  for screwing you.

00:04:17,698 --> 00:04:23,230
SPEAKER_0:  and he wouldn't do it instead he just kept going back to the the general the group the the the Jews in general I mean that's

00:04:23,714 --> 00:04:26,462
SPEAKER_0:  That's textbook bigotry. And if we're put in any other context.

00:04:27,266 --> 00:04:28,446
SPEAKER_0:  he would probably recognize it.

00:04:28,802 --> 00:04:29,278
SPEAKER_0:  as such.

00:04:30,722 --> 00:04:37,118
SPEAKER_1:  To the degree is where it's fuel hate in the world. What's the way to reverse that process? What's the way to alleviate the hate?

00:04:37,890 --> 00:04:39,102
SPEAKER_0:  I mean, when it comes to...

00:04:39,330 --> 00:04:40,990
SPEAKER_0:  alleviating the kind of stuff that he's saying.

00:04:41,378 --> 00:04:42,078
SPEAKER_0:  Obviously.

00:04:42,754 --> 00:04:43,422
SPEAKER_0:  debunking it.

00:04:45,218 --> 00:04:47,518
SPEAKER_0:  making clear that what he's saying is garbage.

00:04:48,642 --> 00:04:50,942
SPEAKER_0:  But the reality is that I think that for...

00:04:51,970 --> 00:04:52,830
SPEAKER_0:  Most people.

00:04:53,346 --> 00:04:55,742
SPEAKER_0:  who are in any way engaged with these issues.

00:04:56,674 --> 00:04:58,686
SPEAKER_0:  I don't think they're being convinced to be anti-Semitic.

00:04:59,074 --> 00:05:04,190
SPEAKER_0:  by yay. I mean, I think there's a group of people who may be swayed that antisemitism is acceptable.

00:05:04,706 --> 00:05:06,110
SPEAKER_0:  because Yay is saying what he's saying.

00:05:06,338 --> 00:05:07,678
SPEAKER_0:  And he's saying so very...

00:05:08,162 --> 00:05:09,918
SPEAKER_0:  loudly and you sang it over and over.

00:05:11,714 --> 00:05:13,438
SPEAKER_0:  Yeah, I think that for example, there are these...

00:05:13,762 --> 00:05:20,190
SPEAKER_0:  signs that were popping up in Los Angeles saying Ye is right. Well that group's been out there posting anti-semitic signs on the freeways for years.

00:05:20,738 --> 00:05:21,438
SPEAKER_0:  and their groups.

00:05:21,762 --> 00:05:30,238
SPEAKER_0:  like that, posting anti-semitic signs where I live in Florida. They've been doing that for years, well before Ye was saying this sort of stuff. It's just like latest opportunity to kind of jump on that particular bandwagon, but...

00:05:31,266 --> 00:05:34,110
SPEAKER_0:  Listen, I think that people do have a moral duty to call that stuff out.

00:05:34,658 --> 00:05:37,022
SPEAKER_1:  So there is a degree to which it normalizes.

00:05:37,986 --> 00:05:43,710
SPEAKER_1:  that kind of idea that Jews control the media, that Jews control X institution.

00:05:45,378 --> 00:05:46,718
SPEAKER_1:  Is there a...

00:05:47,650 --> 00:05:48,958
SPEAKER_1:  way to talk about.

00:05:49,762 --> 00:05:51,742
SPEAKER_1:  a high representation of a group.

00:05:52,130 --> 00:05:52,606
SPEAKER_1:  like.

00:05:52,866 --> 00:05:53,694
SPEAKER_1:  Jewish people.

00:05:54,018 --> 00:05:54,846
SPEAKER_1:  in a certain

00:05:55,874 --> 00:05:58,814
SPEAKER_1:  institution like the media or Hollywood and so on.

00:05:59,138 --> 00:06:00,766
SPEAKER_1:  without it being a hateful.

00:06:01,634 --> 00:06:02,686
SPEAKER_0:  conversation..

00:06:03,074 --> 00:06:04,318
SPEAKER_0:  a high percentage of.

00:06:04,770 --> 00:06:05,598
SPEAKER_0:  higher than.

00:06:06,274 --> 00:06:09,022
SPEAKER_0:  statistically represented in the population, percentage of

00:06:10,050 --> 00:06:16,094
SPEAKER_0:  Hollywood agents are probably Jewish, a higher percentage of lawyers generally are probably Jewish, a higher percentage of accountants are probably Jewish.

00:06:16,610 --> 00:06:20,062
SPEAKER_0:  Also, a higher percentage of engineers are probably Asian.

00:06:20,610 --> 00:06:24,030
SPEAKER_0:  Statistical truths are statistical truths. It doesn't necessarily

00:06:24,386 --> 00:06:25,822
SPEAKER_0:  mean anything about.

00:06:26,338 --> 00:06:26,750
SPEAKER_0:  the

00:06:27,266 --> 00:06:35,422
SPEAKER_0:  nature of the people who are being talked about their a myriad of reasons why people might be disproportionately in one arena or another ranging from the cultural

00:06:35,778 --> 00:06:37,694
SPEAKER_0:  to sometimes the genetic I mean, they're certain.

00:06:38,050 --> 00:06:42,526
SPEAKER_0:  areas of the world where people are better long distance runners because of their genetic

00:06:42,818 --> 00:06:44,702
SPEAKER_0:  adaptations in those particular areas of the world.

00:06:44,994 --> 00:06:46,270
SPEAKER_0:  That's not racist, that's just fact.

00:06:46,690 --> 00:06:51,806
SPEAKER_0:  What starts to get racist is when you are attributing a bad characteristic to an entire population.

00:06:52,258 --> 00:06:53,022
SPEAKER_0:  based on.

00:06:54,082 --> 00:06:54,526
SPEAKER_0:  The.

00:06:55,106 --> 00:06:58,174
SPEAKER_0:  notion that that some members of that population are doing bad things.

00:06:58,434 --> 00:07:01,534
SPEAKER_1:  Yeah, there's a jump between. It's also possible that.

00:07:01,986 --> 00:07:04,510
SPEAKER_1:  record label owners as a group.

00:07:05,602 --> 00:07:07,422
SPEAKER_1:  have a kind of culture that

00:07:07,842 --> 00:07:10,974
SPEAKER_1:  Fs over artists. Sure. Fs over artists.

00:07:11,234 --> 00:07:14,494
SPEAKER_1:  And it's also possible that there's a high representation of Jews.

00:07:15,234 --> 00:07:18,558
SPEAKER_1:  in the group of people that own record labels.

00:07:19,106 --> 00:07:20,446
SPEAKER_1:  but it's that small.

00:07:20,802 --> 00:07:22,974
SPEAKER_1:  but a very big leap that people take from.

00:07:23,682 --> 00:07:26,014
SPEAKER_1:  the group that own record labels to.

00:07:26,786 --> 00:07:27,582
SPEAKER_1:  all Jews.

00:07:27,906 --> 00:07:28,670
SPEAKER_0:  For sure.

00:07:29,154 --> 00:07:31,390
SPEAKER_0:  I think that one of the other issues also is that...

00:07:32,322 --> 00:07:33,726
SPEAKER_0:  Anti-Semitism is...

00:07:34,178 --> 00:07:39,870
SPEAKER_0:  Fascinating because it breaks down into so many different parts meaning that if you look at sort of different types of anti-semitism

00:07:40,162 --> 00:07:44,030
SPEAKER_0:  If you're a racist against black people, it's typically because you're racist based on the color of their skin.

00:07:44,354 --> 00:07:47,230
SPEAKER_0:  If you're racist against the Jews, you're anti-Semitic.

00:07:47,458 --> 00:07:53,854
SPEAKER_0:  then there are actually a few different ways that breaks down. You have anti-Semitism in terms of ethnicity, which is like Nazi-esque anti-Semitism.

00:07:54,434 --> 00:07:56,926
SPEAKER_0:  You have Jewish parentage, you have a Jewish grandparent.

00:07:57,250 --> 00:08:01,214
SPEAKER_0:  Therefore, your blood is corrupt and you are inherently going to have bad properties.

00:08:01,666 --> 00:08:03,998
SPEAKER_0:  Then there's sort of old school religious antisemitism.

00:08:04,226 --> 00:08:16,734
SPEAKER_0:  which is that the Jews are the killers of Christ or the Jews are the sons of pigs and monkeys, and therefore Judaism is bad and therefore Jews are bad. And the way that you get out of that anti-Semitism, historically speaking, is mass conversion.

00:08:16,962 --> 00:08:18,558
SPEAKER_0:  which most anti-Semitism for

00:08:18,786 --> 00:08:20,958
SPEAKER_0:  couple thousand years actually was not a thank you was

00:08:21,314 --> 00:08:24,862
SPEAKER_0:  who's much more rooted in this sort of stuff, right? have you converted out of the faith?

00:08:25,282 --> 00:08:25,758
SPEAKER_0:  Then.

00:08:26,402 --> 00:08:28,222
SPEAKER_0:  the anti-semitism was quote unquote alleviated.

00:08:28,834 --> 00:08:30,046
SPEAKER_0:  And then there's a sort of

00:08:30,818 --> 00:08:34,110
SPEAKER_0:  bizarre anti-Semitism, that's political anti-Semitism, and that is...

00:08:34,754 --> 00:08:36,062
SPEAKER_0:  members of a group.

00:08:36,578 --> 00:08:40,222
SPEAKER_0:  that I don't like are disproportionately Jewish, therefore all Jews.

00:08:40,578 --> 00:08:41,054
SPEAKER_0:  R

00:08:43,234 --> 00:08:53,374
SPEAKER_0:  members of this group or are predominantly represented in this group. So you'll see Nazis saying the communists are Jews. You'll see communists saying the Nazis are Jews. Or you'll see communists saying that the capitalists rather.

00:08:53,666 --> 00:08:54,174
SPEAKER_0:  Our Jews.

00:08:54,530 --> 00:09:05,278
SPEAKER_0:  And so that's the weird thing about anti-Semitism. It's kind of like the Jews behind every corner. It's basically a big conspiracy theory. Unlike a lot of other forms of racism, which are not really conspiracy theory, anti-Semitism tends to be a conspiracy theory.

00:09:05,570 --> 00:09:09,118
SPEAKER_0:  about the levers of power being controlled by a shadowy cadre.

00:09:09,442 --> 00:09:12,094
SPEAKER_0:  of people who are getting together behind closed doors to control things.

00:09:12,642 --> 00:09:17,982
SPEAKER_1:  Yeah, the most absurd illustration of anti-Semitism, just like you said, is Stalin versus Hitler.

00:09:18,818 --> 00:09:19,774
SPEAKER_1:  over Poland.

00:09:20,994 --> 00:09:21,534
SPEAKER_1:  every

00:09:22,050 --> 00:09:23,934
SPEAKER_1:  Bad guy was a Jew.

00:09:24,194 --> 00:09:24,766
SPEAKER_1:  It was like...

00:09:25,026 --> 00:09:27,710
SPEAKER_1:  So every enemy, there's a lot of different enemy groups.

00:09:28,034 --> 00:09:30,430
SPEAKER_1:  uh... intellectuals political so on military

00:09:31,458 --> 00:09:36,926
SPEAKER_1:  behind any movement that is considered the enemy for the nazis in any movement that is considered the enemy

00:09:37,218 --> 00:09:39,454
SPEAKER_1:  for the Soviet army.

00:09:39,874 --> 00:09:40,638
SPEAKER_1:  are the Jews.

00:09:41,538 --> 00:09:43,166
SPEAKER_1:  What is the fact that Hitler

00:09:43,554 --> 00:09:44,254
SPEAKER_1:  took power.

00:09:46,018 --> 00:09:47,326
SPEAKER_1:  teach you about human nature.

00:09:48,066 --> 00:09:50,302
SPEAKER_1:  when you look back at the history of the 20th century. what

00:09:50,914 --> 00:09:52,030
SPEAKER_1:  What did you learn from that time?

00:09:52,930 --> 00:09:56,926
SPEAKER_0:  I mean, there are a bunch of lessons to Hitler taking power. The first thing I think people-

00:09:57,538 --> 00:10:02,750
SPEAKER_0:  ought to recognize about Hitler taking power is that the power had been centralized in the government before Hitler took it.

00:10:03,586 --> 00:10:05,534
SPEAKER_0:  So if you actually look at the history of Nazi Germany.

00:10:05,858 --> 00:10:07,774
SPEAKER_0:  The Weimar Republic had effectively collapsed.

00:10:08,386 --> 00:10:11,102
SPEAKER_0:  the power had been centralized in the chancellery.

00:10:11,394 --> 00:10:12,446
SPEAKER_0:  and I had in app собственn

00:10:12,674 --> 00:10:13,310
SPEAKER_0:  really under.

00:10:13,570 --> 00:10:14,046
SPEAKER_0:  Hindenburg.

00:10:14,722 --> 00:10:16,254
SPEAKER_0:  for a couple of years before that.

00:10:16,834 --> 00:10:21,214
SPEAKER_0:  And so it was only a matter of time until someone who was bad grabbed the power.

00:10:21,666 --> 00:10:26,686
SPEAKER_0:  and so the struggle between the Reds and the Browns in Naziism in pre-Nazi Germany.

00:10:27,298 --> 00:10:30,878
SPEAKER_0:  led to this kind of up spiraling of radical sentiment.

00:10:31,106 --> 00:10:31,742
SPEAKER_0:  that allowed.

00:10:32,098 --> 00:10:34,174
SPEAKER_0:  Hitler in through the front door, not through the back door.

00:10:34,562 --> 00:10:35,390
SPEAKER_0:  He was elected.

00:10:35,586 --> 00:10:37,461
SPEAKER_1:  So you think communists could have also taken power?

00:10:37,461 --> 00:10:41,598
SPEAKER_0:  I mean, there's no question communists could have taken power. They were a serious force in pre-Nazi Germany.

00:10:41,986 --> 00:10:44,894
SPEAKER_1:  Do you think there was an underlying current that would have led to an atrocity?

00:10:45,250 --> 00:10:46,046
SPEAKER_1:  if the communists

00:10:46,434 --> 00:10:49,950
SPEAKER_0:  taken power. I'm not saying it's a metrocity, but obviously the communists in Soviet Russia

00:10:50,274 --> 00:10:52,798
SPEAKER_0:  at exactly this time, we're committing the halatomar.

00:10:53,410 --> 00:11:00,030
SPEAKER_0:  So there were very few good guys in terms of good parties. The moderate parties were being dragged by the radicals.

00:11:00,610 --> 00:11:02,910
SPEAKER_0:  into alliance with them to prevent.

00:11:03,234 --> 00:11:03,710
SPEAKER_0:  The worst.

00:11:04,034 --> 00:11:06,622
SPEAKER_0:  case scenario from the other guy, right? If you look at

00:11:06,914 --> 00:11:12,702
SPEAKER_0:  I'm sort of fascinated by the history of this period because it really does speak to how does a democracy

00:11:13,026 --> 00:11:18,110
SPEAKER_0:  I mean, the 20s Weimar Republic was a very liberal democracy. How does a liberal democracy break down into...

00:11:18,498 --> 00:11:19,966
SPEAKER_0:  complete fascism and then in two.

00:11:20,258 --> 00:11:20,862
SPEAKER_0:  genocide.

00:11:21,378 --> 00:11:26,174
SPEAKER_0:  And there's a character who was very prominent in the history of that time, named Franz von Papen.

00:11:26,498 --> 00:11:28,958
SPEAKER_0:  who was actually the second to last chancellor.

00:11:29,346 --> 00:11:32,478
SPEAKER_0:  of the republic before hitler so he was the chancellor and then he handed over to schleicher

00:11:32,962 --> 00:11:33,726
SPEAKER_0:  and then he ends it up.

00:11:34,210 --> 00:11:36,926
SPEAKER_0:  Schleicher ended up collapsing and that ended up handing power over to Hitler.

00:11:37,474 --> 00:11:38,430
SPEAKER_0:  It was Papenhood.

00:11:38,658 --> 00:11:40,350
SPEAKER_0:  stumped for Hitler to become Chancellor.

00:11:40,962 --> 00:11:42,462
SPEAKER_0:  Papin was a

00:11:42,754 --> 00:11:43,838
SPEAKER_0:  was a Catholic Democrat?

00:11:44,578 --> 00:11:45,342
SPEAKER_0:  He didn't like Hitler.

00:11:45,762 --> 00:11:47,518
SPEAKER_0:  He thought that Hitler was a radical.

00:11:47,746 --> 00:11:48,350
SPEAKER_0:  And nut job.

00:11:48,898 --> 00:11:52,286
SPEAKER_0:  but he also thought that Hitler being a buffoon as he saw it.

00:11:52,738 --> 00:11:53,662
SPEAKER_0:  was going to.

00:11:54,114 --> 00:11:55,262
SPEAKER_0:  essentially be usable.

00:11:55,586 --> 00:11:59,902
SPEAKER_0:  by the right forces in order to prevent the communists from taking power.

00:12:00,898 --> 00:12:04,542
SPEAKER_0:  maybe in order to restore some sort of legitimacy to the regime because he was popular.

00:12:05,314 --> 00:12:06,750
SPEAKER_0:  in order for Papin to...

00:12:07,106 --> 00:12:08,030
SPEAKER_0:  retain power himself.

00:12:08,738 --> 00:12:10,654
SPEAKER_0:  and then immediately after Hitler taking power.

00:12:10,946 --> 00:12:13,694
SPEAKER_0:  Hitler basically kills all of Papin's friends. Papin out of-

00:12:13,986 --> 00:12:16,606
SPEAKER_0:  quote-unquote loyalty stays on, he ends up helping.

00:12:16,866 --> 00:12:17,950
SPEAKER_0:  the Anshulus in Austria.

00:12:18,178 --> 00:12:21,086
SPEAKER_0:  Now all this stuff is really interesting mainly because what it speaks to is

00:12:21,634 --> 00:12:29,470
SPEAKER_0:  The great lie we tell ourselves is that people who are evil are not like us. They're a class apart. People who do evil things. People who support evil people. People who are not like us.

00:12:29,890 --> 00:12:31,838
SPEAKER_0:  And that's an easy call. Everybody.

00:12:32,386 --> 00:12:34,110
SPEAKER_0:  everybody in history who has sinned.

00:12:34,370 --> 00:12:35,742
SPEAKER_0:  is a person who's very different from me.

00:12:36,226 --> 00:12:47,166
SPEAKER_0:  Robert George, the philosopher over at Princeton, he's fond of doing a sort of thought experiment in his classes where he asks people to raise their hand if they had lived in Alabama in 1861. Many of you would be abolitionists.

00:12:47,554 --> 00:12:49,790
SPEAKER_0:  And everybody raises their hand. He says, of course, that's not true.

00:12:50,658 --> 00:12:51,422
SPEAKER_0:  Of course that's not true.

00:12:52,130 --> 00:12:54,142
SPEAKER_0:  The best protection against...

00:12:54,402 --> 00:12:59,646
SPEAKER_0:  evil is recognizing that it lies in every human heart and the possibility that it takes.

00:13:00,002 --> 00:13:00,574
SPEAKER_0:  You over.

00:13:01,090 --> 00:13:03,678
SPEAKER_0:  And so you have to be very cautious in how you approach.

00:13:04,354 --> 00:13:05,342
SPEAKER_0:  these issues and

00:13:05,634 --> 00:13:12,254
SPEAKER_0:  the back and forth of politics, the sort of bipolarity of politics, or the polarization in politics might be a better way to put it.

00:13:13,602 --> 00:13:14,110
SPEAKER_0:  Mix it.

00:13:14,338 --> 00:13:21,246
SPEAKER_0:  very easy to kind of fall into the rock'em, sock'em robots that eventually could theoretically allow you to support somebody who's truly...

00:13:22,562 --> 00:13:23,646
SPEAKER_0:  frightening and hideous.

00:13:24,194 --> 00:13:26,398
SPEAKER_0:  in order to stop somebody who you think is more frightening.

00:13:26,754 --> 00:13:29,022
SPEAKER_0:  And hideous. You see this kind of language, by the way, now.

00:13:29,378 --> 00:13:36,222
SPEAKER_0:  predominating almost all over the Western world, right? My political enemy is an enemy of democracy. My political enemy is gonna end the Republic. My political enemy...

00:13:36,450 --> 00:13:39,678
SPEAKER_0:  is going to be the person who destroys the country we live in and so

00:13:40,386 --> 00:13:41,054
SPEAKER_0:  that person

00:13:41,890 --> 00:13:43,806
SPEAKER_0:  has to be stopped by any means necessary.

00:13:44,130 --> 00:13:45,086
SPEAKER_0:  And that's.

00:13:45,506 --> 00:13:46,462
SPEAKER_0:  That's dangerous stuff.

00:13:46,946 --> 00:13:50,622
SPEAKER_1:  So the communists had to be stopped in Nazi Germany, and so they're the devil.

00:13:51,074 --> 00:13:52,190
SPEAKER_1:  So any...

00:13:52,450 --> 00:13:53,470
SPEAKER_1:  Useful buffoon.

00:13:54,434 --> 00:13:57,886
SPEAKER_1:  as long as they're effective against the communists would do.

00:13:58,626 --> 00:14:03,262
SPEAKER_1:  Do you ever wonder because the people that are participating in evil may not understand that they're doing evil?

00:14:04,194 --> 00:14:05,214
SPEAKER_1:  Do you ever sit back?

00:14:06,242 --> 00:14:06,622
SPEAKER_1:  You know.

00:14:06,946 --> 00:14:09,726
SPEAKER_1:  in the quiet of your mind and think, am I participating in evil?

00:14:10,242 --> 00:14:10,974
SPEAKER_0:  That's

00:14:11,362 --> 00:14:15,806
SPEAKER_0:  My business partner and I, one of our favorite memes is from...

00:14:16,098 --> 00:14:19,614
SPEAKER_0:  There's a British comedy show that name escapes me of these two.

00:14:19,874 --> 00:14:26,110
SPEAKER_0:  guys who are members of the SS and they're dressed in the SS uniforms and the black uniforms with the skulls on them and they're saying to each other

00:14:26,434 --> 00:14:30,270
SPEAKER_0:  One says to the other guy, you notice like the British, the symbol is something.

00:14:30,594 --> 00:14:32,638
SPEAKER_0:  It's something nice, and it's like an eagle.

00:14:32,898 --> 00:14:38,398
SPEAKER_0:  But it's a skull and crossbones. You see the Americans, you see their blue uniforms. They're very nice and pretty. Awesome.

00:14:39,266 --> 00:14:39,582
SPEAKER_0:  Black.

00:14:39,938 --> 00:14:40,798
SPEAKER_0:  Are we the baddies?

00:14:41,186 --> 00:14:49,950
SPEAKER_0:  And, you know, that's it. And the truth is we look back at the Nazis and we say, well, of course they were the baddies. They wore black uniforms. They had jackboots and they had this and that.

00:14:50,402 --> 00:14:50,814
SPEAKER_0:  and

00:14:51,074 --> 00:14:52,158
SPEAKER_0:  Of course they were the bad guys.

00:14:52,546 --> 00:14:54,462
SPEAKER_0:  but evil rarely presents its face.

00:14:54,850 --> 00:14:58,686
SPEAKER_0:  So clearly. So yeah, I mean, I think you have to constantly be thinking along.

00:14:58,914 --> 00:14:59,934
SPEAKER_0:  those lines.

00:15:00,194 --> 00:15:01,470
SPEAKER_0:  Hopefully you try to avoid it.

00:15:02,274 --> 00:15:04,254
SPEAKER_0:  You can only do the best that a human being can do.

00:15:04,994 --> 00:15:05,534
SPEAKER_0:  Yeah, I mean...

00:15:05,762 --> 00:15:07,006
SPEAKER_0:  The answer is yes.

00:15:07,682 --> 00:15:08,190
SPEAKER_0:  I would say that.

00:15:09,378 --> 00:15:09,854
SPEAKER_0:  I spent an...

00:15:10,658 --> 00:15:12,638
SPEAKER_0:  inordinate amount of time, reflecting on...

00:15:12,962 --> 00:15:13,438
SPEAKER_0:  weather.

00:15:14,050 --> 00:15:15,038
SPEAKER_0:  I'm doing the right thing.

00:15:15,522 --> 00:15:23,422
SPEAKER_0:  And I may not always do the right thing. I'm sure a lot of people think that I'm doing the wrong thing on a daily basis. But it's definitely a question that has to enter your mind as a historically.

00:15:24,322 --> 00:15:24,926
SPEAKER_0:  aware.

00:15:25,218 --> 00:15:26,942
SPEAKER_0:  and hopefully morally decent person.

00:15:27,138 --> 00:15:30,270
SPEAKER_1:  Do you think you're mentally strong enough if you realize?

00:15:30,946 --> 00:15:33,406
SPEAKER_1:  that you're on the wrong side of history.

00:15:33,890 --> 00:15:37,438
SPEAKER_1:  to switch sides. Very few people in history seem to be strong enough to do that.

00:15:37,538 --> 00:15:38,654
SPEAKER_0:  I mean, I think that...

00:15:39,202 --> 00:15:40,414
SPEAKER_0:  The answer I hope would be yes.

00:15:40,834 --> 00:15:43,358
SPEAKER_0:  uh... you never know until the time comes you have to do it

00:15:43,778 --> 00:15:44,734
SPEAKER_0:  I will say that...

00:15:45,218 --> 00:15:47,646
SPEAKER_0:  Having heterodox opinions in a wide variety of areas.

00:15:48,162 --> 00:15:49,822
SPEAKER_0:  is something that...

00:15:50,114 --> 00:15:52,094
SPEAKER_0:  I have done before. I'm the only-

00:15:53,314 --> 00:15:56,382
SPEAKER_0:  person I've ever heard of in public life who actually has a list.

00:15:56,770 --> 00:16:01,982
SPEAKER_0:  on their website of all the dumb, stupid things they've ever said. So, I go through and I...

00:16:02,274 --> 00:16:10,759
SPEAKER_0:  either say this is why I still believe this or this is why what I said was terrible and stupid. And I'm sure that list will get a lot longer. Yeah, look forward to it. Come on.

00:16:10,759 --> 00:16:11,509
SPEAKER_1:

00:16:11,509 --> 00:16:12,259
SPEAKER_0:  Yeah, exactly.

00:16:12,259 --> 00:16:17,598
SPEAKER_1:  It actually is a super, super long list. People should check it out. And it's quite honest and raw.

00:16:18,274 --> 00:16:19,966
SPEAKER_1:  What do you think about?

00:16:20,482 --> 00:16:22,110
SPEAKER_1:  It's interesting to ask you, given...

00:16:23,650 --> 00:16:24,862
SPEAKER_1:  how pro-life you are.

00:16:25,634 --> 00:16:31,806
SPEAKER_1:  about Ye's comments about comparing the Holocaust to the 900,000 abortions.

00:16:32,130 --> 00:16:33,278
SPEAKER_1:  in the United States a year.

00:16:33,762 --> 00:16:34,110
SPEAKER_0:  So.

00:16:35,010 --> 00:16:38,078
SPEAKER_0:  I'll take this from two angles. As a pro-life person, I actually didn't find it offensive.

00:16:38,434 --> 00:16:43,614
SPEAKER_0:  Because if you believe, as I do, that unborn and preborn lives deserve protection...

00:16:44,162 --> 00:16:45,502
SPEAKER_0:  than the slaughter of.

00:16:46,178 --> 00:16:49,182
SPEAKER_0:  just under a million of them every year for the last almost 50 years.

00:16:49,538 --> 00:16:52,638
SPEAKER_0:  is a historic tragedy on par with a holocaust.

00:16:53,410 --> 00:17:02,558
SPEAKER_0:  From the outside perspective, I get why people would say there's a difference in how people view the pre-born as to how people view, say, a seven-year-old who's being killed in the Holocaust, like the visceral power.

00:17:03,010 --> 00:17:07,998
SPEAKER_0:  an evil of the nazi shoving full grown human beings in and small children gas chambers

00:17:08,290 --> 00:17:09,470
SPEAKER_0:  can't be compared to.

00:17:10,178 --> 00:17:19,422
SPEAKER_0:  a person who even from pro-life perspective may not fully understand the consequences of their own decisions or from a pro-choice perspective fully understand the consequences but just doesn't think that that person is a person.

00:17:19,714 --> 00:17:21,214
SPEAKER_0:  that that's actually different.

00:17:21,442 --> 00:17:22,174
SPEAKER_0:  I understand.

00:17:22,434 --> 00:17:25,406
SPEAKER_0:  both sides of it. I wasn't offended by Ye's comments.

00:17:25,634 --> 00:17:27,710
SPEAKER_0:  in that way though because if you're if you're pro-life

00:17:28,034 --> 00:17:28,670
SPEAKER_0:  human being.

00:17:28,962 --> 00:17:34,174
SPEAKER_0:  then you do think that what's happening is a great tragedy on scale that involves the dehumanization of an entire class of people.

00:17:35,746 --> 00:17:36,734
SPEAKER_0:  The pre-born.

00:17:36,930 --> 00:17:38,878
SPEAKER_1:  So the philosophically you understand the comparison.

00:17:39,266 --> 00:17:39,710
SPEAKER_1:  I did it.

00:17:41,474 --> 00:17:45,278
SPEAKER_1:  So in his comments, in the jumping from the individual to the group.

00:17:46,114 --> 00:17:47,198
SPEAKER_1:  I'd like to ask you...

00:17:47,490 --> 00:17:50,558
SPEAKER_1:  You're one of the most effective people in the world at attacking the left.

00:17:51,938 --> 00:17:54,270
SPEAKER_1:  and sometimes they can slip into attack in the group.

00:17:56,194 --> 00:17:57,278
SPEAKER_1:  Do you worry that there's...

00:17:57,538 --> 00:18:02,814
SPEAKER_1:  That's the same kind of oversimplification that Yeh is doing about Jewish people that you can sometimes do.

00:18:03,234 --> 00:18:04,574
SPEAKER_1:  with the left as a group.

00:18:05,250 --> 00:18:08,158
SPEAKER_0:  So, when I speak about the left, I'm speaking about a philosophy.

00:18:09,058 --> 00:18:11,870
SPEAKER_0:  I'm not really speaking about individual human beings as...

00:18:12,642 --> 00:18:19,198
SPEAKER_0:  the leftists group and then try to name who the members of this individual group are. I also make a distinction between the left and liberals.

00:18:19,810 --> 00:18:25,278
SPEAKER_0:  There are a lot of people who are liberal who disagree with me on taxes, disagree with me on foreign policy, disagree with me on a lot of things.

00:18:25,602 --> 00:18:29,022
SPEAKER_0:  the people who I'm talking about generally, and I talk about the left in the United States.

00:18:29,346 --> 00:18:34,974
SPEAKER_0:  are people who believe that alternative points of view ought to be silenced because they are damaging and harmful.

00:18:35,330 --> 00:18:41,694
SPEAKER_0:  simply based on the disagreement. So that's one distinction. The second distinction again is when I talk about the right versus the left typically I'm talking about.

00:18:42,082 --> 00:18:43,518
SPEAKER_0:  a battle of competing philosophies.

00:18:44,066 --> 00:18:46,142
SPEAKER_0:  And so I'm not speaking about typically.

00:18:47,266 --> 00:18:50,974
SPEAKER_0:  It would be hard to- if you put a person in front of me and say, What is this person of the left or of the right?

00:18:51,330 --> 00:18:52,190
SPEAKER_0:  having just met them.

00:18:52,578 --> 00:18:54,814
SPEAKER_0:  I wouldn't be able to label them in the same way that if you...

00:18:55,042 --> 00:18:57,534
SPEAKER_0:  met somebody named Greenstein, you immediately got you.

00:18:57,858 --> 00:18:58,846
SPEAKER_0:  I make black persons.

00:18:59,138 --> 00:18:59,678
SPEAKER_0:  black person.

00:19:00,130 --> 00:19:03,486
SPEAKER_0:  And the adherence to a philosophy makes you a member of.

00:19:04,450 --> 00:19:11,230
SPEAKER_0:  a group, if I think the philosophy is bad, that doesn't necessarily mean that you as a person are bad, but it does mean that I think your philosophy is bad.

00:19:11,330 --> 00:19:14,366
SPEAKER_1:  Yeah, so the grouping is based on the philosophy versus something.

00:19:15,522 --> 00:19:22,270
SPEAKER_1:  like a race, like the color of your skin or race as in the case of the Jewish people. So it's a different thing.

00:19:22,626 --> 00:19:24,574
SPEAKER_1:  you can be a little bit more.

00:19:25,058 --> 00:19:29,183
SPEAKER_1:  nonchalant and careless in attacking a group because it's ultimately attacking a set of

00:19:29,183 --> 00:19:41,086
SPEAKER_0:  Well, I mean, it's really nonchalant in attacking the set of ideas, and I don't know that nonchalant would be the way I'd put it. I try to be exact when you're, you know, you don't always hit, but, you know, if I say that I oppose the communists.

00:19:41,634 --> 00:19:43,038
SPEAKER_0:  Right? andою

00:19:43,618 --> 00:19:46,622
SPEAKER_0:  Presumably I'm speaking of people who believe in the communist philosophy.

00:19:47,266 --> 00:19:53,278
SPEAKER_0:  Now the question is whether I'm mislabeling, right, whether I'm taking someone who's not actually a communist and then shoving them in that group of communists, right? That'd be inaccurate.

00:19:54,018 --> 00:19:56,510
SPEAKER_1:  The dangerous thing is it expands the group.

00:19:57,122 --> 00:20:01,726
SPEAKER_1:  as opposed to you talking about the philosophy, you're throwing everybody who's ever said.

00:20:01,986 --> 00:20:02,878
SPEAKER_1:  I'm curious about.

00:20:03,202 --> 00:20:06,334
SPEAKER_1:  I'm curious about socialism, because there's like a gradient.

00:20:06,754 --> 00:20:07,774
SPEAKER_1:  You know, it's like...

00:20:08,130 --> 00:20:09,886
SPEAKER_1:  to throw something at you.

00:20:10,114 --> 00:20:11,390
SPEAKER_1:  I think Joe Biden said.

00:20:11,810 --> 00:20:13,278
SPEAKER_1:  MAGA Republicans, right? Right.

00:20:14,210 --> 00:20:14,686
SPEAKER_1:  You know.

00:20:15,074 --> 00:20:19,486
SPEAKER_1:  I think that's a very careless statement because the thing you jump to immediately is

00:20:20,258 --> 00:20:21,383
SPEAKER_1:  Everyone who votes for-

00:20:21,383 --> 00:20:22,133
SPEAKER_0:  for Trump.

00:20:22,133 --> 00:20:23,582
SPEAKER_1:  Right. Go

00:20:24,226 --> 00:20:28,286
SPEAKER_1:  the in the in the charitable interpretation that means a set of ideas.

00:20:28,706 --> 00:20:41,470
SPEAKER_0:  My problem with the MAGA Republicans line from Biden is that he went on in the speech that he made in front of Independence Hall to actually try and define what it meant to be a MAGA Republican who was a threat to the Republic was the kind of language that he was using.

00:20:41,890 --> 00:20:50,238
SPEAKER_0:  And later on in the speech, she actually suggested, well, you know, there are moderate Republicans, and the moderate Republicans are people who agree with me on like the Inflation Reduction Act. Like, well, that can't be the...

00:20:50,594 --> 00:20:53,246
SPEAKER_0:  the dividing line between a MAGA Republican.

00:20:53,474 --> 00:20:59,102
SPEAKER_0:  and a moderate like a moderate publican somebody who agrees with you that you gotta name me like a republican who disagrees with you

00:20:59,490 --> 00:21:00,606
SPEAKER_0:  fairly strenuously.

00:21:00,866 --> 00:21:02,270
SPEAKER_0:  but it's not in this group of threats.

00:21:02,594 --> 00:21:07,582
SPEAKER_0:  to the republic make that distinction we can have a fair discussion about whether the idea of election denial for example

00:21:08,098 --> 00:21:10,654
SPEAKER_0:  make somebody a threat to institutions.

00:21:10,978 --> 00:21:16,638
SPEAKER_0:  That's a conversation that we can have, then we'll have to discuss how much power they have, what the actual perspective is.

00:21:17,026 --> 00:21:17,758
SPEAKER_0:  delve into it.

00:21:17,986 --> 00:21:18,974
SPEAKER_0:  But I think that...

00:21:19,362 --> 00:21:25,470
SPEAKER_0:  he was being over broad and sort of labeling all of his political enemies under one rubric now again in politics this stuff sort of happens all the time I'm not gonna

00:21:25,858 --> 00:21:28,574
SPEAKER_0:  Clean hands here because I'm sure that I've been inexact

00:21:29,122 --> 00:21:29,598
SPEAKER_0:  But...

00:21:29,954 --> 00:21:31,134
SPEAKER_0:  somebody will be.

00:21:31,778 --> 00:21:37,365
SPEAKER_0:  good in that particular situation is for somebody to sort of read back the quote and I'll let you know where I've been inaccurate I'll try to do that and

00:21:37,365 --> 00:21:39,646
SPEAKER_1:  And also you don't shy away from humor and

00:21:40,002 --> 00:21:45,150
SPEAKER_1:  Occasional trolling and mockery and all that kind of stuff for the for the farm for the chaos all that kind of stuff. I mean

00:21:45,250 --> 00:21:51,774
SPEAKER_0:  I try not to do trollery for trollery's sake, but if the show's not entertaining and not fun, people aren't gonna listen.

00:21:52,130 --> 00:21:57,630
SPEAKER_0:  and so if you can have fun with politics, the truth about politics is we all take it very seriously because it has some serious ramifications.

00:21:58,114 --> 00:21:59,838
SPEAKER_0:  Politics is Veep, it is not House of Cards.

00:22:00,610 --> 00:22:05,534
SPEAKER_0:  The general rule of politics is that everyone is a moron unless proven otherwise.

00:22:05,826 --> 00:22:08,222
SPEAKER_0:  that virtually everything is done out of stupidity rather than malice.

00:22:08,770 --> 00:22:12,446
SPEAKER_0:  and that if you actually watch politics as a comedy, you'll have a lot more fun. And so...

00:22:12,738 --> 00:22:18,334
SPEAKER_0:  The difficulty for me is I take politics seriously, but also I have the ability to sort of flip the switch and suddenly it all becomes incredibly funny.

00:22:18,882 --> 00:22:26,110
SPEAKER_0:  Because it really is. Like if you just watch it from a pure entertainment perspective and you put aside the fact that it affects hundreds of millions of people, then...

00:22:26,786 --> 00:22:27,486
SPEAKER_0:  watching.

00:22:28,546 --> 00:22:28,862
SPEAKER_0:  Yep.

00:22:29,922 --> 00:22:33,374
SPEAKER_0:  President Trump being president, I mean, he's one of the funniest humans who's ever lived.

00:22:33,634 --> 00:22:34,590
SPEAKER_0:  watching Kamala Harris.

00:22:35,042 --> 00:22:35,998
SPEAKER_0:  Be Kamala Harrison.

00:22:36,290 --> 00:22:43,203
SPEAKER_0:  talking about how much she loves Venn diagrams or electric buses. I mean, that's funny stuff. So if I can't make fun of that, then my job becomes pretty morose pretty quick.

00:22:43,203 --> 00:22:47,262
SPEAKER_1:  Yeah, it's funny to figure out what is the perfect balance between

00:22:48,066 --> 00:22:51,486
SPEAKER_1:  uh... seen the human absurdity of of the game of it

00:22:51,810 --> 00:22:52,574
SPEAKER_1:  horses.

00:22:52,802 --> 00:22:56,574
SPEAKER_1:  taking it seriously enough because it does affect hundreds of millions of people.

00:22:56,930 --> 00:22:58,334
SPEAKER_1:  It's a weird balance to strike.

00:22:58,658 --> 00:23:00,830
SPEAKER_1:  It's like, I am afraid with the internet.

00:23:01,282 --> 00:23:02,430
SPEAKER_1:  that everything becomes a joke.

00:23:03,170 --> 00:23:06,398
SPEAKER_0:  I totally agree with this. I will say this, I try to make less-

00:23:07,010 --> 00:23:08,254
SPEAKER_0:  jokes about the ideas.

00:23:08,610 --> 00:23:10,878
SPEAKER_0:  and more jokes about the people in the same way that I make jokes about myself.

00:23:11,362 --> 00:23:13,342
SPEAKER_0:  I'm pretty self-effacing in terms of my humor.

00:23:13,858 --> 00:23:15,870
SPEAKER_0:  I would say at least half the jokes on my show are about me.

00:23:16,706 --> 00:23:23,838
SPEAKER_0:  When I'm reading ads for Tommy John and they're talking about their no wedgie guarantee, I'll say things like, you know, that would help me in high school, because it would've.

00:23:24,194 --> 00:23:29,790
SPEAKER_0:  I mean, just factually speaking. So if I can speak that way about myself, I feel like everybody else can take it as well.

00:23:31,202 --> 00:23:32,094
SPEAKER_0:  Difficult question.

00:23:32,674 --> 00:23:35,806
SPEAKER_1:  In 2017, there was a mosque shooting in Quebec City.

00:23:36,226 --> 00:23:38,718
SPEAKER_1:  Six people died, five others seriously injured.

00:23:39,170 --> 00:23:42,750
SPEAKER_1:  The 27 year old gunman consumed a lot of content online.

00:23:43,586 --> 00:23:46,398
SPEAKER_1:  and check Twitter accounts a lot of a lot of people.

00:23:46,626 --> 00:23:49,118
SPEAKER_1:  But one of the people he checked quite a lot of is you.

00:23:49,730 --> 00:23:52,222
SPEAKER_1:  93 times in the month leading up to the shooting.

00:23:53,154 --> 00:23:55,006
SPEAKER_1:  if you could talk to that young man.

00:23:55,426 --> 00:23:58,718
SPEAKER_1:  What would you tell him and maybe other young men listening to this?

00:23:59,170 --> 00:23:59,966
SPEAKER_1:  that have

00:24:00,322 --> 00:24:02,302
SPEAKER_1:  hate in their heart in that same way.

00:24:02,626 --> 00:24:03,358
SPEAKER_1:  What would you tell him?

00:24:03,522 --> 00:24:04,766
SPEAKER_0:  You're getting it wrong.

00:24:05,442 --> 00:24:09,310
SPEAKER_0:  if anything that I or anyone else in mainstream politics says.

00:24:09,570 --> 00:24:11,582
SPEAKER_0:  drives you to violence, you're getting it wrong.

00:24:11,938 --> 00:24:12,862
SPEAKER_0:  You're getting it wrong.

00:24:13,250 --> 00:24:13,918
SPEAKER_0:  Now again.

00:24:14,178 --> 00:24:19,870
SPEAKER_0:  when it comes to stuff like this, I have a hard and fast rule that I've applied evenly across the spectrum, and that is I never blame.

00:24:20,386 --> 00:24:21,438
SPEAKER_0:  People's politics?

00:24:21,890 --> 00:24:25,182
SPEAKER_0:  for other people committing acts of violence unless they're actively advocating violence.

00:24:25,762 --> 00:24:26,206
SPEAKER_0:  So.

00:24:26,466 --> 00:24:30,558
SPEAKER_0:  when a fan of Bernie Sanders shoots up a Congressional baseball game that is not Bernie Sanders' fault.

00:24:30,914 --> 00:24:35,486
SPEAKER_0:  I may not like his rhetoric, I may disagree with him on everything, Bernie Sanders did not tell somebody to go shoot up a congressional baseball game.

00:24:35,970 --> 00:24:40,638
SPEAKER_0:  when a nutcase in San Francisco goes and hits Paul Pelosi with a hammer.

00:24:40,994 --> 00:24:43,038
SPEAKER_0:  I'm not going to blame Kevin McCarthy, the House Speaker, for that.

00:24:43,682 --> 00:24:45,214
SPEAKER_0:  when somebody threatens Brett Kavanaugh.

00:24:45,570 --> 00:24:46,078
SPEAKER_0:  I'm not gonna-

00:24:46,594 --> 00:24:52,702
SPEAKER_0:  I'm not going to suggest that that was Joe Biden's fault because it's not Joe Biden's fault. I mean, we can play this game all day long. And I find that the people who are most.

00:24:53,442 --> 00:24:55,742
SPEAKER_0:  intensely focused on playing this game are people who tend to

00:24:55,970 --> 00:24:56,478
SPEAKER_0:  Oppose.

00:24:57,186 --> 00:25:00,606
SPEAKER_0:  the politics of the person as opposed to actually believing sincerely.

00:25:01,026 --> 00:25:03,518
SPEAKER_0:  that this has driven somebody into the arms of.

00:25:03,906 --> 00:25:05,086
SPEAKER_0:  the god of violence.

00:25:06,306 --> 00:25:06,782
SPEAKER_0:  You know, I.

00:25:07,106 --> 00:25:07,582
SPEAKER_0:  I have.

00:25:08,098 --> 00:25:10,078
SPEAKER_0:  4.7 million Twitter followers I have.

00:25:10,626 --> 00:25:13,470
SPEAKER_0:  eight million Facebook followers, I have five million YouTube followers.

00:25:13,730 --> 00:25:15,038
SPEAKER_0:  I would imagine that some of them...

00:25:15,586 --> 00:25:16,734
SPEAKER_0:  are people who...

00:25:17,154 --> 00:25:21,342
SPEAKER_0:  are violent. I would imagine that some of them are people who do evil things or want to do evil things.

00:25:22,082 --> 00:25:22,846
SPEAKER_0:  And um...

00:25:23,362 --> 00:25:30,302
SPEAKER_0:  I wish that there were a wand that we could wave that would prevent those people from deliberately or mistakenly misinterpreting things as a call to violence.

00:25:30,786 --> 00:25:35,678
SPEAKER_0:  It's it's just a negative byproduct of the fact that you can reach a lot of people and so

00:25:36,578 --> 00:25:38,942
SPEAKER_0:  you know if somebody could point me to the comment that that

00:25:39,298 --> 00:25:39,998
SPEAKER_0:  I suppose.

00:25:40,226 --> 00:25:43,390
SPEAKER_0:  quote unquote, drove somebody to go and literally murder human beings.

00:25:43,938 --> 00:25:44,670
SPEAKER_0:  then.

00:25:44,994 --> 00:25:46,654
SPEAKER_0:  I would appreciate it so I could, so I could.

00:25:47,106 --> 00:25:47,614
SPEAKER_0:  talk about.

00:25:48,098 --> 00:25:49,694
SPEAKER_0:  the comment but i i don't

00:25:51,074 --> 00:25:52,798
SPEAKER_0:  Mainly because I just think that.

00:25:54,050 --> 00:25:55,870
SPEAKER_0:  if we remove agency from individuals.

00:25:56,962 --> 00:25:58,398
SPEAKER_0:  And we, if we blame.

00:25:58,850 --> 00:26:06,718
SPEAKER_0:  broad-scale political rhetoric for every act of violence, we're not gonna, the people who are gonna pay the price are actually the general population because free speech will go away.

00:26:07,202 --> 00:26:08,286
SPEAKER_0:  if the idea is that.

00:26:08,514 --> 00:26:12,830
SPEAKER_0:  things that we say could drive somebody who is unbalanced to go do something evil.

00:26:13,922 --> 00:26:15,422
SPEAKER_0:  The necessary byproduct is hate.

00:26:15,810 --> 00:26:16,862
SPEAKER_0:  Is that- is that-

00:26:17,122 --> 00:26:21,950
SPEAKER_0:  speech is a form of hate hate is a form of violence speech is a form of violence speech needs to be curved

00:26:22,626 --> 00:26:24,990
SPEAKER_0:  And that to me is deeply disturbing.

00:26:25,954 --> 00:26:26,398
SPEAKER_1:  So.

00:26:27,138 --> 00:26:32,830
SPEAKER_1:  Definitely he, that man, that 27 year old man is the only one responsible for the evil he did.

00:26:33,986 --> 00:26:36,734
SPEAKER_1:  What if he and others like him are not nutcases?

00:26:38,402 --> 00:26:39,806
SPEAKER_1:  What if they're people with pain?

00:26:41,026 --> 00:26:42,238
SPEAKER_1:  with anger in their heart.

00:26:42,818 --> 00:26:43,774
SPEAKER_1:  What would you say to them?

00:26:44,386 --> 00:26:47,998
SPEAKER_1:  You are exceptionally influential and other people like you.

00:26:48,546 --> 00:26:50,846
SPEAKER_1:  that speak passionately about ideas.

00:26:51,074 --> 00:26:53,982
SPEAKER_1:  What do you think is your opportunity to alleviate?

00:26:54,242 --> 00:26:55,326
SPEAKER_1:  the hate in their heart.

00:26:55,746 --> 00:26:58,462
SPEAKER_0:  If we're speaking about people who aren't mentally ill and people who are just...

00:26:58,850 --> 00:26:59,646
SPEAKER_0:  Misguided.

00:27:00,258 --> 00:27:07,102
SPEAKER_0:  I'd say to him, the thing I said to every other young man in the country, you need to find meaning and purpose in forming.

00:27:07,362 --> 00:27:08,798
SPEAKER_0:  connections that actually matter.

00:27:09,026 --> 00:27:11,710
SPEAKER_0:  in a belief system that actually promotes.

00:27:12,642 --> 00:27:13,214
SPEAKER_0:  general.

00:27:13,666 --> 00:27:16,350
SPEAKER_0:  prosperity and and and promote helping other people

00:27:16,962 --> 00:27:17,694
SPEAKER_0:  And this is why.

00:27:18,082 --> 00:27:26,718
SPEAKER_0:  The message that I most commonly say to young men is it's time for you to grow up, mature, get a job, get married, have a family, take care of the people around you, become a useful part of your community.

00:27:27,586 --> 00:27:28,638
SPEAKER_0:  I've never.

00:27:28,866 --> 00:27:33,214
SPEAKER_0:  at any point in my entire career suggested violence as a resort to

00:27:34,018 --> 00:27:34,654
SPEAKER_0:  political.

00:27:35,554 --> 00:27:36,350
SPEAKER_0:  political issues.

00:27:36,930 --> 00:27:37,918
SPEAKER_0:  and the whole point of having.

00:27:38,274 --> 00:27:42,718
SPEAKER_0:  a political conversation is that it's a conversation. If I didn't think that it were worth trying convincing people.

00:27:43,042 --> 00:27:44,734
SPEAKER_0:  my point of view I wouldn't do what I do for a living.

00:27:45,698 --> 00:27:46,942
SPEAKER_1:  So violence doesn't solve.

00:27:47,234 --> 00:27:47,998
SPEAKER_1:  No, it doesn't.

00:27:49,762 --> 00:27:50,206
SPEAKER_1:  As if.

00:27:51,170 --> 00:27:53,534
SPEAKER_1:  This wasn't already a difficult conversation.

00:27:55,298 --> 00:27:57,246
SPEAKER_1:  Let me ask about...

00:27:57,538 --> 00:27:58,430
SPEAKER_1:  Ilhan Omar.

00:27:58,914 --> 00:27:59,774
SPEAKER_1:  You've called out.

00:28:00,066 --> 00:28:03,294
SPEAKER_1:  her criticism of Israel policies as anti-Semitic.

00:28:03,778 --> 00:28:07,486
SPEAKER_1:  Is there a difference between criticizing a race of people, like the Jews, and a-

00:28:08,002 --> 00:28:09,150
SPEAKER_1:  and criticizing.

00:28:09,986 --> 00:28:10,526
SPEAKER_1:  Um...

00:28:10,946 --> 00:28:12,071
SPEAKER_1:  policies of a nation.

00:28:12,071 --> 00:28:12,766
SPEAKER_0:  Of course.

00:28:13,122 --> 00:28:17,758
SPEAKER_0:  Of course, I criticize the policies of Israel on a fairly regular basis, I would assume from a different angle than Ohan Omar does.

00:28:18,178 --> 00:28:24,798
SPEAKER_0:  But yeah, I mean, I criticize the policies of a wide variety of states. And to take an example, I mean, I've criticized...

00:28:25,154 --> 00:28:28,638
SPEAKER_0:  Israel's policy in giving control of the Temple Mount to the Islamic walk, which...

00:28:28,962 --> 00:28:31,486
SPEAKER_0:  effectively prevents anybody except for Muslims from praying up there.

00:28:31,906 --> 00:28:36,222
SPEAKER_0:  I've also criticized the Israeli government for their COVID crackdown. You can criticize the policies of any government.

00:28:36,674 --> 00:28:44,318
SPEAKER_0:  But that's not what Ohana Omar does. Ohana Omar doesn't actually believe that there should be a state of Israel. She believes that Zionism is racism and that the existence of a Jewish state...

00:28:44,802 --> 00:28:45,534
SPEAKER_0:  in Israel.

00:28:45,858 --> 00:28:47,358
SPEAKER_0:  is in and of itself.

00:28:47,618 --> 00:28:51,646
SPEAKER_0:  the great sin that is a statement she would make about no other people in no other land.

00:28:52,130 --> 00:28:54,910
SPEAKER_0:  She would not say that the French don't deserve a state for the French. She wouldn't say that.

00:28:55,170 --> 00:28:56,446
SPEAKER_0:  Somalis wouldn't deserve a state.

00:28:56,802 --> 00:28:58,270
SPEAKER_0:  In Somalia, she wouldn't say that.

00:28:58,882 --> 00:29:00,350
SPEAKER_0:  that German is supposed to serve a state in Germany.

00:29:00,738 --> 00:29:01,566
SPEAKER_0:  She wouldn't say for the-

00:29:02,082 --> 00:29:02,782
SPEAKER_0:  50 plus.

00:29:03,138 --> 00:29:09,278
SPEAKER_0:  Islamic states that exist across the world, that they don't deserve states of their own, it is only the Jewish state that has fallen under her significant scrutiny.

00:29:09,634 --> 00:29:10,558
SPEAKER_0:  And she also...

00:29:10,786 --> 00:29:13,246
SPEAKER_0:  promulgates lies about one specific

00:29:13,666 --> 00:29:14,142
SPEAKER_0:  state.

00:29:14,530 --> 00:29:23,070
SPEAKER_0:  in the form of suggesting, for example, that Israel is an apartheid state, which it is most eminently not, considering that the last unity government in Israel included an Arab party that there are Arabs who sit.

00:29:23,554 --> 00:29:24,606
SPEAKER_0:  on the Israeli Supreme Court.

00:29:24,994 --> 00:29:30,686
SPEAKER_0:  and all the rest. And then beyond that, obviously she's engaged in some of the same sort of antisemitic tropes that you heard from Yeh, right? The stuff about.

00:29:31,106 --> 00:29:34,174
SPEAKER_0:  It's all about the Benjamins, that American support for Israel is all about the Benjamins.

00:29:34,818 --> 00:29:37,694
SPEAKER_0:  And she's had to be trided by members of her own party about this sort of stuff before.

00:29:38,370 --> 00:29:40,766
SPEAKER_1:  Can you empathize with the plight of Palestinian people?

00:29:41,314 --> 00:29:42,078
SPEAKER_0:  Absolutely.

00:29:42,338 --> 00:29:43,198
SPEAKER_0:  I mean, I, you know.

00:29:43,522 --> 00:29:49,950
SPEAKER_0:  Some of the uglier things that I've ever said in my career are things that I said very early on when I was 17, 18, 19. I started writing syndicated common when I was 17, I'm now 38.

00:29:50,338 --> 00:29:55,998
SPEAKER_0:  So virtually all the dumb things, not say virtually all, many of the dumb things, the plurality of the dumb things that I've said came from the A.

00:29:56,226 --> 00:29:58,238
SPEAKER_0:  Ages, I would say 17 to maybe 23.

00:29:58,466 --> 00:30:00,094
SPEAKER_0:  And they are rooted

00:30:00,354 --> 00:30:02,110
SPEAKER_0:  Again, in sloppy thinking.

00:30:02,338 --> 00:30:06,846
SPEAKER_0:  I feel terrible for people who have lived under the thumb and currently live under the thumb.

00:30:07,202 --> 00:30:11,390
SPEAKER_0:  Hamas, which is a national terrorist group, or the Palestinian Authority, which is a corrupt oligarchy.

00:30:11,874 --> 00:30:13,886
SPEAKER_0:  steals money from its people and leaves them.

00:30:14,530 --> 00:30:15,102
SPEAKER_0:  in misery.

00:30:15,522 --> 00:30:17,662
SPEAKER_0:  or Islamic Jihad, which is an actual terrorist group.

00:30:18,242 --> 00:30:18,974
SPEAKER_0:  And the- the-

00:30:19,330 --> 00:30:24,254
SPEAKER_0:  basic rule for the region in my view is if these groups were willing to

00:30:24,578 --> 00:30:28,222
SPEAKER_0:  make peace with Israel, they would have a state literally tomorrow. If they are not.

00:30:28,450 --> 00:30:31,230
SPEAKER_0:  then there will be no peace. And it really is that simple. 91-SufficeremarketheIsrael.

00:30:31,682 --> 00:30:41,310
SPEAKER_0:  The formula is typically used to become a bit of a bumper sticker, but it happens to be factually correct. If the Palestinians put down their guns tomorrow, there would be a state. If the Israelis put down their guns, there'd be no Israel.

00:30:43,586 --> 00:30:43,998
SPEAKER_1:  Yeah.

00:30:45,090 --> 00:30:51,294
SPEAKER_1:  You get attacked a lot on the internet. Oh, yeah. You got it. I gotta ask you about your own psychology.

00:30:52,898 --> 00:30:54,878
SPEAKER_1:  How do you not let that break you mentally?

00:30:56,162 --> 00:30:57,214
SPEAKER_1:  and how do you...

00:30:57,506 --> 00:31:01,918
SPEAKER_1:  avoid letting that lead to a resentment of the groups that attack you.

00:31:02,050 --> 00:31:05,790
SPEAKER_0:  I mean, it's so there are a few sort of practical things that I've done. So for example,

00:31:06,338 --> 00:31:06,878
SPEAKER_0:  I would say that.

00:31:07,234 --> 00:31:13,502
SPEAKER_0:  four years ago, Twitter was all consuming. Twitter is an ego machine, especially the notifications button, right? The notifications button is just...

00:31:13,730 --> 00:31:18,430
SPEAKER_0:  people talking about you all the time in a human tendency as well people talking about me gotta see what they're saying about me

00:31:18,690 --> 00:31:20,094
SPEAKER_0:  which is a recipe for insanity.

00:31:20,322 --> 00:31:22,206
SPEAKER_0:  So my wife actually said.

00:31:22,562 --> 00:31:25,726
SPEAKER_0:  Twitter is making your life miserable, you need to take it off your phone. Twitter is not on my phone.

00:31:26,338 --> 00:31:27,518
SPEAKER_0:  If I want to log on to Twitter.

00:31:27,842 --> 00:31:32,126
SPEAKER_0:  I have to go onto my computer and I have to make the conscious decision to go onto Twitter.

00:31:32,386 --> 00:31:34,261
SPEAKER_0:  and then take a look at what's going on. I could just imagine.

00:31:34,261 --> 00:31:37,374
SPEAKER_1:  Imagine you like there's a computer in the basement you descend into.

00:31:37,602 --> 00:31:38,727
SPEAKER_1:  to check Twitter.

00:31:38,727 --> 00:31:41,854
SPEAKER_0:  If you look at when I actually tweet, it's generally like in the...

00:31:42,114 --> 00:31:46,046
SPEAKER_0:  run up to recording my show or when I'm prepping for my show later in the afternoon.

00:31:46,466 --> 00:31:47,070
SPEAKER_0:  For example.

00:31:47,234 --> 00:31:50,609
SPEAKER_1:  That doesn't affect you negatively mentally, like put you in a bad mental space.

00:31:50,609 --> 00:31:52,158
SPEAKER_0:  Not particularly if it's restricted.

00:31:52,770 --> 00:31:57,406
SPEAKER_0:  to sort of what's being watched now. I will say that I think the most important thing is you have to.

00:31:57,954 --> 00:32:00,542
SPEAKER_0:  surround yourself with a group of people who are

00:32:00,802 --> 00:32:01,790
SPEAKER_0:  who you trust enough to.

00:32:02,210 --> 00:32:04,446
SPEAKER_0:  make serious critiques of you when you're doing something wrong.

00:32:04,866 --> 00:32:06,622
SPEAKER_0:  but also you know that they have your best interests at heart.

00:32:07,106 --> 00:32:13,278
SPEAKER_0:  Because the internet is filled with people who don't have your best interests at heart and who hate your gods. So you can't really take those critiques seriously or it does wreck you.

00:32:14,018 --> 00:32:14,430
SPEAKER_0:  and

00:32:15,074 --> 00:32:21,054
SPEAKER_0:  The world is also filled with sycophants, right? Then the more successful you become, there are a lot of people who will tell you you're always doing the right thing.

00:32:21,538 --> 00:32:27,454
SPEAKER_0:  I'm very lucky. I got married when I was 24, my wife was 20, so she's known me long before I was famous or wealthy or anything.

00:32:27,842 --> 00:32:29,758
SPEAKER_0:  And so she's a good sounding board.

00:32:30,178 --> 00:32:31,774
SPEAKER_0:  i have a family that's one of them

00:32:32,002 --> 00:32:33,854
SPEAKER_0:  that's willing to call me out on my bullshit is you.

00:32:34,178 --> 00:32:35,422
SPEAKER_0:  Talk to you too. YAY 한�time

00:32:35,938 --> 00:32:38,174
SPEAKER_0:  I have friends who are able to do that.

00:32:38,530 --> 00:32:43,710
SPEAKER_0:  I try to have open lines of communications with people who I believe have my best interest at heart. But one of the sort of

00:32:44,418 --> 00:32:48,990
SPEAKER_0:  conditions being friends that when you see me do something wrong I'd like for you to let me know that so I can correct it.

00:32:49,730 --> 00:32:51,166
SPEAKER_0:  I don't want to leave bad impressions out there.

00:32:51,266 --> 00:32:54,046
SPEAKER_1:  The sad thing about the internet is just looking at the critiques you get.

00:32:54,818 --> 00:32:58,622
SPEAKER_1:  I see very few critiques from people that actually want you to succeed and want you to grow.

00:32:58,914 --> 00:33:01,790
SPEAKER_1:  I mean they're very, they're not sophisticated, they're just...

00:33:02,338 --> 00:33:02,750
SPEAKER_1:  there.

00:33:03,106 --> 00:33:04,766
SPEAKER_1:  I don't know, they're cruel.

00:33:05,154 --> 00:33:07,806
SPEAKER_1:  The critiques are just, it's not the actual critiques, it's just...

00:33:08,002 --> 00:33:12,734
SPEAKER_0:  And that's most of Twitter. Twitter is a place to...

00:33:13,634 --> 00:33:17,246
SPEAKER_0:  to smack and be smacked. I mean, that's anybody who uses Twitter for a

00:33:17,826 --> 00:33:21,118
SPEAKER_0:  for an intellectual conversation, I think, is engaging in category error.

00:33:21,346 --> 00:33:27,559
SPEAKER_0:  I use it to spread love. I think it's still possible. You're the only one. It's you and no one else, my friend. All right.

00:33:27,559 --> 00:33:31,518
SPEAKER_1:  But on that topic, what do you think about Elon buying Twitter? Would you like?

00:33:32,290 --> 00:33:36,286
SPEAKER_1:  What are you hopeful on that front? What would you like to see Twitter improve?

00:33:36,578 --> 00:33:37,022
SPEAKER_0:  So.

00:33:37,346 --> 00:33:41,182
SPEAKER_0:  I'm very hopeful about Elon buying Twitter. I mean, I think that...

00:33:42,114 --> 00:33:45,694
SPEAKER_0:  Elon is significantly more transparent than what has taken place up till now.

00:33:46,306 --> 00:33:53,054
SPEAKER_0:  He seems committed to the idea that he's gonna broaden the Overton window to allow for conversations that simply were banned before everything ranging from

00:33:53,378 --> 00:33:55,678
SPEAKER_0:  efficacy of masks with regard to COVID.

00:33:55,970 --> 00:33:57,534
SPEAKER_0:  to whether men can become women.

00:33:57,762 --> 00:33:58,302
SPEAKER_0:  and all the rest.

00:33:58,594 --> 00:34:01,534
SPEAKER_0:  A lot of things that would get you banned on Twitter before without any sort of real

00:34:01,826 --> 00:34:02,558
SPEAKER_0:  explanation.

00:34:02,818 --> 00:34:07,934
SPEAKER_0:  It seems like he's dedicated to at least explaining what the standards are going to be and being broader.

00:34:08,226 --> 00:34:11,646
SPEAKER_0:  in allowing a variety of perspectives on the outlet, which I think is wonderful.

00:34:12,130 --> 00:34:16,574
SPEAKER_0:  I think that's also why people are freaking out. I think the kind of wailing and gnashing of teeth and...

00:34:17,122 --> 00:34:18,526
SPEAKER_0:  wearing a sackcloth and ash.

00:34:18,754 --> 00:34:20,318
SPEAKER_0:  by so many members of the legacy media.

00:34:20,802 --> 00:34:22,462
SPEAKER_0:  I think a lot of that is because

00:34:23,330 --> 00:34:24,958
SPEAKER_0:  Twitter essentially was.

00:34:25,314 --> 00:34:28,606
SPEAKER_0:  an oligarchy in which certain perspectives were allowed and certain perspectives just

00:34:28,866 --> 00:34:29,406
SPEAKER_0:  We're not.

00:34:29,890 --> 00:34:32,766
SPEAKER_0:  and that was part of a broader social media reimposed.

00:34:33,474 --> 00:34:34,238
SPEAKER_0:  Oligarchy.

00:34:34,530 --> 00:34:37,310
SPEAKER_0:  in the aftermath of 2017.

00:34:37,538 --> 00:34:37,854
SPEAKER_0:  Ferb.

00:34:38,146 --> 00:34:39,934
SPEAKER_0:  just to really understand I think what what

00:34:40,226 --> 00:34:42,110
SPEAKER_0:  it means for Elon to take over Twitter.

00:34:42,338 --> 00:34:46,718
SPEAKER_0:  I think that we have to take a look at sort of the history of media in the United States in two minutes or less.

00:34:47,170 --> 00:34:48,638
SPEAKER_0:  the United States, the media.

00:34:48,898 --> 00:34:58,398
SPEAKER_0:  for most of its existence up until about 1990, at least from about 1930s until the 1990s, virtually all media was three major television networks, a couple major newspapers and the wire services.

00:34:58,690 --> 00:35:05,598
SPEAKER_0:  Every had a local newspaper that did all the foreign policy and all the national policy. McClatchy, Reuters, AP, AFP, etc.

00:35:05,986 --> 00:35:06,398
SPEAKER_0:  So.

00:35:06,626 --> 00:35:09,406
SPEAKER_0:  That monopoly or oligopoly existed until the rise.

00:35:09,794 --> 00:35:10,782
SPEAKER_0:  of the internet there was sort of

00:35:11,106 --> 00:35:13,438
SPEAKER_0:  and talk radio and Fox News, but.

00:35:13,730 --> 00:35:15,902
SPEAKER_0:  There certainly was not this plethora of sources then.

00:35:16,130 --> 00:35:21,118
SPEAKER_0:  the internet explodes and all of a sudden you get news everywhere and the way the people are accessing that news is

00:35:21,890 --> 00:35:25,566
SPEAKER_0:  You're, I believe, significantly younger than I am, but we used to do this thing called bookmarking.

00:35:25,794 --> 00:35:26,974
SPEAKER_0:  Or are you a bookmark?

00:35:27,426 --> 00:35:29,438
SPEAKER_0:  a series of websites and then you would visit them every morning.

00:35:30,306 --> 00:35:31,006
SPEAKER_0:  And then, uh...

00:35:31,266 --> 00:35:32,702
SPEAKER_0:  And then social media came up.

00:35:32,962 --> 00:35:40,126
SPEAKER_0:  Was this on AOL? Yeah, exactly. You had the dial up, and it was actually a can connected to a string. And you would actually just go, ee, ee, ee.

00:35:40,418 --> 00:35:40,766
SPEAKER_0:  And

00:35:41,154 --> 00:35:42,302
SPEAKER_0:  And then...

00:35:42,626 --> 00:35:44,830
SPEAKER_0:  uh... there came a point where social media arose

00:35:45,058 --> 00:35:50,910
SPEAKER_0:  And social media was sort of a boon for everybody because you no longer had to bookmark anything, you just followed your favorite accounts and all of them would pop up.

00:35:51,170 --> 00:35:59,838
SPEAKER_0:  And you follow everything on Facebook and it would all pop up and it was all centralized. And for a while everybody was super happy because this was the brand new wave of the future. It made everything super easy. Suddenly outlets.

00:36:00,194 --> 00:36:09,470
SPEAKER_0:  like mine, were able to see new eyeballs because it was all centralized in one place, right? You didn't have to do it through Google optimization. You could now just put it on Facebook and so many eyeballs were on Facebook, you'd get more traffic.

00:36:09,730 --> 00:36:11,422
SPEAKER_0:  And everybody seemed pretty happy with this arrangement.

00:36:11,778 --> 00:36:14,622
SPEAKER_0:  until precisely the moment Donald Trump became president. at that point.

00:36:15,138 --> 00:36:16,222
SPEAKER_0:  than the sort of

00:36:16,450 --> 00:36:19,230
SPEAKER_0:  pre-existing supposition of a lot of

00:36:19,490 --> 00:36:20,798
SPEAKER_0:  The Power is the Bee, which was...

00:36:21,666 --> 00:36:23,998
SPEAKER_0:  Democrats are going to continue winning from here on out so we can sort of

00:36:24,258 --> 00:36:26,398
SPEAKER_0:  use these social media platforms as...

00:36:26,914 --> 00:36:30,590
SPEAKER_0:  ways to push our information and still allow for there to be other information out there.

00:36:31,202 --> 00:36:32,542
SPEAKER_0:  The immediate response was.

00:36:32,770 --> 00:36:43,710
SPEAKER_0:  we need to reestablish this siphoning of information. It was misinformation and disinformation that won Donald Trump the election. We need to pressure the social media companies to start cracking down on misinformation and disinformation.

00:36:44,098 --> 00:36:44,830
SPEAKER_0:  and actually see this.

00:36:45,218 --> 00:36:59,294
SPEAKER_0:  in the historical record, you can see how Jack Dorsey's talk about free speech shifted from about 2015 to about 2018. You can see Mark Zuckerberg gave a speech at Georgetown in 2018, in which he talked about free speech and its value. And by 2019, he was going in front of Congress talking about how he was responsible.

00:36:59,586 --> 00:37:04,190
SPEAKER_0:  for the stuff that was on Facebook, which is not true. He's not responsible for the stuff on Facebook, right? It's a platform.

00:37:04,482 --> 00:37:07,614
SPEAKER_0:  Is AT&T responsible for the stuff you say on your phone? The answer is typically no.

00:37:07,874 --> 00:37:08,990
SPEAKER_0:  So when that happened...

00:37:09,506 --> 00:37:12,958
SPEAKER_0:  all of these because all the eyeballs have now been centralized in these social media sites.

00:37:13,474 --> 00:37:22,078
SPEAKER_0:  they were able to suddenly control what you could see and what you could not see. And the most obvious example was obviously leading up to 2020, the election that they...

00:37:22,306 --> 00:37:24,574
SPEAKER_0:  killing of the Hunter Biden story is a great example of this.

00:37:25,090 --> 00:37:25,598
SPEAKER_0:  And so.

00:37:25,826 --> 00:37:30,238
SPEAKER_0:  Elon coming in and taking over one of the social media services and saying, I'm not playing by your rules.

00:37:30,594 --> 00:37:31,934
SPEAKER_0:  There's not going to be this sort of...

00:37:32,770 --> 00:37:33,726
SPEAKER_0:  group of people.

00:37:34,018 --> 00:37:41,758
SPEAKER_0:  in the halls of power. We're gonna decide what we can see and hear. Instead, I'm gonna let a thousand flowers bloom. There'll be limits, could be on more case by case basis.

00:37:42,146 --> 00:37:44,126
SPEAKER_0:  We're going to allow perspectives.

00:37:45,602 --> 00:37:46,526
SPEAKER_0:  mainstream but-

00:37:46,754 --> 00:37:50,494
SPEAKER_0:  maybe not mainstream in the halls of of academia or in the halls of media.

00:37:50,786 --> 00:37:52,126
SPEAKER_0:  Let those be sad.

00:37:52,386 --> 00:37:53,342
SPEAKER_0:  I think it's a really good thing.

00:37:54,690 --> 00:37:58,014
SPEAKER_0:  that comes with some responsibilities How wounded you feel about being an pronouns person

00:37:58,274 --> 00:37:59,646
SPEAKER_0:  which would be, you know, to be.

00:38:00,610 --> 00:38:06,334
SPEAKER_0:  for example i think more responsible in dissemination information self-sumptime certainly got himself in trouble the other day for tweeting out that

00:38:07,362 --> 00:38:10,686
SPEAKER_0:  story about Paul Pelosi that was speculative and untrue.

00:38:11,074 --> 00:38:11,614
SPEAKER_0:  And I think...

00:38:11,938 --> 00:38:12,350
SPEAKER_0:  I don't

00:38:12,610 --> 00:38:13,694
SPEAKER_0:  I think what he did is, you know.

00:38:13,986 --> 00:38:16,126
SPEAKER_0:  horrific, he's elided it when he found out that it was false.

00:38:16,866 --> 00:38:25,118
SPEAKER_0:  And that's actually free speech working, right? He said something wrong, people ripped into him, he realized he was wrong and he deleted it, which seems to be a better solution than preemptively banning content.

00:38:25,378 --> 00:38:27,870
SPEAKER_0:  which only raises more questions than it actually stops.

00:38:28,674 --> 00:38:29,342
SPEAKER_0:  With that said...

00:38:29,986 --> 00:38:32,254
SPEAKER_0:  as the face of responsible free speech.

00:38:33,186 --> 00:38:35,006
SPEAKER_0:  you know and and that's sort of what he's pitching twitter

00:38:35,330 --> 00:38:39,651
SPEAKER_0:  he I think should enact that himself and be a little more careful in the stuff that he tweets out

00:38:39,651 --> 00:38:41,118
SPEAKER_1:  That's a tricky balance.

00:38:41,506 --> 00:38:45,694
SPEAKER_1:  The reason a lot of people are freaking out is because one, he's putting his thumb on the scale.

00:38:46,082 --> 00:38:49,374
SPEAKER_1:  by saying he is more likely of a Republican.

00:38:49,762 --> 00:38:53,598
SPEAKER_1:  He's showing himself to be center right and sort of just having a political opinion.

00:38:53,954 --> 00:38:55,614
SPEAKER_1:  versus being this amorphous.

00:38:55,970 --> 00:38:57,822
SPEAKER_1:  that doesn't have a political opinion.

00:38:58,306 --> 00:39:03,294
SPEAKER_1:  I think if I were to guess, I haven't talked to him about it, but if I were to guess he's sending a kind of signal.

00:39:03,874 --> 00:39:09,278
SPEAKER_1:  that's important for the twitter the company itself because if we're being honest most employees are left-leaning

00:39:09,506 --> 00:39:11,262
SPEAKER_1:  So you have to kind of send a signal that.

00:39:11,810 --> 00:39:13,342
SPEAKER_1:  like a resisting mechanism.

00:39:13,762 --> 00:39:14,494
SPEAKER_1:  to say like.

00:39:14,818 --> 00:39:18,622
SPEAKER_1:  uh... this is mostly employees are left is is good for

00:39:18,978 --> 00:39:19,326
SPEAKER_1:  uh

00:39:19,810 --> 00:39:30,462
SPEAKER_1:  for Elon to be more right to balance out the way the actual engineering is done, to say we're not going to do any kind of activism inside the engineering. If I were to guess, that's kind of the effective.

00:39:30,754 --> 00:39:31,102
SPEAKER_1:  Um.

00:39:31,906 --> 00:39:34,942
SPEAKER_1:  aspect of that of that mechanism and the other one by.

00:39:35,170 --> 00:39:36,382
SPEAKER_1:  posting a Pelosi thing.

00:39:36,770 --> 00:39:37,982
SPEAKER_1:  is probably...

00:39:38,466 --> 00:39:40,638
SPEAKER_1:  to expand the Overton window, like saying...

00:39:41,090 --> 00:39:42,174
SPEAKER_1:  We can play.

00:39:42,722 --> 00:39:47,637
SPEAKER_1:  We could post stuff, we could post conspiracy theories, and then through discourse figure out what it is.

00:39:47,637 --> 00:39:51,518
SPEAKER_0:  is and isn't true. Yeah, again, like I say, I mean, I think that the, that is a better mechanism.

00:39:51,778 --> 00:39:53,150
SPEAKER_0:  in action, then...

00:39:53,602 --> 00:39:58,654
SPEAKER_0:  What it was before, I just think it gave people who hate his guts the opening to kind of slap him for...

00:39:59,010 --> 00:40:01,374
SPEAKER_0:  No reason, but I can see the strategy of it for sure.

00:40:01,666 --> 00:40:02,686
SPEAKER_0:  And I think that the...

00:40:03,170 --> 00:40:06,238
SPEAKER_0:  You know, the general idea that he's kind of pushing...

00:40:06,914 --> 00:40:10,078
SPEAKER_0:  right where the company had pushed left before. I think that there is actually...

00:40:10,434 --> 00:40:14,270
SPEAKER_0:  unilateral polarization right now in politics, at least with regard to social media.

00:40:14,786 --> 00:40:17,502
SPEAKER_0:  in which one side basically says the solution to...

00:40:18,082 --> 00:40:20,958
SPEAKER_0:  disinformation is to shut down free speech.

00:40:21,410 --> 00:40:29,726
SPEAKER_0:  from the other side and the other side is basically like people like me are saying the solution to disinformation is to let a thousand like I'd rather have people on the left

00:40:30,050 --> 00:40:32,254
SPEAKER_0:  also being able to put out stuff that I disagree with.

00:40:32,514 --> 00:40:36,318
SPEAKER_0:  than for there to be anybody who's sort of in charge of these social media platforms and using them.

00:40:36,738 --> 00:40:41,182
SPEAKER_0:  as editorial sites. I mean, they're plenty of... I'm not criticizing MSNBC for not putting on right-wing opinions. I mean, that's fine.

00:40:41,634 --> 00:40:42,782
SPEAKER_0:  ironic conservative side.

00:40:43,330 --> 00:40:48,030
SPEAKER_0:  We're not going to put up left-wing opinions on a wide variety of issues because we are a conservative site, but...

00:40:48,290 --> 00:40:49,726
SPEAKER_0:  if you pitch yourself as a platform.

00:40:50,050 --> 00:40:54,270
SPEAKER_0:  That's a different thing. If you pitch yourself as the town square, as Elon likes to call it.

00:40:54,658 --> 00:40:56,862
SPEAKER_0:  then I think Elon has a better idea of that than.

00:40:57,410 --> 00:40:59,774
SPEAKER_0:  Many of the former employees did, especially now that we have that.

00:41:00,002 --> 00:41:02,014
SPEAKER_0:  report from the intercept suggesting that there are.

00:41:02,242 --> 00:41:03,934
SPEAKER_0:  people from Twitter working with DHS to...

00:41:04,418 --> 00:41:06,270
SPEAKER_0:  to monitor quote unquote disinformation.

00:41:06,498 --> 00:41:08,286
SPEAKER_0:  and being rather vague about what this information meant.

00:41:08,738 --> 00:41:10,590
SPEAKER_1:  Yeah, I don't think activism has a place.

00:41:11,138 --> 00:41:13,950
SPEAKER_1:  in what is fundamentally an engineering company.

00:41:14,594 --> 00:41:15,742
SPEAKER_1:  that's building a platform.

00:41:16,802 --> 00:41:17,278
SPEAKER_1:  uh...

00:41:17,570 --> 00:41:21,566
SPEAKER_1:  Like the people inside the company should not be putting a thumb on the scale of what is and isn't allowed.

00:41:21,986 --> 00:41:28,638
SPEAKER_1:  You should create a mechanism for the people to decide what isn't allowed. Do you think Trump should have been removed?

00:41:29,666 --> 00:41:30,558
SPEAKER_1:  from Twitter.

00:41:31,106 --> 00:41:32,574
SPEAKER_1:  Should his account be restored?

00:41:32,834 --> 00:41:33,982
SPEAKER_0:  His account should be restored.

00:41:34,274 --> 00:41:38,494
SPEAKER_0:  And this is coming from somebody who really dislikes an enormous number of Donald Trump's tweets.

00:41:38,914 --> 00:41:41,310
SPEAKER_0:  Again, he's a very important

00:41:41,730 --> 00:41:42,750
SPEAKER_0:  political personage?

00:41:43,778 --> 00:41:44,510
SPEAKER_0:  Even if you weren't.

00:41:44,994 --> 00:41:48,894
SPEAKER_0:  I don't think that he should be banned from Twitter or Facebook in coordinated fashion.

00:41:49,826 --> 00:41:50,846
SPEAKER_0:  By the way, I hold that.

00:41:51,106 --> 00:41:53,950
SPEAKER_0:  opinion about people who I think are far worse than Donald Trump.

00:41:54,242 --> 00:41:54,878
SPEAKER_0:  Right, people.

00:41:55,842 --> 00:42:00,263
SPEAKER_0:  Everyone knows I'm not an Alex Jones guy. I don't like Alex Jones. I think Alex Jones... Uh-oh, I think Alex...

00:42:00,263 --> 00:42:01,310
SPEAKER_1:  Should be back on Twitter.

00:42:01,634 --> 00:42:03,454
SPEAKER_0:  I do actually, because I think that...

00:42:03,682 --> 00:42:05,150
SPEAKER_0:  There are plenty of people who are willing to-

00:42:05,730 --> 00:42:07,166
SPEAKER_0:  say that what he's saying.

00:42:07,522 --> 00:42:09,822
SPEAKER_0:  is wrong and I'm not a big fan of this idea that...

00:42:10,690 --> 00:42:11,198
SPEAKER_0:  because.

00:42:11,682 --> 00:42:12,766
SPEAKER_0:  people I disagree with.

00:42:13,058 --> 00:42:14,750
SPEAKER_0:  and people who personally tired by the way

00:42:15,298 --> 00:42:19,550
SPEAKER_0:  Alex Jones has been has said some things about me personally that I'm not real fond of.

00:42:20,034 --> 00:42:22,398
SPEAKER_0:  Well, we're not besties. No, it turns out. Yeah.

00:42:22,946 --> 00:42:25,886
SPEAKER_0:  All I've said is I don't really enjoy the show. She said some other stuff about...

00:42:26,242 --> 00:42:29,822
SPEAKER_0:  the Antichrist and such, but that's a bit of a different thing, I suppose.

00:42:30,306 --> 00:42:31,582
SPEAKER_0:  Yeah, even so.

00:42:31,874 --> 00:42:36,382
SPEAKER_0:  I'm just not a big fan of this idea. Like, I've defended people who have really gone after me.

00:42:36,674 --> 00:42:38,782
SPEAKER_0:  on a personal level have targeted me.

00:42:40,898 --> 00:42:42,430
SPEAKER_0:  The town square is online.

00:42:43,202 --> 00:42:45,406
SPEAKER_0:  Banning people from the town square is unpersoning them.

00:42:46,114 --> 00:42:50,622
SPEAKER_0:  Unless you violated a criminal statute, you should not be unpersoned in American society.

00:42:50,978 --> 00:42:51,838
SPEAKER_0:  as a general rule.

00:42:52,418 --> 00:42:54,206
SPEAKER_0:  That doesn't mean that companies that...

00:42:54,530 --> 00:42:57,246
SPEAKER_0:  are not platforms, don't have the ability to respond to you.

00:42:57,698 --> 00:42:58,078
SPEAKER_0:  I think.

00:42:58,914 --> 00:43:02,302
SPEAKER_0:  Adidas is right to terminate its contract with Kanye, for example.

00:43:02,722 --> 00:43:03,134
SPEAKER_0:  Worth a try.

00:43:03,650 --> 00:43:04,126
SPEAKER_0:  Um...

00:43:04,482 --> 00:43:05,438
SPEAKER_0:  You know, that's, but.

00:43:06,242 --> 00:43:06,718
SPEAKER_0:  Twitter, ain't.

00:43:06,946 --> 00:43:07,422
SPEAKER_0:  Adidas.

00:43:08,930 --> 00:43:09,918
SPEAKER_1:  So the way...

00:43:10,178 --> 00:43:15,710
SPEAKER_1:  Your stansong free speech to the degree it's possible to achieve on a platform like Twitter is

00:43:16,066 --> 00:43:19,934
SPEAKER_1:  You fight bad speech with more speech, with better speech.

00:43:20,706 --> 00:43:21,374
SPEAKER_1:  And that's.

00:43:22,466 --> 00:43:22,910
SPEAKER_1:  Um.

00:43:23,266 --> 00:43:25,694
SPEAKER_1:  So if Alex Jones and Trump is.

00:43:26,050 --> 00:43:27,102
SPEAKER_1:  Allow back on.

00:43:28,162 --> 00:43:32,254
SPEAKER_1:  in the coming months and years leading up to the 2024 election.

00:43:32,642 --> 00:43:34,238
SPEAKER_1:  You think that's gonna make for a better world?

00:43:34,690 --> 00:43:35,422
SPEAKER_1:  in the long term.

00:43:36,034 --> 00:43:36,574
SPEAKER_0:  I think that...

00:43:36,866 --> 00:43:43,518
SPEAKER_0:  on the principle that people should be allowed to do this and the alternative being a group of thought bosses telling us what we can and cannot see, yes.

00:43:43,874 --> 00:43:47,902
SPEAKER_0:  Do I think in the short term it's gonna mean a lot of things that I don't like very much? Sure, I mean...

00:43:48,258 --> 00:43:48,702
SPEAKER_0:  That's.

00:43:48,994 --> 00:43:52,158
SPEAKER_0:  Them's the cost of doing business, you know? Like, I think that one of the-

00:43:52,386 --> 00:43:55,166
SPEAKER_0:  One of the costs of freedom is people doing things that I don't particularly like.

00:43:55,874 --> 00:43:56,350
SPEAKER_0:  and

00:43:56,578 --> 00:43:58,622
SPEAKER_0:  I would prefer the freedom, with all the-

00:43:58,882 --> 00:44:01,246
SPEAKER_0:  with all the stuff I don't like, then not the freedom.

00:44:01,634 --> 00:44:02,782
SPEAKER_0:  Let me linger on the love.

00:44:02,946 --> 00:44:03,486
SPEAKER_1:  a little bit.

00:44:03,906 --> 00:44:10,622
SPEAKER_1:  You and a lot of people are pretty snarky on Twitter, sometimes to the point of mockery, derision, even-

00:44:11,202 --> 00:44:11,710
SPEAKER_1:  bit of.

00:44:12,002 --> 00:44:13,086
SPEAKER_1:  If I were to say...

00:44:13,442 --> 00:44:14,206
SPEAKER_1:  bad faith.

00:44:14,562 --> 00:44:15,966
SPEAKER_1:  in the kind of mockery.

00:44:16,482 --> 00:44:22,398
SPEAKER_1:  Um, and you see it as a war, like I disagree with both you and Elon on this. Elon sees Twitter as a war zone.

00:44:23,010 --> 00:44:25,374
SPEAKER_1:  or at least I saw it that way in the past.

00:44:26,306 --> 00:44:28,542
SPEAKER_1:  Have you ever considered being nicer on Twitter?

00:44:28,866 --> 00:44:32,638
SPEAKER_1:  Like, as a voice that a lot of people look up to.

00:44:33,058 --> 00:44:34,654
SPEAKER_1:  that if, if Ben Shapiro

00:44:35,554 --> 00:44:37,406
SPEAKER_1:  becomes a little bit more about love.

00:44:38,050 --> 00:44:39,518
SPEAKER_1:  that's gonna inspire a lot of people.

00:44:39,842 --> 00:44:42,206
SPEAKER_1:  Or no, is it just too fun for you?

00:44:42,338 --> 00:44:44,318
SPEAKER_0:  The answer is yes, sure it's occurred to me, like it-

00:44:44,898 --> 00:44:52,350
SPEAKER_0:  Let's put it this way, there are a lot of tweets that actually don't go out that I delete. I'll say that Twitter's new function, that 30 second function is a friend of mine.

00:44:52,642 --> 00:44:54,718
SPEAKER_0:  Every so often I'll tweet something and it'll...

00:44:55,074 --> 00:44:57,438
SPEAKER_0:  I'll think about it a second time. Do I need to say this? Probably not.

00:44:57,922 --> 00:44:58,974
SPEAKER_1:  Can you make a book?

00:44:59,842 --> 00:45:01,118
SPEAKER_1:  published.

00:45:01,442 --> 00:45:06,215
SPEAKER_1:  after you pass away of all the tweets that you didn't send.

00:45:06,215 --> 00:45:10,206
SPEAKER_0:  I don't know, my kids are still gonna be around, I hope. So that's the legacy.

00:45:10,434 --> 00:45:15,998
SPEAKER_0:  But yeah, I mean sure the answer is yes, and this is a good piece of what we would call an orthodox Judaism, Musser

00:45:16,386 --> 00:45:19,838
SPEAKER_0:  This is like, he's giving me a muster schmooze right now. This is like the kind of-

00:45:20,194 --> 00:45:23,774
SPEAKER_0:  be a better person and stuff. I agree with you. I agree with you. And yeah.

00:45:24,034 --> 00:45:26,462
SPEAKER_0:  I will say that Twitter is sometimes too much fun.

00:45:26,754 --> 00:45:27,486
SPEAKER_0:  I try to be.

00:45:27,970 --> 00:45:28,350
SPEAKER_0:  and

00:45:28,898 --> 00:45:29,502
SPEAKER_0:  I try to be.

00:45:29,730 --> 00:45:30,142
SPEAKER_0:  At least.

00:45:30,594 --> 00:45:32,542
SPEAKER_0:  if not even-handed, then...

00:45:33,186 --> 00:45:34,590
SPEAKER_0:  Equal opportunity in my derision.

00:45:35,138 --> 00:45:38,206
SPEAKER_0:  I remember that during the 2016 primaries, I used to...

00:45:38,466 --> 00:45:38,846
SPEAKER_0:  post.

00:45:39,138 --> 00:45:42,462
SPEAKER_0:  rather snarky tweets about virtually all of the candidates Republican.

00:45:42,690 --> 00:45:43,422
SPEAKER_0:  and Democrat.

00:45:43,810 --> 00:45:44,766
SPEAKER_0:  Alright, and uh...

00:45:45,026 --> 00:45:46,462
SPEAKER_0:  Every so often I'll still do.

00:45:46,850 --> 00:45:53,022
SPEAKER_0:  some of that. I do think actually the amount of snark on my Twitter feed has gone down fairly significantly. I think if you go back a couple of years it was probably a little more snarky.

00:45:53,410 --> 00:45:56,286
SPEAKER_0:  Today I'm trying to use it a little bit more in terms of strategy.

00:45:56,706 --> 00:45:59,326
SPEAKER_0:  to get out information. Now that doesn't mean I'm not gonna.

00:45:59,554 --> 00:46:00,542
SPEAKER_0:  make jokes about.

00:46:00,802 --> 00:46:01,470
SPEAKER_0:  For example.

00:46:02,274 --> 00:46:02,590
SPEAKER_0:  You know.

00:46:03,234 --> 00:46:05,406
SPEAKER_0:  Joe Biden. I will make jokes about Joe Biden.

00:46:05,890 --> 00:46:08,702
SPEAKER_0:  He's the President of the United States. Nobody else will mock him, so.

00:46:09,154 --> 00:46:11,550
SPEAKER_0:  The entire comedic establishment has decided they actually work for him.

00:46:12,130 --> 00:46:14,686
SPEAKER_1:  So the president of the United States, no matter who they are.

00:46:15,362 --> 00:46:16,062
SPEAKER_1:  get the snark.

00:46:16,418 --> 00:46:21,246
SPEAKER_0:  Yes, yes, and President Trump, I think, is fairly aware that he got this knock from me as well.

00:46:21,474 --> 00:46:25,599
SPEAKER_0:  When it comes to snarking the president, I'm not going to stop that. I think the president deserves to be snarked. So you're not afraid of attacks.

00:46:25,599 --> 00:46:26,014
SPEAKER_1:  Trump.

00:46:26,626 --> 00:46:28,670
SPEAKER_0:  No, I mean, I've done it before.

00:46:30,018 --> 00:46:33,342
SPEAKER_1:  Can you say what your favorite and least favorite?

00:46:33,794 --> 00:46:36,702
SPEAKER_1:  things are about President Trump and President Biden.

00:46:37,186 --> 00:46:41,726
SPEAKER_1:  one at a time. So maybe one thing that you can say super positive Trump Controversial

00:46:42,018 --> 00:46:43,838
SPEAKER_1:  and one thing super negative about Trump.

00:46:44,226 --> 00:46:52,510
SPEAKER_0:  Okay, so the super positive thing about Trump is that because he has no preconceived views that are establishmentarian, he's sometimes willing to go out of the box and do things.

00:46:52,770 --> 00:46:54,046
SPEAKER_0:  that haven't been tried before.

00:46:54,498 --> 00:46:59,070
SPEAKER_0:  And sometimes that works. I mean, the best example being the entire foreign policy establishment telling him.

00:46:59,394 --> 00:47:02,334
SPEAKER_0:  that he couldn't get a Middle Eastern deal done unless he centered.

00:47:02,562 --> 00:47:05,310
SPEAKER_0:  the Palestinian-Israeli conflict and instead he just went right around that.

00:47:05,634 --> 00:47:07,582
SPEAKER_0:  and ended up cutting a bunch of peace deals in the Middle East.

00:47:07,874 --> 00:47:14,878
SPEAKER_0:  or moving the embassy in Jerusalem, right? Sometimes he does stuff and it's really out of the box and it actually works. And that's kind of awesome in politics.

00:47:15,202 --> 00:47:15,870
SPEAKER_0:  And neat to see.

00:47:16,322 --> 00:47:18,046
SPEAKER_0:  The downside of Trump is that he has

00:47:18,402 --> 00:47:18,782
SPEAKER_0:  NO.

00:47:19,202 --> 00:47:20,158
SPEAKER_0:  capacity to

00:47:20,738 --> 00:47:22,430
SPEAKER_0:  to use any sort of.

00:47:23,426 --> 00:47:25,566
SPEAKER_0:  There's no filter between brain and mouth.

00:47:25,954 --> 00:47:30,334
SPEAKER_0:  Well, whatever happens in his brain is the thing that comes out of his mouth. I know a lot of people find that charming and wonderful.

00:47:30,658 --> 00:47:31,070
SPEAKER_0:  and

00:47:31,362 --> 00:47:35,326
SPEAKER_0:  from time to time, and it is very funny, but I don't think that it is a particularly-

00:47:35,714 --> 00:47:40,542
SPEAKER_0:  Excellent personal quality in a person who has as much responsibility as President Trump has. Middle name,

00:47:40,898 --> 00:47:42,398
SPEAKER_0:  damaging and bad things.

00:47:42,658 --> 00:47:44,318
SPEAKER_0:  on Twitter. I think that he

00:47:44,706 --> 00:47:45,150
SPEAKER_0:  Um...

00:47:45,602 --> 00:47:51,966
SPEAKER_0:  seems consumed in some ways by his own grievances, which is why you've seen him focusing in on election 2020 so much.

00:47:52,514 --> 00:47:58,078
SPEAKER_0:  And I think that that is very negative about President Trump. So I'm very grateful to President Trump as a conservative for many of the things that he did.

00:47:58,466 --> 00:48:01,822
SPEAKER_0:  I think that a lot of his personality issues are pretty severe.

00:48:02,914 --> 00:48:03,806
SPEAKER_1:  What about...

00:48:04,610 --> 00:48:05,054
SPEAKER_0:  Joe Biden.

00:48:05,666 --> 00:48:09,662
SPEAKER_0:  So I think that the thing that I like most about Joe Biden......

00:48:10,306 --> 00:48:11,326
SPEAKER_0:  I will say that.

00:48:12,002 --> 00:48:12,510
SPEAKER_0:  Biden.

00:48:13,186 --> 00:48:13,598
SPEAKER_0:  Two things.

00:48:13,922 --> 00:48:14,366
SPEAKER_0:  One.

00:48:14,594 --> 00:48:15,102
SPEAKER_0:  Biden.

00:48:15,714 --> 00:48:16,606
SPEAKER_0:  seems to be.

00:48:16,930 --> 00:48:17,758
SPEAKER_0:  A very good father.

00:48:18,754 --> 00:48:21,822
SPEAKER_0:  by all available evidence, right? There are a lot of people who are put out.

00:48:22,050 --> 00:48:27,998
SPEAKER_0:  you know, kind of tape of him talking to Hunter and Hunter's having trouble with drugs or whatever. And I keep listening to that tape and thinking...

00:48:29,186 --> 00:48:34,718
SPEAKER_0:  He seems like a really good dad. Like the stuff that he's saying to his son is stuff that, God forbid, if that were happening with my kid, I'd be saying to my kid.

00:48:35,458 --> 00:48:38,942
SPEAKER_0:  And so, you know, you can't help but feel for the guys. It's been incredibly difficult.

00:48:39,778 --> 00:48:42,494
SPEAKER_0:  go of it with his first wife and the death of...

00:48:42,722 --> 00:48:44,190
SPEAKER_0:  of members of his family.

00:48:44,482 --> 00:48:48,190
SPEAKER_0:  And then bowdying, I mean, like that kind of stuff obviously is deeply sympathetic and his is

00:48:48,642 --> 00:48:50,590
SPEAKER_0:  You know, he seems like a deeply sympathetic father.

00:48:50,946 --> 00:48:53,630
SPEAKER_0:  As far as his politics

00:48:54,146 --> 00:48:55,422
SPEAKER_0:  He seems like a slap on the back.

00:48:55,682 --> 00:48:57,054
SPEAKER_0:  you know, kind of guy and...

00:48:57,378 --> 00:49:01,726
SPEAKER_0:  I don't mind that. I think that's nice. So far as it goes, it's sort of an old school politics where...

00:49:01,954 --> 00:49:04,510
SPEAKER_0:  Things are done with handshake and personal relationships.

00:49:05,122 --> 00:49:08,766
SPEAKER_0:  The thing I don't like about him is I think sometimes that's really not genuine. I think that sometimes...

00:49:09,058 --> 00:49:12,062
SPEAKER_0:  I think that's his personal tendency, but I think sometimes...

00:49:12,418 --> 00:49:13,854
SPEAKER_0:  he allows the...

00:49:14,146 --> 00:49:18,814
SPEAKER_0:  prevailing winds of his party to carry him to incredibly radical places and then he just doubles down.

00:49:19,362 --> 00:49:20,766
SPEAKER_0:  on the radicalism.

00:49:21,186 --> 00:49:30,171
SPEAKER_0:  in some pretty disingenuous ways. And there I would cite the Independence Day speech or the Independence Hall speech, which I thought was truly one of the worst speeches I've seen a president give.

00:49:30,171 --> 00:49:31,671
SPEAKER_1:  So you don't think he's trying to be a unif-

00:49:31,671 --> 00:49:32,798
SPEAKER_0:  Fire in general. Not at all.

00:49:33,058 --> 00:49:35,294
SPEAKER_0:  I mean, that's what he was elected to do.

00:49:35,650 --> 00:49:39,198
SPEAKER_0:  He was elected to do two things, not be alive and be a unifier. Those were the two things.

00:49:39,586 --> 00:49:42,270
SPEAKER_0:  And when I say not be alive, I don't mean physically dead.

00:49:43,170 --> 00:49:49,534
SPEAKER_0:  This is where the scenario comes in. But what I do mean is that he was elected to not be particularly activist.

00:49:50,306 --> 00:49:53,598
SPEAKER_0:  Basically the mandate was don't be Trump. Be sane, don't be Trump.

00:49:53,826 --> 00:49:54,558
SPEAKER_0:  Calm everything down.

00:49:54,978 --> 00:49:58,174
SPEAKER_0:  And instead he got in, he's like, what if we spend seven trillion dollars? What if we...

00:49:58,562 --> 00:50:05,406
SPEAKER_0:  What if we pull out of Afghanistan without any sort of plan? What if I start labeling all of my political enemies, enemies of the republic? What if I start?

00:50:05,826 --> 00:50:07,006
SPEAKER_0:  bringing

00:50:07,330 --> 00:50:19,358
SPEAKER_0:  Dylan Mulvaney to the White House and talking about how it is a moral sin to prevent the genital mutilation of minors. I mean, like, this kind of stuff is very radical stuff. And this is not a president who has pursued a unifying agenda, which is why his approval rating…

00:50:19,650 --> 00:50:23,198
SPEAKER_0:  sank from 60% when he entered office to low 40s or high 30s today.

00:50:23,522 --> 00:50:30,718
SPEAKER_0:  Unlike President Trump, who never had a high approval rating, Trump came into office and he had like a 45% approval rating. And when he left office, he had about a 43% approval rating.

00:50:31,042 --> 00:50:36,254
SPEAKER_0:  and bounced around between 45 and 37, pretty much his entire presidency. Biden went from being a very popular guy coming in.

00:50:36,514 --> 00:50:40,958
SPEAKER_0:  So a very unpopular guy right now. And if you're Joe Biden, you should be looking in the mirror and wondering exactly why.

00:50:41,346 --> 00:50:45,566
SPEAKER_1:  Yeah. Do you think that pulling out from Afghanistan could be flipped as a pro for Biden in

00:50:45,858 --> 00:50:47,070
SPEAKER_1:  terms that he actually did it.

00:50:47,522 --> 00:50:50,302
SPEAKER_0:  I think it's gonna be almost impossible. I think the American people...

00:50:50,722 --> 00:50:54,174
SPEAKER_0:  are incredibly inconsistent about their own views on foreign policy.

00:50:55,074 --> 00:50:59,390
SPEAKER_0:  In other words, we like to be isolationist until it comes time for us to be defeated and humiliated.

00:50:59,810 --> 00:51:02,142
SPEAKER_0:  uh... when when that happens we cannot like it very much

00:51:03,170 --> 00:51:05,278
SPEAKER_1:  You mentioned Biden being a good father.

00:51:06,082 --> 00:51:11,070
SPEAKER_1:  Can you make the case for and against the Hunter Biden laptop story.

00:51:11,426 --> 00:51:15,102
SPEAKER_1:  for it being a big deal and against it being a big deal.

00:51:15,426 --> 00:51:19,134
SPEAKER_0:  Sure, so the case four being a big deal is basically twofold. One is

00:51:19,394 --> 00:51:21,406
SPEAKER_0:  that it is clearly relevant if the

00:51:21,634 --> 00:51:22,462
SPEAKER_0:  President's son.

00:51:22,882 --> 00:51:30,686
SPEAKER_0:  is running around to foreign countries picking up bags of cash because his last name is Biden while his father is vice president of the United States.

00:51:31,106 --> 00:51:33,534
SPEAKER_0:  and it raises questions as to influence peddling.

00:51:34,018 --> 00:51:41,790
SPEAKER_0:  for either the vice president or the former vice president using political connections. Did he make any money? Who was the big guy? Right, all these open questions. Obviously implicate

00:51:42,338 --> 00:51:42,910
SPEAKER_0:  Indeed.

00:51:43,234 --> 00:51:44,862
SPEAKER_0:  questions to be asked and then.

00:51:45,090 --> 00:51:48,958
SPEAKER_0:  The secondary reason that the story is big is actually because of the reaction of the story, the banning of the story.

00:51:49,378 --> 00:51:53,854
SPEAKER_0:  is in and of itself a major story. If there's any story that implicates a presidential-

00:51:54,178 --> 00:51:57,022
SPEAKER_0:  candidate in the last month of an election and there is a media blackout.

00:51:57,826 --> 00:52:03,582
SPEAKER_0:  including a social media blackout that obviously raises some very serious questions about informational flow and dissemination in the United States.

00:52:03,778 --> 00:52:04,542
SPEAKER_1:  So no matter how.

00:52:05,218 --> 00:52:09,022
SPEAKER_1:  how big of a deal the story is, it is a big deal that there's a censorship of any.

00:52:09,346 --> 00:52:13,950
SPEAKER_0:  relevant story. When there's a coordinated collusive blackout, yeah that's a serious and major problem.

00:52:14,338 --> 00:52:21,342
SPEAKER_0:  So those are the two reasons why it would be a big story. The two reasons, a reason why it would not be a big story perhaps is...

00:52:21,602 --> 00:52:22,046
SPEAKER_0:  If.

00:52:22,338 --> 00:52:23,038
SPEAKER_0:  It turns out...

00:52:23,394 --> 00:52:26,750
SPEAKER_0:  And we don't really know this yet, but let's say that that Hunter Biden was basically.

00:52:27,298 --> 00:52:29,310
SPEAKER_0:  off on his own doing what he was doing.

00:52:29,666 --> 00:52:38,814
SPEAKER_0:  being a derelict or drug addict or acting badly. And his dad had nothing to do with it and Joe was telling the truth. But the problem is we never actually got those questions answered.

00:52:39,138 --> 00:52:42,814
SPEAKER_0:  If it had turned out to be nothing of a story, the nice thing about stories that turn out to be nothing is that

00:52:43,042 --> 00:52:44,382
SPEAKER_0:  After they turn out to be nothing, they're nothing.

00:52:44,866 --> 00:52:46,302
SPEAKER_0:  the biggest problem with this story.

00:52:46,530 --> 00:52:48,350
SPEAKER_0:  is that it wasn't allowed to take the normal life.

00:52:49,154 --> 00:52:50,430
SPEAKER_0:  cycle of a story which is

00:52:50,818 --> 00:52:54,462
SPEAKER_0:  Original story breaks. Follow-on questions are asked. Follow-on questions are answered.

00:52:54,850 --> 00:52:56,926
SPEAKER_0:  Story is either now a big story or into nothing.

00:52:57,506 --> 00:52:58,430
SPEAKER_0:  One when a sp-

00:52:58,786 --> 00:53:01,982
SPEAKER_0:  The life cycle of the story is cut off right at the very beginning, right when it's born.

00:53:02,338 --> 00:53:07,678
SPEAKER_0:  then that allows you to speculate in any direction you want. You can speculate, it means nothing. It's nonsense, it's Russian.

00:53:07,906 --> 00:53:15,870
SPEAKER_0:  It's a Russian laptop. It's disinformation. Or on the other hand, this means that Joe Biden was personally calling Hunter and telling him to pick up a sack of cash over in Beijing.

00:53:16,194 --> 00:53:18,558
SPEAKER_0:  and then he became president and he's influence peddling. So.

00:53:18,786 --> 00:53:23,422
SPEAKER_0:  This is why it's important to allow these stories to go forward. So this is why actually the bigger story for the moment...

00:53:23,778 --> 00:53:27,806
SPEAKER_0:  is not the laptop, it's the reaction to the laptop because it cut off that life cycle of the story.

00:53:28,386 --> 00:53:29,278
SPEAKER_0:  And then, you know.

00:53:29,698 --> 00:53:36,446
SPEAKER_0:  At some point, I would assume that there will be some follow on questions that are actually answered. I mean, the House is pledging, if it goes Republican, to investigate all of this.

00:53:36,834 --> 00:53:39,294
SPEAKER_0:  Again, I wouldn't be supremely surprised if it turns out that

00:53:40,418 --> 00:53:41,278
SPEAKER_0:  There was no direct.

00:53:41,506 --> 00:53:42,078
SPEAKER_0:  involvement.

00:53:42,434 --> 00:53:46,366
SPEAKER_0:  of Joe in this sort of stuff, because it turns out, as I said before, that all of politics is V.

00:53:47,010 --> 00:53:51,166
SPEAKER_0:  And this is always the story with half the scandals that you see is that everybody assumes that there's some sort of

00:53:51,394 --> 00:53:51,934
SPEAKER_0:  deepen.

00:53:52,578 --> 00:53:53,246
SPEAKER_0:  abiding.

00:53:53,506 --> 00:53:57,342
SPEAKER_0:  clever plan that some politician is implementing it and then you look at it and it turns out that then all

00:53:58,114 --> 00:53:59,806
SPEAKER_0:  It's just something dumb, right? This sort of-

00:54:00,258 --> 00:54:03,550
SPEAKER_0:  Perfect example of this, you know, President Trump with the classified documents in Mar-a-Lago.

00:54:03,842 --> 00:54:04,158
SPEAKER_0:  So.

00:54:04,418 --> 00:54:08,926
SPEAKER_0:  People on the left, it's probably nuclear codes. Probably he's taking secret documents and selling them to the Russians or the Chinese.

00:54:09,410 --> 00:54:10,366
SPEAKER_0:  And the real-

00:54:10,722 --> 00:54:15,454
SPEAKER_0:  Most obvious explanation is Trump looked at the papers and he said, I like these papers. Then he just decided to keep them.

00:54:16,130 --> 00:54:22,366
SPEAKER_0:  And then people came to him and said, Mr. President, you're not allowed to keep those papers. He said, who are those people? I don't care about what they have to say. I'm putting them in the other room in a box.

00:54:23,266 --> 00:54:24,702
SPEAKER_0:  Like, which is my...

00:54:25,634 --> 00:54:29,310
SPEAKER_0:  It is highly likely that that is what happened. And it's very disappointing to people, I think.

00:54:29,666 --> 00:54:30,718
SPEAKER_0:  when they realize it.

00:54:31,074 --> 00:54:39,550
SPEAKER_0:  The human brain, I mean, you know this better than I do, but the human brain is built to find patterns, right? It's what we like to do. We like to find plans and patterns because this is how we survived in the wild, is you found a plan, you found a pattern.

00:54:40,322 --> 00:54:41,534
SPEAKER_0:  He cracked the code of the universe.

00:54:41,762 --> 00:54:43,166
SPEAKER_0:  When it comes to politics, the-

00:54:43,490 --> 00:54:45,054
SPEAKER_0:  conspiracy theories that we see so often.

00:54:45,314 --> 00:54:47,294
SPEAKER_0:  It's largely because we're seeing inexplicable events.

00:54:47,970 --> 00:54:52,958
SPEAKER_0:  Unless you just assume everyone's a moron. If you assume that there's a lot of stupidity going on, everything becomes quickly explicable.

00:54:53,314 --> 00:54:54,430
SPEAKER_0:  If you assume that

00:54:54,786 --> 00:55:01,630
SPEAKER_0:  that there must be some rationale behind it. You have to come up with increasingly convoluted conspiracy theories to explain just why people are acting the way that they're acting.

00:55:02,146 --> 00:55:03,230
SPEAKER_0:  And I find that-

00:55:03,618 --> 00:55:06,974
SPEAKER_0:  I won't say 100% of the time, but 94% of the time.

00:55:07,426 --> 00:55:08,126
SPEAKER_0:  The, the...

00:55:08,610 --> 00:55:10,238
SPEAKER_0:  conspiracy theory turns out just to be.

00:55:10,498 --> 00:55:10,878
SPEAKER_0:  people.

00:55:11,234 --> 00:55:15,230
SPEAKER_0:  being dumb and then other people reacting in dumb ways to the original people being dumb.

00:55:15,618 --> 00:55:16,414
SPEAKER_1:  But it's also...

00:55:16,866 --> 00:55:18,686
SPEAKER_1:  To me in that same way very possible.

00:55:19,234 --> 00:55:21,790
SPEAKER_1:  uh... very likely that uh... harbiden

00:55:22,402 --> 00:55:26,206
SPEAKER_1:  Hunter Biden getting money in Ukraine, I guess, for consulting and all that kind of stuff.

00:55:26,594 --> 00:55:28,446
SPEAKER_1:  is a nothing burger, is a-

00:55:28,706 --> 00:55:34,353
SPEAKER_1:  He's qualified, he's getting money as he should. There's a lot of influence peddling in general in terms that's not...

00:55:34,353 --> 00:55:34,942
SPEAKER_0:  corrupt.

00:55:35,170 --> 00:55:38,014
SPEAKER_0:  The most obvious explanation there probably is that he was

00:55:38,882 --> 00:55:41,982
SPEAKER_0:  Fake influence peddling, meaning he wants Ukraine, and he's like, guess what, my dad's Joe.

00:55:42,530 --> 00:55:43,166
SPEAKER_0:  And don't let go.

00:55:43,522 --> 00:55:52,735
SPEAKER_0:  You don't have any qualifications in oil and natural gas, and you don't really have a great resume. But your dad is Joe, and then that was kind of the end of it. They gave him a bag of cash hoping he would do something. He never did anything. And are making this sound-

00:55:52,735 --> 00:56:01,342
SPEAKER_1:  worse than it is. I think that in general consulting is done in that way. I agree with you.

00:56:01,602 --> 00:56:14,430
SPEAKER_1:  and this is an illustration of corruption. If you can criticize consulting, which I would, which they're basically not providing, you look at a resume and who's who. Like if you went to Harvard, I can criticize the same.

00:56:14,658 --> 00:56:17,278
SPEAKER_1:  If you have Harvard on your resume,

00:56:17,890 --> 00:56:20,958
SPEAKER_1:  You're more likely to be hired as a consultant. Maybe there's a...

00:56:21,186 --> 00:56:30,423
SPEAKER_1:  network there of people that you know, and you hire them in that same way. If your last name is Biden, if your last name, there's a lot of last names that sound pretty good at it, right? For sure, for sure. For sure.

00:56:30,423 --> 00:56:36,446
SPEAKER_0:  And Hunter Biden admitted that much, by the way, right? In an open interview, he was like, if your last name weren't Biden, wouldn't you have got that job? And he's like, probably not.

00:56:37,154 --> 00:56:38,302
SPEAKER_0:  And you're right.

00:56:38,690 --> 00:56:39,550
SPEAKER_0:  I agree with you.

00:56:39,682 --> 00:56:43,870
SPEAKER_1:  It's not like he's getting a ridiculous amount of money. He was getting like a pretty standard.

00:56:44,098 --> 00:56:54,046
SPEAKER_1:  consulting kind of money, which also would criticize because they get a ridiculous amount of money. But I, sort of even to push back on the life cycle or to steal man the side.

00:56:55,010 --> 00:57:01,246
SPEAKER_1:  that was concerned about the Hunterbine laptop story. I don't know if there is a natural life cycle of a story.

00:57:01,602 --> 00:57:04,222
SPEAKER_1:  because there's something about the virality of the internet.

00:57:04,834 --> 00:57:07,038
SPEAKER_1:  that we can't predict that a story can just.

00:57:07,810 --> 00:57:10,686
SPEAKER_1:  take hold and the conspiracy around it.

00:57:11,266 --> 00:57:14,590
SPEAKER_1:  builds, especially around politics, where the interpretation

00:57:15,234 --> 00:57:19,518
SPEAKER_1:  some popular sexy interpretation of a story that might not be connected to reality at all.

00:57:20,002 --> 00:57:20,894
SPEAKER_1:  will become viral.

00:57:21,250 --> 00:57:24,286
SPEAKER_1:  And that, from Facebook's perspective, is probably what they're worried about.

00:57:24,578 --> 00:57:25,150
SPEAKER_1:  is uh

00:57:25,762 --> 00:57:26,206
SPEAKER_1:  Uh...

00:57:26,434 --> 00:57:28,414
SPEAKER_1:  organized misinformation campaign.

00:57:29,570 --> 00:57:31,006
SPEAKER_1:  makes up a sexy story.

00:57:31,266 --> 00:57:32,606
SPEAKER_1:  or sexy interpretation.

00:57:33,026 --> 00:57:33,982
SPEAKER_1:  of the...

00:57:34,242 --> 00:57:35,806
SPEAKER_1:  of the vague story that we have.

00:57:36,322 --> 00:57:38,174
SPEAKER_1:  and that has an influence.

00:57:38,466 --> 00:57:42,206
SPEAKER_0:  on the populace. I mean, I think that's true, but I think the question becomes who's the great adjudicator here, and he's right about that.

00:57:42,466 --> 00:57:45,886
SPEAKER_0:  Right, who adjudicates when the story ought to be allowed to go through?

00:57:46,338 --> 00:57:49,342
SPEAKER_0:  even a bad life cycle or allowed to go viral.

00:57:49,634 --> 00:57:55,326
SPEAKER_0:  as opposed to not. Now it's one thing if you wanna say, okay, we can spot the Russian accounts that are actually promoting this stuff, they belong to the Russian government, gotta shut that down.

00:57:55,618 --> 00:58:01,726
SPEAKER_0:  I think everybody agrees. This is actually one of the slides that's happened linguistically that I really object to, is the slide between

00:58:02,114 --> 00:58:03,518
SPEAKER_0:  disinformation and misinformation.

00:58:03,906 --> 00:58:09,150
SPEAKER_0:  You notice there is this evolution. In 2017 there's a lot of talk about disinformation. It was Russian disinformation. The Russians were putting out...

00:58:09,378 --> 00:58:12,510
SPEAKER_0:  Deliberately false information in order to skew election results was the accusation.

00:58:12,898 --> 00:58:14,686
SPEAKER_0:  And then people started using disinformation.

00:58:14,946 --> 00:58:20,478
SPEAKER_0:  or misinformation. And misinformation is either mistaken information or information that is quote unquote out of context.

00:58:20,802 --> 00:58:22,846
SPEAKER_0:  that becomes very subjective very quickly as to what

00:58:23,202 --> 00:58:24,222
SPEAKER_0:  Out of context means...

00:58:24,578 --> 00:58:29,726
SPEAKER_0:  And it doesn't necessarily have to be from a foreign source, it can be from a domestic source, right? It could be somebody misinterpreting something here.

00:58:29,954 --> 00:58:33,246
SPEAKER_0:  It could be somebody interpreting something correctly, but PolitiFact thinks that it's out of context.

00:58:33,602 --> 00:58:35,870
SPEAKER_0:  And that sort of stuff gets very murky very quickly.

00:58:36,194 --> 00:58:40,606
SPEAKER_0:  And so I'm deeply uncomfortable with the idea that Facebook, I mean, Zuckerberg was on.

00:58:40,994 --> 00:58:42,686
SPEAKER_0:  with Rogan and talking about how.

00:58:43,074 --> 00:58:45,502
SPEAKER_0:  You know, the FBI had basically set look out for.

00:58:45,730 --> 00:58:52,254
SPEAKER_0:  Russian interference in the election and then all of these people were out there saying that the laptop was Russian disinformation so he basically shut it down.

00:58:52,610 --> 00:58:56,638
SPEAKER_0:  That sort of stuff is frightening, especially because it wasn't Russian disinformation. I mean, the laptop was real.

00:58:57,058 --> 00:58:58,782
SPEAKER_0:  And so the fact that...

00:58:59,362 --> 00:59:00,766
SPEAKER_0:  You have people who...

00:59:01,442 --> 00:59:02,046
SPEAKER_0:  seem to-

00:59:02,466 --> 00:59:03,614
SPEAKER_0:  Let's put this way, it seems as though.

00:59:04,098 --> 00:59:09,022
SPEAKER_0:  Maybe this is wrong. It seems as though when a story gets killed preemptively like this, it is almost universally

00:59:09,346 --> 00:59:11,742
SPEAKER_0:  A story that negatively affects one side of the political aisle.

00:59:12,386 --> 00:59:14,590
SPEAKER_0:  I can't remember the last time there was a story.

00:59:15,138 --> 00:59:17,758
SPEAKER_0:  on the right that was disinformation or misinformation.

00:59:18,082 --> 00:59:24,958
SPEAKER_0:  where social media stepped in and they went, we cannot have this, this cannot be distributed. We're going to all colludes that this information is not distributed.

00:59:25,282 --> 00:59:27,710
SPEAKER_0:  Maybe in response to the story being proved false, it gets taken down.

00:59:28,514 --> 00:59:34,974
SPEAKER_0:  What made the Hunter Biden thing so amazing is that it wasn't really even a response to anything. It was like the story got posted, there were no actual doubts expressed.

00:59:35,938 --> 00:59:41,662
SPEAKER_0:  as to the verified falsity of the story. It was just supposition that it had to be false and everybody jumped in. So I think.

00:59:41,890 --> 00:59:44,126
SPEAKER_0:  That confirmed a lot of the conspiracy theories people had about...

00:59:44,418 --> 00:59:45,694
SPEAKER_0:  about social media and how it works.

00:59:46,306 --> 00:59:46,942
SPEAKER_1:  Yeah, so...

00:59:47,362 --> 00:59:53,630
SPEAKER_1:  If the reason you want to slow down the viral spread of a thing is at all grounded in

00:59:54,082 --> 00:59:54,846
SPEAKER_1:  Partisanship.

00:59:55,490 --> 00:59:56,062
SPEAKER_1:  That's a problem.

00:59:56,802 --> 00:59:59,934
SPEAKER_1:  Like you should be very honest with yourself and ask yourself that question.

01:00:00,226 --> 01:00:03,678
SPEAKER_1:  Is it because I'm on the left or on the right that I want to slow this down?

01:00:04,162 --> 01:00:05,566
SPEAKER_1:  Versus is it hate?

01:00:06,786 --> 01:00:09,054
SPEAKER_1:  uh, bipartisan hate speech.

01:00:10,114 --> 01:00:13,246
SPEAKER_1:  Right, so that's, it's really tricky.

01:00:13,570 --> 01:00:22,622
SPEAKER_1:  But I like you I'm very uncomfortable in general with any kind of slowing down with any kind of censorship But if if there's something like a conspiracy theory that spreads hate you

01:00:23,298 --> 01:00:24,254
SPEAKER_1:  that becomes viral.

01:00:25,602 --> 01:00:26,174
SPEAKER_1:  Um...

01:00:26,530 --> 01:00:30,142
SPEAKER_1:  I still lean to let that conspiracy theory spread.

01:00:31,010 --> 01:00:33,758
SPEAKER_1:  Because the alternative is dangerous. watch another

01:00:34,018 --> 01:00:37,406
SPEAKER_0:  It's sort of like the ring of power, right? Like everybody wants the ring, because with the ring you can...

01:00:37,634 --> 01:00:40,318
SPEAKER_0:  stop the bad guys from going forward but it turns out that the ring

01:00:40,930 --> 01:00:43,326
SPEAKER_0:  gives you enormous power, and that power can be used in the wrong ways too.

01:00:44,482 --> 01:00:46,462
SPEAKER_1:  You had the daily wire?

01:00:46,690 --> 01:00:47,134
SPEAKER_1:  which...

01:00:47,778 --> 01:00:48,702
SPEAKER_1:  I'm a member of.

01:00:48,962 --> 01:00:51,587
SPEAKER_0:  Uh, I appreciate that. Thank you.

01:00:51,587 --> 01:00:58,814
SPEAKER_1:  I recommend everybody sign up to it. It should be part of your regular diet, whether you're on the left and the right, the far left or the far right, everybody should be part of your regular diet.

01:00:59,298 --> 01:01:00,414
SPEAKER_1:  Okay, that said...

01:01:01,122 --> 01:01:04,382
SPEAKER_1:  Do you worry about the audience capture aspect of it?

01:01:04,610 --> 01:01:07,070
SPEAKER_1:  because it is a platform for conservatives.

01:01:07,778 --> 01:01:08,350
SPEAKER_1:  and

01:01:08,898 --> 01:01:10,558
SPEAKER_1:  You have a powerful voice on there.

01:01:11,682 --> 01:01:12,190
SPEAKER_1:  very

01:01:12,450 --> 01:01:15,582
SPEAKER_1:  It might be difficult for you to go against.

01:01:16,194 --> 01:01:17,630
SPEAKER_1:  the talking points are.

01:01:17,954 --> 01:01:21,726
SPEAKER_1:  against the stream of ideas that is usually connected to.

01:01:22,274 --> 01:01:23,134
SPEAKER_1:  conservative thought.

01:01:23,746 --> 01:01:24,670
SPEAKER_1:  Do you worry about that?

01:01:25,282 --> 01:01:31,070
SPEAKER_0:  I mean, the audience would obviously be upset with me and would have a right to be upset with me if I suddenly flipped all my positions on a dime.

01:01:31,618 --> 01:01:36,510
SPEAKER_0:  I have enough faith in my audience that I can say things that I think are true and that may disagree with the audience.

01:01:37,154 --> 01:01:42,718
SPEAKER_0:  you know, on a fairly regular basis, I would say. But they understand that on the deeper principle, we're on the same side.

01:01:43,170 --> 01:01:44,478
SPEAKER_0:  of the Alice, I hope that much.

01:01:44,802 --> 01:01:45,502
SPEAKER_0:  from the audience.

01:01:45,762 --> 01:01:52,958
SPEAKER_0:  That's also why we provide a number of different views on the platform, many of which I disagree with but are sort of within the generalized range of conservative thought.

01:01:53,538 --> 01:01:54,430
SPEAKER_0:  That I-

01:01:55,234 --> 01:02:02,974
SPEAKER_0:  It's something I do have to think about every day though, yeah. I mean, you have to think about like, am I saying this because I'm afraid of taking off my audience? Or am I saying this because I actually...

01:02:03,330 --> 01:02:03,998
SPEAKER_0:  Believe this.

01:02:04,674 --> 01:02:05,022
SPEAKER_0:  and

01:02:05,282 --> 01:02:05,822
SPEAKER_0:  Yeah, that's it.

01:02:06,402 --> 01:02:09,150
SPEAKER_0:  That's a delicate dance a little bit. You have to be sort of honest with yourself.

01:02:10,530 --> 01:02:11,742
SPEAKER_1:  Yeah, somebody like, um...

01:02:12,450 --> 01:02:14,270
SPEAKER_1:  Sam Harris is pretty good at this.

01:02:14,786 --> 01:02:20,350
SPEAKER_1:  at fighting, at saying the most outrageous thing that he knows. He almost leans into it.

01:02:20,994 --> 01:02:23,518
SPEAKER_1:  He knows he'll piss off a lot of his audience.

01:02:23,906 --> 01:02:26,014
SPEAKER_1:  uh... sometimes you'll have to test the system

01:02:26,882 --> 01:02:35,166
SPEAKER_1:  is like if you feel you almost exaggerate your feelings just to make sure to send a signal to the audience that you're not captured by them.

01:02:36,098 --> 01:02:38,110
SPEAKER_1:  uh... so speaking of people disagree with

01:02:39,682 --> 01:02:45,630
SPEAKER_1:  What is your favorite thing about Candice Owens and what is one thing you disagree with her on?

01:02:46,306 --> 01:02:50,046
SPEAKER_0:  Well, my hair thing about Candice is that she will say things that nobody else will say.

01:02:50,690 --> 01:03:01,694
SPEAKER_0:  My least favorite thing about Candace is that she will say things that nobody else will say. Um, yeah. I mean, listen, she says things that are audacious and I think need to be said sometimes. I think that she is morally wrong.

01:03:02,274 --> 01:03:04,670
SPEAKER_0:  I think the way she responded to Kanye, I've said this clearly.

01:03:04,994 --> 01:03:10,398
SPEAKER_0:  was dead wrong and morally wrong. What was her response? Her original response was that she

01:03:10,818 --> 01:03:13,438
SPEAKER_0:  proffered confusion of what Ye was actually talking.

01:03:13,698 --> 01:03:14,046
SPEAKER_0:  about.

01:03:14,594 --> 01:03:22,590
SPEAKER_0:  And then she was defending her friend. I wish that the way that she had responded was by saying, he's my friend and also he said something bad and anti-Semitic.

01:03:23,490 --> 01:03:24,382
SPEAKER_0:  I wish that you'd said that.

01:03:25,378 --> 01:03:26,206
SPEAKER_0:  So right away.

01:03:26,658 --> 01:03:27,038
SPEAKER_0:  Right away.

01:03:27,746 --> 01:03:28,126
SPEAKER_1:  Yeah.

01:03:28,354 --> 01:03:29,598
SPEAKER_1:  I think you can also.

01:03:30,562 --> 01:03:37,566
SPEAKER_1:  This is an interesting human thing. You can be friends with people that you disagree with and you can be friends with people that actually say hateful stuff.

01:03:37,922 --> 01:03:39,518
SPEAKER_1:  and one of the ways to help.

01:03:39,874 --> 01:03:42,302
SPEAKER_1:  alleviate hate is being friends with people that's...

01:03:42,882 --> 01:03:44,318
SPEAKER_1:  that say hateful things.

01:03:44,514 --> 01:03:45,438
SPEAKER_0:  Yeah, and then calling them out.

01:03:45,922 --> 01:03:48,286
SPEAKER_0:  on a personal level when they do say.

01:03:49,250 --> 01:03:50,375
SPEAKER_0:  wrong or hateful things.

01:03:50,375 --> 01:03:52,734
SPEAKER_1:  a place of love and respect and privately.

01:03:53,154 --> 01:03:56,702
SPEAKER_0:  privately is also a big thing, right? I mean, like the public demand for...

01:03:56,930 --> 01:03:58,174
SPEAKER_0:  you know, denunciation.

01:03:58,562 --> 01:03:59,678
SPEAKER_0:  from friends to friends.

01:04:00,066 --> 01:04:01,182
SPEAKER_0:  I is is.

01:04:01,570 --> 01:04:02,334
SPEAKER_0:  Difficultin'.

01:04:02,658 --> 01:04:06,430
SPEAKER_0:  I certainly have compassion for Candace given the fact that she's so close with you.

01:04:07,234 --> 01:04:09,246
SPEAKER_1:  Yeah, it breaks my heart sometimes, the public.

01:04:09,570 --> 01:04:13,310
SPEAKER_1:  the public fights between friends and broken friendships. I've seen quite a few.

01:04:13,794 --> 01:04:14,398
SPEAKER_1:  friendships.

01:04:14,914 --> 01:04:16,542
SPEAKER_1:  publicly break over COVID.

01:04:17,442 --> 01:04:21,790
SPEAKER_1:  COVID made people behave their worst in many cases, which.

01:04:22,018 --> 01:04:22,462
SPEAKER_1:  dumb

01:04:24,130 --> 01:04:25,342
SPEAKER_1:  Yeah, it breaks my heart a little bit.

01:04:26,146 --> 01:04:28,254
SPEAKER_1:  because like the human connection.

01:04:29,090 --> 01:04:34,398
SPEAKER_1:  is a prerequisite for effective debate and discussion and battles over ideas.

01:04:35,426 --> 01:04:40,350
SPEAKER_1:  Has there been any argument from the opposite political aisle that has made you change your mind about something?

01:04:41,762 --> 01:04:43,166
SPEAKER_1:  if you if you look back

01:04:45,058 --> 01:04:45,598
SPEAKER_0:  So.

01:04:46,178 --> 01:04:47,198
SPEAKER_0:  I will say that the...

01:04:50,018 --> 01:04:52,606
SPEAKER_0:  I'm thinking it through because I think that...

01:04:53,122 --> 01:04:55,326
SPEAKER_0:  My view's probably on foreign policy more somewhat.

01:04:56,258 --> 01:04:58,462
SPEAKER_0:  I would say that I was much more interventionist when I was younger.

01:04:59,010 --> 01:05:00,574
SPEAKER_0:  I'm significantly less interventionist now.

01:05:01,218 --> 01:05:02,302
SPEAKER_0:  I'd probably put myself. Poor soul.

01:05:02,818 --> 01:05:05,982
SPEAKER_0:  Sure, I was a big backer of the Iraq war, I think now in retrospect.

01:05:06,498 --> 01:05:09,694
SPEAKER_0:  I might not be a backer of the Iraq war if the same situation arose again.

01:05:10,562 --> 01:05:15,294
SPEAKER_0:  based on the amount of evidence that had been presented or based on the sort of...

01:05:16,418 --> 01:05:18,238
SPEAKER_0:  willingness of the american public to go it

01:05:19,074 --> 01:05:25,406
SPEAKER_0:  If you're going to get involved in a war, you have to know what the end point looks like, and you have to know what the American people really are willing to bear, and the American people are not willing to bear it.

01:05:26,242 --> 01:05:26,782
SPEAKER_0:  Open ended.

01:05:27,266 --> 01:05:28,062
SPEAKER_0:  occupations.

01:05:28,450 --> 01:05:31,870
SPEAKER_0:  And so knowing that, you have to consider that going in.

01:05:32,546 --> 01:05:34,910
SPEAKER_0:  So on foreign policy, I become a lot more of a...

01:05:35,394 --> 01:05:36,766
SPEAKER_0:  It's almost Henry Kissinger Realist.

01:05:37,346 --> 01:05:38,398
SPEAKER_0:  in some ways.

01:05:38,946 --> 01:05:40,958
SPEAKER_0:  Alright, and when it comes to...

01:05:41,570 --> 01:05:42,078
SPEAKER_0:  Um...

01:05:42,466 --> 01:05:44,862
SPEAKER_0:  Social policy, I would say that I'm fairly...

01:05:45,538 --> 01:05:46,078
SPEAKER_0:  strong.

01:05:46,466 --> 01:05:49,182
SPEAKER_0:  where I was, I may have become.

01:05:49,602 --> 01:05:55,870
SPEAKER_0:  slightly convinced actually by more the conservative side of the aisle on things like drug legalization. I think when I was younger I was much more pro drug legalization.

01:05:56,514 --> 01:05:59,710
SPEAKER_0:  than I am now, at least on the local level. On a federal level, I think the federal government.

01:06:00,450 --> 01:06:01,278
SPEAKER_0:  can't really do much.

01:06:01,538 --> 01:06:04,926
SPEAKER_0:  other than close the borders with regard to fentanyl trafficking, for example, but

01:06:05,218 --> 01:06:08,702
SPEAKER_0:  When it comes to how drugs were in local communities, you can see how drugs were in local communities pretty easily.

01:06:09,090 --> 01:06:12,465
SPEAKER_1:  Which is weird because I saw you smoke a joint right before.

01:06:12,465 --> 01:06:15,966
SPEAKER_0:  of those conversations. It's my biggest thing. I mean, I try to keep that secret. All right.

01:06:16,322 --> 01:06:18,782
SPEAKER_1:  Uh, well, that's interesting about intervention.

01:06:19,586 --> 01:06:22,206
SPEAKER_1:  Can you comment about the war in Ukraine?

01:06:23,074 --> 01:06:24,670
SPEAKER_1:  It's a deeply personal thing.

01:06:25,090 --> 01:06:26,238
SPEAKER_1:  Um, but I think.

01:06:26,530 --> 01:06:30,590
SPEAKER_1:  you're able to look at it from a geopolitics perspective. What is the role of the United States?

01:06:30,850 --> 01:06:33,438
SPEAKER_1:  in this conflict, before the conflict, during the conflict.

01:06:33,922 --> 01:06:35,934
SPEAKER_1:  and right now in helping.

01:06:36,642 --> 01:06:37,502
SPEAKER_1:  Achieve peace.

01:06:38,050 --> 01:06:40,190
SPEAKER_0:  I think before the conflict, the big problem is that...

01:06:40,482 --> 01:06:41,726
SPEAKER_0:  the West took.

01:06:42,626 --> 01:06:55,486
SPEAKER_0:  almost the worst possible view, which was encourage Ukraine to keep trying to join NATO and the EU, but don't let them in. And so what that does is it achieves the purpose of getting Russia really, really, really ticked off and feeling threatened, but also does not give.

01:06:55,906 --> 01:07:09,694
SPEAKER_0:  any of the protections of NATO or the EU to Ukraine. I mean, Zelensky is on film when he was a comedy actor, making that exact joke, right? He has Merkel on the other line, and she's like, oh, welcome to NATO. And he's like, great. Is this Ukraine on the line?

01:07:10,082 --> 01:07:11,998
SPEAKER_0:  And... oops!

01:07:12,354 --> 01:07:20,286
SPEAKER_0:  But so, you know, that sort of policy is sort of nonsensical. If you're going to offer a lines to somebody, offer a lines to them, and if you're going to guarantee their security, you're going to offer a lines to them,

01:07:20,738 --> 01:07:22,910
SPEAKER_0:  And the West failed signally to do that.

01:07:23,490 --> 01:07:25,758
SPEAKER_0:  So that was mistakes in the run-up to the war.

01:07:26,082 --> 01:07:27,038
SPEAKER_0:  Once the war began...

01:07:27,330 --> 01:07:30,206
SPEAKER_0:  then the responsibility of the West became too.

01:07:30,626 --> 01:07:31,070
SPEAKER_0:  Give.

01:07:31,458 --> 01:07:35,614
SPEAKER_0:  Ukraine as much material as is necessary to repel the invasion.

01:07:36,098 --> 01:07:36,926
SPEAKER_0:  Eh, and...

01:07:37,602 --> 01:07:43,678
SPEAKER_0:  the West did really well with that. I think we were late on the ball in the United States. It seemed like Europe led the way a little bit more than the United States did there.

01:07:43,938 --> 01:07:44,990
SPEAKER_0:  But in terms of.

01:07:45,442 --> 01:07:48,702
SPEAKER_0:  effectuating American interests in the region.

01:07:48,930 --> 01:07:51,294
SPEAKER_0:  which being an American is what I'm chiefly concerned about.

01:07:51,586 --> 01:07:55,870
SPEAKER_0:  And the American interests were several fold. One is preserved borders.

01:07:56,290 --> 01:07:57,022
SPEAKER_0:  Who is?

01:07:57,378 --> 01:08:01,150
SPEAKER_0:  Degrade the Russian aggressive military because Russia's military has been aggressive.

01:08:01,666 --> 01:08:03,966
SPEAKER_0:  and they are geopolitical rival of the United States.

01:08:04,322 --> 01:08:15,390
SPEAKER_0:  three, recalibrate the European balance with China. Europe was sort of balancing with Russia and China. And then because of the war, they sort of rebalanced away from China and Russia, which is a real geostrategic opportunity.

01:08:15,874 --> 01:08:17,054
SPEAKER_0:  for the United States.

01:08:17,954 --> 01:08:22,590
SPEAKER_0:  It seemed like most of those goals have already been achieved at this point for the United States. And so then the question becomes, what is the best way to achieve that goal?

01:08:22,946 --> 01:08:29,598
SPEAKER_0:  What's the off ramp here and what is the thing you're trying to prevent? So what's the best opportunity? What's the best case scenario? What's the worst case scenario? And then what's realistic?

01:08:29,858 --> 01:08:36,318
SPEAKER_0:  So best case scenario is Ukraine forces Russia entirely out of Ukraine, including Luhansk and Crimea, right? That's the best case scenario.

01:08:36,642 --> 01:08:41,598
SPEAKER_0:  Virtually no one thinks that's accomplishable, including the United States, right? The White House has basically said as much.

01:08:41,826 --> 01:08:43,646
SPEAKER_0:  It's still close to imagine, particularly Crimea.

01:08:43,970 --> 01:08:46,046
SPEAKER_0:  the Russians being forced out of Crimea.

01:08:46,402 --> 01:08:48,350
SPEAKER_0:  The Ukrainians have been successful in pushing

01:08:48,866 --> 01:08:50,782
SPEAKER_0:  the Russians out of certain parts of Lhansk, Indonesia.

01:08:51,042 --> 01:08:55,614
SPEAKER_0:  But the idea that they're going to be able to push the entire Russian army completely back to the Russian borders.

01:08:56,098 --> 01:08:58,782
SPEAKER_0:  that would be at best a very, very long and difficult slog.

01:08:59,138 --> 01:09:08,967
SPEAKER_0:  in the middle of a collapsing Ukrainian economy, which is a point that Zelensky has made. It's like, it's not enough for you guys to give us military aid. We're in the middle of a war. We're going to need economic aid as well. So it's a pretty open-ended and strong commitment.

01:09:08,967 --> 01:09:11,742
SPEAKER_1:  Can take a small tangent on that and your best-case scenario

01:09:12,130 --> 01:09:13,982
SPEAKER_1:  if that does militarily happen.

01:09:14,530 --> 01:09:15,486
SPEAKER_1:  including Crimea.

01:09:16,226 --> 01:09:19,166
SPEAKER_1:  Do you think there's a world in which Vladimir Putin

01:09:20,034 --> 01:09:20,446
SPEAKER_1:  would.

01:09:21,026 --> 01:09:21,438
SPEAKER_1:  Um.

01:09:22,210 --> 01:09:26,846
SPEAKER_1:  be able to convince the Russian people that this was a good conclusion to the war.

01:09:26,946 --> 01:09:35,998
SPEAKER_0:  Right, so the problem is that the best-case scenario might also be the worst-case scenario, meaning that there are a couple of scenarios that are sort of the worst-case scenario, and this is sort of the puzzlement of the situation.

01:09:36,418 --> 01:09:45,342
SPEAKER_0:  One is that Putin feels so boxed in, so unable to go back to his own people and say, we just wasted tens of thousands of lives here for no reason, that he unleashed a tactical...

01:09:45,858 --> 01:09:46,910
SPEAKER_0:  Nuclear weapon on the battlefield.

01:09:47,234 --> 01:09:53,150
SPEAKER_0:  Nobody knows what happens after that. So we put NATO planes in the air to take out Russian assets, do Russian start shooting down.

01:09:53,506 --> 01:10:03,038
SPEAKER_0:  planes does Russia then threaten to escalate even further by attacking an actual NATO civilian center or or even Ukrainian civilian center with nuclear weapons and where it goes from there nobody knows because

01:10:03,298 --> 01:10:05,310
SPEAKER_0:  nuclear weapons haven't been used since 1945.

01:10:05,634 --> 01:10:10,430
SPEAKER_0:  So that is a worst case scenario. It's an unpredictable scenario that could evolve into...

01:10:10,946 --> 01:10:12,414
SPEAKER_0:  really, really significant problems.

01:10:12,642 --> 01:10:13,630
SPEAKER_0:  The other worst case scenario.

01:10:14,178 --> 01:10:15,902
SPEAKER_0:  It could be a best case scenario, it could be a worst, we just don't know.

01:10:16,162 --> 01:10:16,958
SPEAKER_0:  is Putin false.

01:10:17,698 --> 01:10:18,558
SPEAKER_0:  What happens after that?

01:10:19,234 --> 01:10:20,318
SPEAKER_0:  who takes over for Putin.

01:10:20,706 --> 01:10:25,438
SPEAKER_0:  Is that person more moderate than Putin? Is that person a liberalizer? It probably won't be in a following, eh?

01:10:25,826 --> 01:10:26,686
SPEAKER_0:  If he's gonna be...

01:10:27,202 --> 01:10:32,798
SPEAKER_0:  ousted it'll probably somebody who's a top member of Putin's brass right now and has capacity to control the military

01:10:33,602 --> 01:10:37,118
SPEAKER_0:  Or it's possible the entire regime breaks down, what you end up with is Syria in Russia.

01:10:37,794 --> 01:10:41,598
SPEAKER_0:  where you just have an entirely out of control region with no centralizing power.

01:10:42,178 --> 01:10:43,710
SPEAKER_0:  which is also a disaster area.

01:10:44,002 --> 01:10:44,542
SPEAKER_0:  And so.

01:10:44,994 --> 01:10:45,694
SPEAKER_0:  Indeed.

01:10:45,954 --> 01:10:51,102
SPEAKER_0:  nature of risk mitigation in sort of an attempt at risk mitigation what actually should be happening right now

01:10:51,490 --> 01:10:51,966
SPEAKER_0:  is.

01:10:52,482 --> 01:10:52,894
SPEAKER_0:  some.

01:10:53,122 --> 01:10:54,526
SPEAKER_0:  Offerum has to be offered to Putin.

01:10:55,074 --> 01:10:58,814
SPEAKER_0:  The offer I'm likely is going to be him maintaining Crimea and parts of Luhansk and Donetsk.

01:10:59,330 --> 01:11:00,798
SPEAKER_0:  It's probably gonna be a commitment, bye.

01:11:01,058 --> 01:11:02,686
SPEAKER_0:  Ukraine not to join.

01:11:02,978 --> 01:11:03,870
SPEAKER_0:  NATO formally.

01:11:04,610 --> 01:11:05,566
SPEAKER_0:  a guarantee.

01:11:06,050 --> 01:11:10,142
SPEAKER_0:  by the West to defend Ukraine in case of an invasion of its borders again.

01:11:10,562 --> 01:11:13,054
SPEAKER_0:  by Russia like an actual treaty obligation. no

01:11:13,410 --> 01:11:16,286
SPEAKER_0:  BS treaty obligation when Ukraine gave up its nuclear weapons.

01:11:16,770 --> 01:11:17,310
SPEAKER_0:  In the 90s.

01:11:17,698 --> 01:11:19,134
SPEAKER_0:  uh... and uh... and that

01:11:19,618 --> 01:11:22,430
SPEAKER_0:  likely how this is going to have to go. The problem is...

01:11:22,658 --> 01:11:24,350
SPEAKER_0:  That requires political courage, not from-

01:11:24,898 --> 01:11:27,454
SPEAKER_0:  Not from Zelensky, it requires courage from probably Biden.

01:11:27,938 --> 01:11:35,966
SPEAKER_0:  because the only, Zelensky's not in a political position where he can go back to his own people who have made unbelievable sacrifices on behalf of their nation and freedom and say to them, guys

01:11:36,290 --> 01:11:37,310
SPEAKER_0:  Now I'm calling it quits.

01:11:37,538 --> 01:11:44,894
SPEAKER_0:  We're gonna have to give them a hand, and ask them to give Putin an off-ramp. I don't think that's an acceptable answer to most Ukrainians at this point in time from the polling data and from the available data we have on the ground.

01:11:45,346 --> 01:11:46,142
SPEAKER_0:  It's gonna actually take.

01:11:46,530 --> 01:11:46,942
SPEAKER_0:  Biden.

01:11:47,746 --> 01:11:50,398
SPEAKER_0:  fighting the bullet and being the bad guy and saying to Zolenski, listen.

01:11:51,170 --> 01:11:55,038
SPEAKER_0:  We've made a commitment of material aid. We were offering you all these things, including.

01:11:55,394 --> 01:11:57,086
SPEAKER_0:  essentially a defense pack.

01:11:57,442 --> 01:11:58,686
SPEAKER_0:  We're offering you all this stuff, but...

01:11:59,746 --> 01:12:04,478
SPEAKER_0:  you don't come to the table, then we're gonna have to start weaning you, like there will have to be a stick there, and it should be a carrot.

01:12:04,962 --> 01:12:05,950
SPEAKER_0:  And so...

01:12:06,274 --> 01:12:11,070
SPEAKER_0:  That will allow Zelensky if Biden were to do that would allow Zelensky to blame Biden for the solution everybody knows has to happen.

01:12:11,394 --> 01:12:13,214
SPEAKER_0:  So once you can go back to his own people and he can say, listen.

01:12:14,178 --> 01:12:14,558
SPEAKER_0:  This is

01:12:14,850 --> 01:12:17,534
SPEAKER_0:  the way it has to go. I don't want it to go this way. But it's not my

01:12:17,858 --> 01:12:19,774
SPEAKER_0:  I'm signing other people's checks, right? I mean, like this is

01:12:20,162 --> 01:12:21,502
SPEAKER_0:  It's not my money.

01:12:21,762 --> 01:12:30,814
SPEAKER_0:  And Biden would take the hit because he wouldn't then be able to blame Ukraine for whatever happens next, which has been the easy road off, I think, for a lot of politicians in the West is for them to just say,

01:12:31,074 --> 01:12:33,982
SPEAKER_0:  Well, this is up to the Ukrainians to decide. It's up to the Ukrainians to decide. Well, this is up to the Ukrainians to decide.

01:12:34,338 --> 01:12:34,654
SPEAKER_0:  Is it?

01:12:35,170 --> 01:12:37,694
SPEAKER_0:  Totally up to the Ukrainians to decide because it seems like

01:12:37,986 --> 01:12:40,638
SPEAKER_0:  The West is signing an awful lot of checks and all of Europe is going to freeze this winter.

01:12:41,570 --> 01:12:41,950
SPEAKER_0:  So.

01:12:42,530 --> 01:12:44,734
SPEAKER_1:  This is the importance of great leadership, by the way.

01:12:45,026 --> 01:12:47,326
SPEAKER_1:  That's why the people we elect is very important.

01:12:48,578 --> 01:12:49,534
SPEAKER_1:  Do you think?

01:12:52,258 --> 01:12:54,686
SPEAKER_1:  Do you think there's power to just one-on-one conversation?

01:12:55,298 --> 01:12:58,238
SPEAKER_1:  or Biden sits down with Zelensky or Biden sits down with Putin.

01:12:58,722 --> 01:12:59,582
SPEAKER_1:  almost in person.

01:13:00,418 --> 01:13:06,974
SPEAKER_1:  Because maybe I'm romanticizing the notion, but having done these podcasts in person, I think there's something fundamentally different than.

01:13:07,842 --> 01:13:09,054
SPEAKER_1:  through a remote call.

01:13:09,666 --> 01:13:11,390
SPEAKER_1:  and also like a distant kind of.

01:13:12,034 --> 01:13:13,022
SPEAKER_1:  recorded.

01:13:13,666 --> 01:13:16,094
SPEAKER_1:  political type speak versus like man-to-man

01:13:16,802 --> 01:13:17,150
SPEAKER_0:  So.

01:13:17,570 --> 01:13:18,782
SPEAKER_0:  I'm deeply afraid that-

01:13:19,170 --> 01:13:23,262
SPEAKER_0:  Putin outplays people in the one-on-one scenarios because he's done it to multiple presidents already.

01:13:23,746 --> 01:13:32,734
SPEAKER_0:  He gets in one-on-one scenarios with Bush, with Obama, with Trump, with Biden, and he seems to be a very canny operator and a very sort of hard-nosed operator in those situations.

01:13:33,122 --> 01:13:41,214
SPEAKER_0:  I think that if you were going to do something like that, like an actual political face to face summit, what you would need is for Biden to first have a conversation with Zelensky, where Zelensky knows what's going on. So,

01:13:41,698 --> 01:13:42,238
SPEAKER_0:  He's aware.

01:13:42,722 --> 01:13:44,734
SPEAKER_0:  And then Biden walks in and he says,

01:13:44,994 --> 01:13:45,630
SPEAKER_0:  to Putin.

01:13:46,082 --> 01:13:46,718
SPEAKER_0:  on camera.

01:13:47,042 --> 01:13:47,902
SPEAKER_0:  Here's the offer.

01:13:49,058 --> 01:13:49,982
SPEAKER_0:  Let's get it together.

01:13:50,562 --> 01:13:51,454
SPEAKER_0:  Let's make peace.

01:13:52,386 --> 01:13:53,950
SPEAKER_0:  You get to keep this stuff.

01:13:54,242 --> 01:13:54,782
SPEAKER_0:  And then.

01:13:55,778 --> 01:13:57,790
SPEAKER_0:  how Putin is going to respond.

01:13:58,530 --> 01:13:59,038
SPEAKER_0:  Um.

01:13:59,746 --> 01:14:05,662
SPEAKER_0:  You know, the big problem for Putin, I think, and the problem with public facing fora, maybe it's a private meeting. If it's a private meeting, maybe that's the best thing.

01:14:06,050 --> 01:14:11,102
SPEAKER_0:  It was a public-facing forum. I think it's a problem because Putin's afraid of being humiliated at this point. If it's a private meeting...

01:14:11,586 --> 01:14:11,934
SPEAKER_0:  then

01:14:12,770 --> 01:14:14,462
SPEAKER_0:  Sure, except that, again...

01:14:14,850 --> 01:14:16,254
SPEAKER_0:  I just, I wonder whether...

01:14:17,538 --> 01:14:18,494
SPEAKER_0:  when it comes to...

01:14:19,106 --> 01:14:21,118
SPEAKER_0:  and a person as canny as Putin.

01:14:21,602 --> 01:14:22,270
SPEAKER_0:  And two.

01:14:23,202 --> 01:14:27,198
SPEAKER_0:  a politician that I really don't think is a particularly sophisticated player in Joe Biden

01:14:27,522 --> 01:14:28,350
SPEAKER_0:  And again, this is not.

01:14:29,026 --> 01:14:30,846
SPEAKER_0:  unique to Biden. I think that most of our presidents...

01:14:31,522 --> 01:14:32,478
SPEAKER_0:  for the last

01:14:32,994 --> 01:14:35,646
SPEAKER_0:  thirty forty years and up in particularly sophisticated players

01:14:36,002 --> 01:14:38,526
SPEAKER_0:  I think that that's a risky scenario.

01:14:40,194 --> 01:14:43,678
SPEAKER_1:  Yeah, I still believe in the power of that, cause otherwise, um,

01:14:45,122 --> 01:14:50,014
SPEAKER_1:  I don't know, I don't think stuff on paper and political speak will solve these kinds of problems.

01:14:50,370 --> 01:14:52,190
SPEAKER_1:  Because from Zelensky's perspective...

01:14:52,674 --> 01:14:54,750
SPEAKER_1:  Nothing but complete victory will do.

01:14:55,778 --> 01:14:56,350
SPEAKER_1:  his

01:14:56,642 --> 01:14:59,486
SPEAKER_1:  as a nation has people sacrificed way too much.

01:14:59,746 --> 01:15:00,606
SPEAKER_1:  and they're all in.

01:15:00,866 --> 01:15:09,406
SPEAKER_1:  And if you look at, because I traveled to Ukraine, I spent time there, I'll be going back there, hopefully also going back to Russia, just speaking to Ukrainians.

01:15:10,114 --> 01:15:11,550
SPEAKER_1:  They're all in.

01:15:12,354 --> 01:15:13,182
SPEAKER_1:  They're all in.

01:15:13,858 --> 01:15:17,374
SPEAKER_1:  Yeah. Nothing but complete victory. Yep, that's right. And so.

01:15:18,338 --> 01:15:20,926
SPEAKER_1:  For that, the only way to achieve peace.

01:15:21,346 --> 01:15:23,838
SPEAKER_1:  is through like honest human to human.

01:15:24,354 --> 01:15:25,118
SPEAKER_1:  conversation.

01:15:25,634 --> 01:15:27,518
SPEAKER_1:  uh... giving both people

01:15:27,874 --> 01:15:29,278
SPEAKER_1:  a way to off-ramp.

01:15:29,666 --> 01:15:32,766
SPEAKER_1:  to walk away victorious. And some of that requires...

01:15:33,730 --> 01:15:34,974
SPEAKER_1:  Speaking honestly.

01:15:35,202 --> 01:15:38,206
SPEAKER_1:  as a human being, but also for America too.

01:15:38,914 --> 01:15:41,758
SPEAKER_1:  actually not even America, honestly, just the president.

01:15:42,082 --> 01:15:43,518
SPEAKER_1:  be able to eat their own ego.

01:15:43,810 --> 01:15:44,190
SPEAKER_1:  a bit.

01:15:44,482 --> 01:15:47,678
SPEAKER_1:  and be the punching bag a little just enough.

01:15:48,034 --> 01:15:51,134
SPEAKER_1:  for both presidents to be able to walk away and say, listen.

01:15:51,362 --> 01:15:52,958
SPEAKER_1:  We got the American president.

01:15:53,250 --> 01:15:54,110
SPEAKER_1:  to come to us.

01:15:54,594 --> 01:15:55,582
SPEAKER_1:  And, uh...

01:15:56,226 --> 01:15:58,718
SPEAKER_1:  I think that makes the president look strong, not weak.

01:15:59,458 --> 01:16:03,870
SPEAKER_0:  I agree with you. I think it would also require some people on the right, people like me, if it's Joe Biden.

01:16:04,098 --> 01:16:06,558
SPEAKER_0:  to say if Biden does that, I see what he's doing and it's the right move.

01:16:07,074 --> 01:16:16,990
SPEAKER_0:  I think one of the things that he's afraid of, to steel man him, I think one of the things he's afraid of is he goes and he makes that sort of deal, and the right says, you just cowered in front of Russia, you just gave away Ukraine, whatever it is.

01:16:17,314 --> 01:16:20,606
SPEAKER_0:  But it's going to require some people on the right to say that.

01:16:20,898 --> 01:16:24,126
SPEAKER_0:  that move is the right move and then hold by it if Biden actually performs that move.

01:16:24,962 --> 01:16:26,494
SPEAKER_1:  You're exceptionally good at debate.

01:16:26,978 --> 01:16:27,518
SPEAKER_1:  uh...

01:16:27,842 --> 01:16:35,806
SPEAKER_1:  You wrote how the debate leftist destroyed them. You're kind of known for this kind of stuff, just exceptionally skilled at conversation and debate.

01:16:36,162 --> 01:16:37,214
SPEAKER_1:  at getting.

01:16:37,698 --> 01:16:38,910
SPEAKER_1:  the facts of the matter.

01:16:39,170 --> 01:16:42,078
SPEAKER_1:  and using logic to get to the conclusion.

01:16:42,434 --> 01:16:43,486
SPEAKER_1:  uh... in the debate

01:16:43,842 --> 01:16:45,534
SPEAKER_1:  You ever worry that this power...

01:16:46,210 --> 01:16:47,198
SPEAKER_1:  Talk about the rain.

01:16:48,770 --> 01:16:51,102
SPEAKER_1:  This power you were given has corrupted.

01:16:51,650 --> 01:16:54,334
SPEAKER_1:  you and your ability to see what's.

01:16:54,754 --> 01:16:56,510
SPEAKER_1:  like to pursue the truth.

01:16:56,962 --> 01:16:58,238
SPEAKER_1:  versus just winning debates.

01:16:58,594 --> 01:17:03,294
SPEAKER_0:  I hope not. I mean, so I think one of the things that's kind of funny about the branding versus the reality.

01:17:03,586 --> 01:17:12,414
SPEAKER_0:  is that most of the things that get characterized as destroying in debates with facts and logic, most of those things are basically me having a conversation with somebody on a college campus.

01:17:12,834 --> 01:17:17,310
SPEAKER_0:  It actually isn't like a formal debate where we sit there and we critique each other's positions.

01:17:17,602 --> 01:17:23,870
SPEAKER_0:  or it's not me insulting anybody, a lot of the clips that have gone very viral is me making an argument and then they're not being like an amazing counter argument.

01:17:24,194 --> 01:17:27,326
SPEAKER_0:  Many of the debates that I've held have been extremely cordial.

01:17:27,682 --> 01:17:32,926
SPEAKER_0:  Let's take the latest example, like about a year ago I debated Anna Kasparian from Young Turks. It was very cordial, it was very nice, right?

01:17:33,570 --> 01:17:38,782
SPEAKER_0:  That's sort of the way that I like to debate. My rule when it comes to debate.

01:17:39,266 --> 01:17:42,110
SPEAKER_0:  and or discussion is that my opponent actually gets to pick.

01:17:42,370 --> 01:17:43,390
SPEAKER_0:  the mode in which we work.

01:17:43,746 --> 01:17:48,798
SPEAKER_0:  So if it's going to be a debate of ideas then we're just going to discuss and critique and clarify.

01:17:49,218 --> 01:17:49,886
SPEAKER_0:  Then we can do that.

01:17:50,210 --> 01:17:53,086
SPEAKER_0:  If somebody comes loaded for bear, then I will...

01:17:53,826 --> 01:17:54,558
SPEAKER_0:  Responding Kind.

01:17:55,010 --> 01:17:55,774
SPEAKER_0:  because

01:17:56,098 --> 01:18:06,206
SPEAKER_0:  one of the big problems, I think, in sort of the debate slash discussion sphere is very often misdiagnosis of what exactly is going on. People who think that discussion is debate and vice versa.

01:18:06,594 --> 01:18:08,766
SPEAKER_0:  and that can be a real problem.

01:18:09,282 --> 01:18:10,078
SPEAKER_0:  And there are people who will...

01:18:12,290 --> 01:18:12,606
SPEAKER_0:  treat.

01:18:13,154 --> 01:18:16,542
SPEAKER_0:  what ought to be a discussion as, for example, an exercise in performance art.

01:18:17,154 --> 01:18:26,270
SPEAKER_0:  And so what that is is mugging or trolling or saying trolly things in order to just get to the... Like that's something I actually don't do during debate. I mean if you actually watch me talk to people, I don't actually do the trolling thing.

01:18:26,850 --> 01:18:30,046
SPEAKER_0:  The trolling thing is almost solely relegated to Twitter and me making jokes on my show.

01:18:30,530 --> 01:18:31,806
SPEAKER_0:  when it comes to actually debating people.

01:18:33,602 --> 01:18:52,414
SPEAKER_0:  sounds actually a lot like what we're doing right now. It's just the person maybe taking just an obverse position to mine. And so that's fine. Usually half of the debate or discussion is me just asking for clarification of terms. Like what exactly do you mean by this so I can drill down on where the actual disagreement may lie because some of the time people think they're disagreeing and they're actually not disagreeing.

01:18:53,026 --> 01:18:53,854
SPEAKER_0:  When I'm...

01:18:54,242 --> 01:19:00,318
SPEAKER_0:  talking with Anna Kasparian and she's talking about how corporate and government have too much power together. I'm like, well, you sound like a tea party. You and I are on the same page about this.

01:19:00,546 --> 01:19:03,038
SPEAKER_0:  That sort of stuff does tend to happen a lot in discussion.

01:19:03,426 --> 01:19:04,606
SPEAKER_0:  I think that...

01:19:04,834 --> 01:19:10,846
SPEAKER_0:  when discussion gets termed debate, it's a problem. When debate gets termed discussion, it's even more problematic because debate is a different thing.

01:19:11,106 --> 01:19:21,150
SPEAKER_1:  And I find that your debate and your conversation is often good faith. You're able to steal man on the other side. You're able to, you're actually listening. You're considering the other side. The times when I see that you, you know.

01:19:21,410 --> 01:19:26,558
SPEAKER_1:  Ben Shapiro destroys leftist. It's usually just like you said, the other side is doing the trolling.

01:19:27,138 --> 01:19:28,670
SPEAKER_1:  because they've...

01:19:29,154 --> 01:19:30,974
SPEAKER_1:  I mean, the people that do criticize you.

01:19:32,290 --> 01:19:34,270
SPEAKER_1:  for that interaction is

01:19:34,530 --> 01:19:37,502
SPEAKER_1:  the people that usually get destroyed are like 20 years old.

01:19:38,082 --> 01:19:39,934
SPEAKER_1:  and they're usually not sophisticated.

01:19:40,450 --> 01:19:42,334
SPEAKER_1:  in any kind of degree.

01:19:42,626 --> 01:19:46,001
SPEAKER_1:  in terms of being able to use logic and reason and facts and so on.

01:19:46,001 --> 01:19:52,222
SPEAKER_0:  that's that's totally fine by the way i mean if people want to criticize me for speaking on college campuses where a lot of political conversation happens both right and left

01:19:52,706 --> 01:19:59,422
SPEAKER_0:  that's fine and then i i've had lots of conversations people on the other side of the out to the right of the podcast and sam harris we talked about a few as i'm more i've done

01:19:59,810 --> 01:20:17,950
SPEAKER_0:  debates with Anna Kasparian, or I've done a debate with Cenk Weigert, or I've had conversations with lots of people on the other side of the aisle. In fact, I believe I'm the only person on the right who recommends that people listen to his shows on the other side of the aisle, right? I mean, I say on my show on a fairly regular basis that people should listen to Positive America. Now, no one on Positive America will ever say that somebody should listen to my show. That isn't for Bowton.

01:20:18,242 --> 01:20:19,838
SPEAKER_0:  That is not something that can be had.

01:20:20,226 --> 01:20:24,286
SPEAKER_0:  It's one of the strangenesses of our politics. It's what I've called the happy birthday problem.

01:20:24,578 --> 01:20:25,886
SPEAKER_0:  I just have a lot of friends who are...

01:20:26,178 --> 01:20:28,030
SPEAKER_0:  of the left and are publicly of the left.

01:20:28,354 --> 01:20:33,214
SPEAKER_0:  And on my birthday, they'll send you a text message, happy birthday, but they will never tweet happy birthday, Westley B.

01:20:33,538 --> 01:20:36,510
SPEAKER_0:  acknowledging that you were born of woman and that this can't be.

01:20:36,738 --> 01:20:39,646
SPEAKER_0:  So on the Sunday special, I've had a bevy of people.

01:20:40,002 --> 01:20:40,766
SPEAKER_0:  Or on the other side.

01:20:41,026 --> 01:20:42,398
SPEAKER_0:  of the aisle, a lot of them.

01:20:43,010 --> 01:20:46,654
SPEAKER_0:  ranging from people in Hollywood like Jason Blom to Larry Wilmore to

01:20:47,234 --> 01:20:51,070
SPEAKER_0:  Sam to just a lot of people on the left. I think we're.

01:20:51,330 --> 01:20:57,086
SPEAKER_0:  in the near future probably into a sunny special with rocana up in california the california congress person very nice guy had on the show

01:20:57,410 --> 01:20:59,742
SPEAKER_0:  That kind of stuff is fun and interesting.

01:21:00,130 --> 01:21:00,990
SPEAKER_0:  But, um...

01:21:01,282 --> 01:21:06,110
SPEAKER_0:  I think that the easy way out for a clip that people don't like is to either immediately clip the clip.

01:21:06,466 --> 01:21:11,678
SPEAKER_0:  I'll take a two minute clip and clip it down to 15 seconds where somebody insults me and then that goes viral. Which is, you know, welcome to the internet.

01:21:12,066 --> 01:21:19,390
SPEAKER_0:  uh... or uh... or to say well you're only debating colleges you're only talking to twenty and i talked a lot more people than that that's just not the stuff you're watching

01:21:20,226 --> 01:21:26,526
SPEAKER_1:  You lost your cool in an interview with BBC's Andrew and Neil and you're really honest about it after which was…

01:21:27,778 --> 01:21:32,510
SPEAKER_1:  refreshing and enjoyable. As the internet said, I've never seen anyone lose an interest.

01:21:34,082 --> 01:21:35,134
SPEAKER_1:  Uh, so...

01:21:36,034 --> 01:21:37,918
SPEAKER_1:  To me, honestly, it was like seeing like.

01:21:38,210 --> 01:21:40,574
SPEAKER_1:  Floyd Mayweather Jr. or somebody like knocked down.

01:21:41,058 --> 01:21:41,438
SPEAKER_1:  Um.

01:21:42,434 --> 01:21:44,510
SPEAKER_1:  What was it? Can you take me to that experience?

01:21:44,674 --> 01:21:48,350
SPEAKER_0:  Here's that day. That day is I have a book release, didn't get a lot of sleep the night before.

01:21:48,802 --> 01:21:50,142
SPEAKER_0:  And this is the last interview of the day.

01:21:50,402 --> 01:21:51,454
SPEAKER_0:  and it's an interview with BBC.

01:21:51,746 --> 01:21:54,046
SPEAKER_0:  I don't know anything about BBC, I don't watch BBC, I don't know any of the hosts.

01:21:54,658 --> 01:21:55,646
SPEAKER_0:  So we get on...

01:21:56,002 --> 01:21:56,510
SPEAKER_0:  the interview.

01:21:56,770 --> 01:21:57,630
SPEAKER_0:  And it's supposed to be about the bug.

01:21:58,210 --> 01:21:58,686
SPEAKER_0:  and

01:21:59,682 --> 01:22:01,886
SPEAKER_0:  The host, Andrew Neil, doesn't ask.

01:22:02,370 --> 01:22:03,550
SPEAKER_0:  Virtually a single question about.

01:22:04,162 --> 01:22:06,718
SPEAKER_0:  He just starts reading me bad old tweets. Which, which-

01:22:06,946 --> 01:22:12,190
SPEAKER_0:  i hate i mean it's it's annoying and stupidness the worst form of interview yeah when somebody just read you battle tweets especially when

01:22:12,418 --> 01:22:13,822
SPEAKER_0:  I've acknowledged battle tweets before.

01:22:14,242 --> 01:22:19,198
SPEAKER_0:  And so I'm going through the list with him. And this interview was solidly 20 minutes. I mean, it was a long interview.

01:22:19,714 --> 01:22:27,262
SPEAKER_0:  And we get to, and I make a couple of particularly annoyed mistakes in the interview. So, annoyed mistake number one is...

01:22:27,682 --> 01:22:28,446
SPEAKER_0:  The ego play.

01:22:28,674 --> 01:22:43,806
SPEAKER_0:  So there's a point in the middle of the interview where I say, I don't even know who you are, which was true. I didn't know who he was. It turns out he's a very famous person in Britain. And so you can't make that ego play. But even if he's not famous, that's not a thing. It's a dumb thing to do, and it's an ass thing to do. So saying that was, you know.

01:22:44,226 --> 01:22:44,926
SPEAKER_0:  More just kind of-

01:22:45,250 --> 01:22:45,982
SPEAKER_0:  peak in silliness.

01:22:46,338 --> 01:22:48,963
SPEAKER_0:  uh... and uh... so that was that was missed a enjoyed what

01:22:48,963 --> 01:22:52,263
SPEAKER_1:  watching that, it was like, oh, Ben is human.

01:22:52,263 --> 01:22:57,406
SPEAKER_0:  but somebody's right so that there is there's that and then the the other mistake was

01:22:57,666 --> 01:22:59,582
SPEAKER_0:  that I just don't watch enough British TV.

01:22:59,842 --> 01:23:07,870
SPEAKER_0:  So the way that interviews are done there are much more adversarial than American TV. In American TV, if somebody is adversarial with you, you assume that they're a member of the other side. That's typically how it is.

01:23:08,290 --> 01:23:14,238
SPEAKER_0:  And so I'm critiquing some of his questions at the beginning, and I thought that the critique of some of his questions is actually fair. He's asking me about abortion.

01:23:14,594 --> 01:23:20,766
SPEAKER_0:  and i thought he was asking it from uh... away framing the question that was inaccurate and so i assume that he was on the left because again i never heard of him

01:23:21,122 --> 01:23:24,094
SPEAKER_0:  And so, you know, I mischaracterized him and...

01:23:24,482 --> 01:23:26,494
SPEAKER_0:  I apologize later for mischaracterizing him.

01:23:26,818 --> 01:23:33,214
SPEAKER_0:  We finally go through the interview, it's 20 minutes, he just keeps going with the bad old tweets, and finally I got up and I took off the microphone and I walked out.

01:23:33,698 --> 01:23:34,238
SPEAKER_0:  and

01:23:34,466 --> 01:23:38,814
SPEAKER_0:  Immediately, I knew it was a mistake. Like within 30 seconds of the end of the interview, I knew it was a mistake.

01:23:39,170 --> 01:23:41,694
SPEAKER_0:  And that's why even before the interview came out.

01:23:42,114 --> 01:23:46,622
SPEAKER_0:  I believe I corrected the record that Andrew Neil is not on the left. That's a mistake by me.

01:23:47,074 --> 01:23:48,990
SPEAKER_0:  And then, you know.

01:23:49,474 --> 01:23:51,166
SPEAKER_0:  took the hit for a bad interview.

01:23:51,490 --> 01:23:52,254
SPEAKER_0:  And

01:23:52,578 --> 01:23:53,790
SPEAKER_0:  So, as far as...

01:23:54,338 --> 01:24:02,814
SPEAKER_0:  you know, what I wish I'd done differently. I wish I'd known who he was. I wish I'd done my research. I wish that I had treated it as though there was a possibility that it was gonna be more adversarial than it was.

01:24:03,394 --> 01:24:04,382
SPEAKER_0:  I think I was in cautious.

01:24:04,674 --> 01:24:07,678
SPEAKER_0:  about the interview because it was pitched as, it's just another book interview.

01:24:07,906 --> 01:24:10,718
SPEAKER_0:  And it wasn't just another book interview, it was treated much more adversarially than that.

01:24:11,330 --> 01:24:14,782
SPEAKER_0:  So I wish that that's on me. I got to research the people who are

01:24:15,170 --> 01:24:17,950
SPEAKER_0:  talking to me and watch their shows and learn about that.

01:24:18,466 --> 01:24:20,926
SPEAKER_0:  And then obviously, you know, the kind of gut level...

01:24:21,250 --> 01:24:24,254
SPEAKER_0:  appeal to ego or arrogance like that, that's a bad look.

01:24:24,738 --> 01:24:27,102
SPEAKER_0:  and shouldn't have done that and losing your cool is always a bad look.

01:24:27,842 --> 01:24:28,222
SPEAKER_1:  So.

01:24:28,482 --> 01:24:29,534
SPEAKER_1:  The fact that that...

01:24:30,146 --> 01:24:35,006
SPEAKER_1:  sort of became somewhat viral and stood out just shows that it happens so rarely to you.

01:24:35,298 --> 01:24:35,614
SPEAKER_1:  uh

01:24:36,162 --> 01:24:36,478
SPEAKER_1:  So.

01:24:36,738 --> 01:24:39,166
SPEAKER_1:  just to look at like the day in the life of Ben Shapiro.

01:24:39,906 --> 01:24:41,342
SPEAKER_1:  You speak a lot.

01:24:43,074 --> 01:24:45,726
SPEAKER_1:  very eloquently about difficult topics.

01:24:46,402 --> 01:24:51,518
SPEAKER_1:  what goes into the research, the mental part. And you always look pretty like energetic and.

01:24:52,450 --> 01:24:56,318
SPEAKER_1:  Like you're not exhausted by the burden, the heaviness.

01:24:56,546 --> 01:24:57,886
SPEAKER_1:  of the topics you're covering.

01:24:58,178 --> 01:25:01,886
SPEAKER_1:  day after day after day after day. So what what goes through the preparation?

01:25:02,466 --> 01:25:03,550
SPEAKER_1:  mentally

01:25:03,874 --> 01:25:06,279
SPEAKER_1:  diet-wise, anything like that. I'm going to take one. One.

01:25:06,279 --> 01:25:10,526
SPEAKER_0:  When do you wake up? Okay, so I wake up when my kids wake me up. Usually that's my-

01:25:10,882 --> 01:25:15,870
SPEAKER_0:  Baby daughter who's two and a half. We are on the monitor usually about 615, 620 AM.

01:25:16,418 --> 01:25:20,126
SPEAKER_0:  So I get up, my wife sleeps in a little bit, I go get the baby.

01:25:20,514 --> 01:25:21,406
SPEAKER_0:  Then my son gets up.

01:25:21,986 --> 01:25:22,494
SPEAKER_0:  And then my...

01:25:22,850 --> 01:25:25,886
SPEAKER_0:  Oh, the starter gets up, I have eight, six, and two. The boys, the middle.

01:25:26,466 --> 01:25:28,341
SPEAKER_1:  Is that both a source of stress and happiness?

01:25:28,341 --> 01:25:35,102
SPEAKER_0:  Oh my god, it's the height of both, right? I mean, it's the source of the greatest happiness. So the way that I characterize it is this, when it comes to sort of.

01:25:35,522 --> 01:25:36,894
SPEAKER_0:  kids in life. So when you're single...

01:25:37,282 --> 01:25:44,958
SPEAKER_0:  your boundaries of happiness and unhappiness, you can be a zero in terms of happiness, you can be like a 10 in terms of happiness. Then you get married and it goes up to like a 20 and a negative 20 because...

01:25:45,250 --> 01:25:49,662
SPEAKER_0:  The happiest stuff is with your wife, and then the most unhappy stuff is when something happens to your spouse. It's the worst thing in the entire world.

01:25:50,018 --> 01:25:58,430
SPEAKER_0:  Then you have kids and all limits are removed. So the best things that have ever happened to me are things where I'm watching my kids and they're playing together and they're being wonderful and sweet and cute and I love them so much.

01:25:58,754 --> 01:26:03,166
SPEAKER_0:  And the worst things are when my son is screaming at me for no reason because he's being insane.

01:26:03,394 --> 01:26:14,206
SPEAKER_0:  and I have to deal with that, right? Or something bad happens to my daughter at school or something like that, that stuff is really bad. So yes, the source of my greatest happiness, the source of my greatest stress. So they get me up at about 6.15 in the morning, I feed them breakfast.

01:26:14,466 --> 01:26:16,382
SPEAKER_0:  I'm kind of scrolling the news while I'm making the mags.

01:26:16,706 --> 01:26:18,302
SPEAKER_0:  And, uh, and.

01:26:19,426 --> 01:26:22,078
SPEAKER_0:  just updating myself on anything that may have happened overnight.

01:26:22,306 --> 01:26:22,846
SPEAKER_0:  I-

01:26:23,106 --> 01:26:24,574
SPEAKER_0:  Go into the office.

01:26:24,802 --> 01:26:30,430
SPEAKER_0:  put on the makeup and the wardrobe or whatever. And then I sit down and do the show. A lot of the prep.

01:26:30,722 --> 01:26:34,270
SPEAKER_0:  is actually done the night before because the new cycle doesn't change all that much between

01:26:35,074 --> 01:26:39,701
SPEAKER_0:  kind of late at night and in the morning, so I can supplement in the morning. So I do the show.

01:26:39,701 --> 01:26:43,451
SPEAKER_1:  So a lot of the preparation, like thinking through what are the big issues in the world is

01:26:43,451 --> 01:26:51,838
SPEAKER_0:  on the night before. Yeah, I mean, and that's reading, you know, pretty much all the legacy media. So I rip on legacy media a lot, but that's because a lot of what they do is really good and a lot of what they do is really bad.

01:26:52,066 --> 01:26:53,278
SPEAKER_0:  I cover a lot of legacy media.

01:26:53,762 --> 01:26:57,790
SPEAKER_0:  So that's probably covering, you know, Wall Street Journal, New York Times, Washington Post, Boston Globe Daily Mail.

01:26:58,050 --> 01:26:58,526
SPEAKER_0:  Um...

01:26:58,754 --> 01:27:03,966
SPEAKER_0:  And then I'll look over at some of the alternative media, I'll look at my own website, Daily Wire, I'll look at Breitbart, I'll look at The Blaze, I'll look at...

01:27:04,290 --> 01:27:08,094
SPEAKER_0:  I'll look at maybe the intracaps. I'll look at a bunch of different sources.

01:27:08,450 --> 01:27:09,822
SPEAKER_0:  And then I will look at.

01:27:10,434 --> 01:27:12,030
SPEAKER_0:  different clips online so.

01:27:12,322 --> 01:27:15,646
SPEAKER_0:  MediaEye comes in handy here, Grabeon comes in handy here.

01:27:16,002 --> 01:27:20,126
SPEAKER_0:  that sort of stuff because my show relies very heavily on being able to play people so you can hear them in their own words.

01:27:20,386 --> 01:27:24,190
SPEAKER_0:  And so that's sort of the media die. So I sit down, I-

01:27:25,218 --> 01:27:25,822
SPEAKER_0:  do the show.

01:27:26,338 --> 01:27:27,678
SPEAKER_0:  And then once I'm done with the show...

01:27:27,938 --> 01:27:28,286
SPEAKER_0:  Bye.

01:27:28,610 --> 01:27:32,510
SPEAKER_0:  usually have between now it's like 11 15 in the morning, maybe

01:27:32,802 --> 01:27:35,870
SPEAKER_0:  because sometimes I'll pre-record the show. So, it's 11.15 in the morning.

01:27:36,162 --> 01:27:37,086
SPEAKER_0:  Oh, go home.

01:27:37,538 --> 01:27:39,326
SPEAKER_0:  And if my wife's available, I'll grab lunch with her.

01:27:39,650 --> 01:27:43,710
SPEAKER_0:  If not, then I will go and work out. I try to work out like

01:27:45,122 --> 01:27:46,782
SPEAKER_0:  five times a week with a trainer, something like that.

01:27:47,138 --> 01:27:49,278
SPEAKER_0:  And then I will...

01:27:49,570 --> 01:27:50,558
SPEAKER_1:  Just regular gem stuff.

01:27:50,850 --> 01:27:51,975
SPEAKER_1:  just Ramadan wus bin Chau.

01:27:51,975 --> 01:27:54,878
SPEAKER_0:  Yeah, weights and plyometrics and...

01:27:55,746 --> 01:27:57,406
SPEAKER_0:  some CrossFit kind of stuff and...

01:27:58,114 --> 01:27:59,678
SPEAKER_0:  Yeah, I mean, beneath this.

01:27:59,970 --> 01:28:04,254
SPEAKER_0:  beneath this mildly sterilized, a hulking monster. Yeah. That, yeah, sure.

01:28:04,962 --> 01:28:07,326
SPEAKER_0:  I'll do that. orbitsr I have one r

01:28:08,034 --> 01:28:08,542
SPEAKER_0:  I will.

01:28:09,218 --> 01:28:10,174
SPEAKER_0:  do reading and writing.

01:28:10,562 --> 01:28:11,710
SPEAKER_0:  Alright, so I'll e-

01:28:11,970 --> 01:28:13,886
SPEAKER_0:  I'm usually working on a book at any given time.

01:28:14,114 --> 01:28:15,989
SPEAKER_1:  uh... or shut off the the rest of the

01:28:15,989 --> 01:28:19,006
SPEAKER_0:  Yes, so I put some music in my ears usually Brahms or Bach

01:28:19,458 --> 01:28:23,422
SPEAKER_0:  Sometimes Beethoven or Mozart. It's those four. Those are on rotation.

01:28:23,746 --> 01:28:24,158
SPEAKER_0:  No rap.

01:28:24,450 --> 01:28:27,166
SPEAKER_0:  No rap, despite my extraordinary rendition of WAP.

01:28:27,554 --> 01:28:28,679
SPEAKER_0:  Yeah. I'm not in fact around.

01:28:28,679 --> 01:28:29,918
SPEAKER_1:  Do you still hate?

01:28:30,946 --> 01:28:40,766
SPEAKER_0:  The song? It's, I will say, I do not think that it is the peak of Western civilized art. I don't think that 100 years from now people will be gluing their faces to a WAP and protest at the environment.

01:28:41,090 --> 01:28:43,783
SPEAKER_1:  but Brahms and the rest will be still.

01:28:43,783 --> 01:28:49,027
SPEAKER_0:  Yes, I would assume if people still have a functioning prefrontal cortex and any sort of taste. Strong words.

01:28:49,027 --> 01:28:54,334
SPEAKER_1:  from Ben Shapiro. All right, so you got some classical music in your ears and you're focusing.

01:28:54,594 --> 01:28:55,719
SPEAKER_1:  Are you at the computer?

01:28:55,719 --> 01:28:57,534
SPEAKER_0:  when you're writing? I'm at the computer.

01:28:57,986 --> 01:29:04,670
SPEAKER_0:  uh... usually we have a kind of a room that has some sun coming in so it's nice in there or I'll go up to a library that we just completed for me.

01:29:05,058 --> 01:29:08,126
SPEAKER_0:  So I'll go up there and I'll write and read. Back with physical books?

01:29:08,546 --> 01:29:12,286
SPEAKER_0:  Yeah, I love physical books. Because I keep Sabbath, I don't use...

01:29:12,770 --> 01:29:13,086
SPEAKER_0:  Kindle.

01:29:13,442 --> 01:29:21,662
SPEAKER_0:  because when I'm reading a book and I hit Sabbath, I have to turn off the Kindle. So that means that I have tons and tons and tons of physical books. When you move from Los Angeles to Florida...

01:29:21,890 --> 01:29:25,278
SPEAKER_0:  I had about 7,000 volumes, I had to discard probably 4,000 of them.

01:29:25,730 --> 01:29:34,078
SPEAKER_0:  And then I've built that back up now, so I'm probably gonna have to go through another round where I put them somewhere else. I tend to tab books rather than highlighting them because I can't highlight on Sabbath.

01:29:34,338 --> 01:29:36,446
SPEAKER_0:  So I have the little stickers and I put them.

01:29:36,962 --> 01:29:40,990
SPEAKER_0:  in the book so a typical book from me you can see it on the book club will be like filled with tabs on the side

01:29:41,282 --> 01:29:42,430
SPEAKER_0:  Things that I want to take now actually.

01:29:42,690 --> 01:29:44,894
SPEAKER_0:  I got a person who I...

01:29:45,154 --> 01:29:46,014
SPEAKER_0:  I um.

01:29:46,306 --> 01:29:49,502
SPEAKER_0:  pay to go through and write down in files.

01:29:49,730 --> 01:29:52,382
SPEAKER_0:  the quotes that I like from the books, so I have those handy.

01:29:53,026 --> 01:29:55,998
SPEAKER_0:  uh... and said which is a good way for me to remember what it is that i've and

01:29:56,898 --> 01:29:58,558
SPEAKER_0:  because I read probably

01:29:59,554 --> 01:30:00,894
SPEAKER_0:  somewhere between three and five bucks a week.

01:30:01,538 --> 01:30:05,598
SPEAKER_0:  And then the, in a good week five. And then.

01:30:05,890 --> 01:30:07,710
SPEAKER_0:  I write, I read.

01:30:07,938 --> 01:30:11,742
SPEAKER_0:  and then I go pick up my kids from school at 3.30. So according to my kids, I have no job.

01:30:12,002 --> 01:30:15,294
SPEAKER_0:  I'm there in the mornings until they leave for school. I pick them up from school.

01:30:15,778 --> 01:30:17,310
SPEAKER_0:  I hang out with them until they go to bed.

01:30:17,538 --> 01:30:21,982
SPEAKER_0:  which is usually 7.30 or so, so I'm helping them with their homework and I'm playing with them and I'm-

01:30:22,370 --> 01:30:25,054
SPEAKER_0:  taking them on rides in the brand new Tesla.

01:30:25,314 --> 01:30:35,038
SPEAKER_0:  which my son is obsessed with. And then I put them to bed and then I sit back down, I prep for the next day, go through all those media sources I was talking about, compile kind of a schedule for what I want the show to look like and...

01:30:35,426 --> 01:30:39,038
SPEAKER_0:  and run of show. It's very detail-oriented, nobody writes anything for me, I write all my own stuff.

01:30:39,586 --> 01:30:41,726
SPEAKER_0:  So every word that comes out of my mouth is my fault.

01:30:42,178 --> 01:30:43,710
SPEAKER_0:  All right, and then.

01:30:44,258 --> 01:30:47,390
SPEAKER_0:  You know, hopefully I have a couple hours to or an hour to hang out with my wife.

01:30:47,778 --> 01:30:48,903
SPEAKER_0:  before before you go to bed.

01:30:48,903 --> 01:30:51,006
SPEAKER_1:  The words you write, do you edit a lot?

01:30:51,234 --> 01:30:53,859
SPEAKER_1:  Or does it just come out, you're thinking like, what are the key I-

01:30:53,859 --> 01:30:57,118
SPEAKER_0:  I want to express. No, I don't tend to edit a lot. So I.

01:30:57,442 --> 01:31:06,014
SPEAKER_0:  thank God I'm able to write extraordinarily quickly. So I write very, very fast. In fact, in a previous life, I was- You also speak fast, so it's similar. Yeah, exactly. I speak in paragraphs.

01:31:06,242 --> 01:31:07,614
SPEAKER_0:  So it's exactly the same thing.

01:31:07,874 --> 01:31:16,286
SPEAKER_0:  In a previous life, I was a ghost writer, so I used to be sort of known as a turnaround specialist in the publishing industry. There'd be somebody who came to the publisher and says,

01:31:16,610 --> 01:31:19,390
SPEAKER_0:  I have three weeks to get this book done. I don't have a word done.

01:31:19,682 --> 01:31:20,126
SPEAKER_0:  And they would.

01:31:20,450 --> 01:31:21,726
SPEAKER_0:  Call me up and be like this person.

01:31:21,954 --> 01:31:22,782
SPEAKER_0:  needs a book written.

01:31:23,106 --> 01:31:25,438
SPEAKER_0:  And so in three weeks, I'd knock out 60,000 words or so.

01:31:25,762 --> 01:31:27,742
SPEAKER_1:  Is there something you can say to the process of?

01:31:28,162 --> 01:31:29,598
SPEAKER_1:  that you follow to think.

01:31:30,082 --> 01:31:32,382
SPEAKER_1:  Like how you think about ideas. Like yeah,

01:31:32,610 --> 01:31:33,950
SPEAKER_1:  Stuff is going on in the world.

01:31:34,754 --> 01:31:39,326
SPEAKER_1:  and trying to understand what is happening, what are the explanations, what are the forces behind this.

01:31:39,586 --> 01:31:44,643
SPEAKER_1:  Do you have a process or just wait for the muse to give you the interpretation?

01:31:44,643 --> 01:31:48,958
SPEAKER_0:  I mean, I think that I don't think it's a formal process, but because I read

01:31:49,858 --> 01:31:52,606
SPEAKER_0:  So there's two ways to do it. One is sometimes-

01:31:53,538 --> 01:31:57,054
SPEAKER_0:  you know, sometimes the daily grind of the news is going to...

01:31:57,282 --> 01:32:00,030
SPEAKER_0:  refer back to core principles that are broader and deeper.

01:32:00,802 --> 01:32:01,310
SPEAKER_0:  So.

01:32:01,794 --> 01:32:03,134
SPEAKER_0:  I thank God because I've read.

01:32:03,490 --> 01:32:04,798
SPEAKER_0:  so much on so many different things.

01:32:05,218 --> 01:32:06,398
SPEAKER_0:  of a lot of different point of views.

01:32:06,626 --> 01:32:10,622
SPEAKER_0:  um... then if if something breaks in a piece of news breaks i can immediately

01:32:10,978 --> 01:32:13,214
SPEAKER_0:  sort of channel that into in the mental Rolodex.

01:32:13,538 --> 01:32:13,982
SPEAKER_0:  these.

01:32:14,370 --> 01:32:20,158
SPEAKER_0:  three big ideas that I think are really important and then I can talk at length about what those ideas are and I can explicate those.

01:32:20,770 --> 01:32:23,550
SPEAKER_0:  And so, for example, when we were talking about...

01:32:24,226 --> 01:32:27,262
SPEAKER_0:  must taking over Twitter before and I immediately go to the history of media.

01:32:27,554 --> 01:32:29,854
SPEAKER_0:  That's me tying it into a broader theme.

01:32:30,594 --> 01:32:33,086
SPEAKER_0:  on, you know, and I do that.

01:32:33,346 --> 01:32:35,678
SPEAKER_0:  I would say fairly frequently, what we're talking about.

01:32:35,938 --> 01:32:36,318
SPEAKER_0:

01:32:37,762 --> 01:32:42,558
SPEAKER_0:  say subsidization of industry and I can immediately tie that into okay what's the history of subsidization in the United States

01:32:42,946 --> 01:32:47,646
SPEAKER_0:  going all the way back to Woodrow Wilson and forward through FDR's industrial policy and how does that tie into sort of broader

01:32:48,002 --> 01:32:49,438
SPEAKER_0:  economic policy internationally.

01:32:49,794 --> 01:32:55,550
SPEAKER_0:  So it allows me to tie into bigger themes because what I tend to read is mostly not news. What I tend to read is mostly books.

01:32:56,418 --> 01:32:59,294
SPEAKER_0:  I would say most of my media diet is actually not the style.

01:32:59,746 --> 01:33:01,502
SPEAKER_0:  the icing on the cake, but the actual cake.

01:33:01,922 --> 01:33:05,310
SPEAKER_0:  is the hundreds of pages in history econ.

01:33:06,434 --> 01:33:10,110
SPEAKER_0:  geography that I'm social science that I'm reading.

01:33:10,594 --> 01:33:12,414
SPEAKER_0:  every week. And so that sort of stuff.

01:33:12,866 --> 01:33:14,590
SPEAKER_0:  allows me to think more deeply.

01:33:15,074 --> 01:33:22,270
SPEAKER_0:  about these things. So that's one way of doing it. The other way of doing it is Russia breaks in the news. I don't know anything about Russia. I immediately go and I purchase five books about Russia and I read all of them.

01:33:23,298 --> 01:33:26,974
SPEAKER_0:  And so one of the unfortunate things about our...

01:33:27,458 --> 01:33:35,038
SPEAKER_0:  The unfortunate thing for me and the unfortunate thing about the world is that if you read two books on a subject, you are now considered by the media an expert on the subject.

01:33:35,394 --> 01:33:44,254
SPEAKER_0:  So that's you know sad and shallow, but that is the way that it is the good news for me Is that my job isn't to be a full expert on any of these subjects, and I don't claim to be right I'm not a Russia expert.

01:33:44,610 --> 01:33:50,590
SPEAKER_0:  I know enough on Russia to be able to understand when people talk about Russia, what the system looks like, how it works, and all of that.

01:33:50,882 --> 01:33:54,206
SPEAKER_0:  and then to explicate that for the common man, which a lot of people who are...

01:33:54,658 --> 01:34:01,758
SPEAKER_0:  infused with the expertise can't really do if you're so deep in the weeds that you're like a full on academic expert on a thing sometimes it's hard to translate that over to a mass audience

01:34:02,050 --> 01:34:03,422
SPEAKER_0:  which is really my job. My ticket.

01:34:03,522 --> 01:34:06,142
SPEAKER_1:  can actually, it's funny with the two books, it can actually,

01:34:06,754 --> 01:34:08,286
SPEAKER_1:  Get a pretty deep understanding if you...

01:34:08,642 --> 01:34:17,246
SPEAKER_1:  read and also think deeply about it. It allows you to approach a thing from first principles. A lot of times if you're a quote unquote expert, you get- Sure.

01:34:17,890 --> 01:34:20,414
SPEAKER_1:  you're carried away by the momentum of what.

01:34:21,282 --> 01:34:23,038
SPEAKER_1:  the field has been thinking about.

01:34:23,554 --> 01:34:29,255
SPEAKER_1:  versus like stepping back, all right, what is really going on? The challenge is to pick the right two books.

01:34:29,255 --> 01:34:29,726
SPEAKER_0:  Right.

01:34:30,178 --> 01:34:38,334
SPEAKER_0:  So that usually what I'll try to find is somebody who knows the topic pretty well and have them recommend or a couple people and have them recommend books. So a couple years ago I knew nothing about Bitcoin. I was at a conference.

01:34:38,626 --> 01:34:44,830
SPEAKER_0:  and a couple of people who you've had on your show actually were there and I asked them give me your top three books on Bitcoin.

01:34:45,506 --> 01:34:47,326
SPEAKER_0:  And so then I went and I read like.

01:34:47,842 --> 01:34:48,766
SPEAKER_0:  Nine books on Bitcoin.

01:34:49,218 --> 01:34:57,022
SPEAKER_0:  And so if you're nine books on Bitcoin, you at least know enough to get by. And so I can actually explain what Bitcoin is and why it works or why it doesn't work in some cases.

01:34:57,282 --> 01:34:58,398
SPEAKER_0:  and what's happening.

01:34:58,722 --> 01:34:59,646
SPEAKER_0:  in the markets that way.

01:34:59,874 --> 01:35:00,606
SPEAKER_0:  So that's...

01:35:00,834 --> 01:35:02,398
SPEAKER_0:  you know, very, very helpful.

01:35:02,498 --> 01:35:04,318
SPEAKER_1:  What Putin is an example.

01:35:04,610 --> 01:35:06,814
SPEAKER_1:  That's a difficult one to find the right books on.

01:35:07,586 --> 01:35:08,830
SPEAKER_1:  I think the new Tsar...

01:35:09,282 --> 01:35:11,646
SPEAKER_1:  is the one I read where it was the most objective.

01:35:11,810 --> 01:35:14,366
SPEAKER_0:  When I read, I think about Putin was one called strong man.

01:35:15,074 --> 01:35:16,542
SPEAKER_0:  It was very highly critical.

01:35:17,026 --> 01:35:19,006
SPEAKER_0:  of Putin, but it gave like a good background.

01:35:19,298 --> 01:35:19,614
SPEAKER_0:  on him.

01:35:20,034 --> 01:35:23,006
SPEAKER_1:  Yeah, so I'm very skeptical sort of things that are very

01:35:23,330 --> 01:35:24,798
SPEAKER_1:  They're critical of Putin.

01:35:25,346 --> 01:35:29,246
SPEAKER_1:  because it feels like there's activism injected into the history.

01:35:29,730 --> 01:35:33,950
SPEAKER_1:  Like the way The Rise and Fall of the Third Reich is written about Hitler, I like because-

01:35:34,274 --> 01:35:36,414
SPEAKER_1:  There's almost not a criticism of Hitler.

01:35:36,674 --> 01:35:38,078
SPEAKER_1:  It's a description of Hitler.

01:35:38,594 --> 01:35:39,454
SPEAKER_1:  which is very...

01:35:39,682 --> 01:35:43,070
SPEAKER_1:  Um, it's easier to do about a historical figure, which

01:35:43,330 --> 01:35:47,486
SPEAKER_1:  With William Shire with the rise of fall, the third record since impressive because he lived through it.

01:35:48,610 --> 01:35:52,606
SPEAKER_1:  It's very tough to find objective descriptions about the history of the man.

01:35:53,026 --> 01:35:54,750
SPEAKER_1:  in a country of Putin.

01:35:55,074 --> 01:35:58,398
SPEAKER_1:  A Zelensky of any difficult Trump is the same.

01:35:58,946 --> 01:36:00,519
SPEAKER_1:  And I feel like...

01:36:00,519 --> 01:36:04,798
SPEAKER_0:  hero villain archetype, right? And it's like, either somebody's completely a hero or completely a villain.

01:36:05,250 --> 01:36:06,078
SPEAKER_0:  And the truth is...

01:36:06,690 --> 01:36:19,326
SPEAKER_0:  pretty much no one is completely a hero or completely a villain. People, in fact, I'm not sure that I love descriptions of people as heroes or villains generally. I think that people tend to do heroic things or do villainous things. In the same way that I'm not sure I love descriptions of people as a genius.

01:36:19,586 --> 01:36:25,310
SPEAKER_0:  My dad used to say this when I was growing up. He used to say, they didn't believe that there were geniuses. He said he believed that there were people with a genius for something.

01:36:25,762 --> 01:36:26,206
SPEAKER_0:  because.

01:36:26,498 --> 01:36:31,134
SPEAKER_0:  People you know, yes, there are people who are very high IQ and we call them geniuses, but does that mean that they're good at?

01:36:31,842 --> 01:36:34,622
SPEAKER_0:  EQ stuff, not necessarily, but there are people who are geniuses at EQ stuff.

01:36:34,882 --> 01:36:37,054
SPEAKER_0:  In other words, it would be more specific to say that...

01:36:37,442 --> 01:36:41,054
SPEAKER_0:  somebody's a genius at engineering than to say just broad spectrum they're a genius and

01:36:41,282 --> 01:36:45,406
SPEAKER_0:  That does avoid the problem of thinking that they're good at something that they're not good at, right? It's a little more specific.

01:36:46,050 --> 01:36:47,774
SPEAKER_1:  So because you read a lot of books, they're-

01:36:48,066 --> 01:36:54,622
SPEAKER_1:  Can you look back? And it's always a tough question because so many, it's like your favorite song, but are there books that have been influential on your life?

01:36:55,298 --> 01:36:59,262
SPEAKER_1:  that impacting your thinking or maybe once you go back to that.

01:37:00,162 --> 01:37:02,110
SPEAKER_1:  that still carry insight for you.

01:37:02,818 --> 01:37:05,662
SPEAKER_0:  The Federalist paper is a big one in terms of sort of how American politics works.

01:37:06,498 --> 01:37:12,862
SPEAKER_0:  The first econ book that I thought was really great, because it was written for teenagers, essentially is one called Economics in One Lesson by Henry Hazlitt.

01:37:13,314 --> 01:37:16,318
SPEAKER_0:  150 pages, I recommend it to everybody sort of 15 and up.

01:37:16,770 --> 01:37:18,110
SPEAKER_0:  It's easier than, say,

01:37:18,370 --> 01:37:20,606
SPEAKER_0:  Thomas Ohl's Basic Econ, which is 400 or 500 pages.

01:37:20,962 --> 01:37:23,587
SPEAKER_1:  And it's looking at what? Like macroeconomics, microeconomics.

01:37:23,587 --> 01:37:26,558
SPEAKER_0:  That kind of stuff. Macro. And then.

01:37:26,946 --> 01:37:33,502
SPEAKER_0:  in terms of that there's a great book by Carl Truman called rise in triumph of the modern self which i think is the best book of the last 10 years

01:37:33,986 --> 01:37:42,398
SPEAKER_0:  That's been sort of impactful on some of the thoughts I've been having lately. What's the key idea in there that's- The key idea is that we've shifted the nature of how identity is done in the West.

01:37:42,722 --> 01:37:43,838
SPEAKER_0:  from how it was historically done.

01:37:44,322 --> 01:37:46,398
SPEAKER_0:  that basically for nearly all of human history...

01:37:46,818 --> 01:37:49,086
SPEAKER_0:  the way that we identify as human beings.

01:37:49,378 --> 01:37:53,950
SPEAKER_0:  is as a mix of our biological drives and then how that interacts with the social institutions around us.

01:37:54,242 --> 01:37:55,614
SPEAKER_0:  And so when you're a child, you're a bunch of...

01:37:56,130 --> 01:37:58,782
SPEAKER_0:  unfettered biological drives and it's your parents job to civilize you.

01:37:59,202 --> 01:38:07,518
SPEAKER_0:  and civilize you literally means bring you into civilization, right? you learn the rules of the road you learn how to integrate into institutions that already exist and are designed to shape you

01:38:07,874 --> 01:38:10,462
SPEAKER_0:  And it's how you interact with those institutions that makes you you.

01:38:10,786 --> 01:38:12,702
SPEAKER_0:  It's not just a set of biological drives. then

01:38:13,122 --> 01:38:14,654
SPEAKER_0:  in the modern world, we've really.

01:38:15,010 --> 01:38:16,062
SPEAKER_0:  driven toward the idea that...

01:38:16,418 --> 01:38:22,206
SPEAKER_0:  What we are is how we feel on the inside without reference to the outside world. And it's the job of the outside world to celebrate and reflect.

01:38:22,434 --> 01:38:23,998
SPEAKER_0:  what we think about ourselves on the inside.

01:38:24,610 --> 01:38:27,006
SPEAKER_0:  And so what that means is that we are driven.

01:38:27,298 --> 01:38:28,254
SPEAKER_0:  Now toward-

01:38:28,482 --> 01:38:39,614
SPEAKER_0:  fighting institutions because institutions are in positions. So everything around us, societal institutions, these are these are things that are crimping our style. They're making us not feel the way that we want to feel. And if we just destroy those things, then we'll be freer and more liberated.

01:38:40,066 --> 01:38:43,518
SPEAKER_0:  It's a much deeper model of how to think about.

01:38:43,938 --> 01:38:50,398
SPEAKER_0:  why our social politics in particular are moving in a particular direction is that a ground shift has happened in how people think about themselves.

01:38:50,754 --> 01:38:51,742
SPEAKER_0:  And this has had some...

01:38:52,258 --> 01:38:54,046
SPEAKER_0:  somewhat kind of shocking.

01:38:54,818 --> 01:38:56,693
SPEAKER_0:  a fact in terms of social politics.

01:38:56,693 --> 01:38:59,582
SPEAKER_1:  there's negative consequences in your view of that but it

01:38:59,810 --> 01:39:00,190
SPEAKER_1:  Um.

01:39:00,450 --> 01:39:02,942
SPEAKER_1:  Is there also a positive consequence of more power?

01:39:03,522 --> 01:39:05,630
SPEAKER_1:  more agency to the individual.

01:39:05,826 --> 01:39:10,366
SPEAKER_0:  I think that you can make the argument that institutions were weighing too heavily in how people formed their identity, but I think that...

01:39:10,946 --> 01:39:16,862
SPEAKER_0:  What we've done is gone significantly too far on the other side. We basically decided to blow up the institutions in favor of unfettered.

01:39:18,050 --> 01:39:18,622
SPEAKER_0:  feeling.

01:39:19,138 --> 01:39:26,878
SPEAKER_0:  slash identity and i think that that is not only a large mistake i think it's gonna have dioramifications for everything from suicidal ideation to institutional

01:39:27,362 --> 01:39:30,526
SPEAKER_0:  longevity in politics and in society more broadly.

01:39:31,138 --> 01:39:34,654
SPEAKER_1:  So speaking about the nature of self, you've been an outspoken.

01:39:34,946 --> 01:39:35,806
SPEAKER_1:  proponent of

01:39:36,098 --> 01:39:36,766
SPEAKER_1:  pro-life.

01:39:37,506 --> 01:39:37,950
SPEAKER_1:  Um...

01:39:38,434 --> 01:39:39,038
SPEAKER_1:  Can you?

01:39:39,298 --> 01:39:40,254
SPEAKER_1:  Can we start by...

01:39:40,994 --> 01:39:43,006
SPEAKER_1:  you try to steal man the case for it.

01:39:43,330 --> 01:39:44,094
SPEAKER_1:  ProChoice.

01:39:44,450 --> 01:39:48,254
SPEAKER_1:  that abortion is not murder and a woman's right to choose.

01:39:48,642 --> 01:39:50,686
SPEAKER_1:  It's a fundamental human right. Freedom.

01:39:51,330 --> 01:39:52,478
SPEAKER_0:  So I think that the...

01:39:53,058 --> 01:39:55,966
SPEAKER_0:  The only way to steal manly pro-choice case is to...

01:39:56,898 --> 01:39:58,334
SPEAKER_0:  and be ideologically consistent.

01:39:59,010 --> 01:40:01,534
SPEAKER_0:  is to suggest that there is no interest.

01:40:01,762 --> 01:40:04,030
SPEAKER_0:  in the life of the unborn.

01:40:05,154 --> 01:40:08,350
SPEAKER_0:  that counter weighs at all freedom of choice.

01:40:08,898 --> 01:40:10,270
SPEAKER_0:  So the

01:40:10,562 --> 01:40:11,966
SPEAKER_0:  So what that means is...

01:40:12,930 --> 01:40:19,326
SPEAKER_0:  We can take the full example or we can take sort of the partial example. So if we take the full example, what that would mean is that up until point of birth, which is sort of the Democratic Party.

01:40:19,874 --> 01:40:20,670
SPEAKER_0:  platform position.

01:40:21,122 --> 01:40:32,062
SPEAKER_0:  uh... that there is that a woman's right to choose ought to extend for any reason whatsoever up to point of birth the only way to argue that is the bodily autonomy is the only factor there is no countervailing factor that would ever outweigh bodily autonomy

01:40:32,770 --> 01:40:35,390
SPEAKER_0:  That would be the strongest version of the argument.

01:40:35,746 --> 01:40:37,630
SPEAKER_0:  Another version of that argument would be that

01:40:37,890 --> 01:40:42,526
SPEAKER_0:  The reason that bodily autonomy ought to weigh so heavily is because women can't...

01:40:42,754 --> 01:40:43,294
SPEAKER_0:  be thee.

01:40:43,618 --> 01:40:45,086
SPEAKER_0:  well, the equals of man.

01:40:45,314 --> 01:40:46,238
SPEAKER_0:  If the

01:40:46,562 --> 01:40:49,022
SPEAKER_0:  this institutes of biology are allowed to decide their futures.

01:40:49,442 --> 01:40:54,270
SPEAKER_0:  Right, if pregnancy changes women in a way that it doesn't change men, it's a form of sex discrimination.

01:40:54,562 --> 01:40:58,686
SPEAKER_0:  for women to ever have to go through with pregnancy, which is an argument that was made by Ruth Bader Ginsburg, kind of.

01:40:59,170 --> 01:41:02,718
SPEAKER_0:  Those are the arguments. The kind of softer version is the.

01:41:03,458 --> 01:41:05,758
SPEAKER_0:  more, I would say, emotionally resonant.

01:41:06,146 --> 01:41:07,230
SPEAKER_0:  version of the argument.

01:41:07,586 --> 01:41:08,094
SPEAKER_0:  Which is that.

01:41:08,546 --> 01:41:10,206
SPEAKER_0:  Bodily autonomy ought to outweigh.

01:41:10,434 --> 01:41:10,846
SPEAKER_0:  the

01:41:11,202 --> 01:41:12,958
SPEAKER_0:  interests of the fetus up till

01:41:13,186 --> 01:41:13,758
SPEAKER_0:  point x.

01:41:14,018 --> 01:41:25,438
SPEAKER_0:  And then people have different feelings about what point X looks like. Is it up to the point of viability? Is it up to the point of the heartbeat? Is it up to 12 weeks or 15 weeks? And that really is where the American public is, where the American public is, broadly speaking, state by state where there are various...

01:41:25,762 --> 01:41:26,878
SPEAKER_0:  Really, really varied opinions.

01:41:27,138 --> 01:41:32,958
SPEAKER_0:  But like broadly speaking, it seems like the American public by pulling data wants somewhere between a 12 and 15 week abortion restriction

01:41:33,250 --> 01:41:36,126
SPEAKER_0:  And they believe that up until 12 or 15 weeks, there's not enough there.

01:41:37,122 --> 01:41:42,206
SPEAKER_0:  to not be specific, but to be kind of how people feel about it, to outweigh a woman's bodily autonomy.

01:41:42,498 --> 01:41:48,286
SPEAKER_0:  and then beyond that point, then there's enough of an interest in the life of the preborn child.

01:41:48,578 --> 01:41:52,574
SPEAKER_0:  uh... it's developed enough that now we care about it enough that it outweighs women's bodily autonomy.

01:41:52,962 --> 01:41:54,430
SPEAKER_1:  What's the strongest case?

01:41:54,946 --> 01:41:55,998
SPEAKER_1:  for pro life.

01:41:56,290 --> 01:41:58,750
SPEAKER_0:  in your mind. In the strongest case for pro life is that.

01:41:59,330 --> 01:42:00,222
SPEAKER_0:  from conception.

01:42:00,738 --> 01:42:03,934
SPEAKER_0:  A human life has been created. It is a human life with potential.

01:42:04,290 --> 01:42:06,206
SPEAKER_0:  that human life potential with potential.

01:42:06,722 --> 01:42:08,446
SPEAKER_0:  now has an independent interest.

01:42:08,674 --> 01:42:09,598
SPEAKER_0:  in its own existence.

01:42:09,762 --> 01:42:13,630
SPEAKER_1:  If I may just ask a quick question. So conception...

01:42:13,922 --> 01:42:14,270
SPEAKER_1:  or not.

01:42:14,530 --> 01:42:16,286
SPEAKER_1:  sperm fertilizes an egg? yes

01:42:17,794 --> 01:42:20,670
SPEAKER_1:  Just to clarify the biological beginning of what concession means.

01:42:20,994 --> 01:42:26,878
SPEAKER_0:  I mean, because that is the beginning of human life. Now, there are other standards that people have drawn, right? Some people say implantation.

01:42:27,106 --> 01:42:27,806
SPEAKER_0:  in the uterus.

01:42:28,258 --> 01:42:29,694
SPEAKER_0:  Some people will suggest.

01:42:30,530 --> 01:42:35,070
SPEAKER_0:  viability some of the brain development or heart development but the the clear dividing line between

01:42:35,490 --> 01:42:41,118
SPEAKER_0:  a human life exists and a human life does not exist is the biological creation of an independent human life with its own DNA strands and etc.

01:42:41,378 --> 01:42:43,358
SPEAKER_0:  which happens at conception.

01:42:43,778 --> 01:42:45,790
SPEAKER_0:  once you acknowledge that there is that independent.

01:42:46,370 --> 01:42:53,438
SPEAKER_0:  human life with potential. And I keep calling it that because people sometimes say potential human life, it's not a potential human life, it's a human life that is not developed yet.

01:42:53,762 --> 01:42:55,070
SPEAKER_0:  to the full extent that it will develop.

01:42:55,938 --> 01:43:00,734
SPEAKER_0:  Once you say that, and once you say that it has its own interest, now you have to... Now the burden of proof is to explain.

01:43:01,218 --> 01:43:01,790
SPEAKER_0:  Why?

01:43:02,050 --> 01:43:03,006
SPEAKER_0:  Bodily Autonomy.

01:43:03,330 --> 01:43:05,374
SPEAKER_0:  ought to allow for the snuffing out.

01:43:05,922 --> 01:43:10,110
SPEAKER_0:  of that human life if we believe that human life ought not to be killed for- for-

01:43:10,754 --> 01:43:13,054
SPEAKER_0:  quote unquote, no good reason. You have to come up with a good reason.

01:43:13,282 --> 01:43:14,494
SPEAKER_0:  The burden of proof has now shifted.

01:43:14,818 --> 01:43:17,566
SPEAKER_0:  Now, you will find people who will say, well, the good reason is...

01:43:17,826 --> 01:43:25,214
SPEAKER_0:  that it's not sufficiently developed to outweigh the mental trauma or emotional trauma that a woman goes through if for example she was raped or the victim of incest.

01:43:25,762 --> 01:43:31,486
SPEAKER_0:  And that is a fairly emotionally resonant argument, but it's not necessarily positive. You can make the argument that...

01:43:31,906 --> 01:43:36,254
SPEAKER_0:  just because something horrific and horrible happened to a woman does not.

01:43:36,514 --> 01:43:37,342
SPEAKER_0:  Rob D.

01:43:37,890 --> 01:43:39,422
SPEAKER_0:  human life of its interest.

01:43:39,682 --> 01:43:40,158
SPEAKER_0:  in life.

01:43:40,770 --> 01:43:43,582
SPEAKER_0:  One of the big problems in trying to draw any line for the...

01:43:44,130 --> 01:43:46,302
SPEAKER_0:  self-interest of life in the in the

01:43:47,266 --> 01:43:47,838
SPEAKER_0:  human life.

01:43:48,162 --> 01:43:51,646
SPEAKER_0:  is that it's very difficult to draw any other line that doesn't seem somewhat arbitrary.

01:43:52,002 --> 01:43:53,598
SPEAKER_0:  You say that independent heartbeat.

01:43:54,082 --> 01:43:54,622
SPEAKER_0:  Be well.

01:43:55,202 --> 01:44:00,222
SPEAKER_0:  You know, people have pacemakers. If you say brain function, people have various levels of brain function as adults.

01:44:00,642 --> 01:44:07,262
SPEAKER_0:  if you say viability. Babies are not viable after they are born. If I left a newborn baby on a table and did not take care of it, it would be dead in two days.

01:44:07,682 --> 01:44:10,174
SPEAKER_0:  So, once you start getting into sort of these lines...

01:44:10,594 --> 01:44:12,126
SPEAKER_0:  It starts to get very fuzzy very quickly.

01:44:12,770 --> 01:44:15,934
SPEAKER_0:  And so if you're looking for sort of a bright line moral rule...

01:44:16,866 --> 01:44:19,486
SPEAKER_0:  That would be the Breitling moral rule. That's sort of the pro-life case.

01:44:19,778 --> 01:44:24,766
SPEAKER_1:  Well, there's still mysterious, difficult scientific questions of things that consciousness.

01:44:25,602 --> 01:44:26,782
SPEAKER_1:  So what to you?

01:44:27,234 --> 01:44:27,678
SPEAKER_1:  does

01:44:27,938 --> 01:44:29,246
SPEAKER_1:  the question of consciousness.

01:44:30,082 --> 01:44:31,742
SPEAKER_1:  How does it come into play in two?

01:44:32,162 --> 01:44:32,926
SPEAKER_1:  this debate.

01:44:33,186 --> 01:44:35,870
SPEAKER_0:  So I don't believe that consciousness is the...

01:44:36,578 --> 01:44:38,750
SPEAKER_0:  sole criterion by which we judge the.

01:44:39,170 --> 01:44:40,286
SPEAKER_0:  self-interest in human life.

01:44:40,994 --> 01:44:41,470
SPEAKER_0:  So.

01:44:42,530 --> 01:44:44,222
SPEAKER_0:  We are unconscious a good deal of our lives.

01:44:44,994 --> 01:44:46,974
SPEAKER_0:  That does not, we will be conscious again.

01:44:47,266 --> 01:44:49,982
SPEAKER_0:  When you're unconscious, when you're asleep, for example.

01:44:50,786 --> 01:44:54,590
SPEAKER_0:  Presumably your life is still worth living. If somebody came in and killed you, that'd be a serious-

01:44:54,818 --> 01:44:55,550
SPEAKER_0:  Moral quandary.

01:44:56,002 --> 01:44:58,206
SPEAKER_1:  At the very least. The birth of consciousness.

01:44:58,594 --> 01:44:59,294
SPEAKER_1:  the...

01:44:59,554 --> 01:45:02,526
SPEAKER_1:  the lighting up of the flame, the initial lighting up of the flame.

01:45:03,074 --> 01:45:06,910
SPEAKER_1:  There does seem to be something special about that. And it's a mystery.

01:45:07,426 --> 01:45:08,574
SPEAKER_1:  of when that happens.

01:45:08,834 --> 01:45:12,734
SPEAKER_0:  Well, I mean, Peter Surner makes the case that basically self-consciousness doesn't exist until you're two and a half.

01:45:13,346 --> 01:45:17,150
SPEAKER_0:  So he says that even infanticide should be okay. He uses the bioethicist over Princeton.

01:45:17,602 --> 01:45:17,982
SPEAKER_0:  So.

01:45:18,338 --> 01:45:24,542
SPEAKER_0:  You get into some real dicey territory once you get into consciousness. Also, the truth is that consciousness is more of a spectrum than it is a...

01:45:24,802 --> 01:45:25,630
SPEAKER_0:  a dividing line.

01:45:26,114 --> 01:45:26,910
SPEAKER_0:  Meaning that.

01:45:27,202 --> 01:45:33,502
SPEAKER_0:  There are people with various degrees of brain function. We don't actually know how conscious they are. And you can get into eugenic territory.

01:45:33,986 --> 01:45:34,782
SPEAKER_0:  pretty quickly.

01:45:35,170 --> 01:45:40,734
SPEAKER_0:  We start dividing between lives that are worth living based on levels of consciousness and lives that are not worth living based on levels of consciousness.

01:45:41,346 --> 01:45:42,526
SPEAKER_1:  Do you find it?

01:45:43,522 --> 01:45:45,150
SPEAKER_1:  the aspect of...

01:45:45,506 --> 01:45:46,398
SPEAKER_1:  Women's.

01:45:46,658 --> 01:45:47,166
SPEAKER_1:  Freedom.

01:45:47,874 --> 01:45:49,438
SPEAKER_1:  Do you feel the tension between that?

01:45:49,762 --> 01:45:51,006
SPEAKER_1:  ability to choose.

01:45:52,642 --> 01:45:55,134
SPEAKER_1:  the trajectory of your own life versus

01:45:55,810 --> 01:45:57,950
SPEAKER_1:  the rights of the unborn child.

01:45:59,298 --> 01:46:00,894
SPEAKER_0:  In one situation, yes, in one situation, no.

01:46:01,378 --> 01:46:02,014
SPEAKER_0:  if you've had.

01:46:02,786 --> 01:46:04,350
SPEAKER_0:  sex with a person voluntarily.

01:46:04,610 --> 01:46:06,654
SPEAKER_0:  And as a product of that, you are now pregnant.

01:46:08,258 --> 01:46:16,702
SPEAKER_0:  You've taken an action with a perfectly predictable result. Even if you took birth control, this is the way that human beings procreated for literally all of human existence, and by the way, also how all mammals procreate.

01:46:17,186 --> 01:46:20,190
SPEAKER_0:  So the idea that this was an entirely unforeseen consequence of your activity...

01:46:20,482 --> 01:46:21,022
SPEAKER_0:  I find.

01:46:21,314 --> 01:46:23,038
SPEAKER_0:  I have less sympathy.

01:46:23,490 --> 01:46:29,246
SPEAKER_0:  for you in that particular situation because you could have made decisions that would not lead you to this particular impasse.

01:46:29,570 --> 01:46:32,830
SPEAKER_0:  In fact, this used to be the basis of marriage, right? It was when we were a-

01:46:33,314 --> 01:46:33,790
SPEAKER_0:  Apparently.

01:46:34,306 --> 01:46:38,302
SPEAKER_0:  more terrible society we used to say that people should wait until they get married to have sex

01:46:38,594 --> 01:46:39,614
SPEAKER_0:  a position that I still hold.

01:46:40,098 --> 01:46:45,982
SPEAKER_0:  And the reason for that was because then if you have sex and you produce a child, then the child will grow up in a two-parent family with stability.

01:46:46,466 --> 01:46:51,454
SPEAKER_0:  So, you know, not a ton of sympathy there. When it comes to rape and incest, obviously heavy, heavy sympathy.

01:46:51,874 --> 01:46:54,558
SPEAKER_0:  And so that's why I think you see, statistically speaking...

01:46:54,914 --> 01:46:58,462
SPEAKER_0:  A huge percentage of Americans, including many pro-life Americans, people who consider themselves pro-life.

01:46:58,978 --> 01:47:00,830
SPEAKER_0:  would consider exceptions for rape and incest.

01:47:01,186 --> 01:47:04,446
SPEAKER_0:  one of the sort of dishonest things that I think happens in abortion debates.

01:47:04,706 --> 01:47:10,174
SPEAKER_0:  is arguing from the fringes. This tends to happen a lot. Pro-choice activists will argue from rape and incest.

01:47:10,594 --> 01:47:12,958
SPEAKER_0:  to the other 99.8% of abortions.

01:47:13,186 --> 01:47:16,958
SPEAKER_0:  Or you'll see people on the pro-life side argue from partial birth abortion to all of abortion.

01:47:17,762 --> 01:47:22,206
SPEAKER_0:  that you actually have to take on sort of mainstream case and decide whether or not that's acceptable or not.

01:47:22,562 --> 01:47:25,726
SPEAKER_1:  but to you the exception just ethically without generalizing it.

01:47:26,306 --> 01:47:29,342
SPEAKER_1:  uh... that is invalid at the exception

01:47:29,634 --> 01:47:36,286
SPEAKER_0:  I don't hold that there should be an exception for rape or incest, because again, I hold by the Brightline rule that once a human life with potential exists, it's a human life.

01:47:36,578 --> 01:47:38,622
SPEAKER_0:  then it has its own interest in life that cannot be.

01:47:39,042 --> 01:47:39,998
SPEAKER_0:  Curbed by...

01:47:40,482 --> 01:47:41,534
SPEAKER_0:  your self-interest.

01:47:42,018 --> 01:47:42,398
SPEAKER_0:  Um.

01:47:42,722 --> 01:47:45,374
SPEAKER_0:  the only exception that I hold by is the same exception that...

01:47:45,602 --> 01:47:48,158
SPEAKER_0:  Literally all pro-lifers hold by which is the life of the mother is put in danger.

01:47:48,354 --> 01:47:52,638
SPEAKER_1:  Such a tough, tough topic, because if you believe that that's the line...

01:47:53,122 --> 01:47:54,494
SPEAKER_1:  then we're committing mass murder.

01:47:55,330 --> 01:47:58,878
SPEAKER_0:  Well, or at least mass killing. So I would say that murder typically requires.

01:47:59,298 --> 01:48:01,022
SPEAKER_0:  level of mens rea.

01:48:01,314 --> 01:48:07,614
SPEAKER_0:  that may be absent in many cases of abortion. Right, because the usual follow-on question is, well, if it's a murder, why don't you prosecute the woman? And the answer is because...

01:48:08,098 --> 01:48:11,966
SPEAKER_0:  The vast majority of people who are having abortions don't actually believe that they're killing a person.

01:48:12,834 --> 01:48:13,630
SPEAKER_0:  They- they- they-

01:48:13,954 --> 01:48:16,766
SPEAKER_0:  have a very different view of what is exactly happening.

01:48:17,186 --> 01:48:18,750
SPEAKER_0:  So, you know, I would say that.

01:48:19,170 --> 01:48:22,974
SPEAKER_0:  There are all sorts of interesting hypotheticals that come in to play when it comes to abortion.

01:48:23,266 --> 01:48:24,798
SPEAKER_0:  and you can play them.

01:48:25,122 --> 01:48:26,494
SPEAKER_0:  Any which way. But-

01:48:27,650 --> 01:48:32,798
SPEAKER_0:  levels that, let's put it this way, there are gradations of wrongs. I don't think that all abortions are equally.

01:48:33,442 --> 01:48:34,558
SPEAKER_0:  blame worthy even if I would.

01:48:35,170 --> 01:48:36,286
SPEAKER_0:  even if I would ban.

01:48:37,474 --> 01:48:38,270
SPEAKER_0:  Virtually all of them.

01:48:38,530 --> 01:48:39,134
SPEAKER_0:  I can't...

01:48:39,362 --> 01:48:42,526
SPEAKER_0:  I think that they're mitigating circumstances that make...

01:48:43,202 --> 01:48:45,758
SPEAKER_0:  while being wrong, some abortions less morally.

01:48:45,986 --> 01:48:47,518
SPEAKER_0:  more than others i think that

01:48:47,810 --> 01:48:50,462
SPEAKER_0:  You know, there is a, I can admit a difference between.

01:48:51,266 --> 01:48:51,774
SPEAKER_0:  between.

01:48:52,098 --> 01:48:52,638
SPEAKER_0:  Killing a-

01:48:53,346 --> 01:48:53,982
SPEAKER_0:  A two week old.

01:48:54,562 --> 01:49:00,414
SPEAKER_0:  embryo in the womb and stabbing a seven-year-old in the face. Like, I can recognize all that while still saying I think that it would be wrong to terminate a pregnancy.

01:49:00,994 --> 01:49:04,606
SPEAKER_1:  Do you think the question of when life begins, which I think is a fascinating question.

01:49:05,186 --> 01:49:05,758
SPEAKER_1:  Um...

01:49:06,018 --> 01:49:07,998
SPEAKER_1:  Is it a question of science or a question of religion?

01:49:08,322 --> 01:49:09,886
SPEAKER_0:  When one life begins, it's a question of science.

01:49:10,210 --> 01:49:13,406
SPEAKER_0:  when that life becomes valuable enough for people to want to protect it.

01:49:13,858 --> 01:49:21,054
SPEAKER_0:  is gonna be a question that is beyond science. Science doesn't have moral judgements to make about the value of human life. This is one of the problems that...

01:49:21,314 --> 01:49:27,518
SPEAKER_0:  Sam Harris and I have had this argument many times and it's always kind of interesting. Because Sam is of the opinion that you can get to aught from his.

01:49:27,906 --> 01:49:32,542
SPEAKER_0:  Right? That science says is, therefore we can learn ought. So human flourishing is the goal of life.

01:49:32,930 --> 01:49:35,838
SPEAKER_0:  And I always say to him, I don't see where you get that from evolutionary biology.

01:49:36,386 --> 01:49:42,846
SPEAKER_0:  You can assume it, just say you're assuming it, but don't pretend that that is a conclusion that you can draw straight from.

01:49:43,778 --> 01:49:45,598
SPEAKER_0:  biological reality itself.

01:49:45,986 --> 01:49:48,158
SPEAKER_0:  Because obviously that doesn't exist in the animal world, for example.

01:49:48,482 --> 01:49:49,406
SPEAKER_0:  Nobody assumes the innate.

01:49:49,730 --> 01:49:50,558
SPEAKER_0:  value of a rant.

01:49:51,554 --> 01:49:55,934
SPEAKER_1:  I think I know your answer to this, but let's test it, because I think you're going to be wrong.

01:49:56,418 --> 01:49:58,526
SPEAKER_1:  So there's a robot behind you.

01:49:59,106 --> 01:50:01,054
SPEAKER_1:  Do you think there will be a time in the future?

01:50:01,634 --> 01:50:05,310
SPEAKER_1:  when it will be unethical and illegal to kill a robot.

01:50:05,602 --> 01:50:06,878
SPEAKER_1:  because they will have sentience.

01:50:08,386 --> 01:50:09,822
SPEAKER_1:  My guess is you would say...

01:50:10,082 --> 01:50:11,806
SPEAKER_1:  No, Lex, there's-

01:50:12,130 --> 01:50:14,686
SPEAKER_1:  because there's a fundamental difference between humans and robots.

01:50:15,010 --> 01:50:17,406
SPEAKER_1:  And I just want to get you on record because I think you'll be wrong.

01:50:17,506 --> 01:50:17,886
SPEAKER_0:  Um...

01:50:18,402 --> 01:50:22,910
SPEAKER_0:  I mean, it depends on the level of development, I would assume, of the robots. I mean, you're assuming.

01:50:23,298 --> 01:50:24,830
SPEAKER_0:  a complexity in the robots that...

01:50:25,506 --> 01:50:27,166
SPEAKER_0:  that eventually imitates what?

01:50:27,458 --> 01:50:29,054
SPEAKER_0:  we in the religious life would call the human soul.

01:50:29,282 --> 01:50:34,142
SPEAKER_0:  The ability to choose freely, for example, which I believe is sort of the capacity for

01:50:34,882 --> 01:50:36,542
SPEAKER_0:  human beings, the ability to suffer.

01:50:36,898 --> 01:50:37,214
SPEAKER_0:  Yeah.

01:50:37,602 --> 01:50:38,686
SPEAKER_0:  If all of that.

01:50:40,738 --> 01:50:41,182
SPEAKER_0:  B.

01:50:42,498 --> 01:50:48,478
SPEAKER_0:  Approved and not programmed, meaning the freely willed capacity of a machine to do

01:50:49,346 --> 01:50:50,238
SPEAKER_0:  X, Y, or Z.

01:50:50,466 --> 01:50:53,566
SPEAKER_1:  you could not pinpoint exactly where it happens in the pro.

01:50:53,954 --> 01:50:54,462
SPEAKER_0:  Right.

01:50:55,074 --> 01:50:56,318
SPEAKER_0:  It's not deterministic.

01:50:57,058 --> 01:50:58,270
SPEAKER_0:  Um, then...

01:50:58,498 --> 01:51:00,190
SPEAKER_0:  It would raise serious moral issues, for sure.

01:51:00,674 --> 01:51:03,134
SPEAKER_0:  I'm not sure I know the answer to that question. Are you afraid of that time?

01:51:03,618 --> 01:51:04,734
SPEAKER_0:  I'm not sure I'm afraid of that time.

01:51:04,962 --> 01:51:05,854
SPEAKER_0:  I mean, it's-

01:51:06,754 --> 01:51:11,629
SPEAKER_0:  any more than I'd be afraid if aliens arrived in the world and had these characteristics.

01:51:11,629 --> 01:51:16,126
SPEAKER_1:  a lot of moral complexities and they don't necessarily have to be in the physical space, that can be in the digital space.

01:51:16,482 --> 01:51:21,342
SPEAKER_1:  There's an increased sophistication and number of bots on the internet including on Twitter.

01:51:21,666 --> 01:51:22,078
SPEAKER_1:  Uh...

01:51:22,498 --> 01:51:25,854
SPEAKER_1:  as they become more and more intelligent, there's going to be serious questions about.

01:51:26,498 --> 01:51:27,838
SPEAKER_1:  What is our moral duty?

01:51:28,354 --> 01:51:29,918
SPEAKER_1:  to protect ones that have.

01:51:30,434 --> 01:51:32,126
SPEAKER_1:  or claim to have an identity.

01:51:32,610 --> 01:51:36,638
SPEAKER_0:  And that'll be really interesting. Actually, what I'm afraid of is the opposite happening, meaning that people...

01:51:37,282 --> 01:51:42,942
SPEAKER_0:  The worst that should happen is that we develop robots so sophisticated that they appear to have free will, and then we treat them with...

01:51:43,266 --> 01:51:43,934
SPEAKER_0:  Human dignity.

01:51:44,226 --> 01:51:47,230
SPEAKER_0:  That should be the worst that happens. What I'm afraid of is the opposite, is that that.

01:51:47,682 --> 01:51:56,478
SPEAKER_0:  we if we're talking about this particular hypothetical that we develop robots that have all of these apparent abilities and then we dehumanize them which leads us to also dehumanize the other humans around us.

01:51:56,962 --> 01:51:57,342
SPEAKER_0:  which

01:51:57,922 --> 01:51:58,974
SPEAKER_0:  you could easily see happening.

01:51:59,394 --> 01:52:01,246
SPEAKER_0:  the devaluation of life to the point where

01:52:01,858 --> 01:52:05,246
SPEAKER_0:  It doesn't really, I mean, people have always treated, unfortunately.

01:52:05,506 --> 01:52:06,366
SPEAKER_0:  newly discovered.

01:52:06,818 --> 01:52:13,918
SPEAKER_0:  other humans this way so it i don't think that's actually a new problem i think it's a it's a pretty old problem it'll just be interesting when it's made of human hands

01:52:14,146 --> 01:52:18,718
SPEAKER_1:  Yeah, it's an opportunity to celebrate humanity or to...

01:52:19,554 --> 01:52:21,310
SPEAKER_1:  bring out the worst in humanity.

01:52:21,922 --> 01:52:25,278
SPEAKER_1:  So the derision that naturally happens, like you said, pointing out.

01:52:25,794 --> 01:52:27,966
SPEAKER_1:  the other. Let me ask you about climate change.

01:52:28,674 --> 01:52:29,726
SPEAKER_1:  There's a...

01:52:29,954 --> 01:52:31,294
SPEAKER_1:  Let's go from the meme.

01:52:31,522 --> 01:52:34,046
SPEAKER_1:  to the profound philosophy.

01:52:34,306 --> 01:52:38,014
SPEAKER_1:  Okay, the meme is there's a clip of you talking about climate change and saying that.

01:52:38,114 --> 01:52:40,199
SPEAKER_0:  The Aquaman meme. You said that for the first time.

01:52:40,199 --> 01:52:42,142
SPEAKER_1:  the sake of argument if the water level.

01:52:42,530 --> 01:52:46,366
SPEAKER_1:  arises five to ten feet in the next hundred years people will just sell

01:52:46,690 --> 01:52:47,998
SPEAKER_1:  their homes and move.

01:52:48,674 --> 01:52:50,462
SPEAKER_1:  And then the meme is Zelda who?

01:52:50,882 --> 01:52:52,670
SPEAKER_1:  uh... can you argue both sides that

01:52:52,930 --> 01:53:01,726
SPEAKER_0:  The argument that they're making is a straw man. The argument that I'm making is over time. I don't mean that if a tsunami's about to hit your house, you can list it on eBay. That's not what I mean, obviously. What I mean is that human beings...

01:53:02,018 --> 01:53:04,670
SPEAKER_0:  have an extraordinary ability to adapt. It's actually our best quality.

01:53:05,026 --> 01:53:06,014
SPEAKER_0:  uh... and that

01:53:06,242 --> 01:53:09,310
SPEAKER_0:  As water levels rise, real estate prices in those areas tends to fall.

01:53:09,762 --> 01:53:12,670
SPEAKER_0:  that over time people tend to abandon those areas.

01:53:13,218 --> 01:53:14,334
SPEAKER_0:  they tend to leave.

01:53:14,690 --> 01:53:24,158
SPEAKER_0:  They tend to, right now, sell their houses, and then they tend to move. And eventually, those houses will be worthless, and you won't have anybody to sell to, but presumably not that many people will be living there by that point, which is one of the reasons.

01:53:24,386 --> 01:53:26,261
SPEAKER_0:  Why the price would be low? Because there's no demand. So

01:53:26,261 --> 01:53:30,910
SPEAKER_1:  It's over 100 years, so all of these price dynamics are very gradual.

01:53:31,234 --> 01:53:32,359
SPEAKER_1:  relative to the other.

01:53:32,359 --> 01:53:39,390
SPEAKER_0:  Correct. That's why the joke of it, of course, is that like I'm saying that tomorrow there's a tsunami on your source step and you're like, oh, Bob will buy my house.

01:53:39,938 --> 01:53:44,063
SPEAKER_0:  Bob Ainkin, buyer house, we all get that. But it's a funny name, I'll admit I laughed at it.

01:53:44,063 --> 01:53:45,950
SPEAKER_1:  How's your view on climate change?

01:53:46,402 --> 01:53:48,062
SPEAKER_1:  the human.

01:53:48,354 --> 01:53:53,694
SPEAKER_1:  contribution to climate change, what we should do in terms of policy to respond to climate change, how has that changed over the years?

01:53:54,050 --> 01:53:54,750
SPEAKER_0:  I would say.

01:53:55,650 --> 01:54:03,262
SPEAKER_0:  The truth is for years and years I've believed that climate change was a reality and that anthropogenic climate change is a reality.

01:54:03,650 --> 01:54:09,726
SPEAKER_0:  I don't argue with the IPCC estimates. I know climatologists at places like MIT or Caltech, and they know this stuff better than I do.

01:54:09,954 --> 01:54:15,646
SPEAKER_0:  So, you know, the notion that climate change is just not happening or that human beings have not contributed to climate change.

01:54:15,938 --> 01:54:22,046
SPEAKER_0:  I find doubtful. The question is to what extent human beings are contributing to climate change. Is it 50%? Is it 70%? Is it 90%?

01:54:22,306 --> 01:54:24,958
SPEAKER_0:  I think there's a little bit more play in the joints there, so it's not totally clear.

01:54:25,218 --> 01:54:31,966
SPEAKER_0:  The one thing I do know, and this I know with factual accuracy, is that all of the measures that are currently being proposed are unworkable and will not happen.

01:54:32,546 --> 01:54:35,230
SPEAKER_0:  So when people say Paris Climate Accords.

01:54:35,554 --> 01:54:38,942
SPEAKER_0:  Even if those were imposed, you're talking about lowering the potential trajectory.

01:54:39,234 --> 01:54:41,054
SPEAKER_0:  of climate change by a fraction of a degree.

01:54:41,666 --> 01:54:43,102
SPEAKER_0:  If you're talking about

01:54:43,394 --> 01:54:43,774
SPEAKER_0:  the

01:54:44,098 --> 01:54:45,086
SPEAKER_0:  if you're talking about.

01:54:45,314 --> 01:54:47,998
SPEAKER_0:  Green New Deal, net zero by 2050.

01:54:48,546 --> 01:54:51,038
SPEAKER_0:  The carbon is up there in the air and the climate change is going to happen.

01:54:51,490 --> 01:54:58,174
SPEAKER_0:  Also, you're assuming that geopolitical dynamics don't exist, so everybody's gonna magically get on the same page, and we're all gonna be...

01:54:58,850 --> 01:55:02,046
SPEAKER_0:  imposing massive carbon taxes to get to net zero.

01:55:02,370 --> 01:55:05,598
SPEAKER_0:  By 2050. I mean like hundreds of times higher than they currently are.

01:55:05,986 --> 01:55:10,814
SPEAKER_0:  And that's not me saying, that's Klaus Schwab saying this of the World Economic Forum, who's a big advocate of exactly this sort of policy.

01:55:11,426 --> 01:55:20,158
SPEAKER_0:  And the reality is that we're gonna have to accept that at least 1.5 degrees Celsius of climate change is baked into the cake by the end of the century. Again, not me talking, William Nordhaus, the economist, who just won the Nobel Prize in this stuff talking.

01:55:20,578 --> 01:55:23,230
SPEAKER_0:  And so what that suggests to me is what we've always known.

01:55:23,490 --> 01:55:25,918
SPEAKER_0:  human beings are crap at mitigation and excellence in adaptation.

01:55:26,466 --> 01:55:28,766
SPEAKER_0:  We are very bad at mitigating our own faults.

01:55:29,090 --> 01:55:31,230
SPEAKER_0:  We are very good at adapting to the problems as they exist.

01:55:31,938 --> 01:55:34,782
SPEAKER_0:  Which means that all of the estimates that billions will die.

01:55:35,106 --> 01:55:38,654
SPEAKER_0:  that there will be mass starvation, that we'll see the migration in just-

01:55:39,042 --> 01:55:41,310
SPEAKER_0:  a few years of hundreds of millions of people

01:55:41,570 --> 01:55:42,110
SPEAKER_0:  Those are wrong.

01:55:42,370 --> 01:55:44,158
SPEAKER_0:  What you'll see is a gradual change of living.

01:55:44,450 --> 01:55:46,910
SPEAKER_0:  People will move away from areas that are inundated on the coast.

01:55:47,138 --> 01:55:51,838
SPEAKER_0:  You'll see people building seawalls. You'll see people adapting new technologies to suck carbon out of the air.

01:55:52,098 --> 01:55:53,918
SPEAKER_0:  you will see geoengineering.

01:55:54,242 --> 01:55:56,478
SPEAKER_0:  And this is the sort of stuff that we should be focused on.

01:55:56,738 --> 01:56:01,822
SPEAKER_0:  and the sort of bizarre focus on what if we just keep tossing hundreds of billions of dollars?

01:56:02,050 --> 01:56:11,966
SPEAKER_0:  at the same three technologies over and over in the hopes that if we subsidize it, this will magically make it more efficient. I've seen no evidence whatsoever that that is going to be the way that we get ourselves.

01:56:12,290 --> 01:56:16,894
SPEAKER_0:  out of this necessity being the mother of invention I think human beings will adapt because we have adapted and we will continue to adapt.

01:56:17,250 --> 01:56:18,974
SPEAKER_1:  So to the degree we invest.

01:56:19,522 --> 01:56:22,334
SPEAKER_1:  in the thread of this should be into the

01:56:22,562 --> 01:56:25,187
SPEAKER_1:  policies that help with the adaptation versus the mitigation.

01:56:25,187 --> 01:56:25,982
SPEAKER_0:  Repsie walls.

01:56:26,530 --> 01:56:27,358
SPEAKER_0:  Geoengineering.

01:56:27,650 --> 01:56:29,310
SPEAKER_0:  developing technologies that carbon out of the air.

01:56:29,858 --> 01:56:37,310
SPEAKER_0:  Again, if I thought that there was more sort of hope for the green technologies currently in play, then subsidization of those technologies I might be a little bit more for, but I haven't seen.

01:56:37,602 --> 01:56:38,078
SPEAKER_0:  Tremendous.

01:56:38,306 --> 01:56:41,982
SPEAKER_0:  progress over the course of the last 30 years in the reliability of, for example, wind energy.

01:56:42,530 --> 01:56:43,774
SPEAKER_0:  or the...

01:56:44,098 --> 01:56:47,262
SPEAKER_0:  ability to store solar energy to the extent necessary to actually

01:56:47,682 --> 01:56:48,318
SPEAKER_0:  Power Grid.

01:56:48,674 --> 01:56:50,549
SPEAKER_1:  What's your thoughts on nuclear energy?

01:56:50,549 --> 01:56:54,270
SPEAKER_0:  Nuclear energy is great. Nuclear energy is a proven source of energy and we should be radically...

01:56:55,426 --> 01:56:56,190
SPEAKER_0:  Extending.

01:56:56,546 --> 01:57:06,270
SPEAKER_0:  the use of nuclear energy. To me, honestly, this is like a litmus test question as to whether you take climate change seriously. If you're on right or left and you take climate change seriously, you should be in favor of nuclear energy.

01:57:06,530 --> 01:57:07,774
SPEAKER_0:  If you're not, I know that you're just.

01:57:08,354 --> 01:57:09,150
SPEAKER_0:  give other priorities

01:57:09,410 --> 01:57:15,230
SPEAKER_1:  Yeah, the fascinating thing about the climate change debate is the dynamics of the fear mongering over the past few decades.

01:57:15,586 --> 01:57:18,654
SPEAKER_1:  because some of the nuclear energy was tied up into that somehow.

01:57:19,010 --> 01:57:21,886
SPEAKER_1:  There's a lot of fear about nuclear energy. It seems like...

01:57:22,466 --> 01:57:25,886
SPEAKER_1:  There's a lot of social phenomena, social dynamics involved versus

01:57:26,466 --> 01:57:28,574
SPEAKER_1:  dealing with just science.

01:57:28,994 --> 01:57:30,046
SPEAKER_1:  It's interesting to watch.

01:57:30,402 --> 01:57:33,854
SPEAKER_1:  And if on my darker days, it makes me cynical about.

01:57:34,210 --> 01:57:37,214
SPEAKER_1:  our ability to use reason and science to...

01:57:37,602 --> 01:57:39,102
SPEAKER_1:  to deal with the threats of the world.

01:57:39,426 --> 01:57:43,326
SPEAKER_0:  I think that our ability to use reason and science to deal with threats of the world is almost

01:57:43,618 --> 01:57:44,638
SPEAKER_0:  A time frame question.

01:57:45,250 --> 01:57:51,358
SPEAKER_0:  So I think that we're, again, we're very bad at looking down the road and saying, because people can't handle, for example, even things like compound interest.

01:57:51,618 --> 01:57:54,142
SPEAKER_0:  Like the idea that if I put a dollar in the bank today that

01:57:54,786 --> 01:57:58,206
SPEAKER_0:  15 years from now that's gonna be worth a lot more than a dollar. People can't actually see that.

01:57:58,530 --> 01:58:02,974
SPEAKER_0:  And so the idea of let's foresee a problem, then we'll deal with it right now, as opposed to 30 years down the road.

01:58:03,266 --> 01:58:08,510
SPEAKER_0:  Typically we let the problem happen and then we solve it and it's bloodier and worse than it would have been if we had solved it 30 years ago.

01:58:09,346 --> 01:58:17,543
SPEAKER_0:  it is in fact effective. And sometimes it turns out the solution that we're proposing 30 years in advance is not effective. And that can be a major problem as well. So that's–

01:58:17,543 --> 01:58:22,110
SPEAKER_1:  That's then to stillman the case for fear-mongering, for irrational fear-mongering.

01:58:22,626 --> 01:58:25,790
SPEAKER_1:  We need to be scared shitless in order for us to do anything.

01:58:26,146 --> 01:58:27,134
SPEAKER_1:  So that's that's.

01:58:27,490 --> 01:58:27,998
SPEAKER_1:  You know, I'm-

01:58:28,322 --> 01:58:33,886
SPEAKER_1:  generally against that, but maybe on a population scale, maybe some of that is necessary.

01:58:34,434 --> 01:58:38,398
SPEAKER_1:  for us to respond appropriately for long-term threats.

01:58:39,074 --> 01:58:40,094
SPEAKER_1:  we should be scared.

01:58:40,290 --> 01:58:42,046
SPEAKER_0:  But I don't think that we can actually do that though.

01:58:42,498 --> 01:58:45,022
SPEAKER_0:  Like, first of all, I think that it's...

01:58:45,282 --> 01:58:46,686
SPEAKER_0:  platonic lies are generally bad.

01:58:46,914 --> 01:58:50,942
SPEAKER_0:  And then second of all, I don't think that we actually have the capacity to do this. I think that the people who are-

01:58:51,938 --> 01:58:56,478
SPEAKER_0:  the sort of elites of our society who get together in rooms and talk about this sort of stuff. And I've been in some of those meetings.

01:58:56,898 --> 01:59:14,302
SPEAKER_0:  at my synagogue Friday night, actually. No, but yeah. I was gonna make the joke, but I'm glad you did. Yeah, you know, I've been in rooms, Davos-like rooms. And when people discuss these sorts of topics and they're like, what if we just tell people that it's gonna be a disaster with tsunamis and day after tomorrow? Like, you guys wouldn't have that power.

01:59:14,690 --> 01:59:15,070
SPEAKER_0:  You don't.

01:59:15,938 --> 01:59:18,238
SPEAKER_0:  By the way, you dramatically undercut your own power because of COVID.

01:59:18,466 --> 01:59:20,318
SPEAKER_0:  to do this sort of stuff because a lot of the

01:59:20,578 --> 01:59:24,478
SPEAKER_0:  sort of, what if we scare the living hell out of you to the point where you stay in your own house for-

01:59:24,738 --> 01:59:27,454
SPEAKER_0:  two years and we tell you you can't send your kids to school.

01:59:27,778 --> 01:59:30,686
SPEAKER_0:  and then we tell you that the vaccine is going to prevent transmission.

01:59:31,234 --> 01:59:39,102
SPEAKER_0:  And then we also tell you that we need to spend $7 trillion in one year and it won't have any inflationary effect and it turns out you're wrong on literally all of those things.

01:59:39,586 --> 01:59:46,215
SPEAKER_0:  The last few years have done more to undermine institutional trust than any time in probably American history. It's pretty pretty amazing. Yeah, I tend to

01:59:46,215 --> 01:59:48,510
SPEAKER_1:  agree with that the only thing we have to fear is fear itself.

01:59:49,538 --> 01:59:50,526
SPEAKER_1:  Let me ask you.

01:59:51,074 --> 01:59:51,518
SPEAKER_1:  back.

01:59:52,130 --> 01:59:53,406
SPEAKER_1:  to the question of God.

01:59:54,338 --> 01:59:56,158
SPEAKER_1:  and a big ridiculous question, who's God?

01:59:57,218 --> 01:59:59,166
SPEAKER_0:  Who is God? So I'm going to, um...

02:00:00,002 --> 02:00:03,006
SPEAKER_0:  I'm going to use sort of the Aquinas formulation of...

02:00:03,458 --> 02:00:04,446
SPEAKER_0:  what God is.

02:00:04,802 --> 02:00:05,406
SPEAKER_0:  Right, that...

02:00:05,954 --> 02:00:06,654
SPEAKER_0:  If you...

02:00:07,426 --> 02:00:08,190
SPEAKER_0:  if there is a.

02:00:08,834 --> 02:00:14,270
SPEAKER_0:  cause of all things, not physical things, if there is a cause underlying the reason of the universe.

02:00:14,530 --> 02:00:15,998
SPEAKER_0:  then that is the thing we call God.

02:00:16,866 --> 02:00:18,078
SPEAKER_0:  So, not a big...

02:00:18,370 --> 02:00:19,326
SPEAKER_0:  and this guy with the beard.

02:00:19,970 --> 02:00:25,758
SPEAKER_0:  You know, like, he is the force underlying the logic of the universe, if there is a logic to the universe.

02:00:26,242 --> 02:00:27,134
SPEAKER_0:  I and

02:00:27,426 --> 02:00:28,574
SPEAKER_0:  He is the.

02:00:29,314 --> 02:00:31,646
SPEAKER_0:  creator in the Judaic view of that universe.

02:00:32,834 --> 02:00:34,846
SPEAKER_0:  and he does have an interest.

02:00:35,298 --> 02:00:35,742
SPEAKER_0:  in

02:00:36,034 --> 02:00:37,182
SPEAKER_0:  us living in accordance.

02:00:37,570 --> 02:00:38,302
SPEAKER_0:  with the

02:00:38,882 --> 02:00:40,062
SPEAKER_0:  laws of the universe that...

02:00:40,322 --> 02:00:45,502
SPEAKER_0:  If you're a religious Jew, you are encoded in the Torah, but if you're not a religious Jew, you would be encoded in the natural law.

02:00:45,794 --> 02:00:47,326
SPEAKER_0:  by sort of Catholic theology.

02:00:47,810 --> 02:00:53,502
SPEAKER_1:  Why do you think God created the universe? Or as is popularly asked, what do you think is the meaning?

02:00:54,562 --> 02:00:55,687
SPEAKER_1:  behind it what's the meaning

02:00:55,687 --> 02:00:57,246
SPEAKER_0:  of life. Meaning of life?

02:00:57,698 --> 02:01:00,702
SPEAKER_0:  So I think that the meaning of life is to...

02:01:01,154 --> 02:01:01,918
SPEAKER_0:  Fulfill.

02:01:02,594 --> 02:01:05,470
SPEAKER_0:  what God made you to do, and that is a series of roles.

02:01:06,402 --> 02:01:09,182
SPEAKER_0:  I think that human beings, and here you have to look to human nature.

02:01:09,506 --> 02:01:10,974
SPEAKER_0:  rather than looking kind of to big.

02:01:11,426 --> 02:01:11,838
SPEAKER_0:  questions.

02:01:13,570 --> 02:01:18,974
SPEAKER_0:  i've had a ball something that i've ever had a lot of you know and i'm ready to book about this actually that that i call

02:01:19,298 --> 02:01:20,926
SPEAKER_0:  colloquially, role theory.

02:01:21,314 --> 02:01:23,134
SPEAKER_0:  And basically the idea is that

02:01:23,810 --> 02:01:27,710
SPEAKER_0:  The way that we interact with the world is through a series of roles. And those are also the things we find most.

02:01:28,322 --> 02:01:28,958
SPEAKER_0:  Important?

02:01:29,314 --> 02:01:30,334
SPEAKER_0:  and most implementable.

02:01:30,882 --> 02:01:32,734
SPEAKER_0:  And there's sort of virtue ethics.

02:01:32,994 --> 02:01:33,662
SPEAKER_0:  Right, which which

02:01:34,050 --> 02:01:37,310
SPEAKER_0:  suggests that if we act in accordance with virtue, like Aristotle.

02:01:37,634 --> 02:01:39,646
SPEAKER_0:  then we will be living the most fulfilled.

02:01:39,938 --> 02:01:40,830
SPEAKER_0:  and meaningful life.

02:01:41,378 --> 02:01:42,110
SPEAKER_0:  And then you have sort of.

02:01:42,562 --> 02:01:45,598
SPEAKER_0:  deontological ethics, like, content ethics, it's a rule-based ethic.

02:01:46,498 --> 02:01:48,030
SPEAKER_0:  You follow the rules, then you'll, then you'll...

02:01:48,354 --> 02:01:49,278
SPEAKER_0:  Find the meaning of life.

02:01:49,634 --> 02:01:50,590
SPEAKER_0:  And then what I'm.

02:01:50,914 --> 02:01:59,006
SPEAKER_0:  proposing is that there's something that I would call role ethics, which is there are a series of roles that we play across our lives, which are also the things that we tend to put on our tombstones and find the most meaningful.

02:01:59,330 --> 02:01:59,774
SPEAKER_0:  So.

02:02:00,450 --> 02:02:01,374
SPEAKER_0:  when you go to a cemetery.

02:02:01,730 --> 02:02:05,726
SPEAKER_0:  You can see what people found most meaningful because the stuff they put on the stone that has like four words on it, right?

02:02:06,178 --> 02:02:07,102
SPEAKER_0:  You're like beloved father.

02:02:07,394 --> 02:02:07,902
SPEAKER_0:  Love it, Mother.

02:02:08,258 --> 02:02:08,798
SPEAKER_0:  Sister.

02:02:09,154 --> 02:02:09,630
SPEAKER_0:  Brother.

02:02:10,402 --> 02:02:12,190
SPEAKER_0:  and you might have a job once in a while.

02:02:12,930 --> 02:02:14,078
SPEAKER_0:  a creator.

02:02:14,370 --> 02:02:20,702
SPEAKER_0:  a religious person, right? These are all roles that have existed across societies and across humanity. And those are the things where we actually find meaning.

02:02:21,058 --> 02:02:22,142
SPEAKER_0:  and the way that we navigate.

02:02:22,434 --> 02:02:23,166
SPEAKER_0:  those roles.

02:02:23,522 --> 02:02:24,446
SPEAKER_0:  brings us meaning.

02:02:24,674 --> 02:02:25,694
SPEAKER_0:  And I think that...

02:02:26,082 --> 02:02:26,494
SPEAKER_0:  God.

02:02:27,042 --> 02:02:31,710
SPEAKER_0:  created us in order to fulfill those roles for purposes that I can't begin to understand because I ain't him.

02:02:32,450 --> 02:02:32,926
SPEAKER_0:  and

02:02:33,218 --> 02:02:35,230
SPEAKER_0:  the more we recognize.

02:02:35,842 --> 02:02:38,142
SPEAKER_0:  those roles and the more we live those roles.

02:02:38,594 --> 02:02:49,310
SPEAKER_0:  And then we can express freedom within those roles. I think that the liberty exists inside each of those roles and that's what makes all of our lives different and fun. We all parents in different ways, but being a parent is a meaningful role. We all have spouses.

02:02:49,538 --> 02:02:49,950
SPEAKER_0:  But

02:02:50,530 --> 02:02:53,854
SPEAKER_0:  you know, how you interact that relationship is what makes your life meaningful and interesting.

02:02:54,242 --> 02:02:55,486
SPEAKER_0:  That is.

02:02:55,906 --> 02:02:56,990
SPEAKER_0:  That is what we were put on earth.

02:02:57,314 --> 02:03:02,718
SPEAKER_0:  to do it, if we perform those roles properly. And those roles do include things like being a creator, like we have a creative instinct as human beings.

02:03:03,010 --> 02:03:04,510
SPEAKER_0:  being a creator, being an innovator.

02:03:05,282 --> 02:03:07,102
SPEAKER_0:  being a defender of your family.

02:03:07,490 --> 02:03:15,198
SPEAKER_0:  Being a social member of your community, which is something that we're built to do. If we fulfill those roles properly, then we will have made the world a better place than we inherited it.

02:03:15,426 --> 02:03:16,702
SPEAKER_0:  and we will also have, have.

02:03:17,730 --> 02:03:20,254
SPEAKER_0:  had the joy of experiencing the sort of flow.

02:03:20,738 --> 02:03:22,782
SPEAKER_0:  they talk about in psychology.

02:03:23,138 --> 02:03:23,518
SPEAKER_0:  where it.

02:03:23,810 --> 02:03:25,854
SPEAKER_0:  when you engage in these roles, you actually do feel a flow.

02:03:26,306 --> 02:03:29,502
SPEAKER_1:  So these roles are a fundamental part of the human condition? Yes.

02:03:29,730 --> 02:03:33,662
SPEAKER_1:  So the book you're working on is constructing a...

02:03:34,530 --> 02:03:36,414
SPEAKER_1:  a system to help us understand.

02:03:37,058 --> 02:03:40,094
SPEAKER_0:  It's looking at, let's assume that all of that's true.

02:03:40,354 --> 02:03:42,046
SPEAKER_0:  The real question in the book is how do you construct?

02:03:42,306 --> 02:03:44,318
SPEAKER_0:  a flourishing and useful

02:03:45,122 --> 02:03:46,302
SPEAKER_0:  society and politics.

02:03:46,722 --> 02:03:48,478
SPEAKER_1:  Ah, so a society level.

02:03:49,026 --> 02:03:50,910
SPEAKER_1:  If this is our understanding of a human being.

02:03:51,138 --> 02:03:52,263
SPEAKER_1:  How do we construct a good system?

02:03:52,263 --> 02:03:57,118
SPEAKER_0:  Right exactly because I think that a lot of political theory is right now based in either

02:03:57,890 --> 02:04:00,510
SPEAKER_0:  J.S. Mill kind of thought, which is all that a good-

02:04:01,026 --> 02:04:03,518
SPEAKER_0:  Politics does, it allows you to wave your hand around until you hit somebody in the face.

02:04:03,874 --> 02:04:09,406
SPEAKER_0:  or Rawlsian thought, which is what if we constructed society in order to achieve the most for the least essentially?

02:04:09,762 --> 02:04:11,070
SPEAKER_0:  You know, what if we...

02:04:11,650 --> 02:04:16,830
SPEAKER_0:  constructed society around what actually makes humans the most fulfilled and that is the the

02:04:18,018 --> 02:04:19,966
SPEAKER_0:  fulfillment of these particular roles.

02:04:20,578 --> 02:04:24,094
SPEAKER_0:  And where does liberty come into that, right? How do you avoid the idea of a tyranny in that? Wellussy

02:04:24,418 --> 02:04:29,406
SPEAKER_0:  You have to be a mother, you must be a father, you must be a... Where does freedom come into that? Can you reject those roles?

02:04:29,698 --> 02:04:33,438
SPEAKER_0:  totally as a society and be okay? The answer probably is not. It's a new society.

02:04:33,666 --> 02:04:34,270
SPEAKER_0:  that actually

02:04:35,266 --> 02:04:35,870
SPEAKER_0:  promotes.

02:04:36,258 --> 02:04:45,022
SPEAKER_0:  and protects those roles, but also protects the freedom inside those roles. And that raises a more fundamental question of what exactly liberty is for. And I think that both the right and the left actually.

02:04:45,282 --> 02:04:49,758
SPEAKER_0:  tend to make a mistake when they discuss liberty. The left tends to think that liberty is an ultimate good.

02:04:50,754 --> 02:04:57,246
SPEAKER_0:  simple choice makes a bad thing good, which is not true. And I think the right talks about liberty in almost the same terms, sometimes.

02:04:57,602 --> 02:04:58,910
SPEAKER_0:  And I think that's not true either.

02:04:59,330 --> 02:05:01,150
SPEAKER_0:  The question is whether liberty is.

02:05:01,826 --> 02:05:03,614
SPEAKER_0:  of inherent value or instrumental value.

02:05:03,874 --> 02:05:07,678
SPEAKER_0:  Is liberty good in and of itself, or is liberty good because it allows you to achieve?

02:05:07,938 --> 02:05:09,086
SPEAKER_0:  X, Y, or Z.

02:05:09,474 --> 02:05:15,454
SPEAKER_0:  and i thought about this one a lot and i i tend to come down on the latter side of the aisle. I mean this is, you asked me areas where I moved, this may be an area where I've moved.

02:05:15,874 --> 02:05:17,982
SPEAKER_0:  Is that I think when you think more shallowly about politics?

02:05:18,338 --> 02:05:21,950
SPEAKER_0:  Or maybe more quickly because this is how we talk in America, about liberties and rights.

02:05:22,242 --> 02:05:27,582
SPEAKER_0:  We tend to think that the right is what makes, not like the political right, rights make things good, liberties make things good.

02:05:28,130 --> 02:05:31,614
SPEAKER_0:  The question really is what are those rights and liberties for? Now, you have to-

02:05:32,002 --> 02:05:33,438
SPEAKER_0:  Be careful so that that doesn't.

02:05:33,730 --> 02:05:36,958
SPEAKER_0:  shade into tyranny, right? You can only have liberty to do the thing that I say that you can do.

02:05:37,730 --> 02:05:39,134
SPEAKER_0:  But there have to be spheres of liberty.

02:05:39,906 --> 02:05:42,974
SPEAKER_0:  are roiling and interesting and filled with debate.

02:05:43,490 --> 02:05:44,862
SPEAKER_0:  but without threatening the chief.

02:05:45,346 --> 02:05:49,598
SPEAKER_0:  institutions that surround those liberties because if you destroy the institutions liberties will go to

02:05:50,210 --> 02:05:55,038
SPEAKER_0:  If you knock down the pillars of the society, the liberties that are on top of those pillars are going to collapse. I think that that's-

02:05:55,554 --> 02:05:58,302
SPEAKER_0:  If people are feeling as though we're on the verge of tyranny, I think that's why.

02:05:59,618 --> 02:06:01,918
SPEAKER_1:  This is fascinating by the way, it's an inst- inst-

02:06:02,210 --> 02:06:03,998
SPEAKER_1:  instrumental perspective on liberty.

02:06:04,418 --> 02:06:06,878
SPEAKER_1:  That's going to have to give me a lot to think about.

02:06:07,330 --> 02:06:08,894
SPEAKER_1:  Let me ask a personal question.

02:06:09,826 --> 02:06:12,062
SPEAKER_1:  Was there ever a time that you had a crisis of faith?

02:06:12,674 --> 02:06:14,078
SPEAKER_1:  Where you questioned your belief in God.

02:06:14,658 --> 02:06:15,006
SPEAKER_0:  Sure.

02:06:15,330 --> 02:06:19,262
SPEAKER_0:  And I would less call it a crisis of faith than an ongoing question of faith.

02:06:19,618 --> 02:06:21,726
SPEAKER_0:  Which I think is, I hope, most religious people.

02:06:22,530 --> 02:06:23,390
SPEAKER_0:  And the word.

02:06:23,874 --> 02:06:29,342
SPEAKER_0:  Israel, right, in Hebrew, Yisrael, means to struggle with God. That's literally what the word means.

02:06:29,602 --> 02:06:31,710
SPEAKER_0:  And so the idea of...

02:06:31,938 --> 02:06:34,846
SPEAKER_0:  struggling with God, right? If you're Jewish, you're B'nai Yisrael.

02:06:35,074 --> 02:06:38,654
SPEAKER_0:  The idea of struggling with God, I think, is endemic to the human condition.

02:06:39,042 --> 02:06:41,470
SPEAKER_0:  If you understand what God's doing, then I think you're wrong.

02:06:42,434 --> 02:06:44,990
SPEAKER_0:  and if you think that that question doesn't matter.

02:06:45,250 --> 02:06:46,110
SPEAKER_0:  then I think you're also wrong.

02:06:46,914 --> 02:06:49,539
SPEAKER_0:  I think that God is a very necessary hypothesis.

02:06:49,539 --> 02:06:49,918
SPEAKER_1:  Goal.

02:06:50,434 --> 02:06:53,735
SPEAKER_1:  The struggle with God is life. That is the process of life.

02:06:53,735 --> 02:06:54,142
SPEAKER_0:  That's right.

02:06:54,498 --> 02:06:57,054
SPEAKER_0:  Because you're never gonna get to that answer, otherwise you're God and you aren't.

02:06:57,442 --> 02:07:00,414
SPEAKER_1:  Why does God allow cruelty and suffering in the world?

02:07:00,930 --> 02:07:01,662
SPEAKER_1:  One of the tough.

02:07:01,890 --> 02:07:02,302
SPEAKER_1:  questions.

02:07:02,434 --> 02:07:02,782
SPEAKER_0:  So.

02:07:03,202 --> 02:07:06,622
SPEAKER_0:  We're going deep here. There's two types of cruelty and suffering.

02:07:07,202 --> 02:07:12,574
SPEAKER_0:  So if we're talking about human cruelty and suffering, because God does not intervene to prevent people from exercising.

02:07:12,962 --> 02:07:13,662
SPEAKER_0:  their free will.

02:07:14,082 --> 02:07:18,078
SPEAKER_0:  Because to do so would be to deprive human beings of the choice that makes them human.

02:07:18,882 --> 02:07:20,574
SPEAKER_0:  This is the sin of the Garden of Eden, basically.

02:07:21,058 --> 02:07:21,534
SPEAKER_0:  is that.

02:07:22,146 --> 02:07:25,086
SPEAKER_0:  God could make you an angel, in which case you wouldn't have the choice to do the wrong thing.

02:07:26,850 --> 02:07:30,750
SPEAKER_0:  so long as we are going to allow for cause and effect in a universe shaped by your choice.

02:07:31,234 --> 02:07:33,118
SPEAKER_0:  cruelty and evil are going to exist.

02:07:33,730 --> 02:07:37,086
SPEAKER_0:  And then there's the question of just the natural cruelty and vicissitudes of life.

02:07:38,146 --> 02:07:40,158
SPEAKER_0:  And the answer there is I think that God obscures himself.

02:07:40,834 --> 02:07:42,078
SPEAKER_0:  I think that if God were to appear...

02:07:42,402 --> 02:07:43,934
SPEAKER_0:  in all of his glory to people.

02:07:44,194 --> 02:07:45,854
SPEAKER_0:  on a regular basis, I think they would make

02:07:46,882 --> 02:07:47,262
SPEAKER_0:  Faith.

02:07:47,618 --> 02:07:49,662
SPEAKER_0:  You wouldn't need it. There'd be no such thing as faith.

02:07:50,338 --> 02:07:51,230
SPEAKER_0:  It would just be...

02:07:51,650 --> 02:07:54,654
SPEAKER_0:  Reality, right? Nobody has to prove to you that the Sun rises every day

02:07:55,298 --> 02:08:00,926
SPEAKER_0:  But if God is to allow us the choice to believe in Him, which is the ultimate choice from a religious point of view...

02:08:01,250 --> 02:08:04,158
SPEAKER_0:  then he's gonna have to obscure himself behind tragedy and horror and...

02:08:04,706 --> 02:08:06,814
SPEAKER_0:  and all those other things. I mean, this is a fairly well known...

02:08:07,362 --> 02:08:09,214
SPEAKER_0:  a cabalistic concept called Tsum Tsum in...

02:08:09,474 --> 02:08:12,318
SPEAKER_0:  Judaism, which is the idea that when God created the universe, he sort of withdrew.

02:08:12,898 --> 02:08:13,886
SPEAKER_0:  in order to make space.

02:08:14,146 --> 02:08:15,582
SPEAKER_0:  for all of these things to happen.

02:08:16,034 --> 02:08:18,718
SPEAKER_1:  So God doesn't have an instrumental perspective on liberty.

02:08:19,074 --> 02:08:27,550
SPEAKER_0:  In a chief sense, he does, because the best use of liberty is going to be belief in him. And you can misuse your liberty, right?

02:08:28,418 --> 02:08:31,102
SPEAKER_0:  there will be consequences if you believe in an afterlife.

02:08:31,490 --> 02:08:33,310
SPEAKER_0:  or if you believe in sort of a generalized...

02:08:33,570 --> 02:08:34,526
SPEAKER_0:  better version of life.

02:08:34,754 --> 02:08:35,422
SPEAKER_0:  led by faith.

02:08:35,746 --> 02:08:37,598
SPEAKER_0:  uh... then liberty does have a purpose

02:08:37,986 --> 02:08:41,374
SPEAKER_0:  but he also believes that you have to give people from a cosmic perspective the liberty.

02:08:41,794 --> 02:08:42,302
SPEAKER_0:  to do.

02:08:42,850 --> 02:08:43,422
SPEAKER_0:  Wrong.

02:08:43,746 --> 02:08:44,158
SPEAKER_0:  without.

02:08:44,418 --> 02:08:52,350
SPEAKER_0:  threatening all the institutions of society. I mean, that's why it does say in the Bible that if man sheds blood by man, shall his blood be shed, right? There are punishments that are that are

02:08:53,634 --> 02:08:55,454
SPEAKER_0:  in biblical thought for doing things that are wrong.

02:08:56,066 --> 02:09:00,990
SPEAKER_1:  So for a human being who lacks the faith in God, so if you're an atheist,

02:09:01,378 --> 02:09:02,503
SPEAKER_1:  Can you still be a good person?

02:09:02,503 --> 02:09:03,326
SPEAKER_0:  Of course.

02:09:03,810 --> 02:09:05,918
SPEAKER_0:  100% and there are a lot of religious people who are crappy people.

02:09:06,338 --> 02:09:07,902
SPEAKER_1:  How do you understand that tension?

02:09:08,418 --> 02:09:12,734
SPEAKER_0:  Well, from a religious perspective, what you would say is that it is perfectly plausible to live.

02:09:13,442 --> 02:09:19,838
SPEAKER_0:  in accordance with a set of rules that don't damage other people without believing in God, you just might be understanding the reason for doing that wrong.

02:09:20,258 --> 02:09:21,310
SPEAKER_0:  is what a religious person would say.

02:09:21,986 --> 02:09:22,398
SPEAKER_0:  Um...

02:09:23,010 --> 02:09:24,286
SPEAKER_0:  This is the conversation again.

02:09:24,642 --> 02:09:31,326
SPEAKER_0:  that I had with Sam basically is you and I agree, I said this to Sam, you and I agree on nearly everything when it comes to morality, like we probably disagree on 15 to 20% of things.

02:09:31,650 --> 02:09:36,126
SPEAKER_0:  The other 80% is because you grew up in a Judeo-Christian society and so do I, we grew up 10 miles from each other.

02:09:36,450 --> 02:09:38,238
SPEAKER_0:  you know, around the turn of the millennium. so

02:09:38,594 --> 02:09:39,614
SPEAKER_0:  There's that.

02:09:39,938 --> 02:09:40,318
SPEAKER_0:  So.

02:09:40,610 --> 02:09:42,942
SPEAKER_0:  You can perfectly well be an atheist living a-

02:09:43,458 --> 02:09:45,150
SPEAKER_0:  good, moral, decent life.

02:09:45,570 --> 02:09:48,990
SPEAKER_0:  because you can live a good moral decent life without believing in God.

02:09:49,282 --> 02:09:53,118
SPEAKER_0:  I don't think you can build a society on that, because I think that relies on the sort of...

02:09:55,170 --> 02:09:58,814
SPEAKER_0:  goodness of mankind natural goodness mankind are believed in actual goodness you don't

02:09:59,170 --> 02:10:03,934
SPEAKER_0:  No, I believe that man is created both sinful and with the capacity for sin and the capacity for good.

02:10:04,770 --> 02:10:05,726
SPEAKER_1:  But if you...

02:10:06,050 --> 02:10:07,422
SPEAKER_1:  Let them be on their own.

02:10:08,130 --> 02:10:08,510
SPEAKER_1:  Isn't

02:10:08,930 --> 02:10:11,230
SPEAKER_0:  Without social institutions to shape them, I think that...

02:10:11,522 --> 02:10:13,086
SPEAKER_0:  that's very likely to go poorly.

02:10:13,538 --> 02:10:16,382
SPEAKER_1:  Interesting. Well, we came to something we disagree on

02:10:16,674 --> 02:10:21,374
SPEAKER_1:  But that might reflect itself in our approach to Twitter as well.

02:10:21,602 --> 02:10:21,982
SPEAKER_1:  Yeah

02:10:22,242 --> 02:10:24,670
SPEAKER_1:  I think if humans are left on their own.

02:10:25,442 --> 02:10:27,678
SPEAKER_1:  the the 10 towards good

02:10:28,482 --> 02:10:31,038
SPEAKER_1:  is they definitely have the capacity for good and evil.

02:10:31,426 --> 02:10:33,662
SPEAKER_1:  but I will left on their own there.

02:10:33,922 --> 02:10:35,614
SPEAKER_1:  I tend to believe they're good.

02:10:36,418 --> 02:10:37,662
SPEAKER_0:  I think they might be good with limits.

02:10:37,890 --> 02:10:38,846
SPEAKER_0:  What I mean by that is that...

02:10:39,266 --> 02:10:42,302
SPEAKER_0:  What the evidence I think tends to show is that human beings are quite tribal.

02:10:42,786 --> 02:10:43,326
SPEAKER_0:  So.

02:10:43,842 --> 02:10:50,078
SPEAKER_0:  what you'll end up with is people who are good with their immediate family and maybe their immediate neighbors and then when they're threatened by an outside tribe then they kill everyone.

02:10:51,170 --> 02:10:55,454
SPEAKER_0:  which is sort of the history of civilization in the pre-civilizational era, which was a very violent time.

02:10:56,162 --> 02:10:57,598
SPEAKER_0:  pre-civilization layer was quite violent.

02:10:58,146 --> 02:10:58,718
SPEAKER_0:  Do you think?

02:10:59,138 --> 02:11:01,470
SPEAKER_1:  on the topic of tribalism in our modern world.

02:11:02,626 --> 02:11:03,998
SPEAKER_1:  What are the pros and cons of trial?

02:11:05,090 --> 02:11:08,478
SPEAKER_1:  Is that something we should try to outgrow as a civilization?

02:11:08,674 --> 02:11:11,262
SPEAKER_0:  I don't think it's ever gonna be possible to fully outgrow.

02:11:11,522 --> 02:11:12,062
SPEAKER_0:  tribalism.

02:11:12,866 --> 02:11:15,070
SPEAKER_0:  I think it's a natural human condition to...

02:11:15,586 --> 02:11:19,134
SPEAKER_0:  want to be with people who think like you or have a common set of beliefs.

02:11:19,874 --> 02:11:29,630
SPEAKER_0:  And I think trying to obliterate that in the name of a universalism likely leads to utopian results that have devastating consequences. Utopian sort of universalism has been failing every time.

02:11:30,178 --> 02:11:34,014
SPEAKER_0:  It's tried, whether you're talking about, now it seems to be, sort of liberal universalism.

02:11:34,434 --> 02:11:37,758
SPEAKER_0:  which is being rejected by a huge number of people around the world in various different cultures.

02:11:38,114 --> 02:11:39,550
SPEAKER_0:  Are you talking about religious?

02:11:40,002 --> 02:11:42,014
SPEAKER_0:  Universalism, which typically comes with

02:11:42,658 --> 02:11:43,230
SPEAKER_0:  religious.

02:11:43,618 --> 02:11:43,998
SPEAKER_0:  everything was pretty simple in terms of

02:11:44,290 --> 02:11:46,270
SPEAKER_0:  What are they talking about, communistic or a Nazi-esque?

02:11:47,266 --> 02:11:51,838
SPEAKER_0:  sort of universalism which comes with mass slaughter. So this is universalism I'm not a believer in.

02:11:52,258 --> 02:11:53,246
SPEAKER_0:  I think that...

02:11:53,570 --> 02:11:54,078
SPEAKER_0:  You have.

02:11:54,434 --> 02:11:56,734
SPEAKER_0:  you know, some values that are fairly limited.

02:11:56,994 --> 02:11:59,390
SPEAKER_0:  that all human beings should hold in common and that's

02:11:59,810 --> 02:12:02,814
SPEAKER_0:  pretty much it. Like, I think that everybody should have.

02:12:03,330 --> 02:12:04,990
SPEAKER_0:  the ability to join with their own.

02:12:05,890 --> 02:12:06,270
SPEAKER_0:  culture.

02:12:06,498 --> 02:12:07,998
SPEAKER_0:  I think how we define tribes is a different thing.

02:12:08,450 --> 02:12:12,798
SPEAKER_0:  So I think that tribes should not be defined by innate physical characteristics, for example.

02:12:13,698 --> 02:12:14,366
SPEAKER_0:  Because I think that.

02:12:14,818 --> 02:12:16,542
SPEAKER_0:  Thank God as a civilization we've outgrown that.

02:12:17,058 --> 02:12:18,590
SPEAKER_0:  And I think that that is...

02:12:19,810 --> 02:12:21,534
SPEAKER_0:  That is a childish way to view the world.

02:12:22,178 --> 02:12:23,838
SPEAKER_0:  and all the tall people aren't a tribe.

02:12:24,098 --> 02:12:26,078
SPEAKER_0:  All the black people, all the white people aren't a tribe.

02:12:26,626 --> 02:12:29,251
SPEAKER_1:  So the tribes should be formed over ideas versus physical.

02:12:29,251 --> 02:12:33,694
SPEAKER_0:  That's right, which is why actually to go back to sort of the beginning of the conversation when it comes to Jews

02:12:34,082 --> 02:12:37,598
SPEAKER_0:  You know, I'm not a big believer in ethnic Judaism.

02:12:38,082 --> 02:12:44,382
SPEAKER_0:  Right, I'm, as a person who takes Judaism seriously, Judaism is more to me than you were born with a last name like Berg or Steen.

02:12:44,898 --> 02:12:47,134
SPEAKER_0:  And so I disagree with you.

02:12:47,458 --> 02:12:50,430
SPEAKER_0:  He would disagree with me, but that's because he was a tribalist, right? Who thought in racial terms.

02:12:50,690 --> 02:12:51,070
SPEAKER_0:  So.

02:12:51,426 --> 02:12:55,518
SPEAKER_1:  uh... so maybe robots will help us see humans as one tribe

02:12:55,842 --> 02:12:56,382
SPEAKER_1:  Maybe that.

02:12:56,578 --> 02:13:02,203
SPEAKER_0:  This is Reagan's idea, right? Reagan said, well, if there's an alien invasion, then we'll all be on the same side. So I'll go over to the Soviets and we'll talk about it.

02:13:02,203 --> 02:13:03,230
SPEAKER_1:  deep truth to that.

02:13:04,066 --> 02:13:04,606
SPEAKER_1:  uh...

02:13:05,346 --> 02:13:06,302
SPEAKER_1:  What does it mean?

02:13:06,626 --> 02:13:07,582
SPEAKER_1:  to be a good man.

02:13:08,386 --> 02:13:09,566
SPEAKER_1:  various roles that

02:13:09,922 --> 02:13:11,230
SPEAKER_1:  a human being takes on.

02:13:12,322 --> 02:13:15,934
SPEAKER_1:  In this role theory that you've spoken about. What does it mean to be?

02:13:16,194 --> 02:13:16,542
SPEAKER_1:  Good.

02:13:17,666 --> 02:13:19,774
SPEAKER_0:  It means to perform. I will do.

02:13:20,066 --> 02:13:22,590
SPEAKER_0:  Aristotle it means to be perform the function well.

02:13:23,266 --> 02:13:26,238
SPEAKER_0:  What Aristotle says is the good is not like moral good, moral evil.

02:13:26,626 --> 02:13:28,286
SPEAKER_0:  In the way that we tend to think about it, he-

02:13:28,578 --> 02:13:30,782
SPEAKER_0:  He meant that a good cup holds liquid.

02:13:31,426 --> 02:13:32,990
SPEAKER_0:  and a good spoon hold soup.

02:13:33,506 --> 02:13:40,670
SPEAKER_0:  It means that a thing that is broken can't hold those things, right? So, the idea of being a good person means that you are fulfilling the function for which you were made.

02:13:41,506 --> 02:13:42,814
SPEAKER_0:  It's a teleological view.

02:13:43,234 --> 02:13:49,534
SPEAKER_0:  of humanity. So if you're a good father, this means that you are bringing up your child in durable values that is going to bring them up.

02:13:50,178 --> 02:13:57,278
SPEAKER_0:  healthy capable of protecting themselves and passing on the traditional wisdom of the ages to future generations while allowing for the capacity for innovation and being a good father.

02:13:57,858 --> 02:13:59,486
SPEAKER_0:  Being a good spouse would mean...

02:13:59,810 --> 02:14:04,382
SPEAKER_0:  protecting and unifying with your spouse and building a safe family.

02:14:04,770 --> 02:14:05,438
SPEAKER_0:  and a-

02:14:05,890 --> 02:14:07,134
SPEAKER_0:  place to raise children.

02:14:07,778 --> 02:14:09,310
SPEAKER_0:  being a good citizen of your community means.

02:14:09,634 --> 02:14:12,702
SPEAKER_0:  protecting the fellow citizens of your community while incentivizing them.

02:14:13,090 --> 02:14:14,430
SPEAKER_0:  to build for themselves.

02:14:15,074 --> 02:14:16,574
SPEAKER_0:  and they they it becomes actually

02:14:16,898 --> 02:14:20,318
SPEAKER_0:  much easier to think of how to... this is why I like the role theory because it's very...

02:14:20,642 --> 02:14:21,118
SPEAKER_0:  hard.

02:14:21,346 --> 02:14:23,358
SPEAKER_0:  since sort of in virtue theory to say be generous

02:14:23,746 --> 02:14:27,806
SPEAKER_0:  Okay, how does that manifest? I don't know what that looks like. Sometimes being generous might be being not.

02:14:28,642 --> 02:14:29,822
SPEAKER_0:  generous to other people, right?

02:14:30,370 --> 02:14:35,806
SPEAKER_0:  When Aristotle says that you should be benevolent. Like what does that mean? This is very vague. I say be a good dad.

02:14:36,098 --> 02:14:41,822
SPEAKER_0:  most people sort of have a gut level understanding of what it means to be a good dad, and mostly what they have a gut level understanding of what it means to be a really bad dad.

02:14:42,338 --> 02:14:46,014
SPEAKER_0:  And so what it means to be a good man is to fulfill those roles.

02:14:46,274 --> 02:14:47,486
SPEAKER_0:  as many of them as you can.

02:14:48,130 --> 02:14:49,726
SPEAKER_0:  properly and at full function.

02:14:49,986 --> 02:14:51,998
SPEAKER_0:  And that's a very hard job. I've said before that.

02:14:52,322 --> 02:14:52,926
SPEAKER_0:  Yeah, because.

02:14:53,314 --> 02:14:55,006
SPEAKER_0:  I engage a lot with the public and all of this.

02:14:55,234 --> 02:14:58,654
SPEAKER_0:  The word great comes up a lot. What does it take to be a great leader? What does it take to be a great person?

02:14:59,010 --> 02:15:02,142
SPEAKER_0:  I've always said to people, it's actually fairly easy to be great, it's very difficult to be good.

02:15:02,946 --> 02:15:09,726
SPEAKER_0:  There are a lot of very great people who are not very good. And there are not a lot of good people. And most of them, frankly, most good people.

02:15:11,650 --> 02:15:15,454
SPEAKER_0:  die mourned by their family and friends, and two generations later they're forgotten, but those are the people.

02:15:15,778 --> 02:15:19,550
SPEAKER_0:  who incrementally move the ball forward in the world, sometimes much more than the people who are considered great.

02:15:20,482 --> 02:15:26,229
SPEAKER_1:  Understand the role in your life that involves being a cup and be damn good at it. Exactly.

02:15:26,229 --> 02:15:26,979
SPEAKER_0:  That's right.

02:15:26,979 --> 02:15:27,998
SPEAKER_1:  Hold the soup.

02:15:28,514 --> 02:15:29,086
SPEAKER_1:  It's very...

02:15:29,314 --> 02:15:32,689
SPEAKER_0:  Jordan Peterson have been there. It's very like lobster with Jordan Peterson.

02:15:32,689 --> 02:15:34,334
SPEAKER_1:  I think people will quote you.

02:15:34,882 --> 02:15:36,926
SPEAKER_1:  for years and years to come on that.

02:15:37,346 --> 02:15:39,710
SPEAKER_1:  What advice would you give a lot of young people to look up to you?

02:15:40,002 --> 02:15:40,958
SPEAKER_1:  What advice?

02:15:41,634 --> 02:15:42,206
SPEAKER_1:  Um...

02:15:42,530 --> 02:15:49,182
SPEAKER_1:  despite the better judgment. No, I'm just kidding. I'm just only kidding. Only kidding. They seriously look up to you and...

02:15:49,538 --> 02:15:54,174
SPEAKER_1:  draw inspiration from your ideas, from your bold thinking, what advice would you give to them?

02:15:54,658 --> 02:15:59,006
SPEAKER_1:  how to live a life worth living, how to have a career.

02:15:59,266 --> 02:16:00,254
SPEAKER_1:  they can be proud of.

02:16:01,442 --> 02:16:02,462
SPEAKER_1:  and everything like that.

02:16:02,594 --> 02:16:03,038
SPEAKER_0:  So.

02:16:04,546 --> 02:16:08,190
SPEAKER_0:  Live out the values that you think are really important and seek those values in others.

02:16:08,738 --> 02:16:10,110
SPEAKER_0:  would be the first piece of advice.

02:16:10,402 --> 02:16:13,310
SPEAKER_0:  Second piece of advice, don't go on Twitter until you're 26.

02:16:13,698 --> 02:16:22,622
SPEAKER_0:  uh... and i think that because your brain is fully developed at that point uh... in the did as i said early on you know i was on social media and writing columns from time i was seventeen

02:16:22,946 --> 02:16:27,678
SPEAKER_0:  It was a great opportunity and as it turns out a great temptation to say enormous numbers of stupid things

02:16:28,034 --> 02:16:33,694
SPEAKER_0:  when you're young, I mean you're kind of trying out ideas and you're putting them on, you're taking them off and social media permanentizes those things.

02:16:33,986 --> 02:16:39,134
SPEAKER_0:  engraves them in stone and then that's used against you for the rest of your life. I tell young people this all the time like...

02:16:39,490 --> 02:16:41,886
SPEAKER_0:  You can be on social media, be on social media, but don't post, like watch.

02:16:42,306 --> 02:16:45,022
SPEAKER_0:  if you want to take in information and more importantly you should read books.

02:16:45,442 --> 02:16:46,750
SPEAKER_0:  Um, as far as...

02:16:47,170 --> 02:16:49,406
SPEAKER_0:  you know, other advice I'd say engage in your community.

02:16:50,050 --> 02:16:51,806
SPEAKER_0:  There's no substitute for engaging your community.

02:16:52,098 --> 02:16:54,750
SPEAKER_0:  uh... engaging interpersonal action because that that will

02:16:55,106 --> 02:16:56,766
SPEAKER_0:  soften you and make you a better person.

02:16:57,442 --> 02:17:03,070
SPEAKER_0:  I've become a better person since I got married. I've become an even better person since I've had kids. So you can imagine how terrible I was before all these things.

02:17:03,426 --> 02:17:04,574
SPEAKER_0:  And uh...

02:17:05,250 --> 02:17:06,846
SPEAKER_0:  and engaging your community.

02:17:07,074 --> 02:17:16,702
SPEAKER_0:  It does allow you to build the things that matter on the most local possible level. I mean, the outcome, by the way, of the sort of politics of the politics of fulfillment that I was talking about earlier is a lot of localism.

02:17:16,994 --> 02:17:19,102
SPEAKER_0:  Because the roles that I'm talking about are largely local roles.

02:17:19,426 --> 02:17:20,894
SPEAKER_0:  So that stuff has to be protected locally.

02:17:21,186 --> 02:17:29,694
SPEAKER_0:  I think we focus way too much in this country and others on like world beating solutions, national solutions, solutions that apply to hundreds of millions of people. How about we get to the solutions that apply for like...

02:17:30,370 --> 02:17:30,814
SPEAKER_0:  Five.

02:17:31,074 --> 02:17:33,022
SPEAKER_0:  And then we get to the solutions that apply to like 20.

02:17:33,250 --> 02:17:37,502
SPEAKER_0:  And then we get to the solutions that involve 200 people or a thousand people. Let's solve that stuff.

02:17:37,730 --> 02:17:38,302
SPEAKER_0:  And I think.

02:17:38,946 --> 02:17:41,438
SPEAKER_0:  The solutions at the higher level flow bottom up, not top down.

02:17:41,954 --> 02:17:43,614
SPEAKER_1:  What about mentors and

02:17:44,002 --> 02:17:45,758
SPEAKER_1:  Maybe role models. Have you had?

02:17:46,306 --> 02:17:52,703
SPEAKER_1:  Have you had a mentor or maybe people you look up to either you interacted on a local scale like you actually knew them or somebody you

02:17:52,703 --> 02:17:57,854
SPEAKER_0:  For me, I'm very lucky. I grew up in a very solid two-parent household. I'm extremely close to my parents.

02:17:58,146 --> 02:17:58,462
SPEAKER_0:  I live.

02:17:58,850 --> 02:18:01,886
SPEAKER_0:  Near my parents. Near my parents.

02:18:02,594 --> 02:18:05,406
SPEAKER_0:  And like right now they live a mile and a half from us.

02:18:05,826 --> 02:18:06,910
SPEAKER_0:  That's the...

02:18:07,106 --> 02:18:08,670
SPEAKER_1:  I would you learn from.

02:18:09,282 --> 02:18:11,518
SPEAKER_1:  about life from your parents and your father.

02:18:11,810 --> 02:18:12,254
SPEAKER_0:  Um...

02:18:12,674 --> 02:18:13,086
SPEAKER_0:  So.

02:18:13,890 --> 02:18:17,598
SPEAKER_0:  Man, so many things from my parents. That's a hard one.

02:18:17,858 --> 02:18:18,238
SPEAKER_0:  I mean...

02:18:18,722 --> 02:18:19,038
SPEAKER_0:  I think.

02:18:19,650 --> 02:18:23,326
SPEAKER_0:  The good stuff for my dad is that you should hold true to your values. He's very big on-

02:18:23,618 --> 02:18:25,630
SPEAKER_0:  You have values, those values are important, hold true to them.

02:18:25,922 --> 02:18:28,958
SPEAKER_1:  Did you understand what your values are, what your principles are early on?

02:18:29,154 --> 02:18:29,886
SPEAKER_0:  Fairly quickly, yeah.

02:18:30,658 --> 02:18:34,142
SPEAKER_0:  And so, you know, he was very big on that, which is why, for example...

02:18:34,402 --> 02:18:35,198
SPEAKER_0:  I get asked a lot.

02:18:35,458 --> 02:18:39,518
SPEAKER_0:  in the Jewish community why I wear a kippah and the answer is it never occurred to me to take off the kippah

02:18:40,002 --> 02:18:40,606
SPEAKER_0:  I always wore it.

02:18:41,090 --> 02:18:45,470
SPEAKER_0:  Why would I take it off at any point? That's the life that I wanna live and you know, that's the way it is.

02:18:45,762 --> 02:18:51,262
SPEAKER_0:  So that was a big one from my dad. From my mom, practicality. My dad is more of a dreamer, my mom is much more practical.

02:18:51,810 --> 02:18:52,382
SPEAKER_0:  And so.

02:18:52,674 --> 02:18:52,990
SPEAKER_0:  You know.

02:18:53,378 --> 02:18:56,830
SPEAKER_0:  the sort of lessons that I learned from my dad are that you can have

02:18:57,186 --> 02:19:02,590
SPEAKER_0:  This is sort of the counter lesson is that you can have a good idea, but if you don't have a plan for implementation, then it doesn't end up as reality.

02:19:03,138 --> 02:19:05,758
SPEAKER_0:  And I think actually he's learned that better over the course of his life too.

02:19:06,082 --> 02:19:06,558
SPEAKER_0:  I'm pet.

02:19:06,818 --> 02:19:07,678
SPEAKER_0:  My dad...

02:19:07,906 --> 02:19:12,190
SPEAKER_0:  from very, from time I was very young. He wanted me to engage with other adults and he wanted me to learn from-

02:19:12,674 --> 02:19:13,694
SPEAKER_0:  other people and...

02:19:13,986 --> 02:19:18,622
SPEAKER_0:  His, one of his rules was if he didn't know something, he would find somebody who he thought did know the thing for me to talk to.

02:19:19,298 --> 02:19:20,126
SPEAKER_0:  That was a big thing.

02:19:20,386 --> 02:19:23,742
SPEAKER_0:  So I'm very lucky. I have wonderful parents. As far as sort of other mentors.

02:19:24,130 --> 02:19:27,038
SPEAKER_0:  In terms of media, Andrew Breitbart was a mentor.

02:19:27,618 --> 02:19:32,414
SPEAKER_0:  Andrew obviously, he was kind of known in his latter days, I think more for the militancy than- than-

02:19:32,898 --> 02:19:33,310
SPEAKER_0:  when I.

02:19:33,634 --> 02:19:34,398
SPEAKER_0:  was very close with him.

02:19:34,722 --> 02:19:36,510
SPEAKER_1:  So for somebody like me who doesn't...

02:19:36,770 --> 02:19:38,334
SPEAKER_1:  Who knows more about the militancy?

02:19:38,754 --> 02:19:42,366
SPEAKER_1:  Can you tell me what is a great, what makes him a great man?

02:19:42,562 --> 02:19:46,430
SPEAKER_0:  What made Andrew great is that he engaged with everyone. I mean, everyone.

02:19:46,658 --> 02:19:48,030
SPEAKER_0:  So there are videos of him.

02:19:48,994 --> 02:19:55,294
SPEAKER_0:  rollerblading down the boulevard people be protesting you literally like rollerblade up to them and he would say let's go to lunch together and he would just do this

02:19:55,874 --> 02:19:57,749
SPEAKER_0:  That's actually who Andrew was. What was the thinking?

02:19:57,749 --> 02:19:59,815
SPEAKER_1:  behind that just just

02:19:59,815 --> 02:20:05,054
SPEAKER_0:  He was just careless. He was much more outgoing than I am actually. He was very warm with people. Like, for me.

02:20:05,794 --> 02:20:07,166
SPEAKER_0:  Yeah, I would say that with Andrew...

02:20:07,554 --> 02:20:08,990
SPEAKER_0:  I knew Andrew for...

02:20:09,730 --> 02:20:10,974
SPEAKER_0:  SamMemory16

02:20:11,234 --> 02:20:11,678
SPEAKER_0:  He-

02:20:12,098 --> 02:20:13,566
SPEAKER_0:  passed away when I would have been.

02:20:14,050 --> 02:20:14,430
SPEAKER_0:  28.

02:20:14,850 --> 02:20:15,838
SPEAKER_0:  So I knew Andrew for-

02:20:16,130 --> 02:20:16,734
SPEAKER_0:  10, 12 years.

02:20:17,218 --> 02:20:17,694
SPEAKER_0:  and

02:20:18,178 --> 02:20:20,670
SPEAKER_0:  people who met Andrew for about 10 minutes.

02:20:22,498 --> 02:20:24,734
SPEAKER_0:  New Andrew 99% as well as my new Andrew.

02:20:25,314 --> 02:20:37,118
SPEAKER_0:  because he was just all out front. Like everything was out here and he loved talking to people. He loved engaging with people. And so this made him a lot of fun and unpredictable and fun to watch and all of that. And then I think Twitter got to him. I think Twitter is...

02:20:37,762 --> 02:20:42,142
SPEAKER_0:  One of the lessons I learned from Andrew is the counter lesson, which is Twitter can poison you. Twitter can really wreck you.

02:20:42,434 --> 02:20:45,950
SPEAKER_0:  Have you spent all day on Twitter reading the comments and getting angry at people who are talking about you?

02:20:46,466 --> 02:20:50,910
SPEAKER_0:  it becomes a very difficult life and I think that, you know, in the last year of his life, Andrew got very caught up.

02:20:51,394 --> 02:20:53,694
SPEAKER_0:  in that because of a series of sort of circumstances.

02:20:54,018 --> 02:20:57,393
SPEAKER_1:  It can actually affect your mind. It can actually make you resentful, all that kind of stuff.

02:20:57,393 --> 02:21:00,862
SPEAKER_0:  I tend to agree with that. So, but the lesson I learned from Andrew is...

02:21:01,218 --> 02:21:04,542
SPEAKER_0:  Engage with everybody, take joy in sort of the mission.

02:21:05,314 --> 02:21:05,790
SPEAKER_0:  You're given.

02:21:06,210 --> 02:21:10,718
SPEAKER_0:  And you can't always fulfill that. Sometimes it's really rough and difficult. I'm not going to pretend that it's all fun.

02:21:11,042 --> 02:21:12,542
SPEAKER_0:  and rainbows all the time because it didn't.

02:21:13,154 --> 02:21:19,006
SPEAKER_0:  And some of the stuff that I have to cover, I don't like. And some of the things I have to say, I don't particularly like. You know, like that happens.

02:21:19,330 --> 02:21:22,878
SPEAKER_0:  But that's what I learned from Andrew. As far as sort of-

02:21:23,202 --> 02:21:25,342
SPEAKER_0:  Other mentors, I had some teachers when I was a kid.

02:21:25,858 --> 02:21:26,366
SPEAKER_0:  Who at?

02:21:26,626 --> 02:21:28,254
SPEAKER_0:  You know, said things that stuck with me, I had a-

02:21:28,866 --> 02:21:32,318
SPEAKER_0:  Fourth grade teacher named Miss Janetti who said, don't let potential be written on your tombstone.

02:21:32,962 --> 02:21:36,734
SPEAKER_0:  Which was a pretty... That's a good line. It's a great line, particularly to a fourth grader.

02:21:37,058 --> 02:21:44,446
SPEAKER_0:  But it was, that was a guy in 11th grade, English teacher named Anthony Miller, who was terrific, really good writer. Yeah, I didn't study English at all.

02:21:44,706 --> 02:21:48,382
SPEAKER_0:  with James Joyce at Trinity College in Dublin and so he and I really got along and

02:21:48,930 --> 02:21:50,302
SPEAKER_0:  He helped my writing a lot.

02:21:51,202 --> 02:21:53,118
SPEAKER_1:  Did you ever have doubt in yourself?

02:21:53,602 --> 02:21:57,630
SPEAKER_1:  I mean, especially as you gotten into the public eye with all the attacks, did you ever doubt?

02:21:57,858 --> 02:22:02,270
SPEAKER_1:  your ability to stay strong, to be able to be a voice of the ideas that you represent.

02:22:02,850 --> 02:22:09,918
SPEAKER_0:  You definitely, I don't doubt my ability to say what I want to say. I doubt my ability to handle the emotional blowback of saying it, meaning that that's-

02:22:10,242 --> 02:22:11,358
SPEAKER_0:  That's difficult, I mean...

02:22:11,778 --> 02:22:12,286
SPEAKER_0:  again.

02:22:12,962 --> 02:22:19,006
SPEAKER_0:  In 2016, the ADL measured that I was the number one target of anti-Semitism on planet Earth.

02:22:19,618 --> 02:22:20,126
SPEAKER_0:  You know, that's.

02:22:20,482 --> 02:22:21,246
SPEAKER_0:  It's not fun.

02:22:21,538 --> 02:22:26,942
SPEAKER_0:  That's unpleasant. And when you take critiques, not from antisemites, but when you take critiques from people generally,

02:22:28,066 --> 02:22:32,638
SPEAKER_0:  We talked about in the beginning how you surround yourself with people who are going to give you good feedback.

02:22:32,962 --> 02:22:38,270
SPEAKER_0:  Sometimes it's hard to tell. Sometimes people are giving you feedback, you know, whether it's well motivated or poorly motivated.

02:22:38,530 --> 02:22:43,550
SPEAKER_0:  And if you are trying to be a decent person, you can't cut off the mechanism of feedback. And so what that means is...

02:22:43,810 --> 02:22:47,486
SPEAKER_0:  Sometimes you take to heart the wrong thing, or you take it hard too much.

02:22:47,874 --> 02:22:54,462
SPEAKER_0:  uh... you're not like that you take it very very seriously lose sleep over it man can tell you number of nights where I've just not slept because of

02:22:54,882 --> 02:22:58,942
SPEAKER_0:  some critique somebody's made of me, and I've thought to myself, maybe that's right. And sometimes it is right.

02:22:59,394 --> 02:23:00,519
SPEAKER_0:  And you know, that's that's.

02:23:00,519 --> 02:23:06,238
SPEAKER_1:  So some of that is good just doing that criticism, but some of that can destroy you. Do you have a shortcut? Or any other side of Reagan that have switches

02:23:06,498 --> 02:23:09,822
SPEAKER_1:  Rogan has talked about taking a lot of mushrooms. Since you're not.

02:23:10,178 --> 02:23:11,998
SPEAKER_1:  You're not into the mushroom thing

02:23:12,258 --> 02:23:12,766
SPEAKER_1:  Um...

02:23:13,058 --> 02:23:14,206
SPEAKER_1:  What's your escape from that?

02:23:14,754 --> 02:23:17,054
SPEAKER_1:  Like when you get low, when you can't sleep.

02:23:17,474 --> 02:23:21,694
SPEAKER_0:  Usually writing is a big one for me. So I the writing for me is cathartic. I love writing

02:23:22,370 --> 02:23:24,126
SPEAKER_0:  That is a huge one.

02:23:24,706 --> 02:23:25,758
SPEAKER_0:  Spending time with my family.

02:23:26,210 --> 02:23:32,478
SPEAKER_0:  Again, I usually have a close circle of friends who I will talk with in order to sort of bounce ideas off of them

02:23:32,930 --> 02:23:35,198
SPEAKER_0:  And then once I've kind of talked it through.

02:23:35,618 --> 02:23:37,054
SPEAKER_0:  I tend to feel a little bit better.

02:23:37,602 --> 02:23:41,342
SPEAKER_0:  Exercise is also a big one. I mean, if I go a few days with that exercise, I tend to get...

02:23:41,794 --> 02:23:42,334
SPEAKER_0:  Pretty grumpy.

02:23:42,562 --> 02:23:43,518
SPEAKER_0:  pretty quickly. I mean, I gotta get...

02:23:43,746 --> 02:23:45,118
SPEAKER_0:  Keep the six pack going somehow, man.

02:23:45,218 --> 02:23:49,054
SPEAKER_1:  There you and Rogan agree.

02:23:49,474 --> 02:23:50,078
SPEAKER_1:  We haven't

02:23:50,978 --> 02:23:54,910
SPEAKER_1:  Aside from Twitter mentioned love, what's the role of love in the human condition?

02:23:55,490 --> 02:23:56,222
SPEAKER_1:  Ben Shapiro.

02:23:57,282 --> 02:23:59,710
SPEAKER_0:  Man, don't get asked for love too much. In fact, I'm-

02:23:59,938 --> 02:24:00,574
SPEAKER_0:  I was a-

02:24:01,122 --> 02:24:01,630
SPEAKER_0:  I was.

02:24:01,826 --> 02:24:03,527
SPEAKER_1:  You don't get that question.

02:24:03,527 --> 02:24:07,038
SPEAKER_0:  No, I typically don't actually. In fact, we were at an event.

02:24:07,490 --> 02:24:08,478
SPEAKER_0:  uh, recently.

02:24:08,738 --> 02:24:10,398
SPEAKER_0:  as a daily wire event and.

02:24:10,754 --> 02:24:13,054
SPEAKER_0:  In the middle of this event is a meet and greet with some of the audience.

02:24:13,346 --> 02:24:23,358
SPEAKER_0:  And in the middle of this event, this guy walks by with this girl, they're talking, and they're talking to me, and their time kind of runs, the security's moving them, and he says, no, no, no, wait, hold on a minute. And he gets down on one knee and he proposes to the girl in front of me.

02:24:23,746 --> 02:24:25,630
SPEAKER_0:  And I said to him, this is the weirdest proposal.

02:24:26,146 --> 02:24:34,526
SPEAKER_0:  in human history, what is happening right now? Like, I was your choice of Cupid here? So well, you know, we actually like got together because we listened to your show.

02:24:35,138 --> 02:24:44,190
SPEAKER_0:  And so I can perform it like a Jewish marriage right now. We're gonna need like a glass, we're gonna need some wine. It's gonna get weird real fast. But yeah, so love doctor, I'm typically not.

02:24:44,514 --> 02:24:45,214
SPEAKER_0:  Ask too much about.

02:24:45,442 --> 02:24:46,750
SPEAKER_0:  The role of love.

02:24:47,042 --> 02:24:47,998
SPEAKER_0:  is

02:24:49,986 --> 02:24:51,966
SPEAKER_0:  important in binding together.

02:24:53,442 --> 02:24:56,638
SPEAKER_0:  human beings who ought to be bound together. And the role of respect is

02:24:57,314 --> 02:24:59,678
SPEAKER_0:  even more important in binding together broader groups of people.

02:25:00,194 --> 02:25:04,670
SPEAKER_0:  I think one of the mistakes that we make in politics is trying to substitute love for respect or respect for love and I think that's a big mistake.

02:25:05,090 --> 02:25:05,950
SPEAKER_0:  So I...

02:25:06,882 --> 02:25:07,294
SPEAKER_0:  Do not.

02:25:07,618 --> 02:25:08,894
SPEAKER_0:  bear tremendous love.

02:25:09,442 --> 02:25:12,158
SPEAKER_0:  in the same sense that I do for my family, for random strangers.

02:25:12,706 --> 02:25:17,726
SPEAKER_0:  I don't. I love my family. I love my kids. Anybody who tells you they love your kid as much as you love your kid is lying to you. It's not true.

02:25:18,402 --> 02:25:19,902
SPEAKER_0:  I love my-

02:25:20,194 --> 02:25:27,486
SPEAKER_0:  I love my community more than I love other communities. I love my state more than I love other states. I love my country more than I love other countries, right? Like that's all normal.

02:25:28,322 --> 02:25:33,310
SPEAKER_0:  And that's all good. The problem of empathy can be when that becomes so tight in it that you're not.

02:25:34,146 --> 02:25:37,086
SPEAKER_0:  outward looking that you don't actually have respect for other people.

02:25:37,346 --> 02:25:41,502
SPEAKER_0:  In the local level, you need love in order to protect you and shield you and give you the strength to go forward.

02:25:41,762 --> 02:25:44,318
SPEAKER_0:  And then beyond that, you need a lot of respect for people who are not.

02:25:44,546 --> 02:25:47,198
SPEAKER_0:  in the circle of love. And I think trying to

02:25:47,682 --> 02:25:49,374
SPEAKER_0:  Yeah, extend love to people who...

02:25:50,946 --> 02:25:54,910
SPEAKER_0:  either are not gonna love you back or are gonna slap you in the face for it.

02:25:55,458 --> 02:25:58,334
SPEAKER_0:  or who you're just not that close to, it either runs the...

02:25:58,658 --> 02:26:00,318
SPEAKER_0:  risk of being airsats and fake.

02:26:00,802 --> 02:26:03,806
SPEAKER_0:  Or it can actually be counterproductive in some senses.

02:26:04,738 --> 02:26:05,790
SPEAKER_1:  Well there's some...

02:26:06,018 --> 02:26:09,790
SPEAKER_1:  sense in which you could have love for other human beings just

02:26:11,330 --> 02:26:14,110
SPEAKER_1:  based on the humanity that connects everybody.

02:26:14,626 --> 02:26:15,582
SPEAKER_1:  Right, so you...

02:26:15,970 --> 02:26:18,590
SPEAKER_1:  loved this whole project that we're a part of.

02:26:19,202 --> 02:26:20,510
SPEAKER_1:  and actually.

02:26:21,474 --> 02:26:25,214
SPEAKER_1:  So another thing we disagree on, so loving a stranger.

02:26:26,178 --> 02:26:29,694
SPEAKER_1:  like having that basic empathy and compassion towards a stranger.

02:26:30,850 --> 02:26:32,446
SPEAKER_1:  even if it can hurt you.

02:26:32,834 --> 02:26:34,622
SPEAKER_1:  I think it's ultimately like a.

02:26:36,386 --> 02:26:39,646
SPEAKER_1:  That to me is what it means to be a good man.

02:26:40,002 --> 02:26:44,478
SPEAKER_1:  to live a good life is to have that compassion with strangers because to me it's almost

02:26:44,706 --> 02:26:45,150
SPEAKER_1:  It's.

02:26:45,442 --> 02:26:48,638
SPEAKER_1:  Easy and natural and obvious to love people close to you.

02:26:49,250 --> 02:26:51,774
SPEAKER_1:  to step outside of yourself and to love others.

02:26:52,034 --> 02:26:52,798
SPEAKER_1:  I think that's what...

02:26:53,186 --> 02:26:56,350
SPEAKER_1:  That's the fabric of a good society. You don't think there's value to that?

02:26:56,866 --> 02:26:59,966
SPEAKER_0:  I think there can be, but I think we're also discussing love almost in two different senses.

02:27:00,482 --> 02:27:04,350
SPEAKER_0:  Meaning that when I talk about love, what I think of immediately is the love I bear for

02:27:04,738 --> 02:27:05,470
SPEAKER_0:  My wife and kids.

02:27:06,466 --> 02:27:08,670
SPEAKER_0:  or in my parents or my siblings. equivalents between Range and Friendship.

02:27:09,186 --> 02:27:10,494
SPEAKER_0:  or the love of my close friends.

02:27:11,010 --> 02:27:13,438
SPEAKER_0:  Okay, but I think that it's...

02:27:14,018 --> 02:27:18,078
SPEAKER_0:  that using that same term to describe how I feel about strangers I think would just be inaccurate.

02:27:18,690 --> 02:27:19,838
SPEAKER_0:  And so that's why I'm...

02:27:20,194 --> 02:27:24,062
SPEAKER_0:  suggesting that respect might be a more solid and realistic foundation.

02:27:24,546 --> 02:27:31,358
SPEAKER_0:  for the way that we treat people far away from us, or people who are strangers, respect for their dignity, respect for their priorities, respect for...

02:27:31,682 --> 02:27:32,702
SPEAKER_0:  their role in life.

02:27:33,122 --> 02:27:34,782
SPEAKER_0:  It might be too much of an ask in other words.

02:27:35,138 --> 02:27:43,966
SPEAKER_0:  There might be the rare human being who's capable of literally loving a homeless man on the street the way that he loves his own family. But if you respect the homeless man on the street the way that you respect...

02:27:44,546 --> 02:27:45,342
SPEAKER_0:  your own family.

02:27:45,698 --> 02:27:47,518
SPEAKER_0:  uh... because everyone is deserved

02:27:47,938 --> 02:27:50,910
SPEAKER_0:  Everyone deserves that respect. I think that you get to the same end without...

02:27:51,554 --> 02:27:54,046
SPEAKER_0:  without forcing people into a position of...

02:27:55,042 --> 02:27:57,982
SPEAKER_0:  of unrealistically expecting themselves to feel a thing they don't feel.

02:27:58,466 --> 02:28:04,702
SPEAKER_0:  You know, one of the big questions in religion that comes up is God makes certain requests that you feel certain ways, right? You're supposed to be...

02:28:05,282 --> 02:28:07,550
SPEAKER_0:  You're supposed to be happy about certain things or...

02:28:07,970 --> 02:28:11,998
SPEAKER_0:  You know, you're supposed to love thy neighbor as thyself, right? You'll notice that in that statement.

02:28:12,226 --> 02:28:13,470
SPEAKER_0:  It's thy neighbor, right? It's not just.

02:28:14,242 --> 02:28:14,974
SPEAKER_0:  Generally anyone.

02:28:15,202 --> 02:28:16,542
SPEAKER_0:  It's love thy neighbors. In any case.

02:28:16,834 --> 02:28:17,959
SPEAKER_0:  The... the... I think that ex-

02:28:17,959 --> 02:28:19,774
SPEAKER_1:  extends to anyone that follows you on Twitter.

02:28:20,194 --> 02:28:26,206
SPEAKER_1:  thy neighbor because God anticipated the social network aspect that is not constrained by geography.

02:28:27,074 --> 02:28:33,246
SPEAKER_0:  Yeah, I'm gonna differ with you on the interpretation on that, but in any case, the sort of, you know, the kind of

02:28:33,698 --> 02:28:34,942
SPEAKER_0:  extension of...

02:28:35,970 --> 02:28:41,406
SPEAKER_0:  love outwards might be too big an ask. So maybe we can start with respect and then hopefully out of that respect can grow.

02:28:41,922 --> 02:28:44,638
SPEAKER_0:  something more if people earn their way in.

02:28:45,218 --> 02:28:49,182
SPEAKER_0:  Because I think that one of the big problems when we were talking about universalism is when people say like, I'm a world citizen.

02:28:49,762 --> 02:28:52,190
SPEAKER_0:  I love people of the other country as much as I love myself.

02:28:52,482 --> 02:28:53,310
SPEAKER_0:  or as much as I love.

02:28:53,570 --> 02:28:54,238
SPEAKER_0:  My country.

02:28:54,562 --> 02:28:55,902
SPEAKER_0:  it tends to actually lead to.

02:28:56,450 --> 02:28:58,398
SPEAKER_0:  in almost crammed-down utopianism.

02:28:59,426 --> 02:29:01,822
SPEAKER_0:  that I think can be kind of difficult because

02:29:02,338 --> 02:29:04,158
SPEAKER_0:  with love comes a certain expectation of...

02:29:04,482 --> 02:29:05,374
SPEAKER_0:  of solidarity.

02:29:06,370 --> 02:29:06,942
SPEAKER_0:  and

02:29:07,490 --> 02:29:14,366
SPEAKER_0:  I think, right, I mean, when you love your family, you love your wife, like, there's a certain level of solidarity that is required inside the home in order to preserve the most loving kind of home.

02:29:14,658 --> 02:29:20,734
SPEAKER_0:  And so if you love everybody, then that sort of implies a certain level of solidarity that may not exist. So maybe the idea is from me.

02:29:21,570 --> 02:29:27,945
SPEAKER_0:  start with respect and then maybe as people respect each other more then then loves an outgrowth of that is supposed to starting with love and then hoping that respect develops

02:29:27,945 --> 02:29:30,142
SPEAKER_1:  yet there's a danger that that word becomes empty.

02:29:30,626 --> 02:29:33,918
SPEAKER_1:  and instead is used for dogmatic kind of.

02:29:35,234 --> 02:29:36,286
SPEAKER_1:  Utopianism.

02:29:36,546 --> 02:29:41,694
SPEAKER_0:  I mean, this is the way that, for example, religious theocracies very often work. We love you so much we have to convert you.

02:29:42,978 --> 02:29:44,158
SPEAKER_1:  So let's start with respect.

02:29:44,674 --> 02:29:45,950
SPEAKER_1:  What I would love to see.

02:29:46,274 --> 02:29:46,782
SPEAKER_1:  Um,

02:29:47,330 --> 02:29:51,486
SPEAKER_1:  After our conversation today, it's to see a Ben Shapiro that continues the growth.

02:29:51,810 --> 02:29:55,454
SPEAKER_1:  on Twitter of being even more respectful than you've already been.

02:29:55,714 --> 02:29:59,390
SPEAKER_1:  and maybe one day converting that into love on Twitter.

02:29:59,746 --> 02:30:02,558
SPEAKER_1:  That would, if I could see that in this world, that would.

02:30:02,946 --> 02:30:04,414
SPEAKER_1:  Make me die, happy man.

02:30:04,578 --> 02:30:07,203
SPEAKER_0:  Wow, that's a little bit more love in the world.

02:30:07,203 --> 02:30:08,703
SPEAKER_1:  world for me.

02:30:08,703 --> 02:30:09,278
SPEAKER_0:  gift.

02:30:09,538 --> 02:30:12,862
SPEAKER_0:  I'll try to make that happen. I do have one question. I'm gonna need you to tell me

02:30:13,474 --> 02:30:16,094
SPEAKER_0:  Can I, like, which jokes are okay? Your joke's still okay?

02:30:16,482 --> 02:30:17,406
SPEAKER_1:  So yeah, can I?

02:30:17,666 --> 02:30:19,541
SPEAKER_1:  Can I just run your Twitter from now on?

02:30:19,541 --> 02:30:22,622
SPEAKER_0:  Just send it to me. 100%. I'll pre-screen you the jokes.

02:30:22,946 --> 02:30:26,321
SPEAKER_0:  And you can tell me if this is a loving joke or if this is a hate-filled obnoxious-

02:30:26,321 --> 02:30:30,334
SPEAKER_1:  surprised by the all the heart emojis that are popping up.

02:30:30,786 --> 02:30:35,518
SPEAKER_1:  on your Twitter. But thank you so much for being bold and fearless and exploring ideas.

02:30:35,778 --> 02:30:43,198
SPEAKER_1:  And your Twitter aside, thank you for being just good faith in all the arguments and all the conversations you're having with people is a huge honor.

02:30:43,362 --> 02:30:45,342
SPEAKER_0:  Thank you for talking to me. Thanks for having me.

02:30:46,370 --> 02:30:48,702
SPEAKER_1:  Thanks for listening to this conversation with Ben Shapiro.

02:30:49,378 --> 02:30:52,702
SPEAKER_1:  To support this podcast, please check out our sponsors in the description.

02:30:53,186 --> 02:30:53,662
SPEAKER_1:  And now...

02:30:53,922 --> 02:30:56,382
SPEAKER_1:  Let me leave you with some words from Ben Shapiro himself.

02:30:57,090 --> 02:30:59,134
SPEAKER_1:  Freedom of speech and thought matters.

02:30:59,682 --> 02:31:01,822
SPEAKER_1:  especially when it is speech and thought.

02:31:02,146 --> 02:31:03,326
SPEAKER_1:  with which we disagree.

02:31:04,130 --> 02:31:06,814
SPEAKER_1:  The moment the majority decides to destroy people.

02:31:07,138 --> 02:31:09,118
SPEAKER_1:  for engaging a thought it dislikes.

02:31:09,922 --> 02:31:10,654
SPEAKER_1:  Stop Crime

02:31:11,042 --> 02:31:12,126
SPEAKER_1:  becomes a reality.

02:31:13,474 --> 02:31:14,302
SPEAKER_1:  Thank you for listening.

02:31:14,594 --> 02:31:15,230
SPEAKER_1:  Hope to see you.

02:31:15,618 --> 02:31:16,062
SPEAKER_1:  next time.
