00:00:00,162 --> 00:00:01,726
SPEAKER_0:  In terms of your mistakes...

00:00:02,082 --> 00:00:04,158
SPEAKER_0:  Society tells you don't make them.

00:00:04,834 --> 00:00:07,358
SPEAKER_0:  because we will judge you and we will look down on you.

00:00:08,162 --> 00:00:11,518
SPEAKER_0:  And I think the really successful people realize that actually know.

00:00:12,162 --> 00:00:15,326
SPEAKER_0:  It's the cycle time of mistakes that gets you to success.

00:00:16,098 --> 00:00:18,206
SPEAKER_0:  because your error rate will diminish.

00:00:18,466 --> 00:00:20,190
SPEAKER_0:  the more mistakes that you make.

00:00:20,770 --> 00:00:21,598
SPEAKER_0:  You observe them?

00:00:21,858 --> 00:00:25,150
SPEAKER_0:  you figure out where it's coming from? Is it a psychological thing? Is it a...

00:00:25,410 --> 00:00:26,558
SPEAKER_0:  you know, cognitive thing.

00:00:26,786 --> 00:00:27,582
SPEAKER_0:  and then you fix it.

00:00:30,242 --> 00:00:33,118
SPEAKER_1:  Following is a conversation with your mouth, palahapitiya.

00:00:33,538 --> 00:00:35,390
SPEAKER_1:  a venture capitalist and engineer.

00:00:35,810 --> 00:00:37,854
SPEAKER_1:  founder and CEO of Social Capital.

00:00:38,274 --> 00:00:41,534
SPEAKER_1:  Previously, an early senior executive at Facebook.

00:00:41,858 --> 00:00:42,334
SPEAKER_1:  and

00:00:42,786 --> 00:00:46,174
SPEAKER_1:  is the co-host of the All In Podcast.

00:00:46,626 --> 00:00:48,478
SPEAKER_1:  A podcast that I highly recommend.

00:00:48,898 --> 00:00:49,662
SPEAKER_1:  For the wisdom.

00:00:50,050 --> 00:00:52,350
SPEAKER_1:  and the camaraderie of the four co-hosts.

00:00:52,738 --> 00:00:53,470
SPEAKER_1:  Also known.

00:00:53,730 --> 00:00:54,686
SPEAKER_1:  as besties.

00:00:55,426 --> 00:00:57,438
SPEAKER_1:  This is the Lux Freedman Podcast.

00:00:57,698 --> 00:00:58,302
SPEAKER_1:  support it.

00:00:58,594 --> 00:01:00,798
SPEAKER_1:  Please check out our sponsors in the description.

00:01:01,154 --> 00:01:02,334
SPEAKER_1:  And now, dear friends.

00:01:02,658 --> 00:01:03,518
SPEAKER_1:  Here's your mouth.

00:01:03,810 --> 00:01:04,670
SPEAKER_1:  Pala hapatia.

00:01:05,826 --> 00:01:10,974
SPEAKER_1:  You grew up in a dysfunctional household on welfare. You've talked about this before.

00:01:11,362 --> 00:01:15,550
SPEAKER_1:  What were for you personally, psychologically, some difficult moments in your childhood?

00:01:16,706 --> 00:01:19,326
SPEAKER_0:  I'll answer that question in a slightly different way, which is that.

00:01:20,482 --> 00:01:21,662
SPEAKER_0:  I think when you grow up...

00:01:22,818 --> 00:01:25,150
SPEAKER_0:  in a household that's defined by.

00:01:25,442 --> 00:01:26,110
SPEAKER_0:  physical.

00:01:26,818 --> 00:01:28,798
SPEAKER_0:  abuse and psychological abuse.

00:01:30,018 --> 00:01:31,678
SPEAKER_0:  You're hypervigilant all the time.

00:01:32,418 --> 00:01:36,158
SPEAKER_0:  And so it's actually easier for me to point to moments where.

00:01:37,090 --> 00:01:37,822
SPEAKER_0:  I was happy.

00:01:38,626 --> 00:01:41,470
SPEAKER_0:  or I felt compassion or I felt safe.

00:01:42,242 --> 00:01:44,958
SPEAKER_0:  Otherwise, every moment, I'll give you a couple of examples. Say hi back again next time when I don't have time AM to say hi again, the next time

00:01:45,858 --> 00:01:47,774
SPEAKER_0:  You know, I was thinking about this a while ago.

00:01:49,442 --> 00:01:50,654
SPEAKER_0:  there was a tree outside.

00:01:51,106 --> 00:01:53,470
SPEAKER_0:  of my apartment where we lived when I was growing up.

00:01:55,202 --> 00:01:57,950
SPEAKER_0:  And my father sometimes would make me go outside.

00:01:58,370 --> 00:01:59,774
SPEAKER_0:  to take the tree branch.

00:02:00,802 --> 00:02:01,790
SPEAKER_0:  that he would hit me with.

00:02:03,074 --> 00:02:07,390
SPEAKER_0:  And so you can imagine if you're a 10, 11 year old kid and you have to deal with that, what do you do?

00:02:07,650 --> 00:02:09,374
SPEAKER_0:  Well, a hypervigilant child.

00:02:09,986 --> 00:02:12,094
SPEAKER_0:  learns how to basically estimate.

00:02:12,738 --> 00:02:14,334
SPEAKER_0:  the strength of these branches.

00:02:15,170 --> 00:02:15,486
SPEAKER_0:  Right?

00:02:15,842 --> 00:02:16,254
SPEAKER_0:  How?

00:02:16,962 --> 00:02:17,534
SPEAKER_0:  Far.

00:02:18,466 --> 00:02:19,934
SPEAKER_0:  Can he go before it breaks?

00:02:21,122 --> 00:02:22,654
SPEAKER_0:  You have to estimate his anger.

00:02:22,882 --> 00:02:25,342
SPEAKER_0:  and estimate the effective strength of.

00:02:25,890 --> 00:02:30,110
SPEAKER_0:  you know, branches and bring back something because, you know, I remember these moments where if it was

00:02:30,786 --> 00:02:33,182
SPEAKER_0:  he would look at it and then he would make me go out again and get it.

00:02:33,538 --> 00:02:34,558
SPEAKER_0:  Right, get a different one.

00:02:35,106 --> 00:02:35,550
SPEAKER_0:  Um...

00:02:36,290 --> 00:02:36,830
SPEAKER_0:  or

00:02:37,346 --> 00:02:39,070
SPEAKER_0:  you know, there was a certain belt that he wore.

00:02:39,810 --> 00:02:41,022
SPEAKER_0:  that had this kind of...

00:02:41,602 --> 00:02:42,878
SPEAKER_0:  belt buckle that stuck out.

00:02:44,610 --> 00:02:49,502
SPEAKER_0:  and you just wanted to make sure if that was the thing that you were going to get hit by.

00:02:50,402 --> 00:02:53,598
SPEAKER_0:  that it wasn't the buckle facing out because that really hurt.

00:02:54,402 --> 00:02:56,030
SPEAKER_0:  And so you became hyper aware.

00:02:56,450 --> 00:02:57,246
SPEAKER_0:  of which.

00:02:57,538 --> 00:03:00,766
SPEAKER_0:  of the buckle was facing out versus facing in in those moments.

00:03:01,698 --> 00:03:04,190
SPEAKER_0:  And there are like hundreds of these little examples.

00:03:04,802 --> 00:03:09,406
SPEAKER_0:  which essentially I would say the through line is that you're just so on edge.

00:03:10,242 --> 00:03:14,942
SPEAKER_0:  Right, and you walk into this house and you're just basically trying to get to the point where you leave the house.

00:03:16,194 --> 00:03:16,606
SPEAKER_0:  Um.

00:03:17,442 --> 00:03:17,918
SPEAKER_0:  And so.

00:03:18,146 --> 00:03:20,286
SPEAKER_0:  in that microcosm of growing up.

00:03:21,250 --> 00:03:22,846
SPEAKER_0:  any moment that's not like that.

00:03:23,298 --> 00:03:25,022
SPEAKER_0:  is seared in my memory.

00:03:25,346 --> 00:03:26,654
SPEAKER_0:  in a way that I just can't.

00:03:27,426 --> 00:03:30,078
SPEAKER_0:  described to a person. I'll give you an example.

00:03:30,914 --> 00:03:35,518
SPEAKER_0:  I volunteered when I was in grade five or six. Can't remember which it was.

00:03:36,162 --> 00:03:37,950
SPEAKER_0:  in the kindergarten of my school.

00:03:38,786 --> 00:03:40,830
SPEAKER_0:  and I would just go and the teacher would, you know.

00:03:41,410 --> 00:03:42,622
SPEAKER_0:  ask you to clean things up.

00:03:43,426 --> 00:03:45,502
SPEAKER_0:  And at the end of that great five year.

00:03:47,010 --> 00:03:49,086
SPEAKER_0:  She took me and two other kids to Dairy Queen.

00:03:51,202 --> 00:03:51,614
SPEAKER_0:  and

00:03:52,322 --> 00:03:55,454
SPEAKER_0:  I'd never gone to a restaurant, literally.

00:03:55,842 --> 00:03:57,502
SPEAKER_0:  because we didn't have the money.

00:03:58,370 --> 00:04:00,062
SPEAKER_0:  And I remember the first time I tasted this.

00:04:00,290 --> 00:04:04,254
SPEAKER_0:  You know, this Dairy Queen meal, it was like a hamburger, fries, a Coke, and a...

00:04:05,026 --> 00:04:05,694
SPEAKER_0:  A blizzard.

00:04:06,242 --> 00:04:07,710
SPEAKER_0:  And I was like, what?

00:04:07,938 --> 00:04:09,310
SPEAKER_0:  is this? And I felt...

00:04:10,626 --> 00:04:11,358
SPEAKER_0:  So special.

00:04:11,650 --> 00:04:13,342
SPEAKER_0:  you know, because you're getting something that...

00:04:13,890 --> 00:04:19,006
SPEAKER_0:  Most people would take for granted, oh, it's a Sunday or I'm really busy, let me go take my kid to.

00:04:19,650 --> 00:04:20,414
SPEAKER_0:  to fast food.

00:04:21,026 --> 00:04:23,486
SPEAKER_0:  I think that until I left high school.

00:04:25,218 --> 00:04:26,430
SPEAKER_0:  I think this is not just.

00:04:26,978 --> 00:04:29,118
SPEAKER_0:  specific to me but a lot of other people.

00:04:30,242 --> 00:04:31,998
SPEAKER_0:  you're in this hypervigilant loop.

00:04:33,186 --> 00:04:34,398
SPEAKER_0:  punctuated with these.

00:04:34,658 --> 00:04:38,078
SPEAKER_0:  incredibly visceral moments of compassion by other people.

00:04:38,850 --> 00:04:39,998
SPEAKER_0:  You know, a different example.

00:04:40,962 --> 00:04:41,374
SPEAKER_0:  Um.

00:04:41,794 --> 00:04:43,678
SPEAKER_0:  We had such a strict budget.

00:04:44,866 --> 00:04:45,854
SPEAKER_0:  and we didn't have a car.

00:04:47,042 --> 00:04:50,654
SPEAKER_0:  And so, you know, I was responsible with my mom to always go shopping.

00:04:51,522 --> 00:04:53,598
SPEAKER_0:  And so I learned very early on how to.

00:04:54,178 --> 00:04:58,174
SPEAKER_0:  look for coupons, how to buy things that were on sale or special.

00:04:59,010 --> 00:05:02,846
SPEAKER_0:  And we had a very basic diet because you have to budget this thing really precisely.

00:05:04,002 --> 00:05:06,494
SPEAKER_0:  but the end of every year.

00:05:07,746 --> 00:05:10,910
SPEAKER_0:  Where I lived, there was a large grocery chain called Loblaws.

00:05:11,874 --> 00:05:13,886
SPEAKER_0:  and Loblaws would discount.

00:05:15,202 --> 00:05:16,318
SPEAKER_0:  a cheesecake.

00:05:16,994 --> 00:05:19,358
SPEAKER_0:  from 799 to 499.

00:05:20,578 --> 00:05:21,118
SPEAKER_0:  and

00:05:21,762 --> 00:05:23,262
SPEAKER_0:  My parents would buy that.

00:05:24,130 --> 00:05:24,862
SPEAKER_0:  once a year.

00:05:25,154 --> 00:05:26,974
SPEAKER_0:  And we probably did that six or seven times.

00:05:28,098 --> 00:05:30,878
SPEAKER_0:  and you can't imagine how special we felt.

00:05:31,202 --> 00:05:32,638
SPEAKER_0:  Myself, my two sisters.

00:05:33,282 --> 00:05:35,518
SPEAKER_0:  We would sit there, we would watch the, you know, the.

00:05:35,842 --> 00:05:37,758
SPEAKER_0:  New Year's Eve celebration on TV, we would.

00:05:38,210 --> 00:05:40,734
SPEAKER_0:  cut this cheesecake into five pieces.

00:05:41,506 --> 00:05:42,494
SPEAKER_0:  It felt like everything.

00:05:43,330 --> 00:05:43,742
SPEAKER_0:  Um...

00:05:44,578 --> 00:05:45,694
SPEAKER_0:  So that's sort of how.

00:05:46,146 --> 00:05:46,526
SPEAKER_0:  You know.

00:05:46,754 --> 00:05:47,582
SPEAKER_0:  my

00:05:48,226 --> 00:05:51,102
SPEAKER_0:  My existence when I was at that age is.

00:05:51,714 --> 00:05:53,630
SPEAKER_0:  For better or for worse, that's how I remember it.

00:05:54,434 --> 00:05:56,094
SPEAKER_1:  the hypervigilance loop.

00:05:56,482 --> 00:05:57,918
SPEAKER_1:  Is that still with you today?

00:05:58,306 --> 00:06:01,534
SPEAKER_1:  What are the echoes of that that's still with you today? The good and the bad.

00:06:02,018 --> 00:06:03,070
SPEAKER_0:  If you put yourself...

00:06:05,890 --> 00:06:06,622
SPEAKER_0:  in the

00:06:07,074 --> 00:06:08,510
SPEAKER_0:  mind of a young child.

00:06:11,618 --> 00:06:11,966
SPEAKER_0:  The.

00:06:12,258 --> 00:06:13,278
SPEAKER_0:  Think that that...

00:06:14,242 --> 00:06:15,038
SPEAKER_0:  does to you.

00:06:16,450 --> 00:06:19,326
SPEAKER_0:  is at a very core basic level, it says you're worthless.

00:06:20,738 --> 00:06:21,982
SPEAKER_0:  Right? Because if you...

00:06:22,402 --> 00:06:25,758
SPEAKER_0:  can step outside of that and you think about any child in the world.

00:06:26,914 --> 00:06:28,478
SPEAKER_0:  They don't deserve to go through that.

00:06:30,562 --> 00:06:35,966
SPEAKER_0:  And at some point, by the way, I should tell you, I don't blame my parents anymore. It was a process to get there, but...

00:06:36,418 --> 00:06:38,078
SPEAKER_0:  I feel like they did the best they could.

00:06:39,522 --> 00:06:43,838
SPEAKER_0:  and they suffered their own issues and enormous pressures and stresses.

00:06:44,930 --> 00:06:45,438
SPEAKER_0:  And so.

00:06:45,698 --> 00:06:46,078
SPEAKER_0:  You know.

00:06:46,658 --> 00:06:48,574
SPEAKER_0:  I've really for the most part forgiven them.

00:06:49,538 --> 00:06:52,062
SPEAKER_1:  How did you start to interrupt like that? Go to that Blame!

00:06:53,282 --> 00:06:55,454
SPEAKER_0:  That was a really long process where...

00:06:56,770 --> 00:06:59,390
SPEAKER_0:  for I would say the first 35 years of my life.

00:07:00,290 --> 00:07:02,750
SPEAKER_0:  I compartmentalized and I avoided.

00:07:02,978 --> 00:07:04,126
SPEAKER_0:  all of those memories.

00:07:05,378 --> 00:07:06,654
SPEAKER_0:  and I saw it.

00:07:07,266 --> 00:07:08,606
SPEAKER_0:  external validation.

00:07:09,666 --> 00:07:15,518
SPEAKER_0:  Right, going back to this self-worth idea, if you're taught as a child that you're worthless, because why would somebody do these things to you?

00:07:16,386 --> 00:07:19,678
SPEAKER_0:  It's not because you're worth something you think to yourself very

00:07:20,130 --> 00:07:21,630
SPEAKER_0:  Viscerally, you're worth nothing.

00:07:22,722 --> 00:07:26,910
SPEAKER_0:  And so then you go out and you seek external validation. Maybe you try to go and get into a-

00:07:27,170 --> 00:07:28,926
SPEAKER_0:  great college, you try to get a good job.

00:07:29,602 --> 00:07:30,814
SPEAKER_0:  you try to make a lot of money.

00:07:31,362 --> 00:07:31,902
SPEAKER_0:  You try to.

00:07:32,386 --> 00:07:32,734
SPEAKER_0:  You know.

00:07:33,122 --> 00:07:37,278
SPEAKER_0:  Demonstrate in superficial ways with the car you drive or the clothes you wear.

00:07:38,178 --> 00:07:40,510
SPEAKER_0:  that you deserve people to care about you.

00:07:41,378 --> 00:07:43,326
SPEAKER_0:  to try to make up for that really deep hole.

00:07:44,226 --> 00:07:46,718
SPEAKER_0:  but at some point it doesn't get filled in.

00:07:47,586 --> 00:07:48,830
SPEAKER_0:  And so you have a choice.

00:07:49,698 --> 00:07:55,358
SPEAKER_0:  And so for me, what happened was in the course of a six month period, I lost my best friend and I lost my father.

00:07:56,098 --> 00:07:56,510
SPEAKER_0:  and

00:07:57,314 --> 00:07:59,294
SPEAKER_0:  It was really like the dam broke loose.

00:07:59,778 --> 00:08:00,350
SPEAKER_0:  because I.

00:08:00,738 --> 00:08:04,350
SPEAKER_0:  the compartmentalization stopped working because the reminder

00:08:05,346 --> 00:08:07,358
SPEAKER_0:  of why I was compartmentalizing was gone.

00:08:08,898 --> 00:08:10,206
SPEAKER_0:  And so I had to go through this.

00:08:10,658 --> 00:08:11,934
SPEAKER_0:  of disharmony

00:08:12,866 --> 00:08:14,078
SPEAKER_0:  really understand.

00:08:15,810 --> 00:08:16,926
SPEAKER_0:  and Steelman.

00:08:17,346 --> 00:08:18,334
SPEAKER_0:  his perspective.

00:08:19,682 --> 00:08:20,990
SPEAKER_0:  And can you imagine?

00:08:21,282 --> 00:08:24,798
SPEAKER_0:  Trying to do that, to go through all of the things where...

00:08:25,250 --> 00:08:27,806
SPEAKER_0:  You have to now look at it from his perspective.

00:08:28,322 --> 00:08:30,270
SPEAKER_0:  and find compassion and empathy.

00:08:30,978 --> 00:08:32,286
SPEAKER_0:  for what he went through.

00:08:33,570 --> 00:08:36,574
SPEAKER_0:  And then I shift the focus to my mom and I said.

00:08:37,154 --> 00:08:38,046
SPEAKER_0:  While you were...

00:08:38,530 --> 00:08:41,694
SPEAKER_0:  Not the victim, actually. You were somewhat complicit as well because...

00:08:42,114 --> 00:08:45,246
SPEAKER_0:  You were of sound mind and body and you were in the room when it happened.

00:08:46,242 --> 00:08:50,430
SPEAKER_0:  So then I had to go through that process with her and steal man her perspective.

00:08:51,746 --> 00:08:52,606
SPEAKER_0:  At the end of it.

00:08:52,898 --> 00:08:54,622
SPEAKER_0:  I never justified what they did.

00:08:54,850 --> 00:08:56,958
SPEAKER_0:  but I've been able to forgive what they did.

00:08:57,762 --> 00:08:59,838
SPEAKER_0:  I think they did the best they could.

00:09:00,546 --> 00:09:01,726
SPEAKER_0:  And at the end of the day.

00:09:02,306 --> 00:09:04,606
SPEAKER_0:  they did the most important thing, which is...

00:09:04,962 --> 00:09:06,846
SPEAKER_0:  They gave me and my sisters a shot.

00:09:07,106 --> 00:09:08,254
SPEAKER_0:  by emigrating.

00:09:08,706 --> 00:09:10,014
SPEAKER_0:  by giving up everything.

00:09:10,370 --> 00:09:11,646
SPEAKER_0:  by staying in Canada.

00:09:12,226 --> 00:09:14,430
SPEAKER_0:  and doing whatever it took between the two of them.

00:09:16,162 --> 00:09:19,486
SPEAKER_0:  to sort of claw and scrape together enough money to live so that

00:09:20,034 --> 00:09:22,014
SPEAKER_0:  my sisters and I could have a shot and.

00:09:22,274 --> 00:09:24,958
SPEAKER_0:  I'm very thankful for them. Could they have done better? прод..?

00:09:25,826 --> 00:09:26,590
SPEAKER_0:  but I'm okay with it.

00:09:27,074 --> 00:09:29,982
SPEAKER_0:  what has taken place, but it's been a long process of.

00:09:30,402 --> 00:09:33,854
SPEAKER_0:  of that steel manning so that you can develop some empathy and compassion.

00:09:34,242 --> 00:09:34,974
SPEAKER_0:  and forgive.

00:09:35,842 --> 00:09:37,438
SPEAKER_1:  Do you think if you talk to your dad?

00:09:39,778 --> 00:09:43,934
SPEAKER_1:  shortly after he died and you went through that process or today you'll be able to

00:09:44,578 --> 00:09:46,526
SPEAKER_1:  have the same strength.

00:09:47,650 --> 00:09:48,254
SPEAKER_1:  to forgive them.

00:09:52,130 --> 00:09:53,118
SPEAKER_0:  I think it would be a very.

00:09:53,474 --> 00:09:54,622
SPEAKER_0:  complicated journey.

00:09:55,938 --> 00:09:56,990
SPEAKER_0:  I think I have learned.

00:09:57,538 --> 00:09:58,398
SPEAKER_0:  to be incredibly.

00:09:59,202 --> 00:10:01,086
SPEAKER_0:  open about what has happened?

00:10:02,050 --> 00:10:04,702
SPEAKER_0:  and all of the mistakes I've made.

00:10:06,722 --> 00:10:07,454
SPEAKER_0:  I think it's.

00:10:07,682 --> 00:10:09,502
SPEAKER_0:  it would require him to be.

00:10:10,402 --> 00:10:11,902
SPEAKER_0:  pretty radically honest about.

00:10:12,546 --> 00:10:13,342
SPEAKER_0:  Confirming?

00:10:14,530 --> 00:10:15,806
SPEAKER_0:  what I think he went through.

00:10:16,898 --> 00:10:22,526
SPEAKER_0:  because otherwise it just wouldn't work. Otherwise I would say, let's keep things where they are, which is I did the work.

00:10:23,426 --> 00:10:26,334
SPEAKER_0:  you know, with people that have helped me, obviously, but.

00:10:26,658 --> 00:10:27,038
SPEAKER_0:  You know.

00:10:27,266 --> 00:10:30,654
SPEAKER_0:  it's better for him to just, you know, kind of hopefully he's looking.

00:10:31,202 --> 00:10:32,574
SPEAKER_0:  from someplace and he's thinking.

00:10:33,794 --> 00:10:37,598
SPEAKER_0:  It was worth it. I think he deserves to think that all of this, because, you know.

00:10:37,986 --> 00:10:38,878
SPEAKER_0:  I think the immigrant.

00:10:39,874 --> 00:10:41,822
SPEAKER_0:  challenge. We're not even the immigrant challenge. The

00:10:42,146 --> 00:10:45,566
SPEAKER_0:  lower middle class challenge, anybody who really wants better for their kids.

00:10:46,050 --> 00:10:48,094
SPEAKER_0:  and doesn't have a good toolkit to give it to them.

00:10:49,602 --> 00:10:50,238
SPEAKER_0:  Some of them.

00:10:51,746 --> 00:10:52,894
SPEAKER_0:  they choke up on the bat.

00:10:53,282 --> 00:10:54,654
SPEAKER_0:  They just get so...

00:10:54,882 --> 00:10:58,238
SPEAKER_0:  Agitated about this idea that all this sacrifice will not be worth it

00:10:59,106 --> 00:11:01,854
SPEAKER_0:  that it spills out in really unproductive ways.

00:11:02,562 --> 00:11:04,254
SPEAKER_0:  and I would put him in that category.

00:11:05,058 --> 00:11:06,366
SPEAKER_1:  and their self.

00:11:07,234 --> 00:11:09,566
SPEAKER_1:  Evaluation introspection.

00:11:09,794 --> 00:11:11,262
SPEAKER_1:  tunnel vision so they're not.

00:11:12,002 --> 00:11:15,838
SPEAKER_1:  able to often see the damage that did. I mean, I know

00:11:16,130 --> 00:11:17,150
SPEAKER_1:  like yourself.

00:11:17,858 --> 00:11:19,934
SPEAKER_1:  few successful people that

00:11:20,322 --> 00:11:21,918
SPEAKER_1:  had very difficult relationships.

00:11:22,594 --> 00:11:26,398
SPEAKER_1:  with their dad and you take the perspective of the dad.

00:11:27,234 --> 00:11:34,014
SPEAKER_1:  they're completely in denial about any of it. So if you actually have a conversation, there would not be a deep honesty there.

00:11:34,370 --> 00:11:34,846
SPEAKER_1:  Uh...

00:11:35,426 --> 00:11:38,366
SPEAKER_1:  And I think that's maybe in part the way of life.

00:11:39,426 --> 00:11:40,990
SPEAKER_0:  Yeah, and you know, I remember...

00:11:41,346 --> 00:11:44,286
SPEAKER_0:  pretty distinctly after I left and in this

00:11:44,770 --> 00:11:46,110
SPEAKER_0:  you know, in my middle thirties.

00:11:46,594 --> 00:11:47,006
SPEAKER_0:  where.

00:11:47,906 --> 00:11:51,358
SPEAKER_0:  you know, by all measure, I had roughly become reasonably successful.

00:11:53,090 --> 00:11:54,942
SPEAKER_0:  and my dad didn't particularly care about that.

00:11:55,714 --> 00:11:56,414
SPEAKER_0:  which was so.

00:11:56,994 --> 00:11:59,294
SPEAKER_0:  because I had to confront the fact that, you know...

00:12:00,354 --> 00:12:03,518
SPEAKER_0:  whether it was a title or money or press clippings.

00:12:03,906 --> 00:12:04,830
SPEAKER_0:  He never really cared.

00:12:05,282 --> 00:12:08,478
SPEAKER_0:  he moved on to a different set of goals, which was more about

00:12:08,962 --> 00:12:10,078
SPEAKER_0:  my character and

00:12:10,338 --> 00:12:12,990
SPEAKER_0:  you know, being a good person to my family and really.

00:12:13,442 --> 00:12:15,006
SPEAKER_0:  preparing me to.

00:12:15,618 --> 00:12:17,438
SPEAKER_0:  lead our family when he wasn't there.

00:12:18,498 --> 00:12:19,390
SPEAKER_0:  And that bothered me.

00:12:20,162 --> 00:12:23,614
SPEAKER_0:  because I thought I got to the finish line and I thought there was going to be a

00:12:24,578 --> 00:12:26,846
SPEAKER_0:  Metal, you know, meaning like I can tell you Lex.

00:12:27,074 --> 00:12:28,702
SPEAKER_0:  You know, he never told me that he loved me.

00:12:29,826 --> 00:12:31,230
SPEAKER_0:  I'm not sure if that's normal or not.

00:12:31,778 --> 00:12:32,926
SPEAKER_0:  It was my normality.

00:12:33,346 --> 00:12:35,870
SPEAKER_0:  and I thought there's going to be something, some gold star.

00:12:36,194 --> 00:12:37,118
SPEAKER_0:  which never appeared.

00:12:38,914 --> 00:12:40,318
SPEAKER_0:  And so that's like a hard thing.

00:12:40,802 --> 00:12:42,750
SPEAKER_0:  to kind of confront because you're like, well.

00:12:43,042 --> 00:12:44,862
SPEAKER_0:  Now what is this all about?

00:12:45,762 --> 00:12:47,806
SPEAKER_0:  Was this all just kind of a...

00:12:48,066 --> 00:12:48,638
SPEAKER_0:  A ruse?

00:12:49,410 --> 00:12:51,998
SPEAKER_0:  But then I realized, well, hold on a second, there were these moments.

00:12:53,378 --> 00:12:55,198
SPEAKER_0:  We're in his way again.

00:12:55,810 --> 00:12:57,054
SPEAKER_0:  putting yourself in his shoes.

00:12:58,114 --> 00:13:00,094
SPEAKER_0:  I think he was trying to say he was sorry.

00:13:00,514 --> 00:13:01,438
SPEAKER_0:  He would hold my hand.

00:13:02,274 --> 00:13:07,134
SPEAKER_0:  and he would interlock the fingers, which I felt is that's a really intimate way of holding somebody's hand, I think.

00:13:07,842 --> 00:13:08,286
SPEAKER_0:  Um.

00:13:08,802 --> 00:13:09,790
SPEAKER_0:  So I remember those things.

00:13:10,818 --> 00:13:14,462
SPEAKER_0:  you know, these are the things that are just etched in at least in my mind and

00:13:15,394 --> 00:13:16,190
SPEAKER_0:  At the end of it.

00:13:16,674 --> 00:13:17,886
SPEAKER_0:  You know, I think...

00:13:18,562 --> 00:13:21,566
SPEAKER_0:  I've done a decent job in repairing my relationship with him.

00:13:21,922 --> 00:13:22,494
SPEAKER_0:  even though...

00:13:22,850 --> 00:13:24,062
SPEAKER_0:  you know, it was posthumous.

00:13:24,674 --> 00:13:27,070
SPEAKER_1:  It does make me wonder in which way.

00:13:27,522 --> 00:13:30,846
SPEAKER_1:  You and I, we might be broken and not see it.

00:13:31,490 --> 00:13:33,310
SPEAKER_1:  It might be hurting others and not see it.

00:13:34,082 --> 00:13:35,550
SPEAKER_0:  Well, I think that when you...

00:13:36,162 --> 00:13:40,158
SPEAKER_0:  grow up in those kinds of environments and they're all different kinds of this kind of dysfunction.

00:13:41,474 --> 00:13:41,854
SPEAKER_0:  If.

00:13:42,690 --> 00:13:45,438
SPEAKER_0:  What you get from that is that you're not worthwhile.

00:13:45,890 --> 00:13:48,894
SPEAKER_0:  You're not, you're less than many, many other people.

00:13:50,754 --> 00:13:54,878
SPEAKER_0:  when you enter adulthood, or semi-adulthood, in your early 20s,

00:13:55,810 --> 00:13:58,334
SPEAKER_0:  you will be in a cycle where you are hurting other people.

00:13:59,618 --> 00:14:00,734
SPEAKER_0:  You may not know it.

00:14:01,730 --> 00:14:04,798
SPEAKER_0:  Hopefully you find somebody who holds you accountable and tells you.

00:14:05,058 --> 00:14:06,494
SPEAKER_0:  and loves you enough through that.

00:14:07,938 --> 00:14:14,110
SPEAKER_0:  But you are going to take all of that disharmony in your childhood and you're going to inject that disharmony into

00:14:14,786 --> 00:14:18,526
SPEAKER_0:  whether it's your professional relationships or your personal relationships or both.

00:14:19,330 --> 00:14:20,062
SPEAKER_0:  Until...

00:14:20,738 --> 00:14:23,390
SPEAKER_0:  you get to some form of rock bottom and you start to repair.

00:14:24,194 --> 00:14:27,006
SPEAKER_0:  And I think there's a lot of people that resonate with that because.

00:14:27,362 --> 00:14:27,966
SPEAKER_0:  They.

00:14:28,610 --> 00:14:33,246
SPEAKER_0:  have each suffered their own things that at some point in their lives have told them that

00:14:33,602 --> 00:14:34,398
SPEAKER_0:  There are less than.

00:14:35,522 --> 00:14:36,254
SPEAKER_0:  and and please

00:14:36,546 --> 00:14:37,726
SPEAKER_0:  and then they go and cope.

00:14:38,530 --> 00:14:39,518
SPEAKER_0:  And when you cope...

00:14:40,354 --> 00:14:43,134
SPEAKER_0:  eventually those coping mechanisms escalate.

00:14:43,554 --> 00:14:46,654
SPEAKER_0:  and at some point it'll be unhealthy, either for you.

00:14:47,106 --> 00:14:48,926
SPEAKER_0:  but oftentimes it's for the people around you.

00:14:49,826 --> 00:14:52,254
SPEAKER_1:  Well, from those humble beginnings.

00:14:52,546 --> 00:14:54,558
SPEAKER_1:  You are now a billionaire.

00:14:55,970 --> 00:15:02,078
SPEAKER_1:  How has money changed your life or maybe the landscape of experience in your life?

00:15:03,714 --> 00:15:04,798
SPEAKER_1:  doesn't buy happiness.

00:15:05,346 --> 00:15:06,974
SPEAKER_0:  It doesn't buy happiness.

00:15:07,586 --> 00:15:09,758
SPEAKER_0:  but it buys you a level of comfort.

00:15:10,306 --> 00:15:13,342
SPEAKER_0:  for you to really amplify what happiness is.

00:15:14,530 --> 00:15:16,414
SPEAKER_0:  I kind of think about it in the following way.

00:15:17,058 --> 00:15:19,774
SPEAKER_0:  Let's just say that there's a hundred things on a table.

00:15:20,642 --> 00:15:23,134
SPEAKER_0:  And the table says, find happiness here.

00:15:24,514 --> 00:15:25,854
SPEAKER_0:  and there are different prices.

00:15:27,938 --> 00:15:29,278
SPEAKER_0:  the way that the world works.

00:15:30,530 --> 00:15:33,086
SPEAKER_0:  is that many of these experiences are cordoned off.

00:15:33,346 --> 00:15:34,686
SPEAKER_0:  little bit behind a velvet rope.

00:15:35,874 --> 00:15:36,318
SPEAKER_0:  where.

00:15:37,986 --> 00:15:41,886
SPEAKER_0:  you think that there's more happiness as the prices of things escalate.

00:15:42,818 --> 00:15:45,790
SPEAKER_0:  Right? If you live in an apartment, you admire the person with the house.

00:15:46,754 --> 00:15:49,182
SPEAKER_0:  If you live in a house, you admire the person with the bigger house.

00:15:50,562 --> 00:15:52,382
SPEAKER_0:  that person admires the person with.

00:15:52,770 --> 00:15:53,598
SPEAKER_0:  You know, um...

00:15:54,146 --> 00:15:54,718
SPEAKER_0:  an island.

00:15:55,138 --> 00:15:55,646
SPEAKER_0:  Right.

00:15:56,034 --> 00:15:56,510
SPEAKER_0:  Um.

00:15:57,506 --> 00:16:03,838
SPEAKER_0:  Some person drives their car, admires the person who flies, who admires the person who flies business class, admires the person who flies first.

00:16:04,642 --> 00:16:05,758
SPEAKER_0:  you know, to private.

00:16:06,018 --> 00:16:08,702
SPEAKER_0:  There's all of these escalations on this table.

00:16:09,890 --> 00:16:11,934
SPEAKER_0:  and most people get to the first five or six.

00:16:13,250 --> 00:16:15,006
SPEAKER_0:  And so they just naturally assume.

00:16:15,458 --> 00:16:16,190
SPEAKER_0:  that items.

00:16:16,514 --> 00:16:18,398
SPEAKER_0:  you know, seven through 100.

00:16:18,946 --> 00:16:20,414
SPEAKER_0:  is really where happiness is found.

00:16:21,538 --> 00:16:23,070
SPEAKER_0:  And just to...

00:16:23,298 --> 00:16:23,646
SPEAKER_0:  You know.

00:16:24,066 --> 00:16:25,470
SPEAKER_0:  tell you the finish line.

00:16:25,698 --> 00:16:29,534
SPEAKER_0:  I've tried 100 and back and I've tried 200 to it.

00:16:30,082 --> 00:16:30,430
SPEAKER_0:  Uh.

00:16:30,914 --> 00:16:32,094
SPEAKER_0:  and happiness isn't there.

00:16:32,770 --> 00:16:33,246
SPEAKER_0:  Um

00:16:34,722 --> 00:16:36,990
SPEAKER_0:  but it does give you a level of comfort. But these are tips are a one and one ambitious journey.

00:16:38,306 --> 00:16:40,094
SPEAKER_0:  And I don't know if it's true or not, but it said that.

00:16:40,674 --> 00:16:41,022
SPEAKER_0:  Um.

00:16:41,250 --> 00:16:43,966
SPEAKER_0:  the absolute sort of like maximal.

00:16:44,546 --> 00:16:47,134
SPEAKER_0:  link between money and happiness.

00:16:47,874 --> 00:16:49,598
SPEAKER_0:  is around $50 million.

00:16:51,458 --> 00:16:56,190
SPEAKER_0:  And it was just like a social studies kind of thing that I think one of the Ivy Leagues put out.

00:16:56,642 --> 00:17:00,702
SPEAKER_0:  And underneath it, the way that they explained it was because you could have a home, you could have...

00:17:01,026 --> 00:17:02,654
SPEAKER_0:  all kinds of the creature comforts.

00:17:02,914 --> 00:17:04,190
SPEAKER_0:  you could take care of your family.

00:17:04,770 --> 00:17:05,150
SPEAKER_0:  Um.

00:17:05,410 --> 00:17:07,166
SPEAKER_0:  and then you were left to ponder.

00:17:07,970 --> 00:17:09,086
SPEAKER_0:  what it is that you really want.

00:17:10,082 --> 00:17:12,766
SPEAKER_0:  I think the challenge for most people is to realize that

00:17:13,634 --> 00:17:15,454
SPEAKER_0:  this escalating arms race of

00:17:16,066 --> 00:17:16,414
SPEAKER_0:  You know.

00:17:16,674 --> 00:17:18,910
SPEAKER_0:  more things will solve your problems.

00:17:19,554 --> 00:17:20,510
SPEAKER_0:  is not true.

00:17:21,538 --> 00:17:21,982
SPEAKER_0:

00:17:22,946 --> 00:17:25,054
SPEAKER_0:  more and better is not the solution.

00:17:25,474 --> 00:17:26,974
SPEAKER_0:  It's this idea that...

00:17:28,770 --> 00:17:29,342
SPEAKER_0:  You.

00:17:30,722 --> 00:17:34,238
SPEAKER_0:  are on a very precise journey that's unique to yourself, you are.

00:17:34,690 --> 00:17:35,422
SPEAKER_0:  playing a game?

00:17:36,290 --> 00:17:37,662
SPEAKER_0:  which only you are the player?

00:17:38,946 --> 00:17:40,382
SPEAKER_0:  Everybody else is an interloper.

00:17:42,050 --> 00:17:44,254
SPEAKER_0:  and you have a responsibility to design the gameplay.

00:17:46,178 --> 00:17:48,126
SPEAKER_0:  And I think a lot of people don't realize that.

00:17:48,386 --> 00:17:52,702
SPEAKER_0:  Because if they did, I think they would make a lot of different decisions about how they live their life.

00:17:53,794 --> 00:17:54,174
SPEAKER_0:  and

00:17:54,434 --> 00:17:56,478
SPEAKER_0:  I still do the same thing. I mean revert.

00:17:58,146 --> 00:18:00,286
SPEAKER_0:  to basically running around asking other people.

00:18:00,770 --> 00:18:02,078
SPEAKER_0:  What will make you like me more?

00:18:03,010 --> 00:18:04,286
SPEAKER_0:  You know what will make...

00:18:04,610 --> 00:18:07,070
SPEAKER_0:  me more popular in your eyes and I try to do it.

00:18:07,490 --> 00:18:08,414
SPEAKER_0:  and it never.

00:18:08,834 --> 00:18:09,278
SPEAKER_0:  Works.

00:18:10,562 --> 00:18:12,606
SPEAKER_0:  It is just a complete dead end.

00:18:12,962 --> 00:18:14,718
SPEAKER_1:  is there negative aspects to money.

00:18:15,938 --> 00:18:16,926
SPEAKER_1:  For example,

00:18:17,538 --> 00:18:19,998
SPEAKER_1:  it becoming harder to find people you can trust.

00:18:20,834 --> 00:18:23,742
SPEAKER_0:  I think the most negative aspect is that it amplifies.

00:18:24,450 --> 00:18:27,102
SPEAKER_0:  a 360 degree view of your personality.

00:18:28,258 --> 00:18:31,710
SPEAKER_0:  because there are a lot of people and society tells you...

00:18:32,290 --> 00:18:33,374
SPEAKER_0:  that more money.

00:18:33,730 --> 00:18:36,414
SPEAKER_0:  is actually better. You are a better person somehow.

00:18:37,250 --> 00:18:41,182
SPEAKER_0:  and you're factually more worthwhile than some other people that have less money.

00:18:41,890 --> 00:18:42,846
SPEAKER_0:  That's also a lie.

00:18:44,130 --> 00:18:45,950
SPEAKER_0:  when you're given that kind of attention.

00:18:46,338 --> 00:18:47,870
SPEAKER_0:  It's very easy for you to become.

00:18:48,130 --> 00:18:49,374
SPEAKER_0:  a caricature of yourself.

00:18:50,146 --> 00:18:53,246
SPEAKER_0:  That's probably the single worst thing that happens to you.

00:18:53,730 --> 00:18:56,478
SPEAKER_0:  But I say it in the opposite way. I think all I've ever seen.

00:18:56,706 --> 00:18:58,206
SPEAKER_0:  In Silicon Valley, as an example,

00:18:58,850 --> 00:18:59,294
SPEAKER_0:  Um.

00:19:00,034 --> 00:19:00,574
SPEAKER_0:  is that.

00:19:01,154 --> 00:19:03,166
SPEAKER_0:  when somebody gets ahold of a lot of money.

00:19:03,490 --> 00:19:06,366
SPEAKER_0:  it tends to cause them to become exactly who they were meant to be.

00:19:07,298 --> 00:19:10,494
SPEAKER_0:  They're either a kind person, they're either a curious person.

00:19:11,010 --> 00:19:11,934
SPEAKER_0:  They're either a jerk.

00:19:12,418 --> 00:19:13,502
SPEAKER_0:  You know, they're either cheap.

00:19:14,018 --> 00:19:19,998
SPEAKER_0:  and they can use all kinds of masks, but now that there's no expectations and society gives you a get out of jail free card,

00:19:20,578 --> 00:19:24,862
SPEAKER_0:  you start to behave the way that's most comfortable to you. So you see somebody's innate personality.

00:19:25,826 --> 00:19:29,790
SPEAKER_0:  And that's a really interesting thing to observe because then you can very quickly bucket sort.

00:19:30,498 --> 00:19:32,382
SPEAKER_0:  Where do you want to spend time and who is really?

00:19:32,930 --> 00:19:34,718
SPEAKER_0:  you know, additive to your gameplay.

00:19:35,970 --> 00:19:38,110
SPEAKER_0:  and who is really a negative detractor to your gameplay.

00:19:38,722 --> 00:19:42,494
SPEAKER_1:  You're an investor, but you're also a kind of philosopher.

00:19:43,074 --> 00:19:49,982
SPEAKER_1:  Um, you analyze the world in all this different, uh, perspectives on all in podcasts on Twitter everywhere.

00:19:50,434 --> 00:19:50,910
SPEAKER_1:  Uh...

00:19:52,514 --> 00:19:53,950
SPEAKER_1:  Do you worry that money?

00:19:54,562 --> 00:19:56,446
SPEAKER_1:  makes puts you out of touch.

00:19:57,314 --> 00:19:57,822
SPEAKER_1:  some.

00:19:58,850 --> 00:20:04,158
SPEAKER_1:  being able to truly empathize with the experience of the general population.

00:20:04,770 --> 00:20:05,214
SPEAKER_1:  which.

00:20:05,442 --> 00:20:09,854
SPEAKER_1:  in part, first of all, on a human level that could be limiting, but also as an analyst.

00:20:10,370 --> 00:20:12,222
SPEAKER_1:  of human civilization that could be limiting.

00:20:13,794 --> 00:20:19,070
SPEAKER_0:  I think it definitely can for a lot of people because it's just, it's an abstraction for you to stop caring.

00:20:20,034 --> 00:20:20,446
SPEAKER_0:  Um...

00:20:20,770 --> 00:20:22,206
SPEAKER_0:  I also think the other thing is that

00:20:23,746 --> 00:20:25,598
SPEAKER_0:  you can very quickly.

00:20:26,146 --> 00:20:27,870
SPEAKER_0:  especially in today's world.

00:20:28,450 --> 00:20:29,566
SPEAKER_0:  become the scapegoat.

00:20:29,986 --> 00:20:34,526
SPEAKER_0:  just to use a Gerardian like René Gerard. If you think about like mimetic theory in a nutshell.

00:20:35,458 --> 00:20:35,774
SPEAKER_0:  You know.

00:20:36,578 --> 00:20:37,726
SPEAKER_0:  We're all competing.

00:20:38,818 --> 00:20:41,822
SPEAKER_0:  for these very scarce resources that we are told is worthwhile.

00:20:42,530 --> 00:20:46,366
SPEAKER_0:  And if you view the world through that Girardian lens.

00:20:47,042 --> 00:20:50,110
SPEAKER_0:  What are we really doing? We are all fighting for scarce resources.

00:20:50,754 --> 00:20:51,422
SPEAKER_0:  Whether that's.

00:20:51,682 --> 00:20:52,606
SPEAKER_0:  Twitter followers.

00:20:52,994 --> 00:20:53,598
SPEAKER_0:  Money.

00:20:53,922 --> 00:20:55,486
SPEAKER_0:  Acclaim notoriety.

00:20:55,938 --> 00:20:58,110
SPEAKER_0:  and we all compete with each other. And in that,

00:20:58,402 --> 00:20:59,166
SPEAKER_0:  competition.

00:21:00,482 --> 00:21:03,582
SPEAKER_0:  You know, Gerard writes, like, the only way you escape that loop...

00:21:04,194 --> 00:21:06,782
SPEAKER_0:  is by scapegoating something or somebody.

00:21:07,970 --> 00:21:12,350
SPEAKER_0:  And I think we are in that loop right now where just the fact of being successful...

00:21:12,706 --> 00:21:14,622
SPEAKER_0:  is a thing that one should scapegoat.

00:21:15,170 --> 00:21:16,926
SPEAKER_0:  to end all of this, you know.

00:21:17,474 --> 00:21:18,462
SPEAKER_0:  tension that we have.

00:21:19,650 --> 00:21:23,934
SPEAKER_0:  I think that it's a little misguided because I don't think it solves the fundamental problem.

00:21:24,674 --> 00:21:25,150
SPEAKER_0:  Um...

00:21:25,442 --> 00:21:27,966
SPEAKER_0:  And we can talk about what the solution to some of these problems are, but...

00:21:28,386 --> 00:21:28,734
SPEAKER_0:  Um.

00:21:29,346 --> 00:21:31,486
SPEAKER_0:  That's, I think, the loop that we're all living.

00:21:32,002 --> 00:21:35,646
SPEAKER_0:  And so if you become a caricature and you feed yourself into it...

00:21:36,578 --> 00:21:38,942
SPEAKER_0:  I mean, you're not doing anything to really advance things.

00:21:40,354 --> 00:21:42,814
SPEAKER_1:  Your nickname is The Dictator. How'd you get the nickname?

00:21:43,074 --> 00:21:45,566
SPEAKER_1:  We're talking about the corrupting nature of money.

00:21:46,018 --> 00:21:47,134
SPEAKER_0:  That came from poker.

00:21:47,682 --> 00:21:52,510
SPEAKER_0:  In a poker game, you know, when you sit down, it's chaos, especially like in our home game.

00:21:53,026 --> 00:21:57,630
SPEAKER_0:  There's a ton of big egos. There's people always watching, you know, rail-birding the game.

00:21:57,954 --> 00:21:59,390
SPEAKER_0:  all kinds of interesting folks.

00:22:00,450 --> 00:22:03,134
SPEAKER_0:  and in that somebody needs to establish.

00:22:03,394 --> 00:22:04,862
SPEAKER_0:  hygiene and rules.

00:22:05,666 --> 00:22:07,774
SPEAKER_0:  and I really care about the integrity of the game.

00:22:08,322 --> 00:22:10,654
SPEAKER_0:  and it would just require somebody to just say, okay, enough.

00:22:11,554 --> 00:22:12,286
SPEAKER_0:  And so.

00:22:12,578 --> 00:22:14,526
SPEAKER_0:  And then people were just like, okay, stop dictating.

00:22:15,106 --> 00:22:16,510
SPEAKER_0:  And that's where that digs in.

00:22:16,930 --> 00:22:22,910
SPEAKER_1:  So who to you, speaking of which, is the greatest poker player of all time, and why is it Phil Hellmuth?

00:22:23,714 --> 00:22:24,286
SPEAKER_0:  Exactly.

00:22:24,642 --> 00:22:27,102
SPEAKER_0:  You know, Muth probably knew this question was coming. Are you sure you don't know the

00:22:27,586 --> 00:22:28,958
SPEAKER_0:  Here's what I'll say, I think Helmuth.

00:22:29,186 --> 00:22:29,630
SPEAKER_0:  is

00:22:30,210 --> 00:22:31,134
SPEAKER_0:  The antidote.

00:22:31,618 --> 00:22:32,254
SPEAKER_0:  to computers.

00:22:32,674 --> 00:22:34,334
SPEAKER_0:  more than any other player playing today.

00:22:35,298 --> 00:22:36,350
SPEAKER_0:  And when you see him...

00:22:37,378 --> 00:22:40,158
SPEAKER_0:  in a heads up situation. So I think like he's played.

00:22:40,770 --> 00:22:41,886
SPEAKER_0:  Nine or ten heads up.

00:22:42,402 --> 00:22:43,390
SPEAKER_0:  tournaments in a row.

00:22:44,418 --> 00:22:47,646
SPEAKER_0:  and he's played like basically call it 10 of the top 20 people so far.

00:22:48,354 --> 00:22:49,662
SPEAKER_0:  And he's beaten all but one of them.

00:22:51,874 --> 00:22:52,926
SPEAKER_0:  When you're playing heads up...

00:22:53,410 --> 00:22:54,526
SPEAKER_0:  You know, 1v1.

00:22:55,586 --> 00:22:56,798
SPEAKER_0:  That is the most.

00:22:57,090 --> 00:22:57,502
SPEAKER_0:  Um.

00:22:59,074 --> 00:23:00,030
SPEAKER_0:  GTO.

00:23:00,962 --> 00:23:04,190
SPEAKER_0:  understandable spot meaning game theory optimal position.

00:23:04,642 --> 00:23:07,294
SPEAKER_0:  That's where computers can give you an enormous edge.

00:23:07,778 --> 00:23:09,406
SPEAKER_0:  The minute you add even a third player...

00:23:09,986 --> 00:23:12,606
SPEAKER_0:  the value of computers and the value of their...

00:23:12,866 --> 00:23:13,822
SPEAKER_0:  recommendations.

00:23:14,530 --> 00:23:16,158
SPEAKER_0:  basically falls off a cliff, okay?

00:23:17,410 --> 00:23:20,734
SPEAKER_0:  One way to think about it is Hellmuth is forced to play against people.

00:23:21,026 --> 00:23:22,814
SPEAKER_0:  that are essentially trained like AIs.

00:23:23,842 --> 00:23:25,054
SPEAKER_0:  And so to be able to beat...

00:23:25,538 --> 00:23:27,198
SPEAKER_0:  You know, eight out of nine of them.

00:23:27,938 --> 00:23:30,014
SPEAKER_0:  means that you are playing so orthogonally.

00:23:30,594 --> 00:23:32,414
SPEAKER_0:  to what is considered game theory optimal.

00:23:32,802 --> 00:23:34,110
SPEAKER_0:  and you're overlaying.

00:23:34,690 --> 00:23:35,422
SPEAKER_0:  human reasoning.

00:23:36,482 --> 00:23:39,870
SPEAKER_0:  the judgment to say, well, in this spot, I should do x, but I'm going to do y.

00:23:40,322 --> 00:23:43,678
SPEAKER_0:  It's not dissimilar in chess, like what makes, you know, Magnus Carlsen so good.

00:23:44,802 --> 00:23:48,158
SPEAKER_0:  Sometimes he takes these weird lines, he'll sacrifice positions.

00:23:48,386 --> 00:23:51,486
SPEAKER_0:  know, he'll overplay certain positions or certain, you know.

00:23:52,098 --> 00:23:55,038
SPEAKER_0:  Bishops versus Knights in all of these spots that are very confusing.

00:23:56,610 --> 00:24:01,918
SPEAKER_0:  And what it does is it throws people off their game. I think he just won a recent online tournament and it's like by move six.

00:24:03,042 --> 00:24:04,190
SPEAKER_0:  There is no GTO.

00:24:05,730 --> 00:24:08,862
SPEAKER_0:  move for his opponent to make because it's like out of the rule book.

00:24:09,250 --> 00:24:10,398
SPEAKER_0:  Maybe he read some game.

00:24:10,626 --> 00:24:12,894
SPEAKER_0:  You know, I read the quote, it was like, he probably read some game.

00:24:13,122 --> 00:24:16,414
SPEAKER_0:  in some bar in Russia in 1954, memorized it.

00:24:16,770 --> 00:24:18,398
SPEAKER_0:  and all of a sudden, BISIX moves in.

00:24:18,722 --> 00:24:21,822
SPEAKER_0:  the computer AI is worthless. So that's what makes Helm Youth great.

00:24:23,650 --> 00:24:24,062
SPEAKER_0:  The.

00:24:25,090 --> 00:24:26,910
SPEAKER_0:  There is one person that I think is.

00:24:27,842 --> 00:24:28,414
SPEAKER_0:  Superior.

00:24:29,442 --> 00:24:29,886
SPEAKER_0:  Um...

00:24:30,338 --> 00:24:33,406
SPEAKER_0:  And I think it's what Daniel also said, and I would echo that because I played Phil.

00:24:33,826 --> 00:24:35,262
SPEAKER_0:  as well, but Phil Ivey is.

00:24:36,386 --> 00:24:38,398
SPEAKER_0:  the most well-rounded

00:24:41,442 --> 00:24:42,366
SPEAKER_0:  cold-blooded.

00:24:43,170 --> 00:24:44,350
SPEAKER_0:  bloodthirsty animal.

00:24:44,578 --> 00:24:44,958
SPEAKER_0:  I don't know.

00:24:45,506 --> 00:24:46,334
SPEAKER_0:  He is

00:24:46,626 --> 00:24:51,518
SPEAKER_0:  He's just, and he sees into your soul, Lex, in a way where you're just like, oh my god.

00:24:51,746 --> 00:24:52,734
SPEAKER_0:  Stop looking at me.

00:24:53,730 --> 00:24:57,918
SPEAKER_0:  Have you ever played him? Yeah, yeah, we've played. We've played and he crushes the games.

00:24:58,498 --> 00:24:59,230
SPEAKER_0:  crushes the games.

00:24:59,554 --> 00:25:00,679
SPEAKER_0:  So what is feeling?

00:25:00,679 --> 00:25:01,118
SPEAKER_1:  crushed.

00:25:01,474 --> 00:25:04,478
SPEAKER_1:  mean and feel like in poker? Is it like...

00:25:04,802 --> 00:25:08,222
SPEAKER_1:  that you just can't read at all, you being constantly pressured.

00:25:08,514 --> 00:25:09,822
SPEAKER_1:  You feel off balance.

00:25:10,050 --> 00:25:14,014
SPEAKER_1:  You try to bluff and the person reads you perfectly that kind of stuff.

00:25:14,402 --> 00:25:19,518
SPEAKER_0:  It's a really, really excellent question because I think this has parallels to a bunch of other things.

00:25:20,482 --> 00:25:25,086
SPEAKER_0:  Okay, let's just use poker as a microcosm to explain a bunch of other systems or games.

00:25:25,954 --> 00:25:27,038
SPEAKER_0:  Maybe it's, um...

00:25:27,938 --> 00:25:28,734
SPEAKER_0:  running a company.

00:25:29,378 --> 00:25:30,398
SPEAKER_0:  investing.

00:25:30,658 --> 00:25:33,598
SPEAKER_0:  Okay, so let's use those three examples, but we use Procore to explain it.

00:25:34,274 --> 00:25:35,678
SPEAKER_0:  What does success look like?

00:25:36,194 --> 00:25:38,782
SPEAKER_0:  Well, success looks like you have positive expected value.

00:25:40,098 --> 00:25:42,622
SPEAKER_0:  In poker, the simple way to summarize that is...

00:25:43,426 --> 00:25:44,222
SPEAKER_0:  Your opponent

00:25:44,994 --> 00:25:46,206
SPEAKER_0:  Let's just say you and I are playing.

00:25:46,882 --> 00:25:48,286
SPEAKER_0:  are going to make a bunch of mistakes.

00:25:48,834 --> 00:25:51,198
SPEAKER_0:  There's a bunch of it that's going to be absolutely perfect.

00:25:51,938 --> 00:25:53,822
SPEAKER_0:  And then there's a few spots where you make mistakes.

00:25:54,914 --> 00:25:55,742
SPEAKER_0:  And then there's a bunch of.

00:25:56,418 --> 00:25:58,590
SPEAKER_0:  places in the poker game where I play perfectly.

00:25:59,586 --> 00:26:00,638
SPEAKER_0:  And I make a few mistakes.

00:26:02,722 --> 00:26:06,366
SPEAKER_0:  Basically, your mistakes minus my mistakes.

00:26:06,754 --> 00:26:07,966
SPEAKER_0:  is the edge, right?

00:26:08,834 --> 00:26:10,910
SPEAKER_0:  That's how poker works.

00:26:11,298 --> 00:26:16,734
SPEAKER_0:  If I make fewer mistakes than you make, I will make money and I will win. That is the objective of the game.

00:26:17,698 --> 00:26:18,942
SPEAKER_0:  Translate that into business.

00:26:19,842 --> 00:26:20,926
SPEAKER_0:  You're running a company?

00:26:21,698 --> 00:26:25,662
SPEAKER_0:  You have a team of employees, you have a pool of human capital that's capable of-

00:26:25,922 --> 00:26:28,574
SPEAKER_0:  of being productive in the world and creating something.

00:26:29,890 --> 00:26:31,742
SPEAKER_0:  but you are going to make mistakes.

00:26:32,610 --> 00:26:33,406
SPEAKER_0:  in making that.

00:26:34,402 --> 00:26:37,694
SPEAKER_0:  Maybe it doesn't completely fit the market. Maybe it's mispriced.

00:26:38,146 --> 00:26:39,262
SPEAKER_0:  Maybe it actually doesn't.

00:26:39,522 --> 00:26:42,558
SPEAKER_0:  require all of the people that you need so the margins are wrong.

00:26:43,810 --> 00:26:46,718
SPEAKER_0:  And then there's the competitive set of all the other alternatives.

00:26:47,138 --> 00:26:48,286
SPEAKER_0:  that customer has.

00:26:49,602 --> 00:26:51,326
SPEAKER_0:  Their mistakes minus your mistakes.

00:26:52,034 --> 00:26:55,966
SPEAKER_0:  is the expected value of Google, Facebook, Apple, etc.

00:26:56,706 --> 00:26:58,142
SPEAKER_0:  Okay, now take investing.

00:26:59,394 --> 00:27:00,862
SPEAKER_0:  Every time you buy something...

00:27:01,506 --> 00:27:03,582
SPEAKER_0:  Somebody else on the other side is selling it to you.

00:27:05,698 --> 00:27:06,654
SPEAKER_0:  Is that their mistake?

00:27:06,978 --> 00:27:07,614
SPEAKER_0:  We don't know yet.

00:27:08,546 --> 00:27:11,070
SPEAKER_0:  but their mistakes minus your mistakes.

00:27:12,194 --> 00:27:15,326
SPEAKER_0:  is how you make a lot of money over long periods of time as an investor.

00:27:16,322 --> 00:27:19,934
SPEAKER_0:  Somebody sold you Google at $40 a share. You bought it and you kept it.

00:27:21,058 --> 00:27:22,270
SPEAKER_0:  Huge mistake on their part.

00:27:22,658 --> 00:27:24,190
SPEAKER_0:  Minimum mistakes on your part.

00:27:25,378 --> 00:27:27,038
SPEAKER_0:  the difference of that is the money that you made.

00:27:28,002 --> 00:27:31,806
SPEAKER_0:  So life can be summarized in many ways in that way. So the question is-

00:27:32,642 --> 00:27:35,710
SPEAKER_0:  What can you do about other people's mistakes? And the answer is nothing.

00:27:36,450 --> 00:27:48,766
SPEAKER_0:  That is somebody else's game. You can try to influence them. You could try to subvert them. Maybe you plant a spy inside of that other person's company to sabotage them. I guess there are things at the edges that you can do.

00:27:50,114 --> 00:27:55,102
SPEAKER_0:  But my firm belief is that life success really boils down to how do you control

00:27:55,938 --> 00:27:56,766
SPEAKER_0:  your mistakes.

00:27:57,986 --> 00:27:59,326
SPEAKER_0:  Now this is a bit counterintuitive.

00:28:00,066 --> 00:28:02,622
SPEAKER_0:  The way you control your mistakes is by making a lot of mistakes.

00:28:04,002 --> 00:28:05,022
SPEAKER_0:  for taking risks.

00:28:05,538 --> 00:28:07,326
SPEAKER_1:  You have to. You have to.

00:28:07,682 --> 00:28:09,557
SPEAKER_1:  You have to, you have to. You have to, you have to.

00:28:09,557 --> 00:28:12,094
SPEAKER_0:  the number of mistakes. Let's just say you want to find love.

00:28:12,610 --> 00:28:15,518
SPEAKER_0:  Yeah. You know, you want to find some go on deeply connected.

00:28:17,346 --> 00:28:18,686
SPEAKER_0:  Are you, do you do that?

00:28:19,010 --> 00:28:21,534
SPEAKER_0:  by not going out on dates and yes.

00:28:21,858 --> 00:28:28,030
SPEAKER_0:  Sorry, sorry. You're the only person that thinks that's the answer to that question. No, I'm joking, I'm joking.

00:28:28,290 --> 00:28:31,582
SPEAKER_0:  Like you have to date people, you have to open yourself up, you have to be

00:28:32,002 --> 00:28:33,086
SPEAKER_0:  authentic and like.

00:28:33,602 --> 00:28:35,998
SPEAKER_0:  You give yourself a chance to get hurt.

00:28:36,482 --> 00:28:40,510
SPEAKER_0:  Yes. But you're a good person, so you know what happens when you get hurt? That is actually their mistake.

00:28:41,570 --> 00:28:42,046
SPEAKER_0:  Okay.

00:28:42,306 --> 00:28:43,710
SPEAKER_0:  And if you are inauthentic...

00:28:44,034 --> 00:28:44,990
SPEAKER_0:  That's your mistake.

00:28:46,018 --> 00:28:48,702
SPEAKER_0:  That's a controllable thing in you. You can tell them the truth.

00:28:49,090 --> 00:28:49,758
SPEAKER_0:  you are.

00:28:50,146 --> 00:28:51,166
SPEAKER_0:  and say here's my.

00:28:51,906 --> 00:28:52,862
SPEAKER_0:  pluses and minuses.

00:28:53,250 --> 00:28:55,646
SPEAKER_0:  My point is, there are very few things in life.

00:28:56,450 --> 00:28:59,646
SPEAKER_0:  that you can't break down, I think, into that very simple idea.

00:29:01,090 --> 00:29:01,470
SPEAKER_0:  and

00:29:02,018 --> 00:29:03,582
SPEAKER_0:  In terms of your mistakes...

00:29:03,970 --> 00:29:06,014
SPEAKER_0:  Society tells you don't make them.

00:29:06,722 --> 00:29:09,214
SPEAKER_0:  because we will judge you and we will look down on you.

00:29:10,050 --> 00:29:13,374
SPEAKER_0:  And I think the really successful people realize that actually know.

00:29:14,018 --> 00:29:15,742
SPEAKER_0:  It's the cycle time of mistakes.

00:29:15,970 --> 00:29:17,182
SPEAKER_0:  that gets you to success.

00:29:17,954 --> 00:29:20,062
SPEAKER_0:  because your error rate will diminish.

00:29:20,354 --> 00:29:22,046
SPEAKER_0:  the more mistakes that you make.

00:29:22,626 --> 00:29:23,454
SPEAKER_0:  You observed them?

00:29:23,746 --> 00:29:27,006
SPEAKER_0:  you figure out where it's coming from. Is it a psychological thing? Is it a-

00:29:27,266 --> 00:29:29,470
SPEAKER_0:  cognitive thing, and then you fix it.

00:29:30,146 --> 00:29:32,990
SPEAKER_1:  So the implied thing there is that there's a.

00:29:34,338 --> 00:29:38,782
SPEAKER_1:  uh, in, in business and investing in poker and dating and life.

00:29:39,298 --> 00:29:43,966
SPEAKER_1:  is that there's this platonic GTO game theory optimal thing out there.

00:29:44,354 --> 00:29:45,886
SPEAKER_1:  And so when you say mistakes.

00:29:46,338 --> 00:29:49,342
SPEAKER_1:  you're always comparing to that optimal path you could have taken.

00:29:49,666 --> 00:29:51,614
SPEAKER_0:  I think slightly different, I would say.

00:29:51,874 --> 00:29:56,382
SPEAKER_0:  Mistake is maybe a bad proxy, but it's the best proxy I have for learning.

00:29:57,250 --> 00:29:59,902
SPEAKER_0:  but I'm using the language of what society tells you.

00:30:01,538 --> 00:30:05,886
SPEAKER_0:  Society tells you that when you try something and it doesn't work, it's a mistake.

00:30:07,138 --> 00:30:11,262
SPEAKER_0:  So I just use that word because it's the word that resonates most with most people. Thank you.

00:30:12,098 --> 00:30:13,790
SPEAKER_0:  The real thing that it is is learning.

00:30:14,114 --> 00:30:15,989
SPEAKER_1:  Yeah, it's like in neural networks.

00:30:15,989 --> 00:30:17,489
SPEAKER_0:  loss. It's loss.

00:30:17,489 --> 00:30:23,358
SPEAKER_1:  Exactly. Yeah, right, so you're using the mistake that is most, the word that is most understandable.

00:30:23,778 --> 00:30:27,422
SPEAKER_1:  Especially by the way people experience it. I guess most of life

00:30:27,906 --> 00:30:29,406
SPEAKER_1:  is a sequence of mistakes.

00:30:29,762 --> 00:30:34,782
SPEAKER_1:  The problem is when you use the word mistake and you think about mistakes, it actually is the.

00:30:35,458 --> 00:30:41,086
SPEAKER_1:  counterproductive effect of you becoming conservative in just being risk averse.

00:30:41,826 --> 00:30:47,646
SPEAKER_1:  So that's, if you flip it and say, try to maximize the number of successes.

00:30:48,002 --> 00:30:48,542
SPEAKER_1:  somehow.

00:30:48,834 --> 00:30:51,006
SPEAKER_1:  that leads you to take more risk.

00:30:51,682 --> 00:30:52,190
SPEAKER_1:  Um...

00:30:52,546 --> 00:30:53,342
SPEAKER_1:  Mistake.

00:30:53,634 --> 00:30:54,590
SPEAKER_0:  scares people.

00:30:55,522 --> 00:30:56,318
SPEAKER_0:  I think mistakes.

00:30:56,674 --> 00:30:57,534
SPEAKER_0:  scare people.

00:30:57,794 --> 00:30:58,270
SPEAKER_0:  because

00:30:58,658 --> 00:30:59,902
SPEAKER_0:  society likes.

00:31:01,442 --> 00:31:03,422
SPEAKER_0:  these very simplified boundaries.

00:31:03,714 --> 00:31:05,406
SPEAKER_0:  of who is winning and who is losing.

00:31:06,242 --> 00:31:08,030
SPEAKER_0:  and they want to reward.

00:31:08,962 --> 00:31:11,198
SPEAKER_0:  people who make traditional choices.

00:31:12,514 --> 00:31:13,502
SPEAKER_0:  and succeed.

00:31:14,850 --> 00:31:15,582
SPEAKER_0:  But the thing is...

00:31:15,810 --> 00:31:16,606
SPEAKER_0:  What's so...

00:31:19,394 --> 00:31:20,510
SPEAKER_0:  corrosive about that.

00:31:21,506 --> 00:31:23,038
SPEAKER_0:  is that they're actually not even.

00:31:23,490 --> 00:31:24,798
SPEAKER_0:  being put in a position.

00:31:25,122 --> 00:31:28,670
SPEAKER_0:  to actually make a quote unquote mistake and fail. So I'll give you a-

00:31:28,930 --> 00:31:31,326
SPEAKER_0:  if you look at like getting into an elite school.

00:31:32,578 --> 00:31:35,198
SPEAKER_0:  Right, society rewards you for being in the Ivy Leagues.

00:31:36,194 --> 00:31:38,558
SPEAKER_0:  in a way that, in my opinion, incorrectly.

00:31:39,010 --> 00:31:41,406
SPEAKER_0:  doesn't reward you for being in a non-IV league school.

00:31:42,434 --> 00:31:43,934
SPEAKER_0:  There's a certain level of status.

00:31:44,418 --> 00:31:47,582
SPEAKER_0:  and presumption of intellect and capability that comes with being there.

00:31:48,802 --> 00:31:49,182
SPEAKER_0:  Um.

00:31:49,698 --> 00:31:50,718
SPEAKER_0:  But that system...

00:31:51,362 --> 00:31:56,830
SPEAKER_0:  doesn't really have a counterfactual because it's not as if you both go to MIT and Ohio State.

00:31:58,114 --> 00:32:03,166
SPEAKER_0:  then we can see two versions of Lex Friedman so that we can figure out that the jig is up and there was no difference.

00:32:03,714 --> 00:32:04,030
SPEAKER_0:

00:32:04,482 --> 00:32:06,686
SPEAKER_0:  Right. And so instead it reinforces.

00:32:07,138 --> 00:32:08,862
SPEAKER_0:  this idea that there is no...

00:32:09,186 --> 00:32:12,926
SPEAKER_0:  Truth-seeking function there is no way to actually make this thing whole

00:32:13,986 --> 00:32:16,862
SPEAKER_0:  And so it tells you, you have to get in here.

00:32:17,090 --> 00:32:19,550
SPEAKER_0:  And if you don't, your life is over. You've made a huge mistake.

00:32:20,226 --> 00:32:21,886
SPEAKER_0:  you know, or you failed completely.

00:32:23,138 --> 00:32:26,174
SPEAKER_0:  And so you have to find different unique ways of dismantling.

00:32:26,946 --> 00:32:27,646
SPEAKER_0:  This is why.

00:32:28,226 --> 00:32:29,790
SPEAKER_0:  you know, part of what I realized.

00:32:30,658 --> 00:32:32,254
SPEAKER_0:  where I got very lucky is.

00:32:32,994 --> 00:32:34,334
SPEAKER_0:  I had no friends in high school.

00:32:35,458 --> 00:32:36,702
SPEAKER_0:  add a few cohort of.

00:32:36,994 --> 00:32:37,854
SPEAKER_0:  acquaintances.

00:32:39,138 --> 00:32:41,182
SPEAKER_0:  But part of being so hyper-vigilant when I grew up...

00:32:41,794 --> 00:32:42,142
SPEAKER_0:  was.

00:32:42,370 --> 00:32:46,398
SPEAKER_0:  I was so ashamed of that world that I had to live in.

00:32:47,010 --> 00:32:48,638
SPEAKER_0:  I didn't want to bring anyone into it.

00:32:49,250 --> 00:32:51,806
SPEAKER_0:  I could not see myself that anybody would accept me.

00:32:53,474 --> 00:32:54,590
SPEAKER_0:  But the thing with that...

00:32:55,266 --> 00:32:57,278
SPEAKER_0:  is that I had no definition.

00:32:57,826 --> 00:32:59,806
SPEAKER_0:  of what expectations should be.

00:33:00,322 --> 00:33:02,462
SPEAKER_0:  So they were not guided by the people around me.

00:33:03,170 --> 00:33:05,991
SPEAKER_0:  And so I would escape to define my expectations.

00:33:05,991 --> 00:33:07,870
SPEAKER_1:  That's interesting, but you didn't feel...

00:33:08,450 --> 00:33:09,054
SPEAKER_1:  Um

00:33:09,410 --> 00:33:10,526
SPEAKER_1:  like your dad.

00:33:11,362 --> 00:33:13,790
SPEAKER_1:  didn't put you in a prison of expectation.

00:33:14,658 --> 00:33:20,158
SPEAKER_1:  or we, because like that's, if you don't have front, like so the flip side of that, you don't have any other signals.

00:33:20,482 --> 00:33:22,910
SPEAKER_1:  It's very easy to believe when you're in a cult.

00:33:23,202 --> 00:33:23,518
SPEAKER_1:  it.

00:33:24,034 --> 00:33:24,830
SPEAKER_0:  Well, he, you know.

00:33:25,698 --> 00:33:26,878
SPEAKER_0:  He was angry.

00:33:27,458 --> 00:33:28,318
SPEAKER_0:  He pushed me.

00:33:29,474 --> 00:33:33,150
SPEAKER_0:  He used me as a mechanism to alleviate his own frustration.

00:33:33,794 --> 00:33:36,702
SPEAKER_0:  And this may sound very crazy, but he also believed in me.

00:33:38,914 --> 00:33:43,789
SPEAKER_0:  And so that's what created this weird duality where you were just, I was always confused about. You can contact me at ccurrington.com

00:33:43,789 --> 00:33:44,638
SPEAKER_1:  be somebody great.

00:33:45,058 --> 00:33:46,183
SPEAKER_1:  He believed that you could.

00:33:46,183 --> 00:33:48,638
SPEAKER_0:  be somebody truly special.

00:33:49,762 --> 00:33:52,894
SPEAKER_0:  because I couldn't reconcile than the other half of the day.

00:33:53,346 --> 00:33:54,494
SPEAKER_0:  you know, those behaviors.

00:33:56,130 --> 00:33:58,974
SPEAKER_0:  but what it allowed me to do was I escaped.

00:33:59,650 --> 00:34:00,574
SPEAKER_0:  in my mind?

00:34:01,346 --> 00:34:04,126
SPEAKER_0:  and I found these archetypes around me.

00:34:05,314 --> 00:34:06,462
SPEAKER_0:  were saviors to me.

00:34:07,778 --> 00:34:10,238
SPEAKER_0:  So, you know, I grew up in Ottawa, Ontario, Canada.

00:34:10,818 --> 00:34:11,230
SPEAKER_0:  I grew up.

00:34:11,618 --> 00:34:17,918
SPEAKER_0:  right at the point where the telecom boom was happening, companies like Nortel and Newbridge networks and Mitel.

00:34:18,338 --> 00:34:19,454
SPEAKER_0:  Bell Northern Research.

00:34:19,906 --> 00:34:21,246
SPEAKER_0:  These are all built in m-

00:34:21,474 --> 00:34:22,974
SPEAKER_0:  in the suburbs of Ottawa.

00:34:24,258 --> 00:34:27,070
SPEAKER_0:  And so there were these larger than life figures entrepreneurs.

00:34:27,298 --> 00:34:28,990
SPEAKER_0:  Terry Matthews, Michael Copeland.

00:34:29,858 --> 00:34:30,622
SPEAKER_0:  And so I thought.

00:34:30,850 --> 00:34:31,646
SPEAKER_0:  I'm going to be like them.

00:34:32,610 --> 00:34:38,270
SPEAKER_0:  I would read Forbes magazine, I would read Fortune magazine, I would look at the rich people on that list and say I would be like them.

00:34:39,074 --> 00:34:39,774
SPEAKER_0:  Not knowing.

00:34:40,834 --> 00:34:43,486
SPEAKER_0:  that maybe that's not who you want it to be.

00:34:44,514 --> 00:34:48,542
SPEAKER_0:  but it was a lifeline and it kept my mind relatively whole.

00:34:49,314 --> 00:34:51,230
SPEAKER_0:  because I could direct my ambition.

00:34:51,650 --> 00:34:52,350
SPEAKER_0:  in a direction.

00:34:53,858 --> 00:34:54,366
SPEAKER_0:  And so.

00:34:54,658 --> 00:34:56,894
SPEAKER_0:  Why that's so important just circling back to this is

00:34:57,282 --> 00:35:00,382
SPEAKER_0:  I didn't have a group of friends who were like, I'm going to go to community college.

00:35:01,282 --> 00:35:04,350
SPEAKER_0:  I didn't have a group of friends that said, well, you know, the goal is just to.

00:35:04,578 --> 00:35:08,222
SPEAKER_0:  Go to university, get a simple job, and join the public service.

00:35:08,674 --> 00:35:09,406
SPEAKER_0:  Have a good life.

00:35:10,210 --> 00:35:14,750
SPEAKER_0:  And so because I had no expectations and I was so afraid to venture out of my own house.

00:35:15,394 --> 00:35:17,406
SPEAKER_0:  I never saw what middle class life was like.

00:35:17,986 --> 00:35:23,262
SPEAKER_0:  and so I never aspired to it. Now, if I was close to it, I probably would have aspired to it because I-

00:35:23,554 --> 00:35:26,366
SPEAKER_0:  My parents in their best year made 32,000 Canadian.

00:35:26,914 --> 00:35:27,390
SPEAKER_0:  together.

00:35:28,706 --> 00:35:33,022
SPEAKER_0:  And if you're trying to raise a family of five people on $32,000, it's a complicated job.

00:35:33,858 --> 00:35:38,494
SPEAKER_0:  And most of the time they were probably making 20 something thousand. And I was working since I was 14. So masterpiece or what?

00:35:39,074 --> 00:35:44,062
SPEAKER_0:  I knew that our station in life was not the destination. We had to get out.

00:35:44,642 --> 00:35:45,022
SPEAKER_0:  Um.

00:35:45,666 --> 00:35:49,982
SPEAKER_0:  But because I didn't have an obvious place, it's not like I had a best friend whose house I was going to and-

00:35:50,242 --> 00:35:51,838
SPEAKER_0:  I saw some normal functional home.

00:35:53,474 --> 00:35:54,462
SPEAKER_0:  If I had had that.

00:35:55,138 --> 00:35:56,862
SPEAKER_0:  In this weird way, I would have aspired to that.

00:35:58,242 --> 00:35:59,774
SPEAKER_1:  What was the worst job you had to do?

00:36:00,322 --> 00:36:01,022
SPEAKER_0:  The best job.

00:36:02,498 --> 00:36:03,294
SPEAKER_0:  but the worst job.

00:36:03,746 --> 00:36:05,406
SPEAKER_0:  was I worked at Burger King.

00:36:05,762 --> 00:36:07,390
SPEAKER_0:  when I was 14 years old, and I would.

00:36:07,778 --> 00:36:08,894
SPEAKER_0:  Do the closing shift.

00:36:09,538 --> 00:36:10,270
SPEAKER_0:  And that was from like.

00:36:10,530 --> 00:36:11,518
SPEAKER_0:  6 p.m.

00:36:11,906 --> 00:36:13,022
SPEAKER_0:  till about two in the morning.

00:36:13,762 --> 00:36:14,334
SPEAKER_0:  and

00:36:14,754 --> 00:36:16,350
SPEAKER_0:  in Ontario where I lived.

00:36:16,834 --> 00:36:18,142
SPEAKER_0:  Ottawa borders Quebec.

00:36:18,466 --> 00:36:21,438
SPEAKER_0:  In Ontario, the drinking age is 19. You can see where I'm going with this.

00:36:22,274 --> 00:36:24,222
SPEAKER_0:  the drinking age in Quebec is 18.

00:36:24,578 --> 00:36:27,102
SPEAKER_0:  And that year made all the difference to all these kids.

00:36:28,002 --> 00:36:31,006
SPEAKER_0:  And so they would go get completely drunk. They would come back.

00:36:31,490 --> 00:36:32,702
SPEAKER_0:  they would come to the Burger King.

00:36:33,218 --> 00:36:38,014
SPEAKER_0:  You know, you would see all these kids you went to high school with. Can you imagine how mortifying it is? You know, you're working there in this getup.

00:36:39,266 --> 00:36:39,774
SPEAKER_0:  and.

00:36:40,418 --> 00:36:42,910
SPEAKER_0:  they would light that place on fire.

00:36:43,298 --> 00:36:44,542
SPEAKER_0:  vomit everywhere.

00:36:44,866 --> 00:36:46,718
SPEAKER_0:  yuking, pooing, peeing.

00:36:47,618 --> 00:36:50,110
SPEAKER_0:  And when the thing shuts down at one o'clock, you know.

00:36:50,818 --> 00:36:52,286
SPEAKER_0:  You gotta clean that all up.

00:36:53,090 --> 00:36:53,502
SPEAKER_0:  All of it.

00:36:54,082 --> 00:36:55,870
SPEAKER_0:  changing the garbage, taking it out.

00:36:56,866 --> 00:36:57,374
SPEAKER_0:  was.

00:36:58,306 --> 00:36:58,814
SPEAKER_0:  Um

00:37:02,178 --> 00:37:04,958
SPEAKER_0:  And it really teaches you, okay, I do not want this job.

00:37:06,050 --> 00:37:06,558
SPEAKER_0:  yeah

00:37:06,946 --> 00:37:07,262
SPEAKER_0:  I don't-

00:37:07,394 --> 00:37:12,254
SPEAKER_1:  But it's funny that that didn't push you towards the stability and the security of the middle class.

00:37:13,186 --> 00:37:15,390
SPEAKER_0:  I didn't have any good examples of that.

00:37:15,970 --> 00:37:18,174
SPEAKER_0:  I didn't have those around me. I was so ashamed.

00:37:19,298 --> 00:37:23,646
SPEAKER_0:  I could have never built a relationship where I could have seen those interactions to want But I got it

00:37:24,450 --> 00:37:29,246
SPEAKER_0:  And so my desires were framed by these two random rich people that lived in my town who I'd never met.

00:37:30,114 --> 00:37:32,926
SPEAKER_0:  and what I read in magazines about people like Bill Gates and Warren Buffett.

00:37:35,874 --> 00:37:36,830
SPEAKER_0:  You weren't.

00:37:36,930 --> 00:37:39,134
SPEAKER_1:  early senior executive at Facebook.

00:37:39,458 --> 00:37:43,006
SPEAKER_1:  uh, during a period of a lot of scaling in the company history. I mean...

00:37:43,298 --> 00:37:46,718
SPEAKER_1:  It's actually a fascinating period of human history in terms of technology.

00:37:48,194 --> 00:37:48,798
SPEAKER_1:  in terms of.

00:37:49,122 --> 00:37:51,262
SPEAKER_1:  human civilization, honestly.

00:37:51,554 --> 00:37:53,662
SPEAKER_1:  What did you learn from that?

00:37:54,850 --> 00:37:58,718
SPEAKER_1:  about what it takes to build and scale a successful tech company.

00:37:59,010 --> 00:37:59,806
SPEAKER_1:  accompany that.

00:38:00,610 --> 00:38:01,214
SPEAKER_1:  has.

00:38:02,018 --> 00:38:03,143
SPEAKER_1:  almost immeasurable.

00:38:03,143 --> 00:38:03,966
SPEAKER_0:  impact on the world.

00:38:06,434 --> 00:38:10,174
SPEAKER_0:  That was an incredible moment in time because everything was so new.

00:38:10,914 --> 00:38:14,206
SPEAKER_0:  your point, like even how the standards of Web 2.0 at that time

00:38:14,626 --> 00:38:16,798
SPEAKER_0:  were being defined, we were defining them.

00:38:17,314 --> 00:38:20,574
SPEAKER_0:  I mean, I think if you look in sort of the, if you search in the patterns,

00:38:21,378 --> 00:38:21,854
SPEAKER_0:  Um,

00:38:22,786 --> 00:38:26,110
SPEAKER_0:  patent library, there's a bunch of these patents that like me and Zuck have for like

00:38:26,594 --> 00:38:27,454
SPEAKER_0:  Random things like

00:38:27,714 --> 00:38:28,286
SPEAKER_0:  Cookies.

00:38:28,642 --> 00:38:32,638
SPEAKER_0:  you know, or like cross-site JavaScript, like all these crazy things that are just like these.

00:38:33,026 --> 00:38:35,838
SPEAKER_0:  the kind of ideas in 2023.

00:38:36,802 --> 00:38:38,526
SPEAKER_0:  we had to invent our way around.

00:38:38,850 --> 00:38:40,574
SPEAKER_0:  How do websites communicate with each other?

00:38:40,962 --> 00:38:41,310
SPEAKER_0:  You know.

00:38:41,602 --> 00:38:45,694
SPEAKER_0:  How do we build in the cloud versus in a data center? How do we actually have high performance systems?

00:38:46,242 --> 00:38:47,582
SPEAKER_0:  You mentioned data science.

00:38:47,938 --> 00:38:48,478
SPEAKER_0:  the term.

00:38:48,770 --> 00:38:55,582
SPEAKER_0:  in the idea we invented this I invented this thing called data scientists because we had a PhD from Google that refused to join unless

00:38:55,906 --> 00:38:58,686
SPEAKER_0:  because he got a job offer that says data analyst.

00:38:59,234 --> 00:38:59,774
SPEAKER_0:  Um

00:39:00,098 --> 00:39:06,473
SPEAKER_0:  And so he said, call him a scientist, because he was a PhD in particle physics. So he really, you know, he was a scientist. And I said, great, you're a scientist here. And I learned for myself that he went to depth in physics and created over the world.

00:39:06,473 --> 00:39:07,454
SPEAKER_1:  a discipline.

00:39:07,938 --> 00:39:09,063
SPEAKER_0:  that launched a discipline.

00:39:09,063 --> 00:39:16,318
SPEAKER_1:  term, you know, what's a Rose by any other name, but yeah, like, you know, sometimes words like this can launch entire.

00:39:17,026 --> 00:39:17,598
SPEAKER_1:  fields.

00:39:18,210 --> 00:39:22,558
SPEAKER_1:  And it did in that case. And you didn't, I mean, I guess at that time you didn't anticipate.

00:39:23,074 --> 00:39:26,590
SPEAKER_1:  the impact of machine learning on the entirety of this whole process.

00:39:26,818 --> 00:39:28,094
SPEAKER_1:  because you need machine learning.

00:39:28,514 --> 00:39:30,942
SPEAKER_1:  to have both ads and recommender.

00:39:31,330 --> 00:39:33,955
SPEAKER_1:  systems to have the feed for the social network.

00:39:33,955 --> 00:39:38,782
SPEAKER_0:  Exactly right. The first real scaled version of machine learning, not AI, but machine learning.

00:39:39,106 --> 00:39:42,878
SPEAKER_0:  was this thing that Facebook introduced called PYMK, which is People You May Know.

00:39:43,554 --> 00:39:45,054
SPEAKER_0:  And the simple idea was that

00:39:45,314 --> 00:39:48,030
SPEAKER_0:  Can we initiate a viral mechanic inside the application?

00:39:49,122 --> 00:39:49,918
SPEAKER_0:  where you log in.

00:39:50,626 --> 00:39:51,870
SPEAKER_0:  We grab your credentials.

00:39:52,290 --> 00:39:53,918
SPEAKER_0:  we go to your email inbox.

00:39:54,946 --> 00:39:56,318
SPEAKER_0:  We harvest your address book.

00:39:57,442 --> 00:39:58,302
SPEAKER_0:  We do a compare.

00:39:58,818 --> 00:40:03,806
SPEAKER_0:  We make some guesses and we start to present other people that you may actually know that may not be in your address book.

00:40:04,258 --> 00:40:06,942
SPEAKER_0:  really simple, you know, a couple joins of some tables, whatever.

00:40:08,098 --> 00:40:11,198
SPEAKER_0:  And it started to just go crazy. And the number of people that

00:40:11,554 --> 00:40:13,982
SPEAKER_0:  you were creating this density and entropy.

00:40:14,626 --> 00:40:16,062
SPEAKER_0:  Inside the social graph,

00:40:16,514 --> 00:40:19,614
SPEAKER_0:  with what was some really simple basic math.

00:40:20,418 --> 00:40:21,790
SPEAKER_0:  And that was eye-opening for us.

00:40:22,274 --> 00:40:27,294
SPEAKER_0:  And what it led us down this path of is really understanding the power of like all this machine learning.

00:40:27,906 --> 00:40:30,078
SPEAKER_0:  And so that infused itself into News Feed.

00:40:30,530 --> 00:40:35,582
SPEAKER_0:  and how the content that you saw could be tailored to who you were and the type of person that you were.

00:40:36,738 --> 00:40:38,014
SPEAKER_0:  There is a moment in time that

00:40:38,754 --> 00:40:40,062
SPEAKER_0:  All of this stuff was so new.

00:40:40,834 --> 00:40:45,694
SPEAKER_0:  How did you translate the app to multiple languages? How do you launch the company in all of these countries?

00:40:46,434 --> 00:40:47,294
SPEAKER_1:  How much of it?

00:40:47,842 --> 00:40:57,374
SPEAKER_1:  is just kind of stumbling into things using your best like first principles gut thinking and how much is it like five, 10, 15, 20 year vision? I think.

00:40:57,602 --> 00:40:59,870
SPEAKER_1:  How much was thinking about the future?

00:41:00,706 --> 00:41:02,142
SPEAKER_1:  of the internet.

00:41:02,466 --> 00:41:05,854
SPEAKER_1:  and the metaverse and humanity and all that kind of stuff.

00:41:06,274 --> 00:41:08,638
SPEAKER_1:  because the news feed also sounds trivial.

00:41:08,834 --> 00:41:10,878
SPEAKER_0:  I'll say something that's like changes everything.

00:41:11,202 --> 00:41:11,518
SPEAKER_0:  What?

00:41:12,450 --> 00:41:14,462
SPEAKER_0:  You have to remember, like, you know, news feed.

00:41:17,090 --> 00:41:19,486
SPEAKER_0:  was named and we had this thing where...

00:41:19,810 --> 00:41:22,142
SPEAKER_0:  we would just name things what they were.

00:41:22,914 --> 00:41:24,030
SPEAKER_0:  And at the time...

00:41:24,642 --> 00:41:26,078
SPEAKER_0:  all of these other companies.

00:41:26,306 --> 00:41:28,798
SPEAKER_0:  And if you go back into the wayback machine, you can see this.

00:41:29,282 --> 00:41:31,454
SPEAKER_0:  people would invent, you know.

00:41:31,906 --> 00:41:34,174
SPEAKER_0:  and I, you know, an MP3 player.

00:41:34,466 --> 00:41:35,998
SPEAKER_0:  and they would come up with some crazy names.

00:41:36,514 --> 00:41:39,390
SPEAKER_0:  or they would invent a software product and come up with a crazy name.

00:41:39,938 --> 00:41:41,406
SPEAKER_0:  And it sounded like...

00:41:41,698 --> 00:41:42,686
SPEAKER_0:  The pharma industry.

00:41:43,074 --> 00:41:43,390
SPEAKER_0:  You know.

00:41:44,098 --> 00:41:45,086
SPEAKER_0:  Glocasmab!

00:41:45,602 --> 00:41:50,014
SPEAKER_0:  know, tag your best friends. And you think, what is this? This makes no sense.

00:41:50,370 --> 00:41:52,414
SPEAKER_0:  And this was Zuck's thing, he was like.

00:41:52,738 --> 00:41:55,486
SPEAKER_0:  Well, this is a feed of news, so we're gonna call it News Feed.

00:41:56,130 --> 00:41:59,326
SPEAKER_0:  This is where you tag your photos, so we're going to call that photo tagging.

00:41:59,682 --> 00:42:00,638
SPEAKER_0:  I mean literally.

00:42:00,994 --> 00:42:02,462
SPEAKER_0:  you know, pretty obvious stuff.

00:42:03,042 --> 00:42:03,390
SPEAKER_0:  Um.

00:42:05,858 --> 00:42:10,974
SPEAKER_0:  The thing, the way that those things came about though, was very experimentally. And this is where I think it's really important for people.

00:42:11,618 --> 00:42:14,334
SPEAKER_0:  to understand, I think Bezos explains this the best.

00:42:15,938 --> 00:42:17,438
SPEAKER_0:  there is a tendency after

00:42:17,826 --> 00:42:18,526
SPEAKER_0:  things work?

00:42:19,426 --> 00:42:20,926
SPEAKER_0:  create a narrative fallacy?

00:42:21,570 --> 00:42:22,718
SPEAKER_0:  because it feeds your ego.

00:42:23,682 --> 00:42:26,430
SPEAKER_0:  and you want to have been the person that saw it.

00:42:28,738 --> 00:42:29,694
SPEAKER_0:  And I think it's much.

00:42:29,986 --> 00:42:30,750
SPEAKER_0:  more honest.

00:42:31,138 --> 00:42:31,902
SPEAKER_0:  to say

00:42:32,354 --> 00:42:33,630
SPEAKER_0:  We were very good.

00:42:34,658 --> 00:42:36,222
SPEAKER_0:  probabilistic thinkers?

00:42:37,314 --> 00:42:42,782
SPEAKER_0:  that tried to learn as quickly as possible, meaning to make as many mistakes as possible.

00:42:43,266 --> 00:42:50,142
SPEAKER_0:  You know, I mean, if you look at this very famous placard that Facebook had from back in the day, what did it say? It said move fast and break things.

00:42:50,850 --> 00:42:52,318
SPEAKER_0:  in societal language.

00:42:52,866 --> 00:42:55,294
SPEAKER_0:  That's saying make mistakes as quickly as you can.

00:42:56,194 --> 00:43:00,574
SPEAKER_0:  Because the minute you break something, you don't do that by design. It's not a feature. Theoretically, it's a bug.

00:43:02,018 --> 00:43:03,006
SPEAKER_0:  He understood that.

00:43:03,490 --> 00:43:04,990
SPEAKER_0:  And we embraced that idea.

00:43:05,666 --> 00:43:11,838
SPEAKER_0:  I used to run this meeting once a week where the whole goal was I want to see that there was a thousand experiments that were run

00:43:12,418 --> 00:43:14,430
SPEAKER_0:  and show me them all from the dumbest.

00:43:14,690 --> 00:43:16,030
SPEAKER_0:  to the most impactful.

00:43:17,154 --> 00:43:21,118
SPEAKER_0:  and we would go through that loop and what did it train people? not that you got celebrated.

00:43:21,634 --> 00:43:22,462
SPEAKER_0:  for the right answer.

00:43:23,458 --> 00:43:24,862
SPEAKER_0:  but you got celebrated for trying.

00:43:26,146 --> 00:43:27,710
SPEAKER_0:  I ran 12 experiments.

00:43:28,258 --> 00:43:30,110
SPEAKER_0:  12 failed and we'd be like, you're the best.

00:43:30,850 --> 00:43:35,390
SPEAKER_1:  Can I just take a small tangent on that is that move fast and break things.

00:43:36,034 --> 00:43:36,350
SPEAKER_1:  has been.

00:43:36,770 --> 00:43:37,502
SPEAKER_1:  Become.

00:43:37,730 --> 00:43:39,614
SPEAKER_1:  as like a catchphrase.

00:43:40,162 --> 00:43:40,734
SPEAKER_1:  of.

00:43:41,218 --> 00:43:44,382
SPEAKER_1:  that embodies the toxic culture of Silicon Valley.

00:43:44,642 --> 00:43:45,470
SPEAKER_1:  in today's.

00:43:46,338 --> 00:43:49,054
SPEAKER_1:  discourse, which confuses me.

00:43:49,346 --> 00:43:51,166
SPEAKER_1:  Of course, words and phrases get

00:43:51,426 --> 00:43:52,350
SPEAKER_1:  sort of captured.

00:43:52,546 --> 00:43:56,926
SPEAKER_0:  and so on. Becomes very reductive, you know, that's a very loaded set of words that together can be.

00:43:58,626 --> 00:44:00,501
SPEAKER_0:  Many years later, people can view very rigidly.

00:44:00,501 --> 00:44:03,582
SPEAKER_1:  Can you steel man each side of that? Innovation 350 сн mirais detection

00:44:04,354 --> 00:44:06,750
SPEAKER_1:  Pro, move fast and break things.

00:44:06,978 --> 00:44:12,894
SPEAKER_0:  against more fast and brisk. So I think the pro of move fast and break things is saying the following.

00:44:13,858 --> 00:44:15,390
SPEAKER_0:  There's a space of things we know.

00:44:16,162 --> 00:44:18,654
SPEAKER_0:  and a massive space of things we don't know.

00:44:19,842 --> 00:44:20,254
SPEAKER_0:  and

00:44:20,610 --> 00:44:22,750
SPEAKER_0:  There's a rate of growth of the things we know.

00:44:24,002 --> 00:44:28,830
SPEAKER_0:  But the rate of growth of the things we don't know is actually, we have to assume, growing faster.

00:44:30,178 --> 00:44:34,718
SPEAKER_0:  So the most important thing is to move into the space of the things we don't know.

00:44:35,234 --> 00:44:36,542
SPEAKER_0:  as quickly as possible.

00:44:37,570 --> 00:44:40,894
SPEAKER_0:  And so in order to acquire knowledge, we're going to assume

00:44:42,018 --> 00:44:44,158
SPEAKER_0:  The failure mode is the nominal state.

00:44:45,954 --> 00:44:48,414
SPEAKER_0:  And so we just need to move as quickly as we can.

00:44:48,802 --> 00:44:52,350
SPEAKER_0:  Break as many things as possible, which means like things are breaking in code.

00:44:53,570 --> 00:44:54,174
SPEAKER_0:  Do the.

00:44:54,434 --> 00:44:55,774
SPEAKER_0:  root cause analysis.

00:44:56,034 --> 00:44:59,678
SPEAKER_0:  figure out how to make things better and then rapidly move into the space.

00:45:00,130 --> 00:45:01,278
SPEAKER_0:  and he or she...

00:45:01,570 --> 00:45:03,646
SPEAKER_0:  who moves fastest into that space will win.

00:45:04,226 --> 00:45:06,590
SPEAKER_1:  It doesn't imply carelessness, right?

00:45:06,850 --> 00:45:08,062
SPEAKER_1:  It doesn't imply...

00:45:09,794 --> 00:45:10,654
SPEAKER_1:  moving

00:45:11,042 --> 00:45:12,894
SPEAKER_1:  fast without also.

00:45:13,186 --> 00:45:16,478
SPEAKER_1:  aggressively picking up the lessons from the mistakes you make.

00:45:16,578 --> 00:45:20,382
SPEAKER_0:  Well, again, that's Steel Manning the Pro, which is it's a thoughtful.

00:45:21,570 --> 00:45:21,950
SPEAKER_0:  Um.

00:45:23,330 --> 00:45:23,838
SPEAKER_0:  Movement.

00:45:24,866 --> 00:45:25,502
SPEAKER_0:  around.

00:45:25,986 --> 00:45:27,934
SPEAKER_0:  velocity and acquisition of knowledge.

00:45:28,962 --> 00:45:30,654
SPEAKER_0:  Now let's deal with the con case.

00:45:32,898 --> 00:45:34,974
SPEAKER_0:  when these systems become big enough.

00:45:36,226 --> 00:45:37,566
SPEAKER_0:  There is no more room.

00:45:38,594 --> 00:45:41,022
SPEAKER_0:  to experiment in an open-ended way.

00:45:41,634 --> 00:45:44,158
SPEAKER_0:  because the implications have broad societal impacts.

00:45:44,738 --> 00:45:45,854
SPEAKER_0:  that are not clear.

00:45:46,082 --> 00:45:46,686
SPEAKER_0:  upfront.

00:45:48,258 --> 00:45:50,398
SPEAKER_0:  So let's take a different, less controversial example.

00:45:50,978 --> 00:45:53,086
SPEAKER_0:  If we said, you know, lipetor.

00:45:53,890 --> 00:45:55,838
SPEAKER_0:  worked well for

00:45:56,258 --> 00:45:57,918
SPEAKER_0:  All people except South Asians.

00:45:58,562 --> 00:46:01,470
SPEAKER_0:  and there's a specific immunoresponse that we can iterate to.

00:46:02,658 --> 00:46:07,390
SPEAKER_0:  And if we move quickly enough, we can run 10,000 experiments, and we think the answer is in that space.

00:46:09,378 --> 00:46:12,990
SPEAKER_0:  Well, the problem is that those 10,000 experiments may kill 10 million people.

00:46:14,306 --> 00:46:14,654
SPEAKER_0:  So.

00:46:14,882 --> 00:46:16,190
SPEAKER_0:  You have to move methodically.

00:46:16,834 --> 00:46:18,686
SPEAKER_0:  When that drug was experimental...

00:46:19,714 --> 00:46:21,502
SPEAKER_0:  and it wasn't being given to.

00:46:21,826 --> 00:46:23,166
SPEAKER_0:  500 million people in the world.

00:46:24,034 --> 00:46:29,374
SPEAKER_0:  Moving fast made sense because you could have a pig model, a mouse model, a monkey model. You could figure out toxicity.

00:46:29,986 --> 00:46:31,454
SPEAKER_0:  but we picked all that low hanging fruit.

00:46:32,706 --> 00:46:35,070
SPEAKER_0:  And so now these small iterations.

00:46:35,778 --> 00:46:39,262
SPEAKER_0:  have huge impacts that need to be measured and implemented.

00:46:40,610 --> 00:46:42,814
SPEAKER_0:  Different example is like, you know, if you work at Boeing.

00:46:43,682 --> 00:46:49,310
SPEAKER_0:  and you have an implementation that gives you 2% efficiency by reshaping the wing or adding winglets.

00:46:50,658 --> 00:46:53,854
SPEAKER_0:  There needs to be a methodical move slow be right.

00:46:54,466 --> 00:46:55,166
SPEAKER_0:  process.

00:46:56,450 --> 00:47:00,286
SPEAKER_0:  because mistakes when they compound, when it's already implemented and at scale.

00:47:00,578 --> 00:47:02,270
SPEAKER_0:  have huge externalities.

00:47:02,690 --> 00:47:06,526
SPEAKER_0:  that are impossible to measure until after the fact. And you see this in the 737 Max.

00:47:07,554 --> 00:47:10,942
SPEAKER_0:  So that's how one would steel man the con case, which is that.

00:47:11,330 --> 00:47:13,118
SPEAKER_0:  when an industry becomes critical.

00:47:13,602 --> 00:47:14,302
SPEAKER_0:  You gotta slow down.

00:47:15,906 --> 00:47:18,014
SPEAKER_1:  It makes me sad because...

00:47:18,562 --> 00:47:22,110
SPEAKER_1:  Some industries, like Twitter and Facebook, are a good example.

00:47:22,946 --> 00:47:25,214
SPEAKER_1:  they achieve scale very quickly.

00:47:26,146 --> 00:47:28,542
SPEAKER_1:  before really exploring the big.

00:47:29,058 --> 00:47:29,790
SPEAKER_1:  area.

00:47:30,338 --> 00:47:31,486
SPEAKER_1:  of things to learn.

00:47:31,938 --> 00:47:32,990
SPEAKER_1:  So you basically...

00:47:33,634 --> 00:47:35,582
SPEAKER_1:  pick one low hanging fruit.

00:47:36,194 --> 00:47:40,319
SPEAKER_1:  and that became your huge success. And now you're sitting there with that stupid.

00:47:40,319 --> 00:47:40,830
SPEAKER_0:  brewing.

00:47:41,250 --> 00:47:44,414
SPEAKER_0:  Well, so you're, I think, so as an example, if you had to.

00:47:46,434 --> 00:47:48,734
SPEAKER_0:  you know, if I was running Facebook for a day.

00:47:49,922 --> 00:47:54,078
SPEAKER_0:  You know, the big opportunity, in my opinion, was really not the metaverse.

00:47:54,850 --> 00:47:59,326
SPEAKER_0:  But it was actually getting the closest that anybody could get to AGI.

00:48:02,018 --> 00:48:07,582
SPEAKER_0:  If I had to steel man that product case, here's how I would have pitched it to the board and to Zuck. Listen.

00:48:08,322 --> 00:48:10,686
SPEAKER_0:  There are three and a half billion people monthly.

00:48:10,946 --> 00:48:11,678
SPEAKER_0:  using this thing.

00:48:12,194 --> 00:48:15,134
SPEAKER_0:  If we think about human intelligence very reductively.

00:48:15,906 --> 00:48:18,974
SPEAKER_0:  we would say that there's a large portion of it which is cognitive

00:48:19,842 --> 00:48:22,558
SPEAKER_0:  And then there's a large portion of it, which is emotional.

00:48:23,554 --> 00:48:26,206
SPEAKER_0:  We have the best ability to build a multimodal model.

00:48:27,074 --> 00:48:30,014
SPEAKER_0:  that basically takes all of these massive inputs together.

00:48:30,466 --> 00:48:31,422
SPEAKER_0:  to try to intuit.

00:48:31,938 --> 00:48:34,302
SPEAKER_0:  how a system would react to all kinds of stimuli.

00:48:35,970 --> 00:48:39,870
SPEAKER_0:  That to me would have been a profound leap forward for humanity.

00:48:40,034 --> 00:48:41,918
SPEAKER_1:  Can you dig into that a little bit more? Yes I do

00:48:42,242 --> 00:48:43,070
SPEAKER_1:  in terms of.

00:48:44,226 --> 00:48:45,854
SPEAKER_1:  Uh, no, this is a board meeting.

00:48:46,114 --> 00:48:47,614
SPEAKER_1:  How would that make Facebook money?

00:48:48,898 --> 00:48:49,566
SPEAKER_0:  I think that.

00:48:50,050 --> 00:48:51,294
SPEAKER_0:  You have all of these.

00:48:51,906 --> 00:48:53,246
SPEAKER_0:  systems over time.

00:48:54,434 --> 00:48:55,742
SPEAKER_0:  that we don't know.

00:48:55,970 --> 00:48:56,670
SPEAKER_0:  could benefit.

00:48:57,026 --> 00:48:57,470
SPEAKER_0:  from.

00:48:58,146 --> 00:48:58,622
SPEAKER_0:  Um...

00:48:58,914 --> 00:49:00,542
SPEAKER_0:  some layer of

00:49:01,058 --> 00:49:02,526
SPEAKER_0:  reasoning to make it better.

00:49:02,978 --> 00:49:03,390
SPEAKER_0:  Um.

00:49:04,450 --> 00:49:06,878
SPEAKER_0:  What does Spotify look like?

00:49:07,362 --> 00:49:09,438
SPEAKER_0:  when instead of just a very simple.

00:49:09,794 --> 00:49:11,006
SPEAKER_0:  recommendation engine.

00:49:11,650 --> 00:49:15,198
SPEAKER_0:  it actually understands sort of your emotional context and your mood.

00:49:15,810 --> 00:49:18,174
SPEAKER_0:  and can move you to a body of music that you would like.

00:49:18,786 --> 00:49:20,478
SPEAKER_0:  What does it look like if...

00:49:20,962 --> 00:49:22,302
SPEAKER_0:  you know, your television.

00:49:22,754 --> 00:49:24,542
SPEAKER_0:  instead of having to go and channel surf.

00:49:24,898 --> 00:49:27,742
SPEAKER_0:  you know, 50,000 shows on a horrible UI.

00:49:28,130 --> 00:49:28,478
SPEAKER_0:  You know.

00:49:28,770 --> 00:49:29,502
SPEAKER_0:  instead just

00:49:29,794 --> 00:49:32,350
SPEAKER_0:  has a sense of what you're into and shows it to you.

00:49:32,898 --> 00:49:33,374
SPEAKER_0:  Um

00:49:33,666 --> 00:49:36,350
SPEAKER_0:  What does it mean when you get in your car?

00:49:36,898 --> 00:49:37,406
SPEAKER_0:  and

00:49:37,634 --> 00:49:42,238
SPEAKER_0:  it actually drives you to a place because you should actually eat there even though you don't know it.

00:49:43,010 --> 00:49:46,078
SPEAKER_0:  These are all random things that make no sense a priori.

00:49:46,818 --> 00:49:47,998
SPEAKER_0:  but it starts to make.

00:49:48,706 --> 00:49:51,454
SPEAKER_0:  the person or the provider of that service.

00:49:52,578 --> 00:49:54,494
SPEAKER_0:  the critical reasoning layer.

00:49:55,042 --> 00:49:58,654
SPEAKER_0:  for all these everyday products that today would look very flat without that reasoning.

00:49:59,682 --> 00:50:03,326
SPEAKER_0:  And I think you license that and you make a lot of money. So in many ways, instead of becoming.

00:50:03,874 --> 00:50:05,726
SPEAKER_0:  more of the pixels that you see.

00:50:06,210 --> 00:50:08,126
SPEAKER_0:  You become more of the bare metal.

00:50:08,610 --> 00:50:12,094
SPEAKER_0:  that actually creates that experience. And if you look at the companies...

00:50:12,994 --> 00:50:16,414
SPEAKER_0:  that are multi-decade legacy kinds of businesses.

00:50:17,058 --> 00:50:21,726
SPEAKER_0:  The thing that they have done is quietly and surreptitiously move down the stack.

00:50:22,178 --> 00:50:28,414
SPEAKER_0:  You never move up the stack to survive. You need to move down the stack. So if you take that OSI reference stack, right.

00:50:28,834 --> 00:50:33,278
SPEAKER_0:  these layers, how you build an app from the physical layer to the transport layer all the way up to the app layer.

00:50:34,082 --> 00:50:34,846
SPEAKER_0:  You can map.

00:50:35,490 --> 00:50:36,574
SPEAKER_0:  from the 1980s.

00:50:36,802 --> 00:50:38,526
SPEAKER_0:  all the big companies that have been created.

00:50:39,138 --> 00:50:43,774
SPEAKER_0:  Right, all the way from Fairchild Semiconductor, not Semi to Intel to Cisco to...

00:50:44,066 --> 00:50:44,670
SPEAKER_0:  Sweet Calm.

00:50:45,474 --> 00:50:45,854
SPEAKER_0:  You know.

00:50:46,594 --> 00:50:47,198
SPEAKER_0:  Oracle.

00:50:47,650 --> 00:50:51,070
SPEAKER_0:  Netscape at one point all the way up to the Googles and Facebooks of the world.

00:50:52,098 --> 00:50:54,334
SPEAKER_0:  But if you look at where all the lock-in happened.

00:50:55,714 --> 00:51:01,246
SPEAKER_0:  It's by companies like Apple, who used to make software saying, I'm going to get one close, I'm going to make the bare metal.

00:51:01,570 --> 00:51:02,814
SPEAKER_0:  and I'm gonna become the platform.

00:51:03,394 --> 00:51:12,190
SPEAKER_0:  Or Google, same thing. I'm gonna create this dominant platform and I'm gonna create a substrate that organizes all this information. That's just omnipresent and everywhere.

00:51:12,994 --> 00:51:14,302
SPEAKER_0:  So the key is.

00:51:14,594 --> 00:51:16,990
SPEAKER_0:  if you are lucky enough to be one of these apps.

00:51:18,050 --> 00:51:19,102
SPEAKER_0:  that are in front of people.

00:51:20,482 --> 00:51:22,206
SPEAKER_0:  You better start digging quickly.

00:51:22,722 --> 00:51:26,622
SPEAKER_0:  and moving your way down and get out of the way and disappear.

00:51:27,138 --> 00:51:29,822
SPEAKER_0:  but by disappearing, you will become much, much bigger.

00:51:30,498 --> 00:51:31,518
SPEAKER_0:  And it's.

00:51:31,746 --> 00:51:33,086
SPEAKER_0:  impossible to usurp you.

00:51:33,506 --> 00:51:36,414
SPEAKER_1:  Yeah, I 100% agree with you.

00:51:37,122 --> 00:51:39,486
SPEAKER_1:  That's why you're so smart. This is a

00:51:39,778 --> 00:51:41,598
SPEAKER_1:  the depersonalization and.

00:51:42,690 --> 00:51:47,518
SPEAKER_1:  the algorithms that enable depersonalization almost like operating system layer

00:51:47,842 --> 00:51:51,998
SPEAKER_1:  So pushing away from the interface and the actual system that does the personalization.

00:51:52,418 --> 00:51:56,062
SPEAKER_1:  I think the challenge is there. There's obviously technical challenges.

00:51:57,378 --> 00:51:59,614
SPEAKER_1:  but there's also societal challenges that.

00:52:01,986 --> 00:52:03,134
SPEAKER_1:  It's like in a relationship.

00:52:03,778 --> 00:52:07,422
SPEAKER_1:  If you have an intimate algorithmic connection with individual humans.

00:52:08,034 --> 00:52:08,638
SPEAKER_1:  you can

00:52:08,866 --> 00:52:13,438
SPEAKER_1:  do both good and bad. And so there's risks that you're taking. You can…

00:52:14,082 --> 00:52:19,294
SPEAKER_1:  So if you're making a lot of money now is Twitter and Facebook with ads, surface layer ads.

00:52:19,938 --> 00:52:22,462
SPEAKER_1:  What is the incentive to take the risk?

00:52:23,170 --> 00:52:25,118
SPEAKER_1:  of guiding people more.

00:52:25,858 --> 00:52:27,774
SPEAKER_1:  because you can hurt people, you can...

00:52:28,034 --> 00:52:29,438
SPEAKER_1:  Piss off people you can-

00:52:30,114 --> 00:52:35,326
SPEAKER_1:  I mean, there is a cost to forming a more intimate relationship with the users.

00:52:36,130 --> 00:52:37,255
SPEAKER_1:  in the short term, I think.

00:52:37,255 --> 00:52:37,758
SPEAKER_0:  You said.

00:52:38,146 --> 00:52:39,838
SPEAKER_0:  a really, really key thing, which is.

00:52:40,674 --> 00:52:42,142
SPEAKER_0:  which was a really great.

00:52:43,234 --> 00:52:45,438
SPEAKER_0:  emotional instinctive reaction which is

00:52:45,666 --> 00:52:48,766
SPEAKER_0:  When I said the AGI thing, you said, well, how would you ever make money from that?

00:52:49,634 --> 00:52:54,494
SPEAKER_0:  That is the key. The presumption is that this thing would not be an important thing at the beginning.

00:52:55,202 --> 00:53:00,606
SPEAKER_0:  And I think what that allows you to do if you were to Twitter or Google or Apple or Facebook, anybody, Microsoft.

00:53:01,154 --> 00:53:03,070
SPEAKER_0:  embarking on building something like this.

00:53:03,618 --> 00:53:05,406
SPEAKER_0:  is that you can actually have it.

00:53:05,954 --> 00:53:07,102
SPEAKER_0:  off the critical path.

00:53:08,002 --> 00:53:09,598
SPEAKER_0:  and you can experiment with this.

00:53:09,922 --> 00:53:11,678
SPEAKER_0:  for years if that's what it takes.

00:53:12,258 --> 00:53:16,990
SPEAKER_0:  to find a version one that is special enough where it's worth showcasing.

00:53:17,986 --> 00:53:22,526
SPEAKER_0:  And so in many ways you get the free option. You're going to be spending any of these companies.

00:53:23,042 --> 00:53:28,158
SPEAKER_0:  We'll be spending tens of billions of dollars in OpEx and CapEx every year and all kinds of stuff.

00:53:29,218 --> 00:53:31,166
SPEAKER_0:  It is not a thing that money...

00:53:31,746 --> 00:53:35,166
SPEAKER_0:  actually makes more likely to succeed. In fact,

00:53:35,906 --> 00:53:38,206
SPEAKER_0:  You actually don't need to give these kinds of things.

00:53:38,530 --> 00:53:39,614
SPEAKER_0:  A lot of money at all.

00:53:39,938 --> 00:53:40,350
SPEAKER_0:  because

00:53:40,706 --> 00:53:43,006
SPEAKER_0:  starting in 2023, or right now.

00:53:43,938 --> 00:53:49,598
SPEAKER_0:  You know, you have the two most important tectonic shifts that have ever happened in our lifetime in technology.

00:53:50,018 --> 00:53:51,006
SPEAKER_0:  They're not talked about.

00:53:51,266 --> 00:53:52,478
SPEAKER_0:  But these things allow.

00:53:52,770 --> 00:53:57,086
SPEAKER_0:  AGI, I think to emerge over the next 10 or 15 years where it wasn't possible for

00:53:57,730 --> 00:54:00,382
SPEAKER_0:  The first thing is that the marginal cost of energy is zero.

00:54:01,282 --> 00:54:02,526
SPEAKER_0:  I'm not going to pay for anything anymore.

00:54:03,522 --> 00:54:07,742
SPEAKER_0:  And we can double click into why that is. And the second is the marginal cost of compute is zero.

00:54:08,450 --> 00:54:09,822
SPEAKER_0:  And so when you take the...

00:54:10,434 --> 00:54:11,902
SPEAKER_0:  multiplication or you know

00:54:12,130 --> 00:54:16,062
SPEAKER_0:  If you want to get really fancy mathematically the convolution of these two things together.

00:54:16,450 --> 00:54:18,302
SPEAKER_0:  It's going to change.

00:54:18,530 --> 00:54:19,326
SPEAKER_0:  everything.

00:54:19,842 --> 00:54:20,158
SPEAKER_0:  So.

00:54:20,482 --> 00:54:21,022
SPEAKER_0:  Think about.

00:54:21,762 --> 00:54:25,502
SPEAKER_0:  what a billion dollars gets today. And we can use OpenAI as an example.

00:54:26,786 --> 00:54:30,302
SPEAKER_0:  A billion dollars gets OpenAI a handful of functional models.

00:54:30,818 --> 00:54:32,478
SPEAKER_0:  and a pretty fast iterative loop.

00:54:34,946 --> 00:54:35,774
SPEAKER_0:  But imagine what.

00:54:36,354 --> 00:54:38,398
SPEAKER_0:  OpenAI had to overcome.

00:54:39,298 --> 00:54:40,958
SPEAKER_0:  that to overcome a compute challenge.

00:54:41,282 --> 00:54:43,454
SPEAKER_0:  they had to strip together a whole bunch of GPUs.

00:54:43,714 --> 00:54:46,046
SPEAKER_0:  that to build all kinds of scaffolding software.

00:54:46,370 --> 00:54:48,030
SPEAKER_0:  They had to find data center support.

00:54:48,450 --> 00:54:54,046
SPEAKER_0:  that consumes all kinds of money. So that billion dollars didn't go that far. So it's a testament to how clever.

00:54:55,010 --> 00:54:56,254
SPEAKER_0:  that OpenAI team is.

00:54:56,930 --> 00:55:02,142
SPEAKER_0:  But in four years from now, when energy costs zero, and basically GPUs are like, you know, they're falling off a truck.

00:55:02,978 --> 00:55:05,310
SPEAKER_0:  and you can use them effectively for free.

00:55:06,722 --> 00:55:11,038
SPEAKER_0:  Now all of a sudden a billion dollars gives you some amount of tarot flops of compute.

00:55:11,458 --> 00:55:12,478
SPEAKER_0:  That is probably...

00:55:13,186 --> 00:55:15,134
SPEAKER_0:  The total number of teraflops available today in the world.

00:55:15,746 --> 00:55:16,478
SPEAKER_0:  Like that's how.

00:55:16,706 --> 00:55:17,790
SPEAKER_0:  gargantuan.

00:55:18,306 --> 00:55:21,182
SPEAKER_0:  This move is when you take these two variables to zero.

00:55:21,858 --> 00:55:25,918
SPEAKER_1:  There's like a million things to ask. I almost don't want to get distracted by.

00:55:26,370 --> 00:55:31,245
SPEAKER_1:  the marginal cost of energy going to zero, because I have no idea what you're talking about ASAP because

00:55:31,245 --> 00:55:32,862
SPEAKER_0:  you the 30 seconds? Sure.

00:55:33,090 --> 00:55:39,774
SPEAKER_0:  Okay. So if you look inside of the two most progressive states, the three most progressive states, New York, California, and Massachusetts.

00:55:40,386 --> 00:55:44,222
SPEAKER_0:  a lot of left leaning folks, a lot of people who believe in climate science and climate change.

00:55:45,090 --> 00:55:48,542
SPEAKER_0:  The energy costs in those three states are the worst they are in the entire country.

00:55:48,930 --> 00:55:50,494
SPEAKER_0:  and energy is compounding.

00:55:50,818 --> 00:55:52,446
SPEAKER_0:  at 3 to 4% per annum.

00:55:52,994 --> 00:55:54,014
SPEAKER_0:  So every decade.

00:55:54,306 --> 00:55:55,262
SPEAKER_0:  to 15 years.

00:55:55,522 --> 00:55:56,862
SPEAKER_0:  energy costs in these states.

00:55:57,218 --> 00:55:57,566
SPEAKER_0:  Double.

00:55:58,178 --> 00:56:02,526
SPEAKER_0:  In some cases and in some months, our energy costs are increasing by 11% a month.

00:56:04,354 --> 00:56:04,734
SPEAKER_0:  But.

00:56:05,282 --> 00:56:06,366
SPEAKER_0:  The ability...

00:56:06,658 --> 00:56:07,518
SPEAKER_0:  to actually.

00:56:07,938 --> 00:56:09,150
SPEAKER_0:  generate energy.

00:56:09,602 --> 00:56:11,262
SPEAKER_0:  is now effectively zero.

00:56:11,682 --> 00:56:16,830
SPEAKER_0:  The cost per kilowatt hour to put a solar panel on your roof and a battery wall inside your garage.

00:56:17,154 --> 00:56:18,846
SPEAKER_0:  It's the cheapest it's ever been.

00:56:19,170 --> 00:56:21,758
SPEAKER_0:  these things are the most efficient they've ever been.

00:56:22,178 --> 00:56:24,190
SPEAKER_0:  And so to acquire energy from the sun...

00:56:24,450 --> 00:56:26,718
SPEAKER_0:  and store it for your use later on.

00:56:27,042 --> 00:56:28,917
SPEAKER_0:  literally is a zero cost proposition.

00:56:28,917 --> 00:56:31,167
SPEAKER_1:  So what's how do you explain the gap between the car?

00:56:31,167 --> 00:56:32,222
SPEAKER_0:  going? Great question.

00:56:33,122 --> 00:56:35,646
SPEAKER_0:  So this is the other side of regulatory capture.

00:56:35,874 --> 00:56:36,190
SPEAKER_0:  Right?

00:56:36,418 --> 00:56:38,654
SPEAKER_0:  You know, we all fight to build monopolies.

00:56:39,138 --> 00:56:41,214
SPEAKER_0:  while there are monopolies hiding in plain sight.

00:56:41,890 --> 00:56:43,390
SPEAKER_0:  The utilities are a perfect example.

00:56:44,098 --> 00:56:46,174
SPEAKER_0:  There are 100 million homes in America.

00:56:46,786 --> 00:56:49,406
SPEAKER_0:  There are about 1,700 utilities in America.

00:56:49,698 --> 00:56:51,070
SPEAKER_0:  So they have captive markets.

00:56:52,290 --> 00:56:55,230
SPEAKER_0:  But in return for that captive market, the law says...

00:56:55,618 --> 00:56:57,982
SPEAKER_0:  need to invest a certain amount per year.

00:56:58,210 --> 00:56:59,646
SPEAKER_0:  in upgrading that power line.

00:57:00,002 --> 00:57:01,502
SPEAKER_0:  in changing out that turbine.

00:57:01,794 --> 00:57:04,990
SPEAKER_0:  in making sure you transition from cold to wind or whatever.

00:57:06,658 --> 00:57:07,646
SPEAKER_0:  Just as an example.

00:57:08,546 --> 00:57:13,214
SPEAKER_0:  Upgrading power lines in the United States over the next decade is a two trillion dollar proposition

00:57:14,114 --> 00:57:17,086
SPEAKER_0:  These 1700 organizations have to spend.

00:57:17,442 --> 00:57:19,870
SPEAKER_0:  I think it's a quarter of a trillion dollars.

00:57:20,098 --> 00:57:20,606
SPEAKER_0:  a year.

00:57:21,986 --> 00:57:23,486
SPEAKER_0:  just to change the power lines.

00:57:23,970 --> 00:57:27,006
SPEAKER_0:  And that is why, even though it costs nothing to make energy,

00:57:27,522 --> 00:57:30,398
SPEAKER_0:  you are paying double every five every seven or eight years.

00:57:31,458 --> 00:57:35,390
SPEAKER_0:  It's CapEx and OpEx have a very brittle old infrastructure. It's like you.

00:57:35,842 --> 00:57:36,926
SPEAKER_0:  trying to build an app.

00:57:37,314 --> 00:57:41,406
SPEAKER_0:  and being forced to build your own data center. And you say, but wait, I just want to write to AWS.

00:57:41,858 --> 00:57:44,094
SPEAKER_0:  I just want to use GCP. I just want to move on.

00:57:44,898 --> 00:57:46,558
SPEAKER_0:  All that complexity is solved for me.

00:57:47,298 --> 00:57:49,886
SPEAKER_0:  And some law says, no, you can't, you gotta use it. So the file is linear, so all its casons are real and simple.

00:57:50,114 --> 00:57:54,814
SPEAKER_0:  That's what consumers are dealing with, but it's also what industrial manufacturing organizations

00:57:55,106 --> 00:57:56,478
SPEAKER_0:  It's what we all deal with.

00:57:56,898 --> 00:58:00,273
SPEAKER_1:  So how do we get rid ourselves of this old infrastructure?

00:58:00,273 --> 00:58:01,374
SPEAKER_0:  They were pink. Fast foward to mod blackstar 7 who knows if it's going to happen or not.

00:58:02,018 --> 00:58:04,350
SPEAKER_0:  The thing that's happening today, which I think is...

00:58:05,410 --> 00:58:08,446
SPEAKER_0:  This is why I think it's the most important trend right now in the world.

00:58:09,570 --> 00:58:10,078
SPEAKER_0:  is that.

00:58:10,498 --> 00:58:12,126
SPEAKER_0:  100 million homeowners?

00:58:13,090 --> 00:58:17,822
SPEAKER_0:  are each going to become their own little power plant and compete with these 1,700 utilities.

00:58:19,490 --> 00:58:24,958
SPEAKER_0:  in the United States or globally. No, just deal with the United States for a second, because I think it's easier to see here.

00:58:25,826 --> 00:58:26,910
SPEAKER_0:  100 million homes.

00:58:27,202 --> 00:58:28,766
SPEAKER_0:  solar panel on the roof and by the way

00:58:29,282 --> 00:58:35,262
SPEAKER_0:  just to make it clear, the sun doesn't need to shine, right? These panels now work where you have these UV bands that can actually,

00:58:35,554 --> 00:58:39,902
SPEAKER_0:  extrapolate beyond the visible spectrum. So they're usable in all weather conditions.

00:58:40,578 --> 00:58:43,294
SPEAKER_0:  and a simple system can support.

00:58:43,714 --> 00:58:46,046
SPEAKER_0:  you collecting enough power to not just

00:58:46,338 --> 00:58:48,222
SPEAKER_0:  run your functional day-to-day life.

00:58:49,218 --> 00:58:52,094
SPEAKER_0:  but then to contribute what's left over back into the grid.

00:58:53,058 --> 00:58:56,734
SPEAKER_0:  for Google's data center or Facebook's data center where you get a small check.

00:58:58,530 --> 00:59:00,350
SPEAKER_0:  the cost is going to zero.

00:59:00,578 --> 00:59:04,542
SPEAKER_1:  How obvious is this to people? You're making a sound. Okay, so you're eating something, and you're talking to yourself.

00:59:04,962 --> 00:59:09,630
SPEAKER_1:  because this is a pretty profound prediction. If the cost is any go to zero.

00:59:10,690 --> 00:59:12,030
SPEAKER_1:  that I mean the compute.

00:59:12,258 --> 00:59:14,142
SPEAKER_1:  the cost of compute going to zero, I can...

00:59:14,690 --> 00:59:16,565
SPEAKER_0:  So the cost to compute going to zero is.

00:59:16,565 --> 00:59:20,094
SPEAKER_1:  understand but the energy seems like a radical prediction of yours.

00:59:20,642 --> 00:59:22,846
SPEAKER_0:  Well, it's just it's just naturally what's happening.

00:59:23,106 --> 00:59:26,270
SPEAKER_0:  Right, now let me give you a different way of explaining this.

00:59:27,138 --> 00:59:28,030
SPEAKER_0:  If you look...

00:59:28,546 --> 00:59:29,566
SPEAKER_0:  at any system.

00:59:29,858 --> 00:59:32,062
SPEAKER_0:  There's a really important thing that happens. What?

00:59:32,514 --> 00:59:37,502
SPEAKER_0:  Clay Christensen calls crossing the chasm. If you explained it numerically, here's how I would explain it to you, Lux.

00:59:38,146 --> 00:59:40,094
SPEAKER_0:  If you introduce a disruptive product...

00:59:41,154 --> 00:59:43,838
SPEAKER_0:  Typically what happens is the first 3 to 5% of people

00:59:44,098 --> 00:59:45,406
SPEAKER_0:  Are these zealous?

00:59:45,890 --> 00:59:46,526
SPEAKER_0:  Believers.

00:59:47,650 --> 00:59:48,766
SPEAKER_0:  and they ignore.

00:59:49,826 --> 00:59:52,638
SPEAKER_0:  all the logical reasons why this product doesn't make any sense.

00:59:53,762 --> 00:59:56,126
SPEAKER_0:  because they believe in the proposition of the future and they buy it.

00:59:57,314 --> 00:59:58,526
SPEAKER_0:  The problem is at 5%.

00:59:58,754 --> 01:00:00,062
SPEAKER_0:  If you want to product.

01:00:00,578 --> 01:00:01,758
SPEAKER_0:  to get to mass market.

01:00:02,114 --> 01:00:03,262
SPEAKER_0:  You have one of two choices.

01:00:03,618 --> 01:00:06,782
SPEAKER_0:  which is you either bring the cost down low enough.

01:00:07,234 --> 01:00:07,678
SPEAKER_0:  or

01:00:07,938 --> 01:00:11,422
SPEAKER_0:  the feature set becomes so compelling that even at a high price point.

01:00:12,034 --> 01:00:14,238
SPEAKER_0:  An example of the latter is the iPhone.

01:00:15,298 --> 01:00:21,726
SPEAKER_0:  The iPhone today, the 14 iPhone, costs more than the original iPhone. It's probably doubled in price over the last 14 or 15 years.

01:00:22,146 --> 01:00:25,758
SPEAKER_0:  but we view it as an essential element of what we need in our daily lives.

01:00:27,522 --> 01:00:31,326
SPEAKER_0:  It turns out that battery EVs and solar panels are an example of the form.

01:00:32,482 --> 01:00:32,830
SPEAKER_0:  because

01:00:33,282 --> 01:00:35,838
SPEAKER_0:  people like President Biden with all of these subsidies.

01:00:37,026 --> 01:00:40,574
SPEAKER_0:  now introduced so much money for people.

01:00:41,250 --> 01:00:43,134
SPEAKER_0:  to just do this where it is a...

01:00:43,458 --> 01:00:46,590
SPEAKER_0:  money-making proposition for 100 million homes.

01:00:47,490 --> 01:00:50,398
SPEAKER_0:  And what you're seeing as a result are all of these companies.

01:00:51,138 --> 01:00:51,870
SPEAKER_0:  who want to get.

01:00:52,258 --> 01:00:53,598
SPEAKER_0:  in front of that trend.

01:00:54,018 --> 01:01:01,886
SPEAKER_0:  Why? Because they want to own the relationship with 100 million homeowners. They want to manage the power infrastructure. Amazon, Home Depot, Lowe's.

01:01:02,274 --> 01:01:04,350
SPEAKER_0:  You know, you can just name the company.

01:01:05,218 --> 01:01:06,462
SPEAKER_0:  So if you do that.

01:01:06,754 --> 01:01:08,254
SPEAKER_0:  and you control that relationship.

01:01:09,122 --> 01:01:13,694
SPEAKER_0:  they're going to show you, they're going to, you know, for example, Amazon will probably say, if you're a member of Prime,

01:01:14,690 --> 01:01:16,670
SPEAKER_0:  We'll stick the panels on your house for free.

01:01:17,634 --> 01:01:18,846
SPEAKER_0:  We'll do all the work for you.

01:01:19,074 --> 01:01:19,550
SPEAKER_0:  for free.

01:01:20,450 --> 01:01:22,494
SPEAKER_0:  and it's just a feature of being a member of Prime.

01:01:23,170 --> 01:01:27,934
SPEAKER_0:  and we'll manage all that energy for you. It makes so much sense and it is mathematically accretive.

01:01:28,546 --> 01:01:29,630
SPEAKER_0:  for Amazon to do that.

01:01:30,434 --> 01:01:31,486
SPEAKER_0:  It's not a creative.

01:01:32,642 --> 01:01:35,454
SPEAKER_0:  for the existing energy industry because they get blown up.

01:01:36,514 --> 01:01:39,198
SPEAKER_0:  It's extremely accretive for peace and prosperity.

01:01:40,066 --> 01:01:45,214
SPEAKER_0:  If you think the number of wars we fight over natural resources, take them all off the table if we don't need energy.

01:01:45,474 --> 01:01:45,918
SPEAKER_0:  from abroad.

01:01:46,818 --> 01:01:47,742
SPEAKER_0:  There's no reason to fight.

01:01:48,706 --> 01:01:49,438
SPEAKER_0:  You know, there's...

01:01:49,794 --> 01:01:51,038
SPEAKER_0:  You'd have to find a reason to fight.

01:01:51,618 --> 01:01:54,110
SPEAKER_0:  Meaning, sorry, there'd be a moral reason to fight.

01:01:54,722 --> 01:01:56,350
SPEAKER_0:  but the last number of wars that we fought.

01:01:57,378 --> 01:02:00,030
SPEAKER_0:  were not as much rooted in morality as they were rooted in.

01:02:00,290 --> 01:02:06,665
SPEAKER_1:  Yeah, it feels like they're very much rooted in conflict over resources, energy.

01:02:06,665 --> 01:02:09,918
SPEAKER_0:  And then sorry, just the last thing I want to say, I keep an orgy, apologies.

01:02:10,498 --> 01:02:11,134
SPEAKER_0:  The chips.

01:02:12,162 --> 01:02:15,166
SPEAKER_0:  All what people want to say is that, you know,

01:02:15,458 --> 01:02:17,662
SPEAKER_0:  Now that we're at 2 and 3 nanometer scale.

01:02:18,242 --> 01:02:20,062
SPEAKER_0:  for typical kind of like transistor fab.

01:02:20,898 --> 01:02:21,278
SPEAKER_0:  We're done.

01:02:21,794 --> 01:02:26,046
SPEAKER_0:  and forget about transistor density, forget about Moore's lots over. And I would just say no.

01:02:26,562 --> 01:02:27,582
SPEAKER_0:  Look at teraflops.

01:02:27,970 --> 01:02:29,502
SPEAKER_0:  and really teraflops is.

01:02:29,890 --> 01:02:33,118
SPEAKER_0:  the combination of CPUs, but much, much less important.

01:02:33,378 --> 01:02:36,798
SPEAKER_0:  and RULI is the combination of ASICs, so application specific ICs.

01:02:37,314 --> 01:02:37,918
SPEAKER_0:  and GPUs.

01:02:39,074 --> 01:02:40,574
SPEAKER_0:  And so you put the two together.

01:02:40,962 --> 01:02:43,838
SPEAKER_0:  I mean, if I gave you a billion dollars five years from now.

01:02:44,834 --> 01:02:47,358
SPEAKER_0:  The amount of damage you could do damage in good way.

01:02:48,066 --> 01:02:48,574
SPEAKER_0:  terms of

01:02:48,802 --> 01:02:50,846
SPEAKER_0:  you know, building racks and racks of GPUs.

01:02:51,074 --> 01:02:55,742
SPEAKER_0:  the kind of models that you could build, the training sets and the data that you could consume to solve a problem.

01:02:57,250 --> 01:02:57,630
SPEAKER_0:  It's-

01:02:57,954 --> 01:03:01,246
SPEAKER_0:  it's enough to do something really powerful, whereas today it's not yet quite enough.

01:03:02,274 --> 01:03:07,102
SPEAKER_1:  So there's this really interesting idea that you talk about in terms of Facebook and Twitter.

01:03:07,650 --> 01:03:09,278
SPEAKER_1:  that's connected to this that.

01:03:09,570 --> 01:03:11,230
SPEAKER_1:  If you were running sort of Twitter.

01:03:11,874 --> 01:03:13,918
SPEAKER_1:  or Facebook that you would move them all.

01:03:14,178 --> 01:03:15,390
SPEAKER_1:  to like AWS.

01:03:16,258 --> 01:03:17,054
SPEAKER_1:  So you would.

01:03:17,410 --> 01:03:21,054
SPEAKER_1:  have somebody else to compute the infrastructure.

01:03:21,410 --> 01:03:23,902
SPEAKER_1:  It probably, if you could explain that reasoning.

01:03:24,994 --> 01:03:31,582
SPEAKER_1:  means that you believe in this idea of energy going to zero, compute going to zero. So let people that are optimizing that.

01:03:32,834 --> 01:03:33,598
SPEAKER_0:  Do the best job.

01:03:34,018 --> 01:03:34,462
SPEAKER_0:  and

01:03:34,818 --> 01:03:35,998
SPEAKER_0:  I think that's a, you know.

01:03:37,122 --> 01:03:40,926
SPEAKER_0:  Initially, in the early 2000s and the beginning of the 2010s,

01:03:41,826 --> 01:03:43,582
SPEAKER_0:  If you were big enough scale.

01:03:44,834 --> 01:03:49,278
SPEAKER_0:  I'm sorry, everybody was building their own stuff. Then between 2010 through 2020,

01:03:49,922 --> 01:03:54,878
SPEAKER_0:  Really, the idea was everybody should be on AWS, except the biggest of the biggest folks.

01:03:56,834 --> 01:03:57,502
SPEAKER_0:  I think in-

01:03:57,762 --> 01:04:03,134
SPEAKER_0:  the 2020s and 30s, I think the answer is actually everybody should be in these public clouds.

01:04:03,682 --> 01:04:07,134
SPEAKER_0:  and the reason is the engineering velocity of the guts.

01:04:08,514 --> 01:04:10,846
SPEAKER_0:  So take a simple example, which is.

01:04:11,138 --> 01:04:14,750
SPEAKER_0:  We have not seen a massive iteration in database design.

01:04:15,010 --> 01:04:19,038
SPEAKER_0:  until Snowflake, right? I think maybe Postgres was like the last big turn of the dial.

01:04:20,642 --> 01:04:21,406
SPEAKER_0:  Why is that?

01:04:21,922 --> 01:04:23,006
SPEAKER_0:  I don't exactly know.

01:04:23,362 --> 01:04:25,374
SPEAKER_0:  except that everybody that's on AWS

01:04:25,986 --> 01:04:28,062
SPEAKER_0:  and everybody that's on GCP and Azure.

01:04:28,706 --> 01:04:29,886
SPEAKER_0:  gets to now benefit.

01:04:30,594 --> 01:04:30,910
SPEAKER_0:  from.

01:04:31,618 --> 01:04:34,750
SPEAKER_0:  $100-plus billion of aggregate market cap.

01:04:35,426 --> 01:04:36,734
SPEAKER_0:  rapidly iterating.

01:04:37,378 --> 01:04:38,398
SPEAKER_0:  making mistakes.

01:04:39,106 --> 01:04:40,670
SPEAKER_0:  fixing solving learning.

01:04:41,346 --> 01:04:42,174
SPEAKER_0:  And that is a...

01:04:42,498 --> 01:04:44,254
SPEAKER_0:  Best in class industry now.

01:04:44,706 --> 01:04:45,022
SPEAKER_0:  Right?

01:04:46,082 --> 01:04:46,462
SPEAKER_0:  Um.

01:04:46,946 --> 01:04:49,950
SPEAKER_0:  then there's going to be all these AI layers around analytics.

01:04:50,338 --> 01:04:50,750
SPEAKER_0:  so that.

01:04:51,330 --> 01:04:53,118
SPEAKER_0:  companies can make better decisions.

01:04:53,922 --> 01:04:58,078
SPEAKER_0:  All of these things will allow you to build more nimble organizations.

01:04:58,594 --> 01:05:00,958
SPEAKER_0:  because you'll have this federated model of development.

01:05:01,826 --> 01:05:03,326
SPEAKER_0:  I'll take these things off the shelf.

01:05:03,874 --> 01:05:05,854
SPEAKER_0:  Maybe I'll roll my own stitching over here.

01:05:06,850 --> 01:05:08,862
SPEAKER_0:  Because the thing that where you make money

01:05:09,218 --> 01:05:11,646
SPEAKER_0:  is still for most people and how the apps.

01:05:11,970 --> 01:05:13,278
SPEAKER_0:  provision and experience.

01:05:13,762 --> 01:05:14,366
SPEAKER_0:  to a user.

01:05:15,042 --> 01:05:17,502
SPEAKER_0:  and everybody else can make a lot of money just servicing that.

01:05:17,954 --> 01:05:19,102
SPEAKER_0:  So they work in a really...

01:05:19,490 --> 01:05:19,870
SPEAKER_0:  Um.

01:05:20,546 --> 01:05:22,462
SPEAKER_0:  They play well together in the sandbox.

01:05:23,106 --> 01:05:24,254
SPEAKER_0:  So in the future.

01:05:24,610 --> 01:05:29,118
SPEAKER_0:  Everybody just should be there. It doesn't make sense for anybody. I don't think because

01:05:29,570 --> 01:05:33,438
SPEAKER_0:  You know, if you were to rule your own data centers, you know, for example, at Google for a long time,

01:05:33,762 --> 01:05:36,350
SPEAKER_0:  had these massive leaps where they had GFS and Bigtable.

01:05:37,250 --> 01:05:40,094
SPEAKER_0:  Those are really good in the 2000s and 2010s.

01:05:41,154 --> 01:05:43,038
SPEAKER_0:  And this is not just throw shade at Google.

01:05:43,394 --> 01:05:46,046
SPEAKER_0:  It's very hard for whatever exists that is a.

01:05:46,562 --> 01:05:51,646
SPEAKER_0:  that is the progeny of GFS and Bigtable to be anywhere near as good as $100 billion industries.

01:05:52,034 --> 01:05:53,438
SPEAKER_0:  attempt to build that stack.

01:05:54,562 --> 01:05:58,174
SPEAKER_0:  and you're putting your organization under enormous pressure to be that good.

01:05:59,042 --> 01:06:03,582
SPEAKER_1:  I guess the implied risk taken there is that you could become the next AWS.

01:06:03,970 --> 01:06:04,702
SPEAKER_1:  Like, uh...

01:06:05,506 --> 01:06:07,774
SPEAKER_1:  Tesla doing some of the compute in-house.

01:06:09,218 --> 01:06:12,382
SPEAKER_1:  I guess the bet there is that you can become the next

01:06:13,058 --> 01:06:14,718
SPEAKER_1:  the next AWS for…

01:06:15,266 --> 01:06:18,334
SPEAKER_1:  the new wave of computation if that level.

01:06:18,722 --> 01:06:19,262
SPEAKER_1:  If that...

01:06:19,906 --> 01:06:22,590
SPEAKER_1:  kind of computation is different. So if it's machine learning...

01:06:23,522 --> 01:06:25,918
SPEAKER_1:  I don't know if anyone's won that battle yet.

01:06:26,434 --> 01:06:28,309
SPEAKER_1:  which is machine learning centric.

01:06:28,309 --> 01:06:31,742
SPEAKER_0:  Well, I think that software has a very powerful property.

01:06:32,258 --> 01:06:36,094
SPEAKER_0:  in that there's a lot of things that can happen asynchronously.

01:06:36,610 --> 01:06:37,022
SPEAKER_0:  so that.

01:06:37,282 --> 01:06:40,670
SPEAKER_0:  real-time inference can be actually really lightweight code.

01:06:41,826 --> 01:06:45,022
SPEAKER_0:  And that's why I think you can have a very federated ecosystem.

01:06:45,506 --> 01:06:47,678
SPEAKER_0:  inside of all of these places.

01:06:48,226 --> 01:06:49,310
SPEAKER_0:  Tesla is very different.

01:06:49,538 --> 01:06:49,918
SPEAKER_0:  because.

01:06:50,466 --> 01:06:52,190
SPEAKER_0:  In order to build the best car,

01:06:52,546 --> 01:06:54,750
SPEAKER_0:  It's kind of like trying to build the best iPhone.

01:06:55,266 --> 01:06:58,750
SPEAKER_0:  which is that you need to control it all the way down to the bare metal in order to do it well.

01:06:59,394 --> 01:07:00,670
SPEAKER_0:  And that's just not.

01:07:00,930 --> 01:07:01,534
SPEAKER_0:  possible.

01:07:02,082 --> 01:07:04,446
SPEAKER_0:  if you're trying to be a systems integrator, which is what.

01:07:04,930 --> 01:07:05,630
SPEAKER_0:  Everybody.

01:07:06,114 --> 01:07:08,510
SPEAKER_0:  other than this modern generation of car companies.

01:07:09,250 --> 01:07:09,758
SPEAKER_0:  have been.

01:07:10,050 --> 01:07:11,710
SPEAKER_0:  and they've done a very good job of that.

01:07:12,514 --> 01:07:16,286
SPEAKER_0:  but it won't be the experience that allows you to win in the next 20 years.

01:07:18,018 --> 01:07:20,830
SPEAKER_1:  So let's linger on this social media thing. So

01:07:21,922 --> 01:07:25,886
SPEAKER_1:  If you, you said if you ran Facebook for a day, let's, let's, let's extend that.

01:07:26,466 --> 01:07:30,142
SPEAKER_1:  if you were to build a new social network today.

01:07:31,458 --> 01:07:32,670
SPEAKER_1:  How would you fix?

01:07:33,570 --> 01:07:35,422
SPEAKER_1:  how would you fix social media?

01:07:36,226 --> 01:07:36,734
SPEAKER_1:  If you...

01:07:37,026 --> 01:07:40,062
SPEAKER_1:  want to answer a different question is if you were.

01:07:40,642 --> 01:07:44,767
SPEAKER_1:  Elon Musk, somebody you know, when you were taking over Twitter, what would you fix?

01:07:44,767 --> 01:07:46,142
SPEAKER_0:  I've thought about this a little bit.

01:07:46,402 --> 01:07:46,814
SPEAKER_0:  Um.

01:07:49,122 --> 01:07:53,278
SPEAKER_0:  First of all, let me give you a backdrop. I wouldn't actually build a social media company at all.

01:07:54,050 --> 01:07:57,022
SPEAKER_0:  And the answer is, the reasoning is the following.

01:07:58,018 --> 01:07:58,398
SPEAKER_0:  Um.

01:07:59,138 --> 01:08:01,502
SPEAKER_0:  I really tend to believe, as you probably got in a sense, of

01:08:01,794 --> 01:08:03,614
SPEAKER_0:  sort of patterns and probabilities.

01:08:05,026 --> 01:08:06,014
SPEAKER_0:  And if you said to me, Chimath-

01:08:06,658 --> 01:08:08,702
SPEAKER_0:  probabilistically answer where.

01:08:08,930 --> 01:08:09,886
SPEAKER_0:  Where are we going?

01:08:10,306 --> 01:08:13,790
SPEAKER_0:  in apps and social experiences, what I would say is, freedom supporter works.

01:08:14,690 --> 01:08:15,966
SPEAKER_0:  We spent the first decade.

01:08:16,322 --> 01:08:17,598
SPEAKER_0:  Building platforms.

01:08:17,890 --> 01:08:18,974
SPEAKER_0:  and getting them to scale.

01:08:20,066 --> 01:08:23,582
SPEAKER_0:  And if you want to think about it, again, back to sort of this poker analogy.

01:08:24,418 --> 01:08:26,718
SPEAKER_0:  Others mistakes minus your mistakes is the value.

01:08:27,714 --> 01:08:29,086
SPEAKER_0:  Well, the value that was captured.

01:08:29,826 --> 01:08:32,286
SPEAKER_0:  was trillions of dollars, essentially to Apple.

01:08:32,706 --> 01:08:33,214
SPEAKER_0:  and to Google.

01:08:34,434 --> 01:08:36,126
SPEAKER_0:  And they did that by basically.

01:08:36,674 --> 01:08:37,022
SPEAKER_0:  Um.

01:08:37,602 --> 01:08:40,574
SPEAKER_0:  attracting billions of monthly active users to their platform.

01:08:43,074 --> 01:08:44,798
SPEAKER_0:  Then this next wave were the apps.

01:08:46,210 --> 01:08:48,702
SPEAKER_0:  Facebook QQ 10 cent TikTok.

01:08:49,122 --> 01:08:49,566
SPEAKER_0:  Twitter.

01:08:49,954 --> 01:08:50,494
SPEAKER_0:  Snapchat.

01:08:51,170 --> 01:08:52,990
SPEAKER_0:  that whole panoply of apps.

01:08:54,050 --> 01:08:55,038
SPEAKER_0:  And interestingly,

01:08:55,266 --> 01:08:57,982
SPEAKER_0:  they were in many ways an atomized version.

01:08:58,338 --> 01:08:59,166
SPEAKER_0:  of the platforms.

01:09:00,066 --> 01:09:01,598
SPEAKER_0:  Right, they sat on top of them.

01:09:01,922 --> 01:09:03,710
SPEAKER_0:  They were an ecosystem participant.

01:09:04,770 --> 01:09:06,398
SPEAKER_0:  but the value they created was the same.

01:09:07,874 --> 01:09:09,566
SPEAKER_0:  Trillions of dollars of enterprise value.

01:09:10,882 --> 01:09:12,734
SPEAKER_0:  billions of monthly active users.

01:09:14,594 --> 01:09:16,606
SPEAKER_0:  Well, there's an interesting phenomenon that's kind of.

01:09:17,154 --> 01:09:18,174
SPEAKER_0:  hiding in plain sight.

01:09:18,978 --> 01:09:19,486
SPEAKER_0:  which is that.

01:09:20,066 --> 01:09:22,142
SPEAKER_0:  the next most obvious atomic unit.

01:09:23,106 --> 01:09:24,254
SPEAKER_0:  or content creators.

01:09:24,930 --> 01:09:26,334
SPEAKER_0:  Now let me give you two examples.

01:09:26,626 --> 01:09:28,798
SPEAKER_0:  Lex Friedman, this random crazy guy.

01:09:29,218 --> 01:09:30,494
SPEAKER_0:  Uh, Mr. Beast.

01:09:31,074 --> 01:09:35,006
SPEAKER_0:  You know, Jimmy Donaldson, just the two of you alone, add it up, okay?

01:09:35,586 --> 01:09:36,286
SPEAKER_0:  And you guys.

01:09:36,578 --> 01:09:39,550
SPEAKER_0:  are going to approach in the next five years, a billion people.

01:09:39,778 --> 01:09:46,153
SPEAKER_0:  The only thing that you guys haven't figured out yet is how to capture trillions of dollars of value. You don't want to and maybe that's not your stated mission.

01:09:46,153 --> 01:09:50,622
SPEAKER_1:  Right, right, but let's just look at Mr. Beast alone because he is trying to do exactly that.

01:09:51,074 --> 01:09:56,542
SPEAKER_0:  And I think Jimmy is going to build an enormous business. But if you take Jimmy and all of the other content creators, right?

01:09:57,218 --> 01:09:58,878
SPEAKER_0:  You guys are atomizing.

01:09:59,970 --> 01:10:00,990
SPEAKER_0:  what the apps have done.

01:10:02,210 --> 01:10:04,670
SPEAKER_0:  You're providing your own curated news feeds.

01:10:05,090 --> 01:10:07,454
SPEAKER_0:  You're providing your own curated communities.

01:10:07,874 --> 01:10:12,286
SPEAKER_0:  You're allowed, you let people move in and out of these things in a very lightweight way.

01:10:12,706 --> 01:10:14,398
SPEAKER_0:  and value is accruing to you. So.

01:10:14,978 --> 01:10:20,734
SPEAKER_0:  The honest answer to your question is I would focus on the content creator side of things because I believe that's where the puck is going.

01:10:21,314 --> 01:10:22,462
SPEAKER_0:  That's a much more.

01:10:22,786 --> 01:10:23,614
SPEAKER_0:  important

01:10:24,194 --> 01:10:28,190
SPEAKER_0:  shift in how we all consume information and content and are entertained.

01:10:28,546 --> 01:10:32,382
SPEAKER_0:  It's through brands like you, individual people that we can humanize and understand.

01:10:32,770 --> 01:10:33,374
SPEAKER_0:  or the filter.

01:10:34,786 --> 01:10:35,838
SPEAKER_1:  But aren't you just-

01:10:36,770 --> 01:10:42,110
SPEAKER_1:  arguing against the point you made earlier, which is what you would recommend is the investment in the AGI. The.

01:10:42,882 --> 01:10:44,757
SPEAKER_1:  the depersonalization. because what

01:10:44,757 --> 01:10:49,054
SPEAKER_0:  they could still be a participant in that end state if that happens.

01:10:49,602 --> 01:10:52,062
SPEAKER_0:  you have the option value of being an enabler of that.

01:10:52,962 --> 01:10:57,758
SPEAKER_0:  You can help improve what they do. Again, you can be this bare metal service provider.

01:10:58,146 --> 01:10:59,422
SPEAKER_0:  where you can be a tax.

01:11:00,546 --> 01:11:02,558
SPEAKER_0:  You can participate in every...

01:11:03,170 --> 01:11:07,326
SPEAKER_0:  that you do, every question that's asked, every comment that's curated.

01:11:07,682 --> 01:11:11,870
SPEAKER_0:  if you could have more intelligence as you provide a service to your fans and your audience.

01:11:12,418 --> 01:11:14,590
SPEAKER_0:  you would probably pay a small percentage of that revenue.

01:11:15,202 --> 01:11:17,150
SPEAKER_0:  I suspect all content creators would.

01:11:17,602 --> 01:11:19,870
SPEAKER_0:  And so it's that stack of services.

01:11:20,450 --> 01:11:26,750
SPEAKER_0:  That is like a smart human being. It's like, you know, how do you help produce this information? You would pay a producer for that. I mean, maybe you would, but...

01:11:27,298 --> 01:11:28,862
SPEAKER_0:  So back to your question, so what would I do?

01:11:29,666 --> 01:11:31,806
SPEAKER_0:  I think that you have to move into that world.

01:11:32,578 --> 01:11:33,470
SPEAKER_0:  pretty aggressively?

01:11:33,954 --> 01:11:34,302
SPEAKER_0:  Um.

01:11:35,106 --> 01:11:37,086
SPEAKER_0:  I think that right now you first have to solve.

01:11:37,570 --> 01:11:39,582
SPEAKER_0:  what is broken inside of these social networks.

01:11:40,802 --> 01:11:42,430
SPEAKER_0:  and I don't think it's a technical problem.

01:11:43,202 --> 01:11:45,182
SPEAKER_0:  So just to put it out there, I don't think it's a.

01:11:46,434 --> 01:11:50,142
SPEAKER_0:  It's one where there are these nefarious organizations. That happens.

01:11:50,754 --> 01:11:53,182
SPEAKER_0:  Brigading XYZ, that happens.

01:11:54,274 --> 01:11:56,574
SPEAKER_0:  But the real problem is a psychological problem.

01:11:56,898 --> 01:11:57,982
SPEAKER_0:  one that we're dealing with.

01:11:58,274 --> 01:11:58,750
SPEAKER_0:  which is.

01:12:00,130 --> 01:12:00,670
SPEAKER_0:  people.

01:12:02,242 --> 01:12:03,998
SPEAKER_0:  through a whole set of situations.

01:12:05,922 --> 01:12:06,622
SPEAKER_0:  have lost.

01:12:08,354 --> 01:12:09,502
SPEAKER_0:  belief in themselves.

01:12:11,714 --> 01:12:12,734
SPEAKER_0:  And I think that that.

01:12:15,874 --> 01:12:22,430
SPEAKER_0:  comes up as this very virulent form of rejection that they tried to put into these social networks. So if you look inside a comments.

01:12:22,818 --> 01:12:26,014
SPEAKER_0:  on anything like you could have a con like you could have a person that says on Twitter.

01:12:26,818 --> 01:12:28,190
SPEAKER_0:  I saved this dog.

01:12:28,418 --> 01:12:29,662
SPEAKER_0:  from a fiery building.

01:12:30,690 --> 01:12:32,286
SPEAKER_0:  and there would be negative commenters.

01:12:33,506 --> 01:12:34,270
SPEAKER_0:  And you're like, well.

01:12:34,530 --> 01:12:34,878
SPEAKER_0:  again.

01:12:35,650 --> 01:12:39,678
SPEAKER_0:  put yourself in their shoes. What do you how do I steal man their case? I do this all the time.

01:12:40,066 --> 01:12:40,894
SPEAKER_0:  You know, I get.

01:12:41,186 --> 01:12:43,710
SPEAKER_0:  people throw shade at me, I'm like, okay, let me steal man their point of view.

01:12:44,610 --> 01:12:48,222
SPEAKER_0:  And the best that I can come up with is, I'm working really hard over here.

01:12:48,770 --> 01:12:49,342
SPEAKER_0:  I'm trying.

01:12:49,954 --> 01:12:51,774
SPEAKER_0:  I played by all the rules that were told to me.

01:12:52,482 --> 01:12:54,398
SPEAKER_0:  I've played well, I've played fairly.

01:12:54,914 --> 01:12:58,814
SPEAKER_0:  And I am not being rewarded in a system of value that you recognize.

01:12:59,746 --> 01:13:01,182
SPEAKER_0:  And that is making me mad.

01:13:02,402 --> 01:13:04,670
SPEAKER_0:  And now I need to cope and I need to vent.

01:13:05,634 --> 01:13:10,014
SPEAKER_0:  So back in the day, my dad used to drink. He would make me go get things to hit me with.

01:13:10,850 --> 01:13:13,918
SPEAKER_0:  Today, you go to Twitter, you spot off, you try to deal with-

01:13:14,370 --> 01:13:15,806
SPEAKER_0:  the latent anger that you feel.

01:13:16,322 --> 01:13:18,974
SPEAKER_0:  So a social network has to be designed in my opinion.

01:13:19,810 --> 01:13:24,510
SPEAKER_0:  to solve that psychological corner case because it is what makes a network unusable.

01:13:25,410 --> 01:13:26,718
SPEAKER_0:  to get real density.

01:13:27,010 --> 01:13:28,638
SPEAKER_0:  You have to find a way.

01:13:29,122 --> 01:13:32,830
SPEAKER_0:  of moving away from that toxicity because it ruins a product experience.

01:13:33,506 --> 01:13:35,070
SPEAKER_0:  you could have the best pixels in the world.

01:13:35,778 --> 01:13:39,454
SPEAKER_0:  but if people are virulently spitting into their keyboards...

01:13:40,578 --> 01:13:44,350
SPEAKER_0:  Other people are just going to say, you know what, I'm done with this. It doesn't make me feel good.

01:13:46,498 --> 01:13:49,150
SPEAKER_0:  The social network has to have a social cost.

01:13:49,602 --> 01:13:50,654
SPEAKER_0:  You can do it in a couple ways.

01:13:51,234 --> 01:13:52,830
SPEAKER_0:  One is where you have real world identity.

01:13:53,346 --> 01:13:55,134
SPEAKER_0:  So then there's a cost to being virulent.

01:13:56,002 --> 01:13:57,054
SPEAKER_0:  and there's a cost to being.

01:13:57,346 --> 01:13:57,918
SPEAKER_0:  Haustik.

01:13:58,882 --> 01:14:03,070
SPEAKER_0:  A second way is to actually just overlay an economic framework.

01:14:03,778 --> 01:14:04,702
SPEAKER_0:  so that there's a more.

01:14:05,026 --> 01:14:07,038
SPEAKER_0:  and economic value that you assign.

01:14:07,458 --> 01:14:08,734
SPEAKER_0:  to basically spouting off.

01:14:09,442 --> 01:14:11,550
SPEAKER_0:  And the more you want to spend, the more you can save.

01:14:12,770 --> 01:14:17,822
SPEAKER_0:  And I think both have a lot of value. I don't know what the right answer is. I tend to like the latter.

01:14:18,466 --> 01:14:21,438
SPEAKER_0:  I think real world identity shuts down a lot of debate.

01:14:22,178 --> 01:14:23,614
SPEAKER_0:  because there's still too much.

01:14:24,322 --> 01:14:24,766
SPEAKER_0:  Um.

01:14:25,314 --> 01:14:28,094
SPEAKER_0:  there's a sensation that there'll be some retribution.

01:14:28,770 --> 01:14:29,150
SPEAKER_0:  Um.

01:14:29,538 --> 01:14:33,022
SPEAKER_0:  So I think there's more free speech over here, but it cannot be costless.

01:14:33,954 --> 01:14:37,918
SPEAKER_0:  Because in that there's a level of toxicity that just makes these products unusable.

01:14:38,594 --> 01:14:39,678
SPEAKER_1:  a third option.

01:14:39,938 --> 01:14:41,150
SPEAKER_1:  And by the way, all of these.

01:14:41,442 --> 01:14:42,270
SPEAKER_1:  work together.

01:14:44,130 --> 01:14:49,022
SPEAKER_1:  If we look at this, what you call the corner case, which is hilarious, what I would call the human condition.

01:14:49,506 --> 01:14:50,631
SPEAKER_1:  Uh...

01:14:50,631 --> 01:14:51,998
SPEAKER_0:

01:14:52,226 --> 01:14:55,486
SPEAKER_1:  Which is, you know, that anger.

01:14:56,162 --> 01:14:58,622
SPEAKER_1:  Is rude with the challenges of life.

01:14:59,330 --> 01:14:59,934
SPEAKER_1:  and

01:15:01,346 --> 01:15:03,614
SPEAKER_1:  What about having a...

01:15:05,090 --> 01:15:07,870
SPEAKER_1:  an algorithm that shows you what you see.

01:15:08,802 --> 01:15:09,150
SPEAKER_1:  That's.

01:15:09,474 --> 01:15:14,686
SPEAKER_1:  personalized to you and helps you maximize your personal growth in the long term.

01:15:15,298 --> 01:15:16,254
SPEAKER_1:  such that...

01:15:16,546 --> 01:15:17,342
SPEAKER_1:  your

01:15:17,762 --> 01:15:19,710
SPEAKER_1:  challenging yourself, you're improving.

01:15:20,002 --> 01:15:20,926
SPEAKER_1:  You're learning.

01:15:21,346 --> 01:15:22,910
SPEAKER_1:  There's just enough of

01:15:23,170 --> 01:15:23,934
SPEAKER_1:  criticism.

01:15:24,770 --> 01:15:26,430
SPEAKER_1:  to keep you on your toes.

01:15:26,850 --> 01:15:33,225
SPEAKER_1:  but just enough of like the dopamine rush to keep you entertained and finding that balance for each individual problem.

01:15:33,225 --> 01:15:35,710
SPEAKER_0:  You just described an AGI of a very...

01:15:36,162 --> 01:15:37,758
SPEAKER_0:  Empathetic wall-rounded friend.

01:15:38,274 --> 01:15:39,070
SPEAKER_1:  Yes, exactly.

01:15:39,778 --> 01:15:43,166
SPEAKER_1:  And then you can throw that person even anonymous.

01:15:43,394 --> 01:15:46,622
SPEAKER_1:  into a pool of discourse and they would be better.

01:15:46,722 --> 01:15:47,550
SPEAKER_0:  I think you're absolutely right.

01:15:48,002 --> 01:15:50,302
SPEAKER_0:  That is a very, very, very elegant way of stating it.

01:15:50,498 --> 01:15:54,430
SPEAKER_1:  You're absolutely right. But like you said, the AGI might be a few years away.

01:15:54,818 --> 01:15:57,438
SPEAKER_1:  So that's a huge investment. Like my concern.

01:15:57,826 --> 01:16:01,278
SPEAKER_1:  My gut feeling is this thing we're calling AGI.

01:16:01,794 --> 01:16:03,838
SPEAKER_1:  is actually not that difficult to.

01:16:04,066 --> 01:16:04,958
SPEAKER_1:  built technically.

01:16:05,474 --> 01:16:07,166
SPEAKER_1:  but it requires a certain culture.

01:16:07,618 --> 01:16:09,246
SPEAKER_1:  And it requires a certain...

01:16:09,890 --> 01:16:11,015
SPEAKER_1:  certain risks to be taken.

01:16:11,015 --> 01:16:13,630
SPEAKER_0:  I think you could reductively boil down.

01:16:14,082 --> 01:16:14,718
SPEAKER_0:  The human.

01:16:15,458 --> 01:16:16,830
SPEAKER_0:  intellect into.

01:16:17,826 --> 01:16:18,942
SPEAKER_0:  cognition and emotion.

01:16:21,154 --> 01:16:21,694
SPEAKER_0:  And you know.

01:16:22,242 --> 01:16:24,254
SPEAKER_0:  depending on who you are and depending on the moment.

01:16:24,770 --> 01:16:26,686
SPEAKER_0:  They're weighted very differently, obviously.

01:16:27,170 --> 01:16:27,550
SPEAKER_0:  Um.

01:16:27,874 --> 01:16:30,302
SPEAKER_0:  Cognition is so easily done by computers.

01:16:31,746 --> 01:16:33,598
SPEAKER_0:  we should assume that that's a solved problem.

01:16:34,754 --> 01:16:38,590
SPEAKER_0:  So our differentiation is the reasoning part. It's the emotional overlay. It's that.

01:16:38,818 --> 01:16:42,206
SPEAKER_0:  It's the empathy, it's the ability to steel man the opposite person's case in

01:16:42,594 --> 01:16:44,126
SPEAKER_0:  and feel why that person.

01:16:44,898 --> 01:16:48,446
SPEAKER_0:  You can forgive them without excusing what they did, as an example.

01:16:49,090 --> 01:16:49,502
SPEAKER_0:  Um...

01:16:50,914 --> 01:16:53,854
SPEAKER_0:  That is a very difficult thing, I think, to capture in software, but...

01:16:55,074 --> 01:16:56,030
SPEAKER_0:  I think it's a matter of.

01:16:56,258 --> 01:16:57,118
SPEAKER_0:  When not if.

01:16:59,554 --> 01:17:00,926
SPEAKER_1:  if done crudely.

01:17:01,314 --> 01:17:03,326
SPEAKER_1:  it takes a form of censorship.

01:17:03,810 --> 01:17:04,158
SPEAKER_1:  Just.

01:17:04,738 --> 01:17:06,526
SPEAKER_1:  banning people off the platform.

01:17:06,914 --> 01:17:10,302
SPEAKER_1:  Let me ask you some tricky questions.

01:17:10,626 --> 01:17:14,622
SPEAKER_1:  Uh, do you think Trump should have been removed from Twitter? No. What's the-

01:17:15,074 --> 01:17:17,118
SPEAKER_1:  What's the pro case?

01:17:17,538 --> 01:17:19,413
SPEAKER_1:  I'm having fun here. Still.

01:17:19,413 --> 01:17:20,734
SPEAKER_0:  on each side.

01:17:21,186 --> 01:17:21,694
SPEAKER_0:  Um,

01:17:23,330 --> 01:17:25,566
SPEAKER_0:  Let's steel man the get them off the platform.

01:17:27,330 --> 01:17:28,350
SPEAKER_0:  Here we have a guy.

01:17:29,218 --> 01:17:29,662
SPEAKER_0:  Cool.

01:17:30,178 --> 01:17:30,590
SPEAKER_0:  Um.

01:17:31,426 --> 01:17:33,278
SPEAKER_0:  virulent in all ways.

01:17:34,114 --> 01:17:34,558
SPEAKER_0:  He.

01:17:34,978 --> 01:17:35,582
SPEAKER_0:  promotes

01:17:35,810 --> 01:17:36,670
SPEAKER_0:  confrontation.

01:17:37,314 --> 01:17:38,558
SPEAKER_0:  Um, he lacks.

01:17:38,914 --> 01:17:39,518
SPEAKER_0:  decorum.

01:17:40,098 --> 01:17:40,542
SPEAKER_0:  He.

01:17:41,250 --> 01:17:42,078
SPEAKER_0:  insights.

01:17:42,530 --> 01:17:44,446
SPEAKER_0:  the fervent believers of his cause.

01:17:45,442 --> 01:17:50,590
SPEAKER_0:  to act up and push the boundaries bordering on potentially even including breaking the law.

01:17:51,906 --> 01:17:52,414
SPEAKER_0:  He.

01:17:52,642 --> 01:17:53,790
SPEAKER_0:  does not observe.

01:17:54,018 --> 01:17:55,294
SPEAKER_0:  the social norms.

01:17:55,650 --> 01:17:57,726
SPEAKER_0:  of a society that keep us well functioning.

01:17:58,018 --> 01:17:59,966
SPEAKER_0:  including an orderly transition of power,

01:18:00,706 --> 01:18:04,126
SPEAKER_0:  If he is left in a moment where he feels trapped and cornered,

01:18:04,866 --> 01:18:06,270
SPEAKER_0:  He could behave in ways.

01:18:06,818 --> 01:18:09,406
SPEAKER_0:  that will confuse the people that believe in him.

01:18:10,082 --> 01:18:12,094
SPEAKER_0:  to act in ways that they so regret.

01:18:13,346 --> 01:18:13,694
SPEAKER_0:  that.

01:18:14,754 --> 01:18:17,598
SPEAKER_0:  it could bring our democracy to an end.

01:18:17,890 --> 01:18:18,270
SPEAKER_0:  or.

01:18:18,690 --> 01:18:21,374
SPEAKER_0:  so much damage or create a wound that's so deep.

01:18:21,986 --> 01:18:24,830
SPEAKER_0:  it will take years of conflict and years of.

01:18:25,218 --> 01:18:25,950
SPEAKER_0:  confrontation.

01:18:26,210 --> 01:18:26,782
SPEAKER_0:  to heal it.

01:18:27,970 --> 01:18:28,990
SPEAKER_0:  We need to remove him?

01:18:29,602 --> 01:18:32,190
SPEAKER_0:  and we need to do it now. It's been too long. We've let it go on.

01:18:33,954 --> 01:18:35,870
SPEAKER_0:  the other side of the argument would be.

01:18:36,642 --> 01:18:38,846
SPEAKER_0:  He was a duly elected person.

01:18:39,426 --> 01:18:41,182
SPEAKER_0:  whose views have been run over.

01:18:41,602 --> 01:18:42,750
SPEAKER_0:  for way too long.

01:18:43,810 --> 01:18:45,342
SPEAKER_0:  And he uses.

01:18:45,954 --> 01:18:48,798
SPEAKER_0:  the ability to say extreme things.

01:18:49,282 --> 01:18:50,654
SPEAKER_0:  in order to showcase

01:18:52,354 --> 01:18:54,590
SPEAKER_0:  corrupt these systems have become.

01:18:55,394 --> 01:18:59,486
SPEAKER_0:  and how insular these organizations are in protecting their own class.

01:19:00,258 --> 01:19:05,918
SPEAKER_0:  And so if you really want to prevent class warfare, and if you really want to keep the American dream alive for everybody,

01:19:06,306 --> 01:19:07,422
SPEAKER_0:  We need to show...

01:19:08,130 --> 01:19:11,070
SPEAKER_0:  that the First Amendment, the Constitution, the Second Amendment

01:19:11,746 --> 01:19:13,374
SPEAKER_0:  all of this infrastructure.

01:19:13,730 --> 01:19:17,662
SPEAKER_0:  is actually bigger than any partisan view, no matter how bad it is.

01:19:18,242 --> 01:19:19,166
SPEAKER_0:  and that people.

01:19:19,938 --> 01:19:21,822
SPEAKER_0:  will make their own decisions.

01:19:22,946 --> 01:19:24,574
SPEAKER_0:  and there are a lot of people...

01:19:25,058 --> 01:19:27,678
SPEAKER_0:  that can see past the words he uses.

01:19:28,706 --> 01:19:31,742
SPEAKER_0:  and focus on the substance of what he's trying to get across.

01:19:32,770 --> 01:19:34,558
SPEAKER_0:  more generally agree than disagree.

01:19:34,946 --> 01:19:36,990
SPEAKER_0:  And so when you silence that voice.

01:19:37,634 --> 01:19:40,446
SPEAKER_0:  What you're effectively saying is this is a rigged game.

01:19:40,834 --> 01:19:45,246
SPEAKER_0:  And all of those things that we were told were not true are actually true.

01:19:46,114 --> 01:19:49,182
SPEAKER_1:  If you were to look at the crude algorithms of Twitter.

01:19:49,762 --> 01:19:51,614
SPEAKER_1:  Of course I don't have any insider knowledge.

01:19:52,194 --> 01:19:54,558
SPEAKER_1:  but I could imagine that they saw.

01:19:55,746 --> 01:19:56,446
SPEAKER_1:  Duh.

01:19:56,898 --> 01:19:59,422
SPEAKER_1:  Let's say there's a metric that measures

01:19:59,682 --> 01:20:00,126
SPEAKER_1:  How?

01:20:00,482 --> 01:20:02,814
SPEAKER_1:  negative the experiences of the platform.

01:20:03,298 --> 01:20:04,574
SPEAKER_1:  and they probably saw...

01:20:04,898 --> 01:20:05,950
SPEAKER_1:  in

01:20:06,242 --> 01:20:07,742
SPEAKER_1:  several ways you could look at this.

01:20:07,970 --> 01:20:10,782
SPEAKER_1:  But the presence of Donald Trump on the platform.

01:20:11,202 --> 01:20:13,118
SPEAKER_1:  was consistently increasing.

01:20:13,634 --> 01:20:15,070
SPEAKER_1:  how shitty people are feeling.

01:20:15,458 --> 01:20:16,958
SPEAKER_1:  short term and long term.

01:20:17,250 --> 01:20:19,038
SPEAKER_1:  because they're probably yelling at each other.

01:20:19,490 --> 01:20:22,366
SPEAKER_1:  having worse and worse and worse experience, if you even do a survey of

01:20:22,658 --> 01:20:25,726
SPEAKER_1:  How do you feel about using this platform over the last week?

01:20:25,986 --> 01:20:26,814
SPEAKER_1:  They would say.

01:20:27,202 --> 01:20:29,502
SPEAKER_1:  relative to maybe a year ago.

01:20:29,922 --> 01:20:35,486
SPEAKER_1:  when Donald Trump was not actively tweeting or so on. So here you're sitting at Twitter and saying

01:20:36,482 --> 01:20:36,926
SPEAKER_1:  Okay.

01:20:37,282 --> 01:20:43,774
SPEAKER_1:  I know everyone's talking about speech and all that kind of stuff, but I kind of want to build a platform where the users are happy.

01:20:44,546 --> 01:20:45,758
SPEAKER_1:  and they're becoming.

01:20:46,018 --> 01:20:49,182
SPEAKER_1:  More and more unhappy. How do I solve this happiness problem?

01:20:49,634 --> 01:20:50,270
SPEAKER_1:  Well, let's.

01:20:51,234 --> 01:20:51,870
SPEAKER_1:  BAN

01:20:53,250 --> 01:20:53,630
SPEAKER_1:  Let's.

01:20:53,858 --> 01:20:57,054
SPEAKER_1:  Uh, yeah, let's ban the sources of the unhappiness.

01:20:57,282 --> 01:20:58,622
SPEAKER_1:  Now we can't just say...

01:20:59,010 --> 01:21:03,614
SPEAKER_1:  your source of unhappiness will ban you. Let's wait until that source says something.

01:21:03,874 --> 01:21:05,694
SPEAKER_1:  that we can claim.

01:21:06,242 --> 01:21:09,223
SPEAKER_1:  breaks our rules, like incites violence or...

01:21:09,223 --> 01:21:11,710
SPEAKER_0:  That would work if you could measure...

01:21:12,866 --> 01:21:20,190
SPEAKER_0:  your construct of happiness properly. The problem is, I think what Twitter looked at were active commenters and got it confused for overall system happiness.

01:21:20,898 --> 01:21:23,230
SPEAKER_0:  because for every piece of content that's created on the internet

01:21:23,746 --> 01:21:27,518
SPEAKER_0:  of the 100 people that consume it, maybe one or two people comment on it.

01:21:28,450 --> 01:21:28,990
SPEAKER_0:  And so.

01:21:29,346 --> 01:21:31,038
SPEAKER_0:  by over-amplifying that signal.

01:21:31,522 --> 01:21:36,606
SPEAKER_0:  and assuming that it was the plurality of people, that's where they actually made a huge blunder.

01:21:37,154 --> 01:21:42,142
SPEAKER_0:  because there was no scientific method, I think, to get to the answer of deplatforming him.

01:21:42,690 --> 01:21:44,254
SPEAKER_0:  and it did expose.

01:21:44,930 --> 01:21:46,814
SPEAKER_0:  this idea that it's a bit of a rigged game.

01:21:47,362 --> 01:21:48,350
SPEAKER_0:  and that there are these.

01:21:48,578 --> 01:21:48,990
SPEAKER_0:  deep.

01:21:49,346 --> 01:21:50,110
SPEAKER_0:  Biases.

01:21:50,786 --> 01:21:53,214
SPEAKER_0:  that some of these organizations have.

01:21:53,922 --> 01:21:57,054
SPEAKER_0:  opinions that are counter to theirs and to their orthodox view of the world.

01:22:00,258 --> 01:22:02,398
SPEAKER_1:  So in general, you lean towards...

01:22:02,818 --> 01:22:03,902
SPEAKER_1:  keeping...

01:22:04,994 --> 01:22:07,806
SPEAKER_1:  first of all, presidents on the platform, but also...

01:22:08,450 --> 01:22:10,046
SPEAKER_1:  controversial voices.

01:22:10,402 --> 01:22:11,262
SPEAKER_0:  all the time.

01:22:11,842 --> 01:22:13,566
SPEAKER_0:  I think it's really important to keep them there.

01:22:13,890 --> 01:22:16,286
SPEAKER_1:  Let me ask you a tricky one in the recent news.

01:22:16,546 --> 01:22:18,462
SPEAKER_1:  that's become especially relevant.

01:22:18,946 --> 01:22:19,774
SPEAKER_1:  for me.

01:22:20,258 --> 01:22:24,510
SPEAKER_1:  What do you think about if you've been paying attention to Yay Kanye West?

01:22:25,186 --> 01:22:27,582
SPEAKER_1:  recent controversial outbursts on social media.

01:22:28,290 --> 01:22:29,118
SPEAKER_1:  about.

01:22:30,082 --> 01:22:30,654
SPEAKER_1:  and

01:22:31,554 --> 01:22:32,350
SPEAKER_1:  Jews.

01:22:33,570 --> 01:22:34,526
SPEAKER_1:  Black people.

01:22:36,066 --> 01:22:37,310
SPEAKER_1:  racism general.

01:22:38,210 --> 01:22:45,662
SPEAKER_1:  slavery, holocaust, all these topics that he touched on in different ways on different platforms.

01:22:45,922 --> 01:22:55,550
SPEAKER_1:  including Twitter. What do you do with that? And like, what do you do with that from a platform perspective? And what do you do from a humanity perspective?

01:22:56,066 --> 01:22:58,206
SPEAKER_1:  of how to add love to the world.

01:22:59,426 --> 01:23:00,190
SPEAKER_0:  Let's um.

01:23:00,610 --> 01:23:01,566
SPEAKER_0:  Should we take both sides of them?

01:23:02,370 --> 01:23:04,670
SPEAKER_0:  Option one is he is.

01:23:05,538 --> 01:23:08,158
SPEAKER_0:  completely out of line and option two is he's not.

01:23:08,802 --> 01:23:10,622
SPEAKER_0:  Just a simple tie. Right.

01:23:11,330 --> 01:23:11,742
SPEAKER_0:  The.

01:23:12,322 --> 01:23:13,022
SPEAKER_0:  Path 1?

01:23:14,498 --> 01:23:15,134
SPEAKER_0:  is

01:23:16,450 --> 01:23:16,958
SPEAKER_0:  using

01:23:17,538 --> 01:23:19,934
SPEAKER_0:  important tastemaker in the world.

01:23:20,642 --> 01:23:23,038
SPEAKER_0:  that defines the belief system for a lot of people.

01:23:24,226 --> 01:23:26,302
SPEAKER_0:  and there just is no room.

01:23:26,978 --> 01:23:28,670
SPEAKER_0:  for any form of.

01:23:29,090 --> 01:23:31,454
SPEAKER_0:  racism or bias or anti-Semitism?

01:23:31,906 --> 01:23:34,686
SPEAKER_0:  in today's day and age, particularly by people.

01:23:35,362 --> 01:23:38,750
SPEAKER_0:  whose words and comments will be amplified around the world.

01:23:39,554 --> 01:23:43,134
SPEAKER_0:  We've already paid a large price for that. And then the expectation.

01:23:44,098 --> 01:23:45,022
SPEAKER_0:  of success.

01:23:45,634 --> 01:23:47,934
SPEAKER_0:  is some amount of societal decorum?

01:23:48,354 --> 01:23:49,726
SPEAKER_0:  that keeps moving the ball forward.

01:23:51,394 --> 01:23:52,510
SPEAKER_0:  The other side would say.

01:23:53,922 --> 01:23:54,462
SPEAKER_0:  Life.

01:23:55,138 --> 01:23:56,670
SPEAKER_0:  I think goes from harmony.

01:23:57,218 --> 01:23:58,046
SPEAKER_0:  to disharmony.

01:23:58,818 --> 01:23:59,294
SPEAKER_0:  repair.

01:24:00,674 --> 01:24:03,678
SPEAKER_0:  and anybody who has gone through a very complicated.

01:24:04,130 --> 01:24:04,734
SPEAKER_0:  Divorce?

01:24:05,570 --> 01:24:08,798
SPEAKER_0:  will tell you that in that moment, your life is extremely.

01:24:09,282 --> 01:24:10,366
SPEAKER_0:  Disharmonious?

01:24:11,394 --> 01:24:13,182
SPEAKER_0:  and you are struggling to cope.

01:24:14,402 --> 01:24:16,478
SPEAKER_0:  and because he is famous.

01:24:18,114 --> 01:24:19,230
SPEAKER_0:  we are seeing...

01:24:20,322 --> 01:24:22,558
SPEAKER_0:  a person really struggling in a moment?

01:24:23,650 --> 01:24:24,638
SPEAKER_0:  that may need help.

01:24:25,698 --> 01:24:27,198
SPEAKER_0:  and we owe it to him.

01:24:27,970 --> 01:24:30,750
SPEAKER_0:  Not for what he said, because that stuff isn't excusable.

01:24:31,522 --> 01:24:32,606
SPEAKER_0:  but we owe it to him.

01:24:33,730 --> 01:24:34,654
SPEAKER_0:  to help him in a way.

01:24:35,298 --> 01:24:36,670
SPEAKER_0:  particularly his friends.

01:24:37,698 --> 01:24:39,294
SPEAKER_0:  And if he has real friends...

01:24:40,194 --> 01:24:43,742
SPEAKER_0:  Hopefully what they see is that what I see on the outside looking in.

01:24:44,642 --> 01:24:45,150
SPEAKER_0:  is

01:24:45,794 --> 01:24:47,518
SPEAKER_0:  person that is clearly struggling.

01:24:49,122 --> 01:24:53,182
SPEAKER_1:  Can I ask you like a human question? And I know it's outside looking in.

01:24:54,562 --> 01:24:56,958
SPEAKER_1:  There's several questions I want to ask.

01:24:57,602 --> 01:25:02,302
SPEAKER_1:  So one is about the pain of going through a divorce and having kids and all that kind of stuff.

01:25:02,946 --> 01:25:05,470
SPEAKER_1:  and two, when you're rich and powerful.

01:25:05,858 --> 01:25:07,166
SPEAKER_1:  and famous, I don't know.

01:25:07,810 --> 01:25:11,454
SPEAKER_1:  Maybe you can enlighten me to which is the most corruptive.

01:25:12,450 --> 01:25:12,798
SPEAKER_1:  Um.

01:25:13,058 --> 01:25:14,142
SPEAKER_1:  But how do you know?

01:25:14,434 --> 01:25:15,454
SPEAKER_1:  for the friends.

01:25:16,514 --> 01:25:17,182
SPEAKER_1:  to trust.

01:25:18,978 --> 01:25:22,622
SPEAKER_1:  So a lot of the world is calling Kanye insane.

01:25:22,978 --> 01:25:24,382
SPEAKER_1:  And if Orlik has mentally-

01:25:24,610 --> 01:25:26,046
SPEAKER_1:  illness, all that kind of stuff.

01:25:26,690 --> 01:25:28,958
SPEAKER_1:  And so how do you have friends close to you?

01:25:29,378 --> 01:25:30,174
SPEAKER_1:  Let's say...

01:25:30,818 --> 01:25:34,110
SPEAKER_1:  that say something like that message, but from a place of...

01:25:34,818 --> 01:25:35,806
SPEAKER_1:  uh, love.

01:25:36,194 --> 01:25:38,526
SPEAKER_1:  and or they actually care for you.

01:25:38,818 --> 01:25:40,702
SPEAKER_1:  as opposed to trying to get you to shut up.

01:25:42,242 --> 01:25:44,126
SPEAKER_1:  The reason I ask all those questions, I think.

01:25:44,994 --> 01:25:47,038
SPEAKER_1:  If you care about the guy, how do you help him?

01:25:48,770 --> 01:25:49,758
SPEAKER_0:  I've been through a divorce.

01:25:50,306 --> 01:25:51,422
SPEAKER_0:  It's gut wrenching.

01:25:52,322 --> 01:25:54,014
SPEAKER_0:  the most horrible part.

01:25:54,786 --> 01:25:55,902
SPEAKER_0:  is having to tell your kids.

01:25:57,826 --> 01:25:59,134
SPEAKER_0:  can't even describe to you.

01:26:00,162 --> 01:26:00,638
SPEAKER_0:  Um.

01:26:00,962 --> 01:26:04,734
SPEAKER_0:  how proud I am of and how resilient these three beautiful little creatures were when

01:26:05,282 --> 01:26:06,878
SPEAKER_0:  My ex-wife and I had to sit them down and-

01:26:07,618 --> 01:26:08,222
SPEAKER_0:  Talk through it.

01:26:09,282 --> 01:26:09,822
SPEAKER_0:  Um...

01:26:10,530 --> 01:26:10,974
SPEAKER_0:  and

01:26:11,650 --> 01:26:12,126
SPEAKER_0:  For that.

01:26:12,386 --> 01:26:13,470
SPEAKER_0:  thing I'll be the s-

01:26:13,762 --> 01:26:15,422
SPEAKER_0:  so protective of them and so.

01:26:16,066 --> 01:26:16,958
SPEAKER_0:  proud of them.

01:26:17,698 --> 01:26:18,110
SPEAKER_0:  Um.

01:26:18,466 --> 01:26:19,166
SPEAKER_0:  It's hard.

01:26:19,490 --> 01:26:20,894
SPEAKER_0:  Now I don't know that that's what.

01:26:21,218 --> 01:26:22,046
SPEAKER_0:  He went through.

01:26:22,690 --> 01:26:29,118
SPEAKER_0:  But it doesn't matter. In that moment, there's no fame, there's no money, there's nothing. There's just the raw intimacy of a nuclear family.

01:26:30,082 --> 01:26:32,030
SPEAKER_0:  breaking up and that there is a death.

01:26:32,802 --> 01:26:34,270
SPEAKER_0:  And it's the death of that idea.

01:26:35,202 --> 01:26:37,694
SPEAKER_0:  and that is extremely, extremely.

01:26:38,498 --> 01:26:39,038
SPEAKER_0:  profound.

01:26:39,266 --> 01:26:41,470
SPEAKER_0:  and its impact, especially in your children.

01:26:42,850 --> 01:26:43,326
SPEAKER_0:  Um...

01:26:43,650 --> 01:26:44,958
SPEAKER_0:  It is really hard.

01:26:45,506 --> 01:26:47,710
SPEAKER_1:  really hard. you have seen yourself.

01:26:48,098 --> 01:26:49,502
SPEAKER_1:  and the way you see the world.

01:26:50,242 --> 01:26:51,390
SPEAKER_1:  being clouded during.

01:26:52,066 --> 01:26:53,630
SPEAKER_1:  especially at first.

01:26:54,018 --> 01:26:55,774
SPEAKER_1:  where you would make poor decisions.

01:26:56,162 --> 01:26:59,294
SPEAKER_1:  outside of that nuclear family. So like.

01:26:59,938 --> 01:27:01,726
SPEAKER_1:  for business decisions, for...

01:27:02,082 --> 01:27:03,326
SPEAKER_1:  tweeting decisions for

01:27:03,586 --> 01:27:03,966
SPEAKER_1:  Fuck.

01:27:04,322 --> 01:27:06,814
SPEAKER_0:  I think that if I had to boil down...

01:27:07,746 --> 01:27:08,670
SPEAKER_0:  A lot of those.

01:27:08,930 --> 01:27:10,014
SPEAKER_0:  What I would say is that.

01:27:10,658 --> 01:27:13,118
SPEAKER_0:  There are moments in my life, Lex, where I have felt.

01:27:13,730 --> 01:27:14,942
SPEAKER_0:  meaningfully less than.

01:27:16,482 --> 01:27:22,814
SPEAKER_0:  And in those moments, the loop that I would fall into is I would look to cope and be seen by other people.

01:27:23,234 --> 01:27:24,510
SPEAKER_0:  so I would throw away.

01:27:25,442 --> 01:27:28,254
SPEAKER_0:  all of the work I was doing around my own internal validation.

01:27:29,602 --> 01:27:30,110
SPEAKER_0:  and

01:27:30,434 --> 01:27:34,046
SPEAKER_0:  I would try to say something or do something that would get the attention of others.

01:27:34,562 --> 01:27:35,742
SPEAKER_0:  and oftentimes...

01:27:36,162 --> 01:27:37,598
SPEAKER_0:  You know, when that loop was.

01:27:37,826 --> 01:27:38,270
SPEAKER_0:  Um.

01:27:38,754 --> 01:27:41,310
SPEAKER_0:  was unproductive, it's because those things had really...

01:27:41,890 --> 01:27:43,614
SPEAKER_0:  crappy consequences. So-

01:27:44,002 --> 01:27:45,246
SPEAKER_0:  You know, that was, that was.

01:27:45,570 --> 01:27:47,422
SPEAKER_0:  Yeah, so yeah, I went through that.

01:27:47,746 --> 01:27:49,502
SPEAKER_0:  as well. So I had to go through.

01:27:50,114 --> 01:27:53,342
SPEAKER_0:  you know, this disharmonious phase in my life and then to repair.

01:27:54,018 --> 01:27:55,230
SPEAKER_0:  You know, I had the benefit.

01:27:55,586 --> 01:27:56,702
SPEAKER_0:  of meeting someone.

01:27:57,250 --> 01:27:57,566
SPEAKER_0:  and

01:27:58,018 --> 01:27:59,294
SPEAKER_0:  building a relationship.

01:28:00,194 --> 01:28:00,670
SPEAKER_0:  Um.

01:28:00,898 --> 01:28:02,046
SPEAKER_0:  block by block.

01:28:02,946 --> 01:28:06,238
SPEAKER_0:  where there is just enormous accountability.

01:28:07,010 --> 01:28:07,422
SPEAKER_0:  where

01:28:08,194 --> 01:28:09,310
SPEAKER_0:  My partner not had.

01:28:09,858 --> 01:28:10,270
SPEAKER_0:  has.

01:28:10,978 --> 01:28:12,062
SPEAKER_0:  just incredible.

01:28:12,386 --> 01:28:13,118
SPEAKER_0:  Empathy?

01:28:14,402 --> 01:28:15,774
SPEAKER_0:  But accountability.

01:28:16,866 --> 01:28:18,974
SPEAKER_0:  And so she can put herself in my shoes.

01:28:19,554 --> 01:28:21,886
SPEAKER_0:  sometimes when I'm a really tough person to be around.

01:28:22,946 --> 01:28:24,638
SPEAKER_0:  then she doesn't let me off the hook.

01:28:24,898 --> 01:28:28,254
SPEAKER_0:  She can forgive me, but it doesn't make, you know, what I may have said or whatever.

01:28:28,802 --> 01:28:30,558
SPEAKER_0:  you know, excusable.

01:28:31,298 --> 01:28:35,710
SPEAKER_0:  and that's been really healthy for me and it's helped me repair my relationships.

01:28:36,482 --> 01:28:37,598
SPEAKER_0:  Be a better parent.

01:28:38,114 --> 01:28:39,070
SPEAKER_0:  you know, be a better.

01:28:39,650 --> 01:28:41,598
SPEAKER_0:  friend to my ex-wife who's a beautiful woman.

01:28:41,858 --> 01:28:44,542
SPEAKER_0:  who I love deeply and will always love her.

01:28:45,122 --> 01:28:46,878
SPEAKER_0:  and it took me a few years to see that.

01:28:47,394 --> 01:28:50,078
SPEAKER_0:  that it was just a chapter that had come to an end, but.

01:28:50,434 --> 01:28:53,150
SPEAKER_0:  She's an incredible mother and an incredible businesswoman.

01:28:53,442 --> 01:28:55,006
SPEAKER_0:  I'm so thankful that I've had.

01:28:55,234 --> 01:28:56,414
SPEAKER_0:  two incredible women in my life.

01:28:57,474 --> 01:28:58,366
SPEAKER_0:  That's like a blessing.

01:28:58,786 --> 01:28:59,742
SPEAKER_0:  but it's hard.

01:29:00,162 --> 01:29:02,430
SPEAKER_1:  So with that, it's hard to find a person.

01:29:02,882 --> 01:29:09,246
SPEAKER_1:  that has that, I mean, a lot of stuff you said is pretty profound, but having that person who has empathy and accountability.

01:29:09,506 --> 01:29:12,542
SPEAKER_1:  So basically that's ultimately what great.

01:29:13,250 --> 01:29:14,014
SPEAKER_1:  Friendship is.

01:29:14,946 --> 01:29:18,321
SPEAKER_1:  which is people that love you have empathy for you, but can also call you on.

01:29:18,321 --> 01:29:21,918
SPEAKER_0:  your bullshit. She's a LeBron James-like figure and the reason I say that is

01:29:23,042 --> 01:29:27,070
SPEAKER_0:  I've seen and met so many people. I've seen the distribution.

01:29:27,330 --> 01:29:27,902
SPEAKER_0:  on

01:29:28,322 --> 01:29:29,982
SPEAKER_0:  scale of friendship and empathy.

01:29:30,786 --> 01:29:33,182
SPEAKER_0:  She's the LeBron James of friendship. She's a goat.

01:29:33,634 --> 01:29:35,198
SPEAKER_0:  Well what's so funny is like, you know...

01:29:35,458 --> 01:29:37,310
SPEAKER_0:  We have a dinner around poker.

01:29:38,114 --> 01:29:40,094
SPEAKER_0:  and it's taken on a life of its own.

01:29:40,610 --> 01:29:41,886
SPEAKER_0:  Mostly because of her?

01:29:42,434 --> 01:29:44,158
SPEAKER_0:  because these guys look d-

01:29:45,314 --> 01:29:46,398
SPEAKER_0:  And I'm like, whoa, whoa, whoa.

01:29:47,362 --> 01:29:52,830
SPEAKER_0:  She's thinking like her registers are already full. She's thinking all kinds of crap with me.

01:29:53,282 --> 01:29:53,694
SPEAKER_0:  Um.

01:29:54,338 --> 01:29:54,878
SPEAKER_0:  But, um...

01:29:55,938 --> 01:29:58,046
SPEAKER_0:  but it's a very innate skill.

01:29:58,594 --> 01:29:59,710
SPEAKER_0:  and it's paired with

01:30:00,194 --> 01:30:02,654
SPEAKER_0:  You know, it's but it's not just an emotional thing, meaning.

01:30:03,618 --> 01:30:06,462
SPEAKER_0:  She's the person that I make all my decisions with.

01:30:07,266 --> 01:30:09,246
SPEAKER_0:  These decisions we're making together as a team.

01:30:09,730 --> 01:30:12,798
SPEAKER_0:  I've never understood that. You know, there's that African proverb like...

01:30:13,442 --> 01:30:15,614
SPEAKER_0:  Go fast, go alone, go far, go together.

01:30:16,738 --> 01:30:17,278
SPEAKER_0:  and

01:30:18,210 --> 01:30:20,414
SPEAKER_0:  Like since I was born, I was by myself.

01:30:21,090 --> 01:30:21,790
SPEAKER_0:  and I had to cope.

01:30:22,050 --> 01:30:23,326
SPEAKER_0:  and I didn't have a good toolkit.

01:30:23,650 --> 01:30:24,542
SPEAKER_0:  to use into the world.

01:30:25,730 --> 01:30:30,206
SPEAKER_0:  And in these last five or six years, she's helped me. And at first, my toolkit was literally like.

01:30:30,786 --> 01:30:31,422
SPEAKER_0:  Sticks.

01:30:31,810 --> 01:30:32,286
SPEAKER_0:  You know?

01:30:32,770 --> 01:30:34,046
SPEAKER_0:  And then I found a way to.

01:30:34,402 --> 01:30:38,590
SPEAKER_0:  You know, she helped me sharpen a little rock and that became a little knife, but even that was crap.

01:30:39,010 --> 01:30:41,950
SPEAKER_0:  and then she showed me fire and then I forged a knife and then...

01:30:42,562 --> 01:30:44,862
SPEAKER_0:  And that's what it feels like we're now this toolkit.

01:30:45,314 --> 01:30:46,878
SPEAKER_0:  is like most average people.

01:30:47,650 --> 01:30:48,478
SPEAKER_0:  And I feel.

01:30:49,378 --> 01:30:50,430
SPEAKER_0:  humble to be average.

01:30:51,010 --> 01:30:51,678
SPEAKER_0:  Because I was.

01:30:52,226 --> 01:30:53,470
SPEAKER_0:  Here, down here on the ground.

01:30:54,978 --> 01:30:58,942
SPEAKER_0:  So it's made all these things more reasonable. So I see.

01:31:00,034 --> 01:31:03,390
SPEAKER_0:  what comes from having deep, profound friendships and love.

01:31:04,098 --> 01:31:05,854
SPEAKER_0:  to help you through these critical moments.

01:31:06,082 --> 01:31:06,974
SPEAKER_0:  I have another friend.

01:31:07,682 --> 01:31:08,030
SPEAKER_0:  Who?

01:31:08,514 --> 01:31:08,862
SPEAKER_0:  Um.

01:31:09,122 --> 01:31:11,870
SPEAKER_0:  who I would say just completely unabashedly loves me.

01:31:12,450 --> 01:31:13,342
SPEAKER_0:  This guy, Rob Goldberg.

01:31:13,890 --> 01:31:14,270
SPEAKER_0:  Heat.

01:31:14,722 --> 01:31:19,326
SPEAKER_0:  doesn't hold me accountable that much, which I love. Like I could say, I killed a homeless person. He's like, ah, they probably deserve it.

01:31:20,258 --> 01:31:20,606
SPEAKER_0:  You know?

01:31:20,866 --> 01:31:24,414
SPEAKER_0:  Whereas Nat would be like, that was not good, what you just did.

01:31:25,282 --> 01:31:26,366
SPEAKER_0:  But I have both.

01:31:27,106 --> 01:31:29,918
SPEAKER_0:  I mean, I have Nat every day. You know, Rob, I don't talk to you that often, but-

01:31:30,626 --> 01:31:31,518
SPEAKER_0:  to have two people.

01:31:33,346 --> 01:31:36,190
SPEAKER_0:  I had zero. I think most people unfortunately have zero.

01:31:36,930 --> 01:31:37,278
SPEAKER_0:  Um.

01:31:37,538 --> 01:31:38,558
SPEAKER_0:  So I think like what.

01:31:38,914 --> 01:31:40,190
SPEAKER_0:  What he needs?

01:31:41,154 --> 01:31:43,038
SPEAKER_0:  Is somebody to just listen?

01:31:44,418 --> 01:31:46,334
SPEAKER_0:  You don't have to put a label on these things.

01:31:47,234 --> 01:31:51,646
SPEAKER_0:  and you just have to try to guide in these very unique moments where you can just like...

01:31:51,938 --> 01:31:52,862
SPEAKER_0:  deescalate.

01:31:54,242 --> 01:32:00,382
SPEAKER_0:  what is going on in your mind and I suspect what's going on in his mind. Again to play armchair quarterback I don't know.

01:32:01,570 --> 01:32:04,926
SPEAKER_0:  is that he is in a moment where he just feels lower than low.

01:32:06,818 --> 01:32:11,806
SPEAKER_0:  And we all do it, we've all had these moments where we don't know how to get attention.

01:32:13,090 --> 01:32:17,822
SPEAKER_0:  And if you didn't grow up in a healthy environment, you may go through a negative way to get attention.

01:32:18,946 --> 01:32:20,798
SPEAKER_0:  And it's not to excuse it.

01:32:21,634 --> 01:32:22,686
SPEAKER_0:  but it's to understand.

01:32:24,386 --> 01:32:27,102
SPEAKER_1:  That's so profound, the feeling less than.

01:32:27,714 --> 01:32:28,542
SPEAKER_1:  And

01:32:29,218 --> 01:32:30,494
SPEAKER_1:  at those low points.

01:32:31,650 --> 01:32:33,310
SPEAKER_1:  going externally to find it.

01:32:33,826 --> 01:32:35,134
SPEAKER_1:  and maybe creating.

01:32:35,970 --> 01:32:36,862
SPEAKER_1:  conflict.

01:32:37,890 --> 01:32:39,070
SPEAKER_1:  and scandal.

01:32:39,426 --> 01:32:40,062
SPEAKER_1:  to get that.

01:32:40,514 --> 01:32:40,958
SPEAKER_1:  attention.

01:32:41,794 --> 01:32:44,126
SPEAKER_0:  The way that my doctor explained it to me is, um...

01:32:45,762 --> 01:32:47,454
SPEAKER_0:  You have to think about your self-worth.

01:32:47,906 --> 01:32:50,238
SPEAKER_0:  like a knot. It's inside.

01:32:50,690 --> 01:32:52,862
SPEAKER_0:  of a very complicated set of knots.

01:32:53,122 --> 01:32:57,086
SPEAKER_0:  So it's like a, some people don't have these knots, it's just presented to you on a platter.

01:32:58,018 --> 01:33:00,158
SPEAKER_0:  But for some of us, because of the way we grow up...

01:33:00,546 --> 01:33:02,462
SPEAKER_0:  It's covered in all these knots.

01:33:03,074 --> 01:33:04,350
SPEAKER_0:  to the whole goal.

01:33:05,122 --> 01:33:06,654
SPEAKER_0:  is to loosen those knots.

01:33:07,714 --> 01:33:12,126
SPEAKER_0:  And it happens slowly, it happens unpredictably, and it takes a long time.

01:33:13,346 --> 01:33:17,758
SPEAKER_0:  And so while you're doing that, you are gonna have moments where when you feel less than, you're not prepared.

01:33:18,306 --> 01:33:19,806
SPEAKER_0:  to look inside and say, actually.

01:33:20,098 --> 01:33:23,134
SPEAKER_0:  Here's how I feel about myself. It's pretty cool. Happy with how I'm where I'm at.

01:33:26,306 --> 01:33:27,230
SPEAKER_1:  I have to ask.

01:33:27,714 --> 01:33:29,022
SPEAKER_1:  on the topic of friendship.

01:33:29,442 --> 01:33:35,806
SPEAKER_1:  You do an amazing podcast called All In Podcast. People should stop listening to this and go listen to that.

01:33:36,034 --> 01:33:41,118
SPEAKER_1:  You just did your hundredth episode. Um, I mean, it's one of my favorite podcasts. It's incredible.

01:33:41,474 --> 01:33:42,462
SPEAKER_1:  for the...

01:33:43,842 --> 01:33:45,790
SPEAKER_1:  the technical and

01:33:46,338 --> 01:33:48,798
SPEAKER_1:  The human psychological wisdom that you guys

01:33:50,082 --> 01:33:51,006
SPEAKER_1:  constantly give.

01:33:51,362 --> 01:33:54,302
SPEAKER_1:  and the way you analyze the world, but also just the chemistry.

01:33:54,530 --> 01:33:57,470
SPEAKER_1:  between you. We are entertaining players today.

01:33:57,794 --> 01:33:59,166
SPEAKER_1:  There's a tension.

01:33:59,714 --> 01:34:04,830
SPEAKER_1:  and there's camaraderie that's all laid out on the table.

01:34:05,794 --> 01:34:08,766
SPEAKER_1:  I don't know the two Davids that well, but I have met Jason.

01:34:09,154 --> 01:34:09,982
SPEAKER_1:  What do you love about him?

01:34:10,434 --> 01:34:11,646
SPEAKER_0:  I mean, I'll give you a little.

01:34:11,938 --> 01:34:13,918
SPEAKER_0:  Psychological breakdown of all three of these guys.

01:34:15,426 --> 01:34:15,902
SPEAKER_0:  Um.

01:34:16,482 --> 01:34:17,246
SPEAKER_0:  Just my opinion.

01:34:17,506 --> 01:34:19,070
SPEAKER_0:  And I love you guys.

01:34:19,810 --> 01:34:20,190
SPEAKER_0:  Um.

01:34:20,546 --> 01:34:22,421
SPEAKER_1:  Would they agree with your psychological breakdown?

01:34:22,421 --> 01:34:23,550
SPEAKER_0:  I don't know, you know.

01:34:23,842 --> 01:34:26,686
SPEAKER_0:  I think that what I would say about J-Cal is...

01:34:27,362 --> 01:34:28,030
SPEAKER_0:  He is.

01:34:28,514 --> 01:34:30,206
SPEAKER_0:  unbelievably loyal

01:34:31,170 --> 01:34:31,742
SPEAKER_0:  Um...

01:34:32,546 --> 01:34:33,182
SPEAKER_0:  To no end.

01:34:34,498 --> 01:34:37,182
SPEAKER_0:  and you know he's like any of those movies.

01:34:38,274 --> 01:34:39,710
SPEAKER_0:  where which are about like the

01:34:40,322 --> 01:34:44,862
SPEAKER_0:  the mafia or whatever where like, you know, something bad's going wrong and you need somebody to show up.

01:34:46,178 --> 01:34:46,878
SPEAKER_0:  That's J.C.L.

01:34:47,010 --> 01:34:47,486
SPEAKER_1:  So if you.

01:34:47,810 --> 01:34:51,427
SPEAKER_1:  killed the said proverbial homeless person, you'll be right there.

01:34:51,427 --> 01:34:56,638
SPEAKER_0:  the body. But he's the one that he'll defend you in every way, shape, or form, even if it's not.

01:34:56,962 --> 01:34:58,366
SPEAKER_0:  doesn't make sense in that moment.

01:34:58,882 --> 01:34:59,838
SPEAKER_0:  He doesn't see.

01:35:01,026 --> 01:35:05,726
SPEAKER_0:  that as an action of whether it'll solve the problem, he sees that as an act of devotion to you, your friend.

01:35:06,370 --> 01:35:08,446
SPEAKER_0:  And that's an incredible gift that he gives us.

01:35:10,178 --> 01:35:12,254
SPEAKER_0:  The other side of it is that, you know, JCal...

01:35:12,930 --> 01:35:14,014
SPEAKER_0:  needs to learn.

01:35:14,786 --> 01:35:15,422
SPEAKER_0:  how to trust.

01:35:15,746 --> 01:35:18,334
SPEAKER_0:  that other people love him back as much as he loves us.

01:35:19,714 --> 01:35:24,702
SPEAKER_0:  And that's where he makes mistakes, because he assumes that he's not as lovable as the rest of us.

01:35:25,442 --> 01:35:28,030
SPEAKER_0:  but he's infinitely more lovable than he understands. He's-

01:35:28,514 --> 01:35:28,958
SPEAKER_0:  I mean.

01:35:29,314 --> 01:35:30,750
SPEAKER_0:  You have to see Lex like he is.

01:35:31,490 --> 01:35:32,894
SPEAKER_0:  unbelievably funny. I mean...

01:35:33,570 --> 01:35:35,614
SPEAKER_0:  I cannot tell you how funny this guy is.

01:35:36,322 --> 01:35:37,726
SPEAKER_0:  next level funny.

01:35:38,018 --> 01:35:40,638
SPEAKER_0:  It has timing, everything, charm.

01:35:41,282 --> 01:35:42,302
SPEAKER_0:  the care he takes.

01:35:43,234 --> 01:35:46,206
SPEAKER_0:  So he is as lovable, but he doesn't believe himself to be.

01:35:46,722 --> 01:35:49,822
SPEAKER_0:  And that manifests itself in areas that drive us all crazy from time.

01:35:50,754 --> 01:35:57,095
SPEAKER_1:  which makes it for a very pleasant listening experience. Okay, so what about the two Davids, Dead Sax and Dead 분들이?

01:35:57,095 --> 01:36:01,470
SPEAKER_0:  David Sachs is the one that I would say I have the most emotional connection with.

01:36:02,050 --> 01:36:02,526
SPEAKER_0:  Um.

01:36:03,298 --> 01:36:05,022
SPEAKER_0:  He and I can go a year without talking.

01:36:05,570 --> 01:36:07,198
SPEAKER_0:  and then we'll talk for four hours straight.

01:36:07,842 --> 01:36:08,734
SPEAKER_0:  and then we know.

01:36:09,122 --> 01:36:09,822
SPEAKER_0:  where we are.

01:36:10,210 --> 01:36:13,406
SPEAKER_0:  and we have this ability to pick up and have a level of intimacy with each other.

01:36:13,954 --> 01:36:14,430
SPEAKER_0:  and

01:36:14,658 --> 01:36:16,894
SPEAKER_0:  I think that's just because I've known David for so long now.

01:36:17,378 --> 01:36:17,886
SPEAKER_0:  Um...

01:36:18,754 --> 01:36:20,190
SPEAKER_0:  that I find really comforting.

01:36:20,930 --> 01:36:24,222
SPEAKER_0:  And then Freeberg is this person who I think is similar to me.

01:36:24,930 --> 01:36:25,342
SPEAKER_0:  had.

01:36:25,634 --> 01:36:27,038
SPEAKER_0:  very turbulent upbringing.

01:36:27,650 --> 01:36:30,366
SPEAKER_0:  has fought through it to build an incredible life for himself.

01:36:30,914 --> 01:36:31,710
SPEAKER_0:  And I have this.

01:36:32,002 --> 01:36:34,110
SPEAKER_0:  enormous respect for his journey.

01:36:34,466 --> 01:36:37,726
SPEAKER_0:  I don't particularly care about his outcomes to be honest, but I just have.

01:36:38,306 --> 01:36:39,550
SPEAKER_0:  I look at that guy and I think...

01:36:40,514 --> 01:36:41,118
SPEAKER_0:  And he did it.

01:36:41,794 --> 01:36:43,358
SPEAKER_0:  And so if I didn't do it.

01:36:44,322 --> 01:36:44,894
SPEAKER_0:  Um...

01:36:45,506 --> 01:36:46,750
SPEAKER_0:  I would be glad that he did it.

01:36:47,266 --> 01:36:48,254
SPEAKER_0:  if it makes any sense.

01:36:48,866 --> 01:36:49,438
SPEAKER_0:  Um...

01:36:50,658 --> 01:36:51,710
SPEAKER_0:  and you can see.

01:36:52,226 --> 01:36:53,086
SPEAKER_0:  that he...

01:36:53,858 --> 01:36:54,302
SPEAKER_0:  Um.

01:36:55,042 --> 01:36:57,310
SPEAKER_0:  feels like his entire responsibility.

01:36:57,634 --> 01:36:59,006
SPEAKER_0:  is really around his kids.

01:37:00,034 --> 01:37:01,342
SPEAKER_0:  and just kind of like.

01:37:02,370 --> 01:37:03,198
SPEAKER_0:  give a better.

01:37:03,426 --> 01:37:04,190
SPEAKER_0:  counterfactual.

01:37:05,346 --> 01:37:06,270
SPEAKER_0:  and uh...

01:37:07,170 --> 01:37:09,278
SPEAKER_0:  And you know, sometimes I think he gets that right and wrong.

01:37:09,922 --> 01:37:12,126
SPEAKER_0:  But he's a very special human being, though.

01:37:12,290 --> 01:37:13,438
SPEAKER_1:  on that show.

01:37:13,890 --> 01:37:15,742
SPEAKER_1:  the two of you have a very kind of...

01:37:16,962 --> 01:37:19,038
SPEAKER_1:  like from a geopolitics perspective.

01:37:19,490 --> 01:37:21,022
SPEAKER_1:  I don't know, there's just a very...

01:37:22,114 --> 01:37:22,654
SPEAKER_1:  uh

01:37:23,234 --> 01:37:25,534
SPEAKER_1:  effective way to think deeply about the world.

01:37:26,082 --> 01:37:32,542
SPEAKER_0:  the big picture of the world. He's a very systems level thinker. Like a system, that's a good way to put it. Yeah. Very, very. Absolutely.

01:37:33,250 --> 01:37:36,574
SPEAKER_0:  very systems level. So looking at everything very rooted in

01:37:37,058 --> 01:37:38,974
SPEAKER_0:  you know, a broad body of knowledge.

01:37:39,426 --> 01:37:42,974
SPEAKER_0:  which I have a tremendous respect for. He brings all these things in.

01:37:44,034 --> 01:37:44,606
SPEAKER_0:  It sucks.

01:37:45,154 --> 01:37:50,910
SPEAKER_0:  incredible because he has this unbelievable understanding of things but it has a core nucleus.

01:37:51,394 --> 01:37:54,686
SPEAKER_0:  So Freebird can just basically abstract a whole bunch of systems and talk about it.

01:37:55,298 --> 01:37:59,262
SPEAKER_0:  I tend to be more like that, where I try to kind of, I find it to be more of a puzzle.

01:38:00,002 --> 01:38:01,694
SPEAKER_0:  Socks is more like anchored in...

01:38:02,018 --> 01:38:05,310
SPEAKER_0:  a philosophical and historical context as the answer.

01:38:05,986 --> 01:38:08,510
SPEAKER_0:  and he starts there, but he gets to these profound...

01:38:08,834 --> 01:38:10,494
SPEAKER_0:  understandings of systems as well.

01:38:11,362 --> 01:38:12,542
SPEAKER_1:  On the podcast.

01:38:12,802 --> 01:38:13,470
SPEAKER_1:  in life.

01:38:13,922 --> 01:38:15,710
SPEAKER_1:  You guys hold to your opinion pretty strong.

01:38:17,346 --> 01:38:21,726
SPEAKER_1:  What's the secret to being able to argue passionately with friends?

01:38:22,210 --> 01:38:22,654
SPEAKER_1:  So.

01:38:23,170 --> 01:38:25,790
SPEAKER_1:  hold your position, but also not murder each other.

01:38:26,146 --> 01:38:27,710
SPEAKER_1:  which you guys seem to come close to.

01:38:28,290 --> 01:38:29,022
SPEAKER_0:  I think it's like.

01:38:29,666 --> 01:38:31,870
SPEAKER_0:  Strong opinions, weakly held.

01:38:33,602 --> 01:38:33,950
SPEAKER_0:  So.

01:38:34,402 --> 01:38:35,678
SPEAKER_0:  I think that's a good way.

01:38:35,938 --> 01:38:39,313
SPEAKER_1:  Is that a haiku?

01:38:39,313 --> 01:38:41,886
SPEAKER_0:  Explain that please. Like, you know, like, look today.

01:38:42,242 --> 01:38:46,910
SPEAKER_0:  You and I, we steel man like the two sides of three different things. Yeah.

01:38:47,618 --> 01:38:48,030
SPEAKER_0:  Um.

01:38:48,706 --> 01:38:50,558
SPEAKER_0:  Now you could be confused and think I...

01:38:50,786 --> 01:38:52,094
SPEAKER_0:  Believe in those things.

01:38:52,578 --> 01:38:58,846
SPEAKER_0:  I believe that it's important to be able to intellectually traverse there, whether I believe in it or not. Like Steelman, not Scrumman.

01:38:59,266 --> 01:39:00,391
SPEAKER_0:  That's a really, but we.

01:39:00,391 --> 01:39:03,614
SPEAKER_1:  intro those things by saying let us steelman this position.

01:39:03,938 --> 01:39:05,822
SPEAKER_1:  Sometimes you guys skip the...

01:39:05,922 --> 01:39:10,494
SPEAKER_0:  We skip, you're right, we edit those things out and sometimes we'll sit on either sides and we'll just kind of

01:39:10,882 --> 01:39:12,990
SPEAKER_0:  bat things back and forth just to see.

01:39:13,474 --> 01:39:14,942
SPEAKER_0:  what the other person thinks.

01:39:15,554 --> 01:39:16,318
SPEAKER_1:  So that's how.

01:39:16,642 --> 01:39:22,526
SPEAKER_1:  Like as fans, we should listen to that sometimes. Like so sometimes cause cause you hold a strong opinion sometimes.

01:39:23,042 --> 01:39:24,606
SPEAKER_1:  Like for example the

01:39:25,026 --> 01:39:26,398
SPEAKER_1:  Cost of energy going to zero.

01:39:27,554 --> 01:39:28,446
SPEAKER_1:  Is that...

01:39:29,442 --> 01:39:31,294
SPEAKER_1:  Like, what's the degree of certainty on that?

01:39:31,714 --> 01:39:33,950
SPEAKER_1:  Is this kind of like you really...

01:39:35,170 --> 01:39:36,382
SPEAKER_1:  taking a prediction.

01:39:36,770 --> 01:39:38,430
SPEAKER_1:  of how the world will unroll.

01:39:38,882 --> 01:39:41,086
SPEAKER_1:  And if it does, this will benefit.

01:39:41,442 --> 01:39:42,910
SPEAKER_1:  a huge amount of

01:39:43,362 --> 01:39:44,766
SPEAKER_1:  companies and people that will.

01:39:44,994 --> 01:39:51,134
SPEAKER_1:  uh... believe that idea so you really you you like uh... you spend a few days a few weeks with that idea

01:39:51,330 --> 01:39:53,822
SPEAKER_0:  I've been spending two years with that idea.

01:39:54,338 --> 01:39:56,990
SPEAKER_0:  and that idea has manifested into.

01:39:57,570 --> 01:39:57,950
SPEAKER_0:  Um.

01:39:58,306 --> 01:39:59,838
SPEAKER_0:  many pages and pages.

01:40:00,354 --> 01:40:00,702
SPEAKER_0:  of

01:40:01,186 --> 01:40:02,398
SPEAKER_0:  more and more.

01:40:02,882 --> 01:40:03,902
SPEAKER_0:  branches of a tree.

01:40:04,994 --> 01:40:10,654
SPEAKER_0:  But it started with that idea. So if you think about this tree, this logical tree that I built, I would consider it more of a mosaic.

01:40:11,266 --> 01:40:12,350
SPEAKER_0:  and at the...

01:40:12,642 --> 01:40:14,270
SPEAKER_0:  bass or root, however you want to talk about it.

01:40:14,498 --> 01:40:15,262
SPEAKER_0:  is this idea.

01:40:15,618 --> 01:40:17,566
SPEAKER_0:  the incremental cost of energy goes to zero.

01:40:17,826 --> 01:40:19,006
SPEAKER_0:  How does it manifest?

01:40:19,618 --> 01:40:21,566
SPEAKER_0:  And so I talked about one traversal.

01:40:21,858 --> 01:40:24,798
SPEAKER_0:  which is the competition of households versus utilities.

01:40:26,210 --> 01:40:28,414
SPEAKER_0:  but if even some of that comes to pass.

01:40:29,090 --> 01:40:33,182
SPEAKER_0:  we're going to see a bunch of other implications from a regulatory and technology perspective.

01:40:33,570 --> 01:40:35,070
SPEAKER_0:  If some of those come to pass.

01:40:35,458 --> 01:40:37,150
SPEAKER_0:  So I've tried to think.

01:40:37,826 --> 01:40:38,494
SPEAKER_0:  sort of this.

01:40:39,010 --> 01:40:40,798
SPEAKER_0:  you know, six, seven, eight hops.

01:40:41,154 --> 01:40:41,694
SPEAKER_0:  forward.

01:40:42,562 --> 01:40:43,518
SPEAKER_0:  and I have some.

01:40:44,034 --> 01:40:47,806
SPEAKER_0:  like to use a chess analogy, I have a bunch of short lines, which I think can work.

01:40:48,738 --> 01:40:49,118
SPEAKER_0:  Um.

01:40:49,378 --> 01:40:51,774
SPEAKER_0:  and I've started to test those by making investments.

01:40:52,802 --> 01:40:55,390
SPEAKER_0:  tens of millions over here to a hundred millions over there.

01:40:56,098 --> 01:40:57,790
SPEAKER_0:  but it's a distribution based on.

01:40:58,306 --> 01:41:00,990
SPEAKER_0:  how probabilistic I think these outcomes are.

01:41:01,634 --> 01:41:04,414
SPEAKER_0:  and how downside protected I can be and how much I will learn.

01:41:04,674 --> 01:41:05,694
SPEAKER_0:  how many mistakes I can make.

01:41:05,954 --> 01:41:06,494
SPEAKER_0:  you know, et cetera.

01:41:07,650 --> 01:41:09,854
SPEAKER_0:  And then very quickly over the next two years.

01:41:10,114 --> 01:41:13,598
SPEAKER_0:  Some of those things will happen or not happen, and I will rapidly re-underwrite.

01:41:14,850 --> 01:41:16,094
SPEAKER_0:  and I'll rewrite that tree.

01:41:17,154 --> 01:41:19,742
SPEAKER_0:  and then I'll get some more data. I'll make some more investments.

01:41:21,058 --> 01:41:22,398
SPEAKER_0:  and I'll rapidly re-underwrite.

01:41:22,818 --> 01:41:26,590
SPEAKER_0:  So, you know, in order for me to get to this tree, maybe you can ask, how did I get there?

01:41:26,850 --> 01:41:28,350
SPEAKER_0:  It was complete accident.

01:41:29,570 --> 01:41:38,270
SPEAKER_0:  The way that it happened was I have a friend of mine who works at a great organization called Fortress. His name is Drew McKnight, and he called me one day and he said, hey, I'm doing a deal. Will you anchor it? We're going public.

01:41:39,234 --> 01:41:41,118
SPEAKER_0:  and it's a rare earth mining company.

01:41:41,378 --> 01:41:41,950
SPEAKER_0:  And I said...

01:41:42,242 --> 01:41:42,878
SPEAKER_0:  true like if-

01:41:43,970 --> 01:41:49,790
SPEAKER_0:  I'm gonna get tarred and feathered in Silicon Valley for backing a mining company. And he said, talk to the guy and learn.

01:41:51,138 --> 01:41:53,150
SPEAKER_0:  and the guy Jim Lutinsky blew me away.

01:41:53,666 --> 01:41:58,462
SPEAKER_0:  He's like, here's what it means for energy. And here's what it means for the supply chain. And here's what it means for the United States vs. China.

01:42:00,130 --> 01:42:02,750
SPEAKER_0:  But Lex, I did that deal, and then I did seven others.

01:42:03,522 --> 01:42:03,838
SPEAKER_0:  and

01:42:04,226 --> 01:42:05,054
SPEAKER_0:  That deal made money.

01:42:05,378 --> 01:42:06,238
SPEAKER_0:  The seven others.

01:42:06,562 --> 01:42:07,070
SPEAKER_0:  Did I?

01:42:08,130 --> 01:42:09,086
SPEAKER_0:  But I learned.

01:42:09,474 --> 01:42:10,654
SPEAKER_0:  I made enough mistakes.

01:42:10,914 --> 01:42:11,742
SPEAKER_0:  or the net of it.

01:42:11,970 --> 01:42:12,414
SPEAKER_0:  was

01:42:12,642 --> 01:42:14,846
SPEAKER_0:  I got to a thesis that I believed in, I could see it.

01:42:15,650 --> 01:42:16,478
SPEAKER_0:  And I was like, okay.

01:42:17,378 --> 01:42:21,022
SPEAKER_0:  I paid the price, I acquired the learning, I made my mistakes, I know where I am at.

01:42:21,506 --> 01:42:23,038
SPEAKER_0:  And this is step one.

01:42:24,034 --> 01:42:29,022
SPEAKER_0:  and then I learned a little bit more, I made some more investments. And that's how I do the job.

01:42:29,570 --> 01:42:30,622
SPEAKER_0:  The minute that you...

01:42:31,202 --> 01:42:33,598
SPEAKER_0:  to wait for perfection in order to make a bet.

01:42:33,858 --> 01:42:34,718
SPEAKER_0:  either on yourself.

01:42:34,978 --> 01:42:35,774
SPEAKER_0:  or a company.

01:42:36,994 --> 01:42:38,782
SPEAKER_0:  a girlfriend, whatever, it's too late.

01:42:39,394 --> 01:42:40,798
SPEAKER_1:  So if we just linger on that...

01:42:41,090 --> 01:42:41,662
SPEAKER_1:  tree.

01:42:42,754 --> 01:42:47,614
SPEAKER_1:  It seems like a lot of geopolitics, a lot of international military even conflict.

01:42:48,066 --> 01:42:49,214
SPEAKER_1:  is around energy.

01:42:49,634 --> 01:42:50,590
SPEAKER_1:  So how?

01:42:51,138 --> 01:42:53,118
SPEAKER_1:  as you're thinking about energy.

01:42:53,410 --> 01:42:56,702
SPEAKER_1:  connect to what you see happening in the next 10, 20 years.

01:42:57,090 --> 01:42:59,614
SPEAKER_1:  Maybe you can look at the war in Ukraine.

01:43:00,418 --> 01:43:05,406
SPEAKER_1:  or relationship with China and other places through this lens of energy.

01:43:05,986 --> 01:43:08,350
SPEAKER_1:  What was the hopeful? What was the cynical?

01:43:08,930 --> 01:43:14,558
SPEAKER_1:  trajectory that the world might take with this drive towards zero energy, zero cost energy.

01:43:14,914 --> 01:43:17,886
SPEAKER_0:  So the United States was in a period of energy surplus.

01:43:18,146 --> 01:43:19,774
SPEAKER_0:  until the last few years.

01:43:20,066 --> 01:43:24,382
SPEAKER_0:  some number of years in Trump and I think some number of now the current administration with President Biden.

01:43:24,994 --> 01:43:25,374
SPEAKER_0:  Um.

01:43:26,242 --> 01:43:27,870
SPEAKER_0:  But we know what it means.

01:43:28,514 --> 01:43:28,926
SPEAKER_0:  Um.

01:43:29,538 --> 01:43:31,230
SPEAKER_0:  to basically have more than enough energy.

01:43:31,906 --> 01:43:33,566
SPEAKER_0:  to fund our own domestic.

01:43:34,018 --> 01:43:36,062
SPEAKER_0:  manufacturing and living standards.

01:43:37,698 --> 01:43:40,798
SPEAKER_0:  And I think that by being able to generate this energy from the sun...

01:43:41,058 --> 01:43:42,430
SPEAKER_0:  that is very capex efficient.

01:43:43,074 --> 01:43:44,926
SPEAKER_0:  that is very climate efficient.

01:43:45,410 --> 01:43:45,790
SPEAKER_0:  Um.

01:43:46,082 --> 01:43:47,486
SPEAKER_0:  gives us a huge tailwind.

01:43:48,738 --> 01:43:49,534
SPEAKER_0:  The second thing.

01:43:49,858 --> 01:43:51,774
SPEAKER_0:  is that we are now in a world.

01:43:52,034 --> 01:43:52,894
SPEAKER_0:  in a regime.

01:43:53,346 --> 01:43:55,550
SPEAKER_0:  for many years to come of non-zero interest rates.

01:43:56,450 --> 01:43:58,462
SPEAKER_0:  and it may interest you to know.

01:43:59,554 --> 01:44:01,374
SPEAKER_0:  the really the last time.

01:44:02,274 --> 01:44:04,062
SPEAKER_0:  that we had.

01:44:04,514 --> 01:44:06,942
SPEAKER_0:  Long dated wars supported?

01:44:07,522 --> 01:44:13,054
SPEAKER_0:  You know, at low interest rates was World War II, where I think the average interest rates was like 1.07% in the 10 year.

01:44:14,658 --> 01:44:18,110
SPEAKER_0:  And every other war tends to have these very quick open and closes.

01:44:18,658 --> 01:44:20,606
SPEAKER_0:  because these long protracted...

01:44:20,866 --> 01:44:22,942
SPEAKER_0:  fights get very difficult to finance.

01:44:23,298 --> 01:44:24,510
SPEAKER_0:  when rates are non-zero.

01:44:25,570 --> 01:44:31,902
SPEAKER_0:  So just as an example, even starting in 2023, so the practical example today in the United States is President Biden's budget.

01:44:32,418 --> 01:44:33,950
SPEAKER_0:  is about 1.5 trillion.

01:44:34,562 --> 01:44:35,614
SPEAKER_0:  for next year. That's

01:44:36,354 --> 01:44:40,542
SPEAKER_0:  not including the entitlement spending, okay? Meaning Medicare, Social Security, right?

01:44:40,834 --> 01:44:46,782
SPEAKER_0:  So the stuff that he wants to spend that he has discretion over is about 1.582 trillion is the exact number.

01:44:48,546 --> 01:44:56,158
SPEAKER_0:  Next year, our interest payments are going to be $455 billion. That's 29% of every budget dollar is going to pay interest.

01:44:57,442 --> 01:44:59,678
SPEAKER_0:  So you have these two worlds coming together.

01:44:59,970 --> 01:45:00,478
SPEAKER_0:  Right, Lex?

01:45:01,154 --> 01:45:02,142
SPEAKER_0:  If you have us.

01:45:03,426 --> 01:45:03,774
SPEAKER_0:  You know.

01:45:04,162 --> 01:45:05,278
SPEAKER_0:  hurtling forward.

01:45:05,986 --> 01:45:08,350
SPEAKER_0:  to being able to generate our own energy and...

01:45:08,930 --> 01:45:11,870
SPEAKER_0:  the economic peril that comes with trying to underwrite.

01:45:12,418 --> 01:45:14,174
SPEAKER_0:  several trillion dollars for war

01:45:14,626 --> 01:45:17,470
SPEAKER_0:  which we can't afford to pay when rates are at 5%.

01:45:17,858 --> 01:45:19,870
SPEAKER_0:  means that despite all the bluster

01:45:20,738 --> 01:45:25,310
SPEAKER_0:  probabilistic distribution of us engaging in war with Russia and Ukraine?

01:45:25,570 --> 01:45:27,038
SPEAKER_0:  seems relatively low.

01:45:28,130 --> 01:45:28,606
SPEAKER_0:  The.

01:45:29,346 --> 01:45:32,190
SPEAKER_0:  The override would obviously be a moral...

01:45:33,890 --> 01:45:34,846
SPEAKER_0:  reason to do it.

01:45:35,458 --> 01:45:38,878
SPEAKER_0:  that may or may not come if there's some nuclear proliferation.

01:45:39,586 --> 01:45:40,990
SPEAKER_0:  Now you have to steal, man.

01:45:41,602 --> 01:45:44,574
SPEAKER_0:  the other side of the equation, which is, well, what were to happen?

01:45:45,090 --> 01:45:49,630
SPEAKER_0:  If you were sitting there and you were Putin, let's deal man setting off a tactical nuke someplace.

01:45:51,298 --> 01:45:51,710
SPEAKER_0:  Okay.

01:45:52,066 --> 01:45:57,438
SPEAKER_0:  I'm getting calls every other day from my two largest energy buyers, India and China.

01:45:57,890 --> 01:45:59,486
SPEAKER_0:  telling me slow my roll.

01:46:01,154 --> 01:46:02,686
SPEAKER_0:  I had the entire world.

01:46:03,170 --> 01:46:05,726
SPEAKER_0:  looking to find the final excuse.

01:46:06,338 --> 01:46:09,374
SPEAKER_0:  to turn me off and unplug me from the entire world economy.

01:46:11,010 --> 01:46:14,430
SPEAKER_0:  the only morally reprehensible thing that's left in my arsenal.

01:46:14,882 --> 01:46:17,822
SPEAKER_0:  that could do all of these things together would be to set off attack nuke.

01:46:18,530 --> 01:46:19,806
SPEAKER_0:  I would be the only person.

01:46:20,066 --> 01:46:21,694
SPEAKER_0:  since World War II to have done that.

01:46:24,258 --> 01:46:24,926
SPEAKER_0:  I mean, you know.

01:46:25,154 --> 01:46:27,838
SPEAKER_0:  It seems like it's a really, really, really...

01:46:28,994 --> 01:46:29,662
SPEAKER_0:  big step.

01:46:30,050 --> 01:46:30,558
SPEAKER_0:  to take.

01:46:31,394 --> 01:46:32,030
SPEAKER_0:  And so.

01:46:32,418 --> 01:46:33,278
SPEAKER_0:  I think that—

01:46:34,210 --> 01:46:36,094
SPEAKER_0:  X of the clamoring for war.

01:46:36,578 --> 01:46:39,358
SPEAKER_0:  that the military industrial complex wants us to buy into.

01:46:40,418 --> 01:46:45,406
SPEAKER_0:  the financial reasons to do it, and the natural resources needs to do it.

01:46:46,274 --> 01:46:48,382
SPEAKER_0:  are making it very unlikely.

01:46:49,474 --> 01:46:50,782
SPEAKER_0:  And that is not just true for us.

01:46:51,938 --> 01:46:56,414
SPEAKER_0:  I think it's also true for Europe. I think the European economy is going to roll over.

01:46:58,114 --> 01:47:01,022
SPEAKER_0:  I think it's going, I see a very hard landing for them.

01:47:01,602 --> 01:47:05,406
SPEAKER_0:  which means that if the economy slows down, there's going to be less need for energy.

01:47:06,626 --> 01:47:07,166
SPEAKER_0:  And so.

01:47:07,394 --> 01:47:13,182
SPEAKER_0:  it starts to become a thing where a negotiated settlement is actually the win-win for everybody.

01:47:14,498 --> 01:47:16,126
SPEAKER_0:  but none of this would be possible.

01:47:16,578 --> 01:47:18,046
SPEAKER_0:  without zero interest rates.

01:47:18,530 --> 01:47:20,702
SPEAKER_0:  In a world of zero interest rates, we would be in.

01:47:23,106 --> 01:47:24,414
SPEAKER_1:  So you believe in the...

01:47:24,802 --> 01:47:28,382
SPEAKER_1:  financial forces and pressures overpowering.

01:47:28,642 --> 01:47:29,767
SPEAKER_1:  I believe in you.

01:47:29,767 --> 01:47:30,366
SPEAKER_0:

01:47:31,138 --> 01:47:34,366
SPEAKER_1:  I really do believe in the- Even in international war.

01:47:35,074 --> 01:47:35,902
SPEAKER_0:  more so there.

01:47:36,130 --> 01:47:37,598
SPEAKER_0:  I think the invisible hand.

01:47:37,986 --> 01:47:40,798
SPEAKER_0:  And by the invisible hand for the audience, I think really what it means is

01:47:41,282 --> 01:47:45,918
SPEAKER_0:  you know, the financial complex and really the central bank complex and

01:47:46,306 --> 01:47:48,670
SPEAKER_0:  the interplay between fiscal and monetary policy.

01:47:49,346 --> 01:47:50,430
SPEAKER_0:  is a very...

01:47:50,658 --> 01:47:52,094
SPEAKER_0:  convoluted and complicated.

01:47:52,610 --> 01:47:53,470
SPEAKER_0:  set of things.

01:47:54,850 --> 01:47:57,022
SPEAKER_0:  But if we had zero interest rates...

01:47:58,274 --> 01:47:59,166
SPEAKER_0:  we would be.

01:47:59,874 --> 01:48:01,022
SPEAKER_0:  Probably in the middle of it now.

01:48:01,890 --> 01:48:05,566
SPEAKER_1:  See, there's a complexity to this game at the international.

01:48:06,338 --> 01:48:07,006
SPEAKER_1:  level.

01:48:07,362 --> 01:48:11,262
SPEAKER_1:  where some nations are authoritarian and are.

01:48:11,586 --> 01:48:12,990
SPEAKER_1:  a significant cut.

01:48:13,602 --> 01:48:14,174
SPEAKER_1:  corruption.

01:48:15,202 --> 01:48:15,742
SPEAKER_1:  And so that.

01:48:16,162 --> 01:48:19,582
SPEAKER_1:  ads from a game theoretic optimal perspective.

01:48:20,226 --> 01:48:21,886
SPEAKER_1:  you know, the invisible hand.

01:48:22,114 --> 01:48:23,998
SPEAKER_1:  is operating in the mud.

01:48:24,770 --> 01:48:25,886
SPEAKER_0:  preventing war.

01:48:27,106 --> 01:48:33,214
SPEAKER_0:  The person that is the most important figure in the world right now is Jerome Powell. He is probably doing more to prevent war than anybody else.

01:48:34,306 --> 01:48:38,974
SPEAKER_0:  keeps ratcheting rates, it's just impossible. It's a mathematical impossibility for the United States.

01:48:39,490 --> 01:48:42,782
SPEAKER_0:  unless there is such a cataclysmic moral transgression by Russia.

01:48:43,202 --> 01:48:44,990
SPEAKER_0:  So there is tail risk that it is possible.

01:48:45,826 --> 01:48:46,366
SPEAKER_0:  where we say.

01:48:46,658 --> 01:48:47,966
SPEAKER_0:  Forget it, all bets are off.

01:48:48,290 --> 01:48:49,534
SPEAKER_0:  We're going back to zero rates.

01:48:49,794 --> 01:48:52,382
SPEAKER_0:  issue a 100 year bond, we're going to finance a war machine.

01:48:53,218 --> 01:48:54,334
SPEAKER_0:  There is a small risk of that.

01:48:54,978 --> 01:48:58,622
SPEAKER_0:  But I think the propensity of the majority of outcomes is more of a negotiated settle.

01:48:59,362 --> 01:49:04,318
SPEAKER_1:  So what about, I mean, if you, what's the motivation of Putin to invade Ukraine in the first place?

01:49:04,770 --> 01:49:05,502
SPEAKER_1:  D lässt uns lágrimosently por todos los presentes en lafficientudb KIM Quickly embraced all those who passed 3% when dreamt first to achieve ten million in January 2019,Put to school這樣子 Without יודע que ahora mismo Internet revealed Tonight God finish Every minute essential because all been Our elegant

01:49:06,434 --> 01:49:07,838
SPEAKER_1:  Forces are the most

01:49:08,994 --> 01:49:09,470
SPEAKER_1:  Um.

01:49:10,018 --> 01:49:11,390
SPEAKER_1:  the most powerful forces.

01:49:12,706 --> 01:49:13,726
SPEAKER_1:  Why did it happen?

01:49:14,850 --> 01:49:17,854
SPEAKER_1:  because it seems like there's other forces at play of...

01:49:18,882 --> 01:49:22,398
SPEAKER_1:  maintaining super power status on the world stage.

01:49:23,170 --> 01:49:23,518
SPEAKER_1:  I'll see you in the next one.

01:49:23,938 --> 01:49:26,398
SPEAKER_1:  It seems like geopolitics doesn't happen just.

01:49:27,266 --> 01:49:28,414
SPEAKER_1:  with the invisible hand.

01:49:28,834 --> 01:49:29,758
SPEAKER_1:  in consideration.

01:49:29,922 --> 01:49:32,862
SPEAKER_0:  I agree with that. I can't beg to know, to be honest. I don't know.

01:49:33,250 --> 01:49:33,726
SPEAKER_0:  Um.

01:49:35,106 --> 01:49:35,710
SPEAKER_0:  But he did it.

01:49:37,282 --> 01:49:39,358
SPEAKER_0:  and I think it's easier for me.

01:49:40,130 --> 01:49:41,470
SPEAKER_0:  to guess the outcome from here.

01:49:41,826 --> 01:49:44,446
SPEAKER_0:  It would have been impossible for me to really understand. It is.

01:49:45,250 --> 01:49:46,558
SPEAKER_0:  What got him to this place?

01:49:47,394 --> 01:49:50,878
SPEAKER_0:  but it seems like there's an end game here and there's...

01:49:51,490 --> 01:49:51,902
SPEAKER_0:  Um...

01:49:52,194 --> 01:49:53,598
SPEAKER_0:  There's not much playability.

01:49:54,562 --> 01:49:54,974
SPEAKER_1:  Yeah.

01:49:55,330 --> 01:49:59,326
SPEAKER_1:  I feel like I'm on unsteady ground because there's been so many experts.

01:49:59,810 --> 01:50:01,982
SPEAKER_1:  at every stage of this that have been wrong.

01:50:02,530 --> 01:50:03,486
SPEAKER_0:  Well, there are no experts.

01:50:03,938 --> 01:50:04,702
SPEAKER_0:  on this.

01:50:07,618 --> 01:50:08,894
SPEAKER_1:  There are no experts, Lex.

01:50:09,346 --> 01:50:15,198
SPEAKER_1:  I understand this. Well, let's dig into that. Because there's some, because we just said Phil Hellmuth is the, um,

01:50:15,650 --> 01:50:16,775
SPEAKER_1:  is the greatest vocal player.

01:50:16,775 --> 01:50:18,110
SPEAKER_0:  of all time. Was the the

01:50:19,330 --> 01:50:21,950
SPEAKER_0:  He doesn't, he's, they would be mistaken.

01:50:22,466 --> 01:50:22,942
SPEAKER_0:  epoque.

01:50:23,426 --> 01:50:26,782
SPEAKER_0:  Phil has an opinion, Ivy has an opinion as well on how to play all these games.

01:50:27,490 --> 01:50:30,878
SPEAKER_0:  Meaning an opinion means here's the lines I take, here are the decisions I make.

01:50:31,586 --> 01:50:34,270
SPEAKER_0:  I live and die by those and if I'm right I win if I'm wrong.

01:50:34,690 --> 01:50:35,166
SPEAKER_0:  I lose.

01:50:35,842 --> 01:50:37,438
SPEAKER_0:  I've made more mistakes than my opponent.

01:50:38,818 --> 01:50:40,286
SPEAKER_1:  I thought you said there's an optimal.

01:50:41,314 --> 01:50:44,350
SPEAKER_1:  So aren't there people that have a deeper understanding?

01:50:45,442 --> 01:50:49,118
SPEAKER_1:  higher likelihood of being able to describe and know the optimal.

01:50:49,410 --> 01:50:50,846
SPEAKER_1:  the optimal set of actions here.

01:50:51,234 --> 01:50:52,446
SPEAKER_1:  at every layer.

01:50:53,794 --> 01:50:55,678
SPEAKER_0:  There theoretically.

01:50:55,938 --> 01:50:57,182
SPEAKER_0:  set of optimal decisions.

01:50:57,698 --> 01:50:59,294
SPEAKER_0:  but you can't play your life.

01:50:59,874 --> 01:51:00,318
SPEAKER_0:  Um...

01:51:01,922 --> 01:51:05,374
SPEAKER_0:  against a computer, like, meaning, the minute that you face an opponent,

01:51:05,858 --> 01:51:08,958
SPEAKER_0:  and that person takes you off that optimal path, you have to adjust.

01:51:10,466 --> 01:51:13,182
SPEAKER_1:  Like what happens if a tactical nuke.

01:51:14,274 --> 01:51:15,102
SPEAKER_0:  It would be really bad.

01:51:15,522 --> 01:51:16,126
SPEAKER_0:  Um...

01:51:17,506 --> 01:51:19,326
SPEAKER_0:  I think the world is resilient enough.

01:51:19,554 --> 01:51:21,790
SPEAKER_0:  I think the Ukrainians are resilient enough to overcome it.

01:51:22,306 --> 01:51:26,238
SPEAKER_0:  It would be really bad. It's just an incredibly sad moment in human history.

01:51:26,402 --> 01:51:28,606
SPEAKER_1:  But do you wonder what US does?

01:51:29,346 --> 01:51:32,382
SPEAKER_1:  Is there any understanding? Do you think people inside the United States?

01:51:33,890 --> 01:51:37,374
SPEAKER_1:  understand. Not the regular citizens, but people in the military.

01:51:37,890 --> 01:51:39,765
SPEAKER_1:  Do you think Joe Biden understands? Do you think?

01:51:39,765 --> 01:51:42,014
SPEAKER_0:  I think Joe Biden does understand. I think that.

01:51:42,722 --> 01:51:43,710
SPEAKER_0:  Do you think they have a clear plan?

01:51:44,162 --> 01:51:45,310
SPEAKER_0:  I think that there are...

01:51:46,786 --> 01:51:47,902
SPEAKER_0:  reasons to let

01:51:48,162 --> 01:51:52,990
SPEAKER_0:  gerontocracy rule, but this is one of the reasons why I think they are better adept than other people.

01:51:53,858 --> 01:51:57,054
SPEAKER_0:  you know, folks that were around during the Bay of Pigs.

01:51:57,378 --> 01:51:59,198
SPEAKER_0:  folks that hopefully have studied that.

01:51:59,682 --> 01:52:00,446
SPEAKER_0:  and study.

01:52:00,674 --> 01:52:02,526
SPEAKER_0:  you know, nuclear de-escalation.

01:52:03,234 --> 01:52:04,926
SPEAKER_0:  will have a better playbook than I do.

01:52:05,442 --> 01:52:06,494
SPEAKER_0:  My suspicion.

01:52:07,746 --> 01:52:08,318
SPEAKER_0:  is that...

01:52:09,314 --> 01:52:12,574
SPEAKER_0:  there is a, you know, in an emergency break glass plan.

01:52:13,186 --> 01:52:16,926
SPEAKER_0:  And I think before military intervention or anything else.

01:52:17,730 --> 01:52:20,990
SPEAKER_0:  I think that there are an enormous number of.

01:52:21,698 --> 01:52:23,614
SPEAKER_0:  financial sanctions.

01:52:24,258 --> 01:52:26,846
SPEAKER_0:  that you can do to just completely cripple.

01:52:27,714 --> 01:52:29,918
SPEAKER_0:  Russia that they haven't undertaken yet.

01:52:30,818 --> 01:52:31,294
SPEAKER_0:  Um...

01:52:31,810 --> 01:52:36,734
SPEAKER_0:  And if you couple that with an economic system in Europe that is less and less in need of energy,

01:52:37,570 --> 01:52:37,950
SPEAKER_0:  because

01:52:38,530 --> 01:52:39,998
SPEAKER_0:  it is going into a recession.

01:52:40,610 --> 01:52:41,982
SPEAKER_0:  It makes it easier.

01:52:42,370 --> 01:52:43,934
SPEAKER_0:  for them to be able to walk away.

01:52:44,322 --> 01:52:47,774
SPEAKER_0:  while the US ships a bunch of LNG over there.

01:52:48,610 --> 01:52:51,235
SPEAKER_0:  I don't know the game theory on all of this, but... Does it make-

01:52:51,235 --> 01:52:52,062
SPEAKER_1:  you nervous?

01:52:52,770 --> 01:52:53,822
SPEAKER_1:  That uh...

01:52:54,242 --> 01:52:55,038
SPEAKER_1:  or we just.

01:52:55,650 --> 01:52:56,606
SPEAKER_1:  being temperamental.

01:52:57,282 --> 01:52:59,678
SPEAKER_1:  It feels like the world hangs in a balance.

01:52:59,938 --> 01:53:01,342
SPEAKER_1:  Like, it feels like...

01:53:02,498 --> 01:53:03,774
SPEAKER_1:  at least for my...

01:53:04,354 --> 01:53:05,598
SPEAKER_1:  naive perspective.

01:53:06,818 --> 01:53:07,710
SPEAKER_1:  I thought...

01:53:08,450 --> 01:53:12,446
SPEAKER_1:  we were getting to a place where surely human civilization can't destroy itself.

01:53:12,866 --> 01:53:15,486
SPEAKER_1:  And here's a presentation of what looks like a hot war.

01:53:15,874 --> 01:53:20,606
SPEAKER_1:  where multiple parties are involved in escalating escalation towards a world war.

01:53:20,898 --> 01:53:23,742
SPEAKER_1:  is not entirely out of the realm of possibility. It's not.

01:53:24,386 --> 01:53:24,990
SPEAKER_0:  Bye.

01:53:25,698 --> 01:53:26,846
SPEAKER_0:  would really, really hope.

01:53:29,122 --> 01:53:29,630
SPEAKER_0:  He.

01:53:30,434 --> 01:53:32,734
SPEAKER_0:  is spending time with his two young twins.

01:53:35,490 --> 01:53:36,030
SPEAKER_1:  This is

01:53:36,898 --> 01:53:37,214
SPEAKER_1:  part.

01:53:37,794 --> 01:53:40,318
SPEAKER_0:  I really hope you're spending time with this kid.

01:53:42,530 --> 01:53:44,062
SPEAKER_1:  Agreed, but not kids.

01:53:44,290 --> 01:53:45,662
SPEAKER_1:  not just kids but friends and

01:53:45,954 --> 01:53:47,079
SPEAKER_1:

01:53:47,079 --> 01:53:48,958
SPEAKER_0:  sure that he may not have friends but.

01:53:50,274 --> 01:53:52,414
SPEAKER_0:  It's very hard for anybody to look at their kids and not.

01:53:52,706 --> 01:53:53,694
SPEAKER_0:  Think about protecting.

01:53:53,954 --> 01:53:54,462
SPEAKER_1:  the future.

01:53:57,474 --> 01:53:58,590
SPEAKER_1:  Well, there's a...

01:53:59,010 --> 01:54:00,606
SPEAKER_1:  partially because of the pandemic.

01:54:01,026 --> 01:54:02,910
SPEAKER_1:  but partially because of the nature of power.

01:54:03,682 --> 01:54:06,590
SPEAKER_1:  It feels like you're surrounded by people you can't trust more and more.

01:54:07,010 --> 01:54:13,566
SPEAKER_1:  I do think the pandemic had an effect on that too, the isolating effect. A lot of people were not their best selves.

01:54:13,826 --> 01:54:14,686
SPEAKER_1:  during the pandemic.

01:54:15,362 --> 01:54:17,662
SPEAKER_1:  from a super heavy topic. Let me go back to.

01:54:18,690 --> 01:54:21,406
SPEAKER_1:  the space where you're one of the most successful people in the world.

01:54:23,394 --> 01:54:24,606
SPEAKER_1:  how to build companies.

01:54:24,834 --> 01:54:26,974
SPEAKER_1:  how to find good companies, what it takes.

01:54:28,482 --> 01:54:33,566
SPEAKER_1:  to find good companies, what it takes to build good companies, what advice do you have for someone who wants to build the next?

01:54:34,146 --> 01:54:36,638
SPEAKER_1:  super successful startup in the tech space.

01:54:37,122 --> 01:54:40,574
SPEAKER_1:  and have a chance to be impactful like Facebook, Apple.

01:54:41,314 --> 01:54:43,262
SPEAKER_0:  That's, I think that's the keyword. If.

01:54:43,906 --> 01:54:47,358
SPEAKER_0:  your precondition is to start something successful you've already failed.

01:54:48,098 --> 01:54:51,422
SPEAKER_0:  you're now you're playing somebody else's game. What success means is not clear.

01:54:52,034 --> 01:54:53,470
SPEAKER_0:  You're walking into the woods.

01:54:54,306 --> 01:54:58,462
SPEAKER_0:  It's murky, it's dark, it's wet, it's raining. There's all these animals about.

01:54:59,202 --> 01:54:59,614
SPEAKER_0:  Um...

01:55:00,578 --> 01:55:01,598
SPEAKER_0:  There's no comfort there.

01:55:02,178 --> 01:55:03,806
SPEAKER_0:  So you better really like hiking.

01:55:05,186 --> 01:55:05,694
SPEAKER_0:  and

01:55:06,562 --> 01:55:07,902
SPEAKER_0:  There's no short way to.

01:55:08,514 --> 01:55:09,086
SPEAKER_0:  shortcut that

01:55:09,634 --> 01:55:10,014
SPEAKER_1:  So.

01:55:10,818 --> 01:55:13,310
SPEAKER_1:  Isn't it obvious what success is? SYNX like success

01:55:13,730 --> 01:55:15,518
SPEAKER_1:  It's scale, so it's not what it is.

01:55:16,098 --> 01:55:16,478
SPEAKER_0:  No.

01:55:17,154 --> 01:55:18,718
SPEAKER_0:  I think that there's a very brittle.

01:55:19,010 --> 01:55:21,630
SPEAKER_0:  basic definition of success that's outside in.

01:55:22,530 --> 01:55:23,038
SPEAKER_0:  Um...

01:55:24,674 --> 01:55:26,750
SPEAKER_0:  But it's not, that's not what it is.

01:55:27,330 --> 01:55:27,710
SPEAKER_0:  Um...

01:55:28,514 --> 01:55:29,150
SPEAKER_0:  You know, he...

01:55:29,378 --> 01:55:32,542
SPEAKER_0:  I know people that are much, much, much richer than I am.

01:55:33,794 --> 01:55:34,142
SPEAKER_0:  You know?

01:55:35,234 --> 01:55:37,246
SPEAKER_0:  and they are just so completely.

01:55:37,474 --> 01:55:37,822
SPEAKER_0:  broken.

01:55:39,202 --> 01:55:40,670
SPEAKER_0:  And I think to myself...

01:55:41,506 --> 01:55:43,390
SPEAKER_0:  the only difference between you and me.

01:55:44,098 --> 01:55:46,942
SPEAKER_0:  is outsiders perception of your wealth versus mine.

01:55:48,130 --> 01:55:48,670
SPEAKER_0:  Put the.

01:55:49,570 --> 01:55:53,406
SPEAKER_0:  the happiness and the joy that I have in the simple basic routines of my life.

01:55:54,242 --> 01:55:55,550
SPEAKER_0:  me enormous joy.

01:55:56,866 --> 01:55:57,534
SPEAKER_0:  And so...

01:55:59,010 --> 01:55:59,902
SPEAKER_0:  I feel successful.

01:56:00,482 --> 01:56:03,518
SPEAKER_0:  no matter what anybody says about my success or lack of success.

01:56:04,482 --> 01:56:04,926
SPEAKER_0:  Um.

01:56:05,378 --> 01:56:06,174
SPEAKER_0:  There are people.

01:56:06,978 --> 01:56:11,294
SPEAKER_0:  that live normal lives, that have good jobs, that have good families.

01:56:11,746 --> 01:56:13,854
SPEAKER_0:  I've had this like, idyllic sense like...

01:56:14,786 --> 01:56:17,374
SPEAKER_0:  I see it on TikTok all the time so I know it exists.

01:56:17,954 --> 01:56:23,390
SPEAKER_0:  these neighborhoods where there's like a cul-de-sac and these beautiful homes and these kids are biking around

01:56:24,258 --> 01:56:27,422
SPEAKER_0:  And every time I see that Lex, I immediately flashback.

01:56:27,810 --> 01:56:28,190
SPEAKER_0:  to.

01:56:28,770 --> 01:56:29,726
SPEAKER_0:  what I didn't have?

01:56:30,338 --> 01:56:31,902
SPEAKER_0:  And I think that's success.

01:56:32,450 --> 01:56:33,822
SPEAKER_0:  Look at how happy those kids are.

01:56:34,498 --> 01:56:39,582
SPEAKER_0:  So no, there is no one definition. And so if people are starting out to try to make.

01:56:40,162 --> 01:56:43,102
SPEAKER_0:  million dollars, 100 million dollars, a billion dollars, you're going to fail.

01:56:44,418 --> 01:56:44,862
SPEAKER_1:  There's a

01:56:45,282 --> 01:56:49,662
SPEAKER_1:  Definition of personal success, but is there's also some level of, um,

01:56:50,690 --> 01:56:54,462
SPEAKER_1:  that's different from person to person, but there's also some level of...

01:56:55,906 --> 01:56:56,702
SPEAKER_1:

01:56:57,314 --> 01:57:01,118
SPEAKER_1:  responsibility you have if there's a mission to have a positive impact on the world.

01:57:01,506 --> 01:57:01,886
SPEAKER_1:  So.

01:57:02,306 --> 01:57:04,158
SPEAKER_1:  I'm not sure that Elon is happy.

01:57:05,346 --> 01:57:09,918
SPEAKER_0:  In fact, I think if you focus on trying to have an impact on the world, I think you're going to end up deeply unhappy.

01:57:10,594 --> 01:57:11,550
SPEAKER_0:  But does that matter?

01:57:12,386 --> 01:57:16,478
SPEAKER_0:  Like why is your own personal happiness matter? It may happen as a byproduct of your own happiness.

01:57:17,538 --> 01:57:21,822
SPEAKER_0:  but I think that you should strive to find your own personal happiness and then measure

01:57:22,530 --> 01:57:23,742
SPEAKER_0:  how that manifests.

01:57:24,162 --> 01:57:26,398
SPEAKER_0:  as it relates to society and to other people.

01:57:27,266 --> 01:57:29,566
SPEAKER_0:  If the answer to those questions is zero.

01:57:30,018 --> 01:57:31,710
SPEAKER_0:  that doesn't make you less of a person.

01:57:32,418 --> 01:57:34,174
SPEAKER_1:  100%, but then the other way.

01:57:34,434 --> 01:57:37,630
SPEAKER_1:  Is there times when you need to sacrifice your own personal happiness?

01:57:38,786 --> 01:57:39,358
SPEAKER_1:  force.

01:57:39,714 --> 01:57:41,589
SPEAKER_1:  for a bigger thing that you've created.

01:57:41,589 --> 01:57:44,158
SPEAKER_0:  Yeah, if you're if you're in a position to do it

01:57:44,834 --> 01:57:47,998
SPEAKER_0:  I think some folks are tested. Elon is probably the best example.

01:57:48,578 --> 01:57:49,118
SPEAKER_0:  and

01:57:50,242 --> 01:57:51,326
SPEAKER_0:  It must be...

01:57:52,578 --> 01:57:54,142
SPEAKER_0:  really, really hard to be him.

01:57:55,234 --> 01:57:55,774
SPEAKER_0:  Um...

01:57:56,354 --> 01:57:57,470
SPEAKER_0:  really hard. I have.

01:57:58,978 --> 01:57:59,806
SPEAKER_0:  enormous

01:58:00,546 --> 01:58:01,374
SPEAKER_0:  levels of

01:58:01,954 --> 01:58:03,198
SPEAKER_0:  empathy and care.

01:58:03,746 --> 01:58:04,094
SPEAKER_0:  for him.

01:58:04,514 --> 01:58:05,918
SPEAKER_0:  I really love him as a person.

01:58:06,370 --> 01:58:07,326
SPEAKER_0:  because I just see.

01:58:07,554 --> 01:58:09,278
SPEAKER_0:  that it's not that fun.

01:58:10,530 --> 01:58:12,350
SPEAKER_0:  and he has these ways of

01:58:13,602 --> 01:58:14,494
SPEAKER_0:  being human.

01:58:15,074 --> 01:58:17,630
SPEAKER_0:  that in his position I just think are so dear.

01:58:18,306 --> 01:58:19,198
SPEAKER_0:  that if he never

01:58:19,426 --> 01:58:22,238
SPEAKER_0:  I just hope he never loses them. Just a simple example, like.

01:58:22,658 --> 01:58:23,486
SPEAKER_0:  two days ago.

01:58:24,354 --> 01:58:25,150
SPEAKER_0:  I don't know why, but...

01:58:25,570 --> 01:58:28,862
SPEAKER_0:  I went on Twitter and I saw the perfume thing. So I'm like...

01:58:29,154 --> 01:58:30,974
SPEAKER_0:  Ah, fuck it, I'm just gonna go buy some perfume.

01:58:31,682 --> 01:58:33,598
SPEAKER_0:  So I bought his perfume, the burnt hair thing. Hey, I love this hair.

01:58:34,338 --> 01:58:34,782
SPEAKER_0:  And I said.

01:58:35,202 --> 01:58:37,726
SPEAKER_0:  And I emailed him the receipt and I'm like, all right, you got me for a bottle.

01:58:38,466 --> 01:58:42,654
SPEAKER_0:  And he responded in like eight seconds and it was just a smiley face or whatever.

01:58:43,330 --> 01:58:46,686
SPEAKER_0:  just deeply normal things that you do amongst people that are just

01:58:47,010 --> 01:58:47,326
SPEAKER_0:  So.

01:58:47,714 --> 01:58:48,702
SPEAKER_0:  Nobody sees that.

01:58:49,634 --> 01:58:51,294
SPEAKER_0:  You know what I mean? But it would be-

01:58:52,258 --> 01:58:55,838
SPEAKER_0:  He deserves for that stuff to be seen because the rest of his life is so brutally hard.

01:58:56,930 --> 01:59:00,126
SPEAKER_0:  He's just a normal guy that is just caught in this

01:59:00,770 --> 01:59:02,366
SPEAKER_0:  Ultra mega vortex.

01:59:04,130 --> 01:59:06,590
SPEAKER_1:  Why do you think there's so few eLons?

01:59:07,906 --> 01:59:08,478
SPEAKER_1:  The next.

01:59:08,706 --> 01:59:09,534
SPEAKER_0:  extremely.

01:59:10,178 --> 01:59:11,582
SPEAKER_0:  lonely set of trade-offs.

01:59:12,994 --> 01:59:13,790
SPEAKER_0:  because to your point.

01:59:14,018 --> 01:59:15,294
SPEAKER_0:  if you get tested.

01:59:16,354 --> 01:59:20,414
SPEAKER_0:  So if you think about it again probabilistically, there's 8 billion people in the world.

01:59:20,930 --> 01:59:22,046
SPEAKER_0:  Maybe 50 of them.

01:59:22,434 --> 01:59:26,654
SPEAKER_0:  get put in a position where they are building something of such colossal importance.

01:59:27,074 --> 01:59:28,446
SPEAKER_0:  that they even have this choice.

01:59:29,282 --> 01:59:30,846
SPEAKER_0:  And then of that 50.

01:59:31,426 --> 01:59:35,422
SPEAKER_0:  Maybe 10 of them are put in a moment where they actually have to make a trade-off.

01:59:36,386 --> 01:59:36,702
SPEAKER_0:  You know.

01:59:36,962 --> 01:59:44,254
SPEAKER_0:  You're not gonna be able to see your fam. I'm making this up. You're not gonna be able to see your family. You're gonna have to basically move into your factory. You're gonna have to sleep on the floor.

01:59:44,738 --> 01:59:45,950
SPEAKER_0:  But here's the outcome.

01:59:46,242 --> 01:59:49,310
SPEAKER_0:  energy independence and you know resource abundance and

01:59:49,602 --> 01:59:50,974
SPEAKER_0:  piece of a massive.

01:59:51,266 --> 01:59:52,062
SPEAKER_0:  He's dividend.

01:59:53,794 --> 01:59:56,958
SPEAKER_0:  And then he says to himself, I don't know that he did, because I've never had this come.

01:59:57,314 --> 01:59:58,526
SPEAKER_0:  Yeah, you know what, that's worth it.

01:59:59,874 --> 02:00:01,854
SPEAKER_0:  And then you look at your kids and you're like.

02:00:03,266 --> 02:00:05,406
SPEAKER_0:  I'm making this decision. I don't know how to explain that to you.

02:00:06,114 --> 02:00:07,838
SPEAKER_0:  Yeah. You want to be in that position?

02:00:08,130 --> 02:00:11,006
SPEAKER_0:  There's no, there's no amount of money where I would want to be in that position. So-

02:00:11,362 --> 02:00:14,206
SPEAKER_0:  That takes an enormous fortitude and a moral compass.

02:00:14,850 --> 02:00:17,086
SPEAKER_0:  that he has and that's what I think people need to.

02:00:17,538 --> 02:00:18,782
SPEAKER_0:  Need to appreciate about that guy.

02:00:19,266 --> 02:00:23,166
SPEAKER_1:  It's also on the first number you said, it's confusing that there's 50 people.

02:00:23,714 --> 02:00:24,542
SPEAKER_1:  or 10 people.

02:00:25,186 --> 02:00:28,542
SPEAKER_1:  like that are put in the position to have that level of impact.

02:00:28,962 --> 02:00:31,614
SPEAKER_1:  It's unclear that that has to be that way. It seems like.

02:00:32,098 --> 02:00:33,150
SPEAKER_1:  there could be much more.

02:00:33,922 --> 02:00:36,126
SPEAKER_0:  There should be, there's definitely people with the potential.

02:00:37,090 --> 02:00:37,470
SPEAKER_0:  Um.

02:00:38,242 --> 02:00:39,038
SPEAKER_0:  You know, think about...

02:00:39,298 --> 02:00:40,542
SPEAKER_0:  Think about his journey, you know?

02:00:41,058 --> 02:00:41,694
SPEAKER_0:  His mom.

02:00:41,922 --> 02:00:45,374
SPEAKER_0:  had to leave a very complicated environment, moved to Canada, moved to Toronto.

02:00:45,730 --> 02:00:47,102
SPEAKER_0:  you know, a small apartment.

02:00:47,586 --> 02:00:51,102
SPEAKER_0:  Just north of Bay and Bloor, you know, if you've ever been to Toronto.

02:00:51,522 --> 02:00:56,126
SPEAKER_0:  I remember talking to her about this apartment. It's so crazy because I used to live like around the corner from that place.

02:00:56,642 --> 02:00:58,526
SPEAKER_0:  and raise these three kids and just have to.

02:00:59,010 --> 02:00:59,358
SPEAKER_0:  So.

02:01:00,450 --> 02:01:03,422
SPEAKER_0:  how many people are going to start with those boundary conditions?

02:01:04,802 --> 02:01:06,590
SPEAKER_0:  you know, and really grind it out.

02:01:07,778 --> 02:01:09,726
SPEAKER_0:  It's just very few people in the end that.

02:01:10,370 --> 02:01:10,910
SPEAKER_0:  Um...

02:01:11,266 --> 02:01:13,662
SPEAKER_0:  will have the resiliency to stick it through.

02:01:14,178 --> 02:01:14,590
SPEAKER_0:  where.

02:01:15,138 --> 02:01:16,702
SPEAKER_0:  you don't give in to the self-doubt.

02:01:18,178 --> 02:01:19,230
SPEAKER_0:  And so it...

02:01:19,554 --> 02:01:20,606
SPEAKER_0:  You know, it's a really.

02:01:21,058 --> 02:01:27,006
SPEAKER_0:  It's just a really hard set of boundary conditions where you can have 50 or 100 of these people. That's why they needed to be really, they need to be really-

02:01:27,650 --> 02:01:28,158
SPEAKER_0:  appreciated.

02:01:28,962 --> 02:01:30,622
SPEAKER_1:  Yeah, well, that's true for her.

02:01:31,778 --> 02:01:33,374
SPEAKER_1:  all humans that...

02:01:35,042 --> 02:01:40,862
SPEAKER_1:  follow the thread of their passion and do something beautiful in this world. It could be on a small scale or a big scale.

02:01:41,186 --> 02:01:42,878
SPEAKER_1:  appreciation is a

02:01:43,938 --> 02:01:49,054
SPEAKER_1:  That's a gift you give to the other person, but also a gift to yourself. That somehow becomes like this.

02:01:49,218 --> 02:01:53,246
SPEAKER_0:  contagious thing. I went to this, you are so right. You just like it.

02:01:53,698 --> 02:01:54,910
SPEAKER_0:  My brain just lit up because

02:01:55,490 --> 02:01:56,734
SPEAKER_0:  Yesterday I went to...

02:01:57,122 --> 02:01:58,718
SPEAKER_0:  an investor day of my friend of mine.

02:01:59,170 --> 02:01:59,614
SPEAKER_0:  Um...

02:02:00,354 --> 02:02:01,566
SPEAKER_0:  describe Brad Kirstner.

02:02:01,986 --> 02:02:02,718
SPEAKER_0:  and you know.

02:02:02,946 --> 02:02:03,710
SPEAKER_0:  On the one...

02:02:04,130 --> 02:02:05,374
SPEAKER_0:  very reductive world.

02:02:05,890 --> 02:02:07,774
SPEAKER_0:  Brad and I are theoretically competitors.

02:02:08,386 --> 02:02:08,862
SPEAKER_0:  But we're not.

02:02:09,282 --> 02:02:12,446
SPEAKER_0:  He makes his own set of decisions. I make my own set of decisions.

02:02:12,770 --> 02:02:15,646
SPEAKER_0:  We're both trying to do our own view of what is good work in the world.

02:02:16,610 --> 02:02:18,526
SPEAKER_0:  but he's been profoundly successful.

02:02:19,106 --> 02:02:19,582
SPEAKER_0:  and

02:02:20,226 --> 02:02:22,238
SPEAKER_0:  It was really the first moment of my.

02:02:23,362 --> 02:02:25,566
SPEAKER_0:  adult life where I could sit in a moment like that.

02:02:26,562 --> 02:02:29,598
SPEAKER_0:  and really be appreciative of his success so that you give this часть a go as it should.

02:02:30,786 --> 02:02:31,326
SPEAKER_0:  And so.

02:02:31,810 --> 02:02:33,438
SPEAKER_0:  you know, a little selfishly for me, but...

02:02:33,794 --> 02:02:34,750
SPEAKER_0:  Mostly for him as well.

02:02:35,458 --> 02:02:36,734
SPEAKER_0:  I was so proud to be in the room.

02:02:37,122 --> 02:02:37,886
SPEAKER_0:  That's my friend.

02:02:38,146 --> 02:02:42,014
SPEAKER_0:  That guy plays poker with me every Thursday. He is crushing it. That's awesome.

02:02:42,562 --> 02:02:46,142
SPEAKER_0:  You know, and that's the, it's a really amazing feeling.

02:02:48,226 --> 02:02:50,366
SPEAKER_1:  I mean to linger on the...

02:02:50,882 --> 02:02:53,502
SPEAKER_1:  the trade-offs, the complicated trade-offs with all of this.

02:02:54,274 --> 02:02:56,190
SPEAKER_1:  What's your take on work-life balance?

02:02:56,898 --> 02:02:59,902
SPEAKER_1:  in a company that's trying to do.

02:03:01,314 --> 02:03:01,886
SPEAKER_1:  Big things.

02:03:03,810 --> 02:03:05,502
SPEAKER_0:  I think that you have to have.

02:03:06,466 --> 02:03:08,190
SPEAKER_0:  some very very strict

02:03:08,418 --> 02:03:09,278
SPEAKER_0:  boundaries?

02:03:10,562 --> 02:03:12,638
SPEAKER_0:  But otherwise, I think balance is kind of.

02:03:14,690 --> 02:03:15,710
SPEAKER_0:  It will make you limited.

02:03:17,026 --> 02:03:18,846
SPEAKER_0:  I think you need to immerse yourself in the problem.

02:03:19,650 --> 02:03:21,790
SPEAKER_0:  but you need to define that immersion with boundaries.

02:03:22,466 --> 02:03:26,398
SPEAKER_0:  So if you ask me, what does my process look like?

02:03:27,458 --> 02:03:30,270
SPEAKER_0:  It's monotonous and regimented, but it's...

02:03:30,754 --> 02:03:31,838
SPEAKER_0:  all the time.

02:03:32,066 --> 02:03:36,126
SPEAKER_0:  except when it's not and that's also monotonous and regimented.

02:03:37,026 --> 02:03:37,502
SPEAKER_0:  Um...

02:03:38,594 --> 02:03:41,310
SPEAKER_0:  And I think that makes me very good at my craft.

02:03:42,338 --> 02:03:44,318
SPEAKER_0:  because it gives me what I need.

02:03:45,346 --> 02:03:49,854
SPEAKER_0:  to stay connected to the problem without feeling resentful about the problem.

02:03:50,498 --> 02:03:54,174
SPEAKER_1:  which part the monotonous all in nature.

02:03:54,498 --> 02:03:54,942
SPEAKER_1:  of it.

02:03:55,362 --> 02:03:58,462
SPEAKER_1:  or the, the, when you say hard boundaries, essentially.

02:04:00,162 --> 02:04:02,302
SPEAKER_1:  go all out until you stop.

02:04:02,690 --> 02:04:04,254
SPEAKER_1:  And you don't stop often.

02:04:04,514 --> 02:04:06,494
SPEAKER_0:  I'm in a little bit of a quandary right now.

02:04:07,266 --> 02:04:09,918
SPEAKER_0:  because I'm trying to redefine my goals.

02:04:11,106 --> 02:04:12,830
SPEAKER_0:  And you're catching me in a moment where.

02:04:14,018 --> 02:04:15,742
SPEAKER_0:  I have even in these last.

02:04:16,578 --> 02:04:17,854
SPEAKER_0:  years of evolution.

02:04:18,562 --> 02:04:20,094
SPEAKER_0:  I think I've made some good progress.

02:04:20,802 --> 02:04:22,750
SPEAKER_0:  but in one very specific way.

02:04:23,202 --> 02:04:24,766
SPEAKER_0:  I'm still very reptilian.

02:04:25,986 --> 02:04:27,230
SPEAKER_0:  and I'm trying to let go.

02:04:27,458 --> 02:04:28,606
SPEAKER_0:  Which way is that exactly?

02:04:29,026 --> 02:04:30,654
SPEAKER_0:  If you can, my business

02:04:30,978 --> 02:04:34,654
SPEAKER_0:  it really gets reduced to what is your annual rate of compounding.

02:04:34,978 --> 02:04:36,542
SPEAKER_0:  That's my demarcation, you know?

02:04:37,122 --> 02:04:41,374
SPEAKER_0:  Steph Curry and LeBron James, Michael Jordan, it's how many points did you average?

02:04:41,698 --> 02:04:42,750
SPEAKER_0:  not just in a season.

02:04:43,682 --> 02:04:44,670
SPEAKER_0:  over your career.

02:04:45,538 --> 02:04:48,318
SPEAKER_0:  you know, and in their case to really be the greatest of all time.

02:04:49,474 --> 02:04:51,262
SPEAKER_0:  It's points, rebounds, assists.

02:04:51,522 --> 02:04:52,126
SPEAKER_0:  steals.

02:04:52,642 --> 02:04:54,238
SPEAKER_0:  There's all kinds of measures.

02:04:55,074 --> 02:04:59,358
SPEAKER_0:  to be in that pantheon of being really, really good at your craft.

02:05:00,834 --> 02:05:01,278
SPEAKER_0:  Um...

02:05:01,538 --> 02:05:04,286
SPEAKER_0:  And in my business, it's very reductive.

02:05:04,514 --> 02:05:05,662
SPEAKER_0:  How well have you compounded?

02:05:06,530 --> 02:05:08,670
SPEAKER_0:  And if you look at all the heroes...

02:05:09,218 --> 02:05:10,398
SPEAKER_0:  that I have.

02:05:11,042 --> 02:05:12,574
SPEAKER_0:  put on a pedestal in my mind.

02:05:14,082 --> 02:05:14,494
SPEAKER_0:  Um...

02:05:15,842 --> 02:05:18,206
SPEAKER_0:  they've compounded, you know, at above.

02:05:18,594 --> 02:05:20,670
SPEAKER_0:  30% for a very long time.

02:05:22,338 --> 02:05:22,974
SPEAKER_0:  As have I.

02:05:24,450 --> 02:05:25,118
SPEAKER_0:  But now...

02:05:25,666 --> 02:05:28,158
SPEAKER_0:  I feel like I really need to let go because...

02:05:28,642 --> 02:05:31,102
SPEAKER_0:  I think I know how to do the basics of my job.

02:05:32,866 --> 02:05:39,582
SPEAKER_0:  And if I had to summarize like an investing challenge or investing, I think really it's, when you first start out investing.

02:05:40,034 --> 02:05:44,350
SPEAKER_0:  You're a momentum person. You saw it in GameStop. Just a bunch of people aping each other.

02:05:45,890 --> 02:05:47,454
SPEAKER_0:  and then it goes from momentum.

02:05:48,194 --> 02:05:48,638
SPEAKER_0:  to.

02:05:48,994 --> 02:05:53,694
SPEAKER_0:  you start to think about cash flows, how much profit is this person gonna make, whatever. So that's like the-

02:05:54,114 --> 02:05:55,838
SPEAKER_0:  evolution, you know, this is the.

02:05:56,194 --> 02:05:57,182
SPEAKER_0:  This is the basic.

02:05:57,698 --> 02:05:58,078
SPEAKER_0:  Bing.

02:05:58,402 --> 02:06:00,542
SPEAKER_0:  to this is a reasonably sophisticated way.

02:06:01,314 --> 02:06:05,214
SPEAKER_0:  then a much smaller group of people think about it in terms of macro geopolitics.

02:06:06,434 --> 02:06:11,038
SPEAKER_0:  but then a very finite few crack this special code, which is there's a philosophy.

02:06:11,554 --> 02:06:13,662
SPEAKER_0:  and it's the philosophy that creates the system.

02:06:15,522 --> 02:06:17,246
SPEAKER_0:  And I'm scratching at that.

02:06:17,538 --> 02:06:22,334
SPEAKER_0:  furiously, but I cannot break through and I haven't broken through. And I know that in order to break through

02:06:22,754 --> 02:06:23,422
SPEAKER_0:  I got a leg though.

02:06:24,290 --> 02:06:28,030
SPEAKER_0:  So this is the journey that I'm in in my professional life.

02:06:28,866 --> 02:06:29,246
SPEAKER_0:  So.

02:06:29,762 --> 02:06:31,198
SPEAKER_0:  It is an all consuming thing.

02:06:32,386 --> 02:06:33,438
SPEAKER_0:  I'm always home for dinner.

02:06:34,146 --> 02:06:36,894
SPEAKER_0:  You know, we have very prescribed moments where we take vacation.

02:06:37,378 --> 02:06:41,503
SPEAKER_0:  the weekends. I can tell you about my week if you're curious, but it's like I would like to join

02:06:41,503 --> 02:06:45,310
SPEAKER_1:  I would love to know your weak it's since its regiment in a matata and

02:06:45,666 --> 02:06:46,791
SPEAKER_1:  uh...

02:06:46,791 --> 02:06:49,534
SPEAKER_0:  monotonous. I woke up, I wake up at 6 45.

02:06:50,690 --> 02:06:51,102
SPEAKER_0:  Um...

02:06:53,058 --> 02:06:53,854
SPEAKER_0:  Get the kids.

02:06:54,306 --> 02:06:55,134
SPEAKER_0:  Go downstairs.

02:06:55,778 --> 02:06:57,022
SPEAKER_0:  We all have some form of.

02:06:57,410 --> 02:07:01,022
SPEAKER_0:  you know, not super healthy breakfast. I make a latte, I've become.

02:07:01,378 --> 02:07:03,230
SPEAKER_0:  And the latte is like...

02:07:03,618 --> 02:07:04,542
SPEAKER_0:  I have a machine.

02:07:04,994 --> 02:07:06,142
SPEAKER_0:  I measure the beans.

02:07:06,402 --> 02:07:10,942
SPEAKER_0:  I make sure that the timer is such where I have to pull it for a certain specific ratio.

02:07:11,906 --> 02:07:15,742
SPEAKER_0:  just so you know, 20 grams, I gotta pull 30 grams with the water and I gotta do it.

02:07:16,354 --> 02:07:17,438
SPEAKER_0:  30 seconds, et cetera.

02:07:17,538 --> 02:07:19,070
SPEAKER_1:  So you're a coffee snob.

02:07:19,362 --> 02:07:20,638
SPEAKER_0:  It helps me stay in rhythm.

02:07:22,050 --> 02:07:24,766
SPEAKER_0:  Before I used to have another machine, I just pushed a button.

02:07:25,858 --> 02:07:28,606
SPEAKER_0:  but then I would push the button religiously the exact same way.

02:07:28,866 --> 02:07:29,598
SPEAKER_0:  You know what I mean?

02:07:30,082 --> 02:07:31,934
SPEAKER_1:  Can I say actually, an a...

02:07:32,226 --> 02:07:33,214
SPEAKER_1:  on that topic.

02:07:33,986 --> 02:07:37,374
SPEAKER_1:  You know, the morning with kids can be pretty stressful.

02:07:37,954 --> 02:07:38,302
SPEAKER_1:  thing.

02:07:38,850 --> 02:07:44,606
SPEAKER_1:  Are you able to find sort of happiness? Is that also that morning is a source of happiness? It's great.

02:07:45,602 --> 02:07:46,462
SPEAKER_0:  My kids are lovely.

02:07:47,170 --> 02:07:48,478
SPEAKER_0:  They're maniacs.

02:07:49,186 --> 02:07:49,598
SPEAKER_0:  Um.

02:07:51,842 --> 02:07:52,830
SPEAKER_0:  I just see.

02:07:53,922 --> 02:07:56,670
SPEAKER_0:  know, and maybe I don't, I've never asked for your breakfast, but I'll just.

02:07:56,994 --> 02:07:57,566
SPEAKER_0:  of my words.

02:07:58,082 --> 02:08:00,670
SPEAKER_0:  I see all of the things in moments.

02:08:01,730 --> 02:08:02,270
SPEAKER_0:  where...

02:08:04,194 --> 02:08:05,918
SPEAKER_0:  There was no compassion given to me.

02:08:06,434 --> 02:08:07,198
SPEAKER_0:  And so I just.

02:08:07,906 --> 02:08:08,670
SPEAKER_0:  I'm Kevin Matanof.

02:08:09,154 --> 02:08:12,030
SPEAKER_0:  love and compassion. I have an infinite patience for my children.

02:08:12,482 --> 02:08:18,334
SPEAKER_0:  Not for other kids. Yes, of course. Not for other kids. So anyway, so we have a breakfast thing.

02:08:19,042 --> 02:08:19,422
SPEAKER_0:  Um.

02:08:20,770 --> 02:08:21,886
SPEAKER_0:  and then I go upstairs.

02:08:22,786 --> 02:08:23,166
SPEAKER_0:  Um.

02:08:23,554 --> 02:08:23,998
SPEAKER_0:  and I.

02:08:24,290 --> 02:08:26,654
SPEAKER_0:  I change and I work out from eight to nine.

02:08:27,490 --> 02:08:29,406
SPEAKER_0:  And that's like the first 15 minutes.

02:08:29,890 --> 02:08:31,486
SPEAKER_0:  I walk up on a steep incline.

02:08:31,778 --> 02:08:32,222
SPEAKER_0:  You know?

02:08:32,578 --> 02:08:33,086
SPEAKER_0:  Uh...

02:08:33,762 --> 02:08:34,974
SPEAKER_0:  12 to 14%.

02:08:35,458 --> 02:08:37,374
SPEAKER_0:  you know, three and a half to four miles per hour.

02:08:40,098 --> 02:08:42,206
SPEAKER_0:  And then, you know, Monday's a push day.

02:08:42,754 --> 02:08:43,422
SPEAKER_0:  Tuesdays.

02:08:44,130 --> 02:08:44,830
SPEAKER_0:  front of the legs.

02:08:45,378 --> 02:08:47,006
SPEAKER_0:  Wednesday's poll, Thursday's.

02:08:47,426 --> 02:08:48,094
SPEAKER_0:  Back of the legs.

02:08:48,578 --> 02:08:49,086
SPEAKER_0:  Um...

02:08:49,698 --> 02:08:50,366
SPEAKER_0:  8 to 9.

02:08:51,234 --> 02:08:55,742
SPEAKER_0:  Monday I always start, I talk to my therapist from 9 to 10, so as soon as I finish working out

02:08:55,970 --> 02:08:56,638
SPEAKER_0:  I get on the phone.

02:08:57,218 --> 02:08:57,758
SPEAKER_0:  I talked to.

02:08:58,754 --> 02:08:59,262
SPEAKER_0:  and

02:08:59,682 --> 02:09:01,694
SPEAKER_0:  It helps me lock in for the...

02:09:02,498 --> 02:09:02,974
SPEAKER_0:  the week.

02:09:03,938 --> 02:09:06,622
SPEAKER_0:  and I'm just talking about the past.

02:09:07,842 --> 02:09:09,278
SPEAKER_0:  And it's just helping me.

02:09:09,762 --> 02:09:11,294
SPEAKER_0:  The recent past? Eventually I come to the final location

02:09:11,586 --> 02:09:14,846
SPEAKER_0:  sometimes the recent past but usually it's about the past past.

02:09:15,778 --> 02:09:17,502
SPEAKER_0:  something that I remember when I was a kid.

02:09:18,946 --> 02:09:21,790
SPEAKER_0:  because that's the work about just loosening those knots.

02:09:22,178 --> 02:09:22,526
SPEAKER_0:  You know?

02:09:23,138 --> 02:09:24,638
SPEAKER_0:  So I put in that hour of work.

02:09:25,538 --> 02:09:26,942
SPEAKER_0:  Respect that hour.

02:09:28,354 --> 02:09:31,262
SPEAKER_0:  then I'm in the office. And then it's like, you know, I go until.

02:09:32,162 --> 02:09:33,662
SPEAKER_0:  12 15 12 30.

02:09:34,722 --> 02:09:35,198
SPEAKER_0:  Go home.

02:09:36,098 --> 02:09:36,638
SPEAKER_0:  Have lunch.

02:09:37,346 --> 02:09:40,062
SPEAKER_0:  like a proper like go home, sit down, have lunch with Nat.

02:09:40,738 --> 02:09:41,630
SPEAKER_0:  She leaves her work.

02:09:42,626 --> 02:09:44,830
SPEAKER_0:  and we talk, how we doing, you know, just check in.

02:09:45,346 --> 02:09:47,230
SPEAKER_0:  Our youngest daughter will be there because she's one.

02:09:48,002 --> 02:09:49,150
SPEAKER_0:  and she's making a mess.

02:09:50,818 --> 02:09:52,478
SPEAKER_0:  and then I'll have another coffee.

02:09:53,186 --> 02:09:55,061
SPEAKER_0:  That's it, my limit for the day.

02:09:55,061 --> 02:09:55,811
SPEAKER_1:  Well, no more gaffing.

02:09:55,811 --> 02:09:56,254
SPEAKER_0:  That's it.

02:09:56,706 --> 02:09:57,726
SPEAKER_0:  And then, uh...

02:09:58,466 --> 02:10:01,502
SPEAKER_0:  I go back to the office and I'll be there until 6, 7 sometimes.

02:10:02,498 --> 02:10:04,382
SPEAKER_0:  And I do that Monday, Tuesday, Wednesday, Thursday.

02:10:05,026 --> 02:10:07,582
SPEAKER_0:  Monday, Tuesday, Thursday, Friday, allowed to have meetings?

02:10:08,130 --> 02:10:10,366
SPEAKER_0:  Wednesday, nothing, it's all reading.

02:10:11,010 --> 02:10:11,518
SPEAKER_0:  Must be.

02:10:11,906 --> 02:10:14,078
SPEAKER_0:  unless it's a complete emergency, it has to be.

02:10:14,754 --> 02:10:18,142
SPEAKER_0:  Kind of a full reading and reading is a bunch of blogs

02:10:18,850 --> 02:10:20,254
SPEAKER_0:  YouTube videos.

02:10:20,674 --> 02:10:22,654
SPEAKER_1:  So no, try not to do any talking.

02:10:23,106 --> 02:10:25,950
SPEAKER_0:  No talking. It's like being in silence, being present.

02:10:26,274 --> 02:10:27,399
SPEAKER_0:  thinking about things.

02:10:27,399 --> 02:10:29,694
SPEAKER_1:  By the way, how do you take notes? Do you have a s-

02:10:29,922 --> 02:10:32,510
SPEAKER_0:  I have a pad and I write stuff down.

02:10:32,834 --> 02:10:34,174
SPEAKER_0:  Sometimes I go to my phone.

02:10:34,498 --> 02:10:36,030
SPEAKER_0:  I'm a little all over the place.

02:10:36,514 --> 02:10:37,950
SPEAKER_0:  Sometimes I do Google Docs.

02:10:38,338 --> 02:10:41,342
SPEAKER_0:  I don't have it. This is one thing I need to get better at actually.

02:10:42,018 --> 02:10:43,390
SPEAKER_0:  But typically what happens is...

02:10:43,938 --> 02:10:46,078
SPEAKER_0:  I actually do a lot of thinking in my mind.

02:10:46,626 --> 02:10:46,942
SPEAKER_0:  and I'm.

02:10:47,234 --> 02:10:49,086
SPEAKER_0:  sort of filing a lot of stuff away.

02:10:49,858 --> 02:10:52,190
SPEAKER_0:  and then it all spills out and then I have to write.

02:10:53,186 --> 02:10:58,110
SPEAKER_0:  And then that gives me a body of work that I can evaluate and think about. And then I usually put it away.

02:10:59,234 --> 02:10:59,646
SPEAKER_0:  Um...

02:11:00,034 --> 02:11:01,470
SPEAKER_0:  and a lot of the time it goes nowhere.

02:11:02,050 --> 02:11:06,046
SPEAKER_0:  But every now and then I come back to it and it just unlocks two or three things and I have a sense of...

02:11:06,402 --> 02:11:07,390
SPEAKER_0:  how else I'm thinking about things.

02:11:08,194 --> 02:11:11,966
SPEAKER_0:  And then Friday at the end of the day, Nat and I talked to a couple of therapists.

02:11:12,834 --> 02:11:15,070
SPEAKER_0:  And that's about checking out properly.

02:11:16,354 --> 02:11:17,214
SPEAKER_0:  So it's like, okay.

02:11:18,178 --> 02:11:19,358
SPEAKER_0:  Now it's like focusing.

02:11:19,618 --> 02:11:20,414
SPEAKER_0:  weekend is.

02:11:20,866 --> 02:11:21,310
SPEAKER_0:  Family.

02:11:22,402 --> 02:11:23,134
SPEAKER_0:  being present.

02:11:23,426 --> 02:11:24,158
SPEAKER_0:  being aware.

02:11:24,610 --> 02:11:25,022
SPEAKER_0:  You know?

02:11:25,538 --> 02:11:27,326
SPEAKER_0:  and if there's email, obviously.

02:11:27,746 --> 02:11:30,398
SPEAKER_0:  if I have to do meetings from time to time, no problem.

02:11:31,042 --> 02:11:31,390
SPEAKER_0:  Um.

02:11:31,746 --> 02:11:32,606
SPEAKER_0:  but there's boundaries.

02:11:32,738 --> 02:11:34,014
SPEAKER_1:  Checking out properly.

02:11:35,138 --> 02:11:38,750
SPEAKER_1:  Oh man, that is so powerful. Just like, yeah.

02:11:38,978 --> 02:11:40,382
SPEAKER_1:  officially transitioning.

02:11:41,858 --> 02:11:44,126
SPEAKER_0:  So these are really important.

02:11:45,218 --> 02:11:46,014
SPEAKER_0:  boundaries.

02:11:46,498 --> 02:11:47,742
SPEAKER_0:  so that I can be immersed.

02:11:48,194 --> 02:11:52,318
SPEAKER_0:  And what that means is like, look, on a Saturday afternoon, you know, on a random day,

02:11:52,962 --> 02:11:55,710
SPEAKER_0:  She'll be like, where's your mouth? And I'll be up in my room.

02:11:56,194 --> 02:11:57,758
SPEAKER_0:  and I've found a podcast.

02:11:58,274 --> 02:11:59,582
SPEAKER_0:  talking about like.

02:12:00,034 --> 02:12:05,950
SPEAKER_0:  Desis, which is like ductile cancer in situ because I've been fascinated about breast cancer surgeries for a while

02:12:06,530 --> 02:12:07,614
SPEAKER_0:  learning about that.

02:12:08,194 --> 02:12:11,870
SPEAKER_0:  And she's like, what are you doing? I'm like, I'm listening to podcasts about Desus.

02:12:12,546 --> 02:12:13,566
SPEAKER_0:  And she's like, what's that?

02:12:13,826 --> 02:12:15,486
SPEAKER_0:  you know, ductile cancer in situ.

02:12:16,290 --> 02:12:16,958
SPEAKER_0:  She's like, okay.

02:12:17,826 --> 02:12:21,662
SPEAKER_0:  And so, you know, so I have time to continue to just constantly.

02:12:21,922 --> 02:12:24,606
SPEAKER_0:  Learning learning putting stuff in my memory banks

02:12:25,122 --> 02:12:28,510
SPEAKER_0:  to organize into something. And that's like a, that's a week.

02:12:29,314 --> 02:12:29,950
SPEAKER_0:  But then.

02:12:30,274 --> 02:12:31,710
SPEAKER_0:  in these fixed moments of time.

02:12:32,610 --> 02:12:35,134
SPEAKER_0:  phone down, everything down, we go on vacation, you know.

02:12:35,874 --> 02:12:39,326
SPEAKER_0:  We go on a boat, we go to whatever, where it's just us and the kids.

02:12:40,098 --> 02:12:41,886
SPEAKER_1:  Is there a structure when you're at work?

02:12:42,338 --> 02:12:46,142
SPEAKER_1:  Is there a structure to your day in terms of meetings, in terms of South Side of Wednesday?

02:12:46,818 --> 02:12:47,943
SPEAKER_1:  You know, because you're...

02:12:47,943 --> 02:12:49,950
SPEAKER_0:  You have to keep meetings to less than 30 minutes.

02:12:51,170 --> 02:12:51,614
SPEAKER_0:  have to.

02:12:52,386 --> 02:12:57,054
SPEAKER_0:  And oftentimes meetings can be as short as like 10 or 15 minutes because then I'm just like, okay.

02:12:57,794 --> 02:13:00,062
SPEAKER_0:  because I'm trying to reinforce.

02:13:00,738 --> 02:13:01,086
SPEAKER_0:  that

02:13:01,346 --> 02:13:03,262
SPEAKER_0:  It's very rare that we all have something.

02:13:03,522 --> 02:13:04,734
SPEAKER_0:  really important to say.

02:13:05,634 --> 02:13:06,206
SPEAKER_0:  And so.

02:13:06,594 --> 02:13:10,334
SPEAKER_0:  ritual that becomes really valuable to get scale.

02:13:11,074 --> 02:13:15,710
SPEAKER_0:  is not the ritual of meetings, but the ritual of respecting the collective time of the unit.

02:13:17,442 --> 02:13:22,206
SPEAKER_0:  And so it's like, you know what, folks? I'm gonna assume that you guys are also tackling really important projects.

02:13:22,722 --> 02:13:27,550
SPEAKER_0:  You also want to have good boundaries in this immersion. Go back to your kids and have dinner with them every night.

02:13:28,130 --> 02:13:31,422
SPEAKER_0:  It's not just for me, it's for you. So how about this? Why don't you go and do your work?

02:13:31,682 --> 02:13:34,270
SPEAKER_0:  This painting didn't need to be 30 minutes, it could be five.

02:13:34,850 --> 02:13:36,638
SPEAKER_0:  and the rest of the time is yours.

02:13:36,994 --> 02:13:40,606
SPEAKER_0:  And it's weird because when people join that system and they join that social capital, they just cannot do it.

02:13:42,434 --> 02:13:45,790
SPEAKER_0:  like FaceTime and it's like, let me make sure and let me talk a lot.

02:13:46,434 --> 02:13:47,486
SPEAKER_0:  I can't say anything.

02:13:48,002 --> 02:13:52,030
SPEAKER_0:  I respect the person that says nothing for two years and the first thing that they say is non-obvious.

02:13:52,578 --> 02:13:55,102
SPEAKER_0:  That person is immensely more valuable than the person that tries to talk.

02:13:56,578 --> 02:14:02,558
SPEAKER_1:  What have you learned from your, so after Facebook you started Social Capital or what is now called Social Capital?

02:14:03,010 --> 02:14:04,414
SPEAKER_1:  What have you learned from?

02:14:05,026 --> 02:14:07,230
SPEAKER_1:  all the successful investing you've done.

02:14:09,186 --> 02:14:11,454
SPEAKER_1:  about investing or about life.

02:14:11,778 --> 02:14:12,903
SPEAKER_1:  Yeah. Are Baharani-

02:14:12,903 --> 02:14:13,598
SPEAKER_0:  a team.

02:14:14,114 --> 02:14:18,206
SPEAKER_0:  I'm very loathe to give advice because I think so much of it is situational, but

02:14:18,850 --> 02:14:21,822
SPEAKER_0:  My observation is that starting a business is really hard.

02:14:22,082 --> 02:14:23,070
SPEAKER_0:  Any kind of business?

02:14:23,810 --> 02:14:26,270
SPEAKER_0:  and most people don't know what they're doing.

02:14:27,106 --> 02:14:28,702
SPEAKER_0:  And as a result, we make.

02:14:29,250 --> 02:14:30,398
SPEAKER_0:  enormous mistakes.

02:14:31,106 --> 02:14:34,782
SPEAKER_0:  But I would summarize this, and this may be a little heterodoxical.

02:14:35,010 --> 02:14:36,574
SPEAKER_0:  I think there are only three kinds of mistakes.

02:14:36,834 --> 02:14:39,518
SPEAKER_0:  Because if we go back to what we said before, in the business...

02:14:40,130 --> 02:14:41,022
SPEAKER_0:  It's just learning.

02:14:41,730 --> 02:14:45,086
SPEAKER_0:  You're exploring the dark space to get to the answer faster than other people.

02:14:46,146 --> 02:14:46,878
SPEAKER_0:  And those...

02:14:47,106 --> 02:14:48,926
SPEAKER_0:  The mistakes that you make are three.

02:14:50,626 --> 02:14:52,446
SPEAKER_0:  or the three kinds of decisions, let's say.

02:14:53,218 --> 02:14:54,430
SPEAKER_0:  You'll hire somebody.

02:14:55,426 --> 02:14:55,966
SPEAKER_0:  and

02:14:57,602 --> 02:15:00,094
SPEAKER_0:  They're really, really, really average.

02:15:00,610 --> 02:15:01,886
SPEAKER_0:  but they're a really good person.

02:15:02,882 --> 02:15:03,230
SPEAKER_0:  Oh yeah.

02:15:04,226 --> 02:15:05,470
SPEAKER_0:  You'll hire somebody.

02:15:06,850 --> 02:15:09,726
SPEAKER_0:  and they really weren't candid with who they are.

02:15:10,370 --> 02:15:15,006
SPEAKER_0:  and their real personality and their morality and their ethics only expose them.

02:15:15,842 --> 02:15:17,182
SPEAKER_0:  over a long period of time.

02:15:18,786 --> 02:15:20,190
SPEAKER_0:  and then you hire somebody.

02:15:21,442 --> 02:15:21,886
SPEAKER_0:  and

02:15:22,114 --> 02:15:22,526
SPEAKER_0:  Uh...

02:15:23,042 --> 02:15:24,414
SPEAKER_0:  They're not that good.

02:15:25,890 --> 02:15:26,942
SPEAKER_0:  morally.

02:15:27,202 --> 02:15:28,478
SPEAKER_0:  but they're highly performant.

02:15:30,306 --> 02:15:31,742
SPEAKER_0:  What do you do with those three things?

02:15:33,410 --> 02:15:35,134
SPEAKER_0:  and I think successful companies.

02:15:36,002 --> 02:15:37,150
SPEAKER_0:  have figured out.

02:15:37,698 --> 02:15:38,686
SPEAKER_0:  how to answer.

02:15:39,234 --> 02:15:42,206
SPEAKER_0:  those three things because those are the things.

02:15:43,362 --> 02:15:45,987
SPEAKER_0:  that in my opinion determine success and failure.

02:15:45,987 --> 02:15:48,734
SPEAKER_1:  So basically hiring and you just identified.

02:15:49,154 --> 02:15:51,029
SPEAKER_1:  three failure cases for hiring.

02:15:51,029 --> 02:15:55,454
SPEAKER_0:  very different failure cases and very complicated ones, right? Like the highly performant person.

02:15:55,810 --> 02:15:57,150
SPEAKER_0:  who's not that great.

02:15:57,698 --> 02:15:58,718
SPEAKER_0:  as a human being.

02:15:59,426 --> 02:16:00,414
SPEAKER_0:  Do you keep them around?

02:16:00,802 --> 02:16:03,518
SPEAKER_0:  Well, a lot of people would err towards keeping that person around.

02:16:03,778 --> 02:16:06,590
SPEAKER_0:  What is the right answer? I don't know, it's the context of the situation.

02:16:07,778 --> 02:16:08,190
SPEAKER_0:  Um.

02:16:08,706 --> 02:16:10,366
SPEAKER_0:  And the second one is also very tricky.

02:16:11,074 --> 02:16:15,678
SPEAKER_0:  What about if they really turned out that they were just not candid with who they are and it took you a long time to figure out who you were?

02:16:16,226 --> 02:16:19,134
SPEAKER_0:  These are all mistakes of the senior person that's running this organization.

02:16:20,162 --> 02:16:21,342
SPEAKER_0:  I think if you can learn...

02:16:22,338 --> 02:16:24,094
SPEAKER_0:  to manage those situations well?

02:16:25,474 --> 02:16:29,278
SPEAKER_0:  Those are the real edge cases where you can make mistakes that are fatal to a company.

02:16:30,498 --> 02:16:35,902
SPEAKER_0:  That's what I've learned over 11 and a half years. Honestly, otherwise the business of investing.

02:16:37,378 --> 02:16:38,814
SPEAKER_0:  I feel that it's like a...

02:16:39,042 --> 02:16:39,902
SPEAKER_0:  It's a secret.

02:16:40,994 --> 02:16:43,742
SPEAKER_0:  And if you are willing to just keep chipping away...

02:16:44,514 --> 02:16:46,302
SPEAKER_0:  You'll peel back enough of these, you know.

02:16:47,138 --> 02:16:51,166
SPEAKER_0:  Layers will come off and you'll see it. The scales will come off and you'll eventually see it.

02:16:51,746 --> 02:16:55,230
SPEAKER_1:  I really struggle with maybe you can be my therapist for a little bit.

02:16:55,714 --> 02:16:58,046
SPEAKER_1:  with that first case which you originally mentioned.

02:16:58,626 --> 02:17:01,022
SPEAKER_1:  Because I love people, I see the good in people.

02:17:01,538 --> 02:17:03,038
SPEAKER_1:  I really struggle with...

02:17:03,458 --> 02:17:04,574
SPEAKER_1:  Just a mediocre.

02:17:04,802 --> 02:17:06,334
SPEAKER_1:  performing person who's

02:17:06,562 --> 02:17:07,646
SPEAKER_1:  who's a good human being.

02:17:08,450 --> 02:17:09,342
SPEAKER_1:  That's a tough one.

02:17:10,562 --> 02:17:11,422
SPEAKER_0:  I'll let you off the hook.

02:17:12,162 --> 02:17:15,038
SPEAKER_0:  I think that those are incredibly important and useful.

02:17:15,618 --> 02:17:15,998
SPEAKER_0:  people.

02:17:16,354 --> 02:17:18,686
SPEAKER_0:  I think that if a company is like a body.

02:17:19,362 --> 02:17:20,510
SPEAKER_0:  They are like cartilage.

02:17:20,738 --> 02:17:22,142
SPEAKER_0:  Can you replace cartilage?

02:17:22,434 --> 02:17:22,750
SPEAKER_0:  Yeah.

02:17:23,426 --> 02:17:24,734
SPEAKER_0:  Would you if you didn't have to?

02:17:25,986 --> 02:17:28,862
SPEAKER_1:  Okay, can I play devil's advocate? Yeah.

02:17:29,218 --> 02:17:30,846
SPEAKER_1:  So those folks...

02:17:31,906 --> 02:17:33,246
SPEAKER_1:  because of their goodness.

02:17:34,242 --> 02:17:35,614
SPEAKER_1:  Make it okay.

02:17:35,970 --> 02:17:36,894
SPEAKER_1:  to be mediocre.

02:17:38,594 --> 02:17:40,510
SPEAKER_1:  They create a culture where

02:17:40,770 --> 02:17:41,150
SPEAKER_1:  Well...

02:17:41,666 --> 02:17:43,486
SPEAKER_1:  we, what's important in life.

02:17:44,066 --> 02:17:46,302
SPEAKER_1:  which is something I agree in my personal life.

02:17:46,690 --> 02:17:51,326
SPEAKER_1:  is to be good to each other, to be friendly, to be good vibes, all that kind of stuff.

02:17:51,682 --> 02:17:52,734
SPEAKER_1:  known as a Google.

02:17:53,154 --> 02:17:57,022
SPEAKER_1:  Just like the good atmosphere, everyone's playing and just, it's fun, fun.

02:17:57,346 --> 02:17:57,790
SPEAKER_1:  Right.

02:17:58,466 --> 02:17:59,006
SPEAKER_1:  Um...

02:18:00,098 --> 02:18:01,086
SPEAKER_1:  to me.

02:18:01,826 --> 02:18:06,110
SPEAKER_1:  Like when I put on my hat of like having a mission and a goal.

02:18:06,786 --> 02:18:07,230
SPEAKER_1:  What?

02:18:07,842 --> 02:18:14,302
SPEAKER_1:  I love to see is the superstars that shine for some in some way, like do something.

02:18:14,530 --> 02:18:15,518
SPEAKER_1:  Incredible.

02:18:15,810 --> 02:18:16,414
SPEAKER_1:  And I want-

02:18:17,282 --> 02:18:18,110
SPEAKER_1:  Everyone.

02:18:18,562 --> 02:18:19,070
SPEAKER_1:  to.

02:18:19,522 --> 02:18:21,630
SPEAKER_1:  also admire that.

02:18:21,986 --> 02:18:24,030
SPEAKER_1:  though supersizing, perhaps not just.

02:18:24,322 --> 02:18:29,086
SPEAKER_1:  for the productivity sake or performing or successful company sake, but because that.

02:18:29,346 --> 02:18:29,886
SPEAKER_1:  to.

02:18:30,594 --> 02:18:33,214
SPEAKER_1:  is an incredible thing that humans are able to accomplish.

02:18:33,442 --> 02:18:34,398
SPEAKER_1:  which is shine.

02:18:34,626 --> 02:18:37,182
SPEAKER_0:  I hear you, but that's not a decision you make, meaning—

02:18:37,602 --> 02:18:40,062
SPEAKER_0:  You get lucky when you have those people in your company.

02:18:40,898 --> 02:18:42,462
SPEAKER_0:  That's not the hard part for you.

02:18:42,818 --> 02:18:46,430
SPEAKER_0:  The hard part is figuring out what to do with one, two, and three.

02:18:46,818 --> 02:18:47,774
SPEAKER_0:  Demote, promote.

02:18:48,066 --> 02:18:49,054
SPEAKER_0:  What do you do?

02:18:50,114 --> 02:18:55,358
SPEAKER_0:  And this is why it's all about those three buckets. I personally believe that folks in that bucket won.

02:18:56,194 --> 02:18:57,022
SPEAKER_0:  As long as those

02:18:57,250 --> 02:19:00,062
SPEAKER_0:  folks aren't more than 50 to 60% of a company.

02:19:00,610 --> 02:19:00,958
SPEAKER_0:  are good.

02:19:01,986 --> 02:19:07,486
SPEAKER_0:  and they can be managed as long as they are one to two degrees away from one of those people that you just mentioned.

02:19:09,218 --> 02:19:12,446
SPEAKER_0:  Because it's easy then to drag the entire company down.

02:19:12,898 --> 02:19:13,310
SPEAKER_0:  If they're.

02:19:13,570 --> 02:19:19,166
SPEAKER_0:  far away from the Lebron James because you don't know what Lebron James looks and feels and smells and you know.

02:19:19,522 --> 02:19:23,742
SPEAKER_0:  So you need that tactile sense of what excellence looks like in front of you.

02:19:24,514 --> 02:19:27,774
SPEAKER_0:  A great example is if you just go on YouTube and you search these clips of how

02:19:28,226 --> 02:19:29,790
SPEAKER_0:  Kobe Bryant's teammates described.

02:19:30,114 --> 02:19:30,430
SPEAKER_0:  Not.

02:19:31,106 --> 02:19:31,518
SPEAKER_0:  Kobe.

02:19:32,162 --> 02:19:33,406
SPEAKER_0:  but how their own.

02:19:33,730 --> 02:19:34,622
SPEAKER_0:  Behavior.

02:19:35,394 --> 02:19:36,414
SPEAKER_0:  not performance.

02:19:36,834 --> 02:19:39,518
SPEAKER_0:  because there was a bunch of average people that Kobe played with his whole crew.

02:19:40,706 --> 02:19:42,110
SPEAKER_0:  their behavior changed.

02:19:43,618 --> 02:19:44,286
SPEAKER_0:  by being.

02:19:44,642 --> 02:19:45,854
SPEAKER_0:  somewhat closer to him.

02:19:46,530 --> 02:19:49,310
SPEAKER_0:  I think that's an important psychological thing to note.

02:19:50,146 --> 02:19:55,614
SPEAKER_0:  for how you can do reasonably good team construction. If you're lucky enough to find those generational talents.

02:19:56,354 --> 02:20:00,414
SPEAKER_0:  You have to find a composition of a team that keeps them roughly close.

02:20:01,218 --> 02:20:02,718
SPEAKER_0:  enough of the auric. That way that

02:20:03,842 --> 02:20:04,862
SPEAKER_0:  group of people.

02:20:06,018 --> 02:20:08,862
SPEAKER_0:  can continue to add value, and then you'll have courage.

02:20:09,218 --> 02:20:11,102
SPEAKER_0:  to fire these next two groups of people.

02:20:11,330 --> 02:20:13,982
SPEAKER_0:  And I think the answer is to fire those two groups of people.

02:20:14,562 --> 02:20:18,270
SPEAKER_0:  Because no matter how good you are, that stuff just injects poison into it.

02:20:18,786 --> 02:20:21,822
SPEAKER_0:  into a living organism and that living organism will die.

02:20:22,050 --> 02:20:23,070
SPEAKER_0:  when exposed to poison.

02:20:23,906 --> 02:20:27,454
SPEAKER_1:  So you invest in a lot of companies, you looked at a lot of companies.

02:20:27,714 --> 02:20:29,854
SPEAKER_1:  What do you think makes for a good leader?

02:20:30,530 --> 02:20:32,094
SPEAKER_1:  So we talked about building a team.

02:20:32,610 --> 02:20:35,582
SPEAKER_1:  but a good leader for a company, what are the qualities?

02:20:36,386 --> 02:20:38,654
SPEAKER_0:  You know, I, when I first meet people...

02:20:39,170 --> 02:20:39,614
SPEAKER_0:  Um...

02:20:39,906 --> 02:20:41,534
SPEAKER_0:  I never asked to see a resume.

02:20:42,434 --> 02:20:43,038
SPEAKER_0:  Um...

02:20:44,386 --> 02:20:49,054
SPEAKER_0:  And when I'm meeting a company CEO for the first time, I couldn't care less about the business.

02:20:49,314 --> 02:20:49,758
SPEAKER_0:  In fact.

02:20:51,010 --> 02:20:51,422
SPEAKER_0:  Um.

02:20:51,874 --> 02:20:53,470
SPEAKER_0:  and I try to take the time.

02:20:54,370 --> 02:20:55,934
SPEAKER_0:  to let them reveal themselves.

02:20:56,482 --> 02:20:59,038
SPEAKER_0:  Now in this environment, you know, I'm doing most of the talking.

02:20:59,522 --> 02:21:04,446
SPEAKER_0:  But if this were the other way around and you were ever raising capital and you said I'm a stitch-mouth, I'd be interested in you looking at this business.

02:21:05,154 --> 02:21:07,166
SPEAKER_0:  I'd probably say eight to 10 words.

02:21:08,002 --> 02:21:09,310
SPEAKER_0:  for hours and just listen.

02:21:09,666 --> 02:21:10,110
SPEAKER_0:  prod.

02:21:10,466 --> 02:21:13,406
SPEAKER_0:  You know, I throw things out prod and I let you meander.

02:21:14,050 --> 02:21:18,558
SPEAKER_0:  And in new meandering, I'm trying to build a sense of who this person is.

02:21:19,202 --> 02:21:20,894
SPEAKER_0:  Once I have a rough sense of that...

02:21:21,282 --> 02:21:21,630
SPEAKER_0:  Which-

02:21:21,890 --> 02:21:24,574
SPEAKER_0:  is not necessarily right, but it's a starting point.

02:21:26,018 --> 02:21:28,446
SPEAKER_0:  then I can go and understand why.

02:21:28,962 --> 02:21:31,166
SPEAKER_0:  this idea makes sense in this moment.

02:21:31,650 --> 02:21:36,222
SPEAKER_0:  And what I'm really trying to do is just kind of like unpack where are the biases.

02:21:36,738 --> 02:21:37,726
SPEAKER_0:  that may make you...

02:21:38,274 --> 02:21:39,006
SPEAKER_0:  you know, fail.

02:21:40,418 --> 02:21:41,470
SPEAKER_0:  and then we go back to you.

02:21:43,266 --> 02:21:44,958
SPEAKER_0:  The thing that Silicon Valley.

02:21:45,186 --> 02:21:47,998
SPEAKER_0:  has the benefit of though is that they don't have to do any of this stuff.

02:21:48,898 --> 02:21:50,046
SPEAKER_0:  if there's momentum.

02:21:50,498 --> 02:21:51,134
SPEAKER_0:  Because then...

02:21:51,554 --> 02:21:54,366
SPEAKER_0:  The rule book goes out the window and people clamor to invest.

02:21:54,914 --> 02:21:56,382
SPEAKER_0:  So one of the things that I do...

02:21:57,410 --> 02:21:58,654
SPEAKER_0:  And this is again back to this.

02:21:59,458 --> 02:22:01,278
SPEAKER_0:  that I inflict on myself.

02:22:02,050 --> 02:22:04,350
SPEAKER_0:  is I have these two things that I look at.

02:22:04,898 --> 02:22:05,758
SPEAKER_0:  Thing number one.

02:22:06,242 --> 02:22:07,230
SPEAKER_0:  is I have a table.

02:22:07,746 --> 02:22:08,318
SPEAKER_0:  that says.

02:22:09,218 --> 02:22:11,454
SPEAKER_0:  How much should we make from all of our best investments?

02:22:11,810 --> 02:22:14,494
SPEAKER_0:  How much did we lose from all of our worst investments?

02:22:14,722 --> 02:22:17,374
SPEAKER_0:  What is the ratio of winners to losers over 11 years?

02:22:18,306 --> 02:22:18,654
SPEAKER_0:  Um.

02:22:19,106 --> 02:22:20,670
SPEAKER_0:  and in our case it's 23 to 1.

02:22:21,602 --> 02:22:24,446
SPEAKER_0:  on billions of dollars. So you can you can kind of like.

02:22:25,058 --> 02:22:26,302
SPEAKER_0:  you can see a lot of signal.

02:22:27,426 --> 02:22:29,054
SPEAKER_0:  but what that allows me to do.

02:22:29,410 --> 02:22:30,078
SPEAKER_0:  is really p-

02:22:30,466 --> 02:22:31,646
SPEAKER_0:  Like say, wait a minute.

02:22:32,226 --> 02:22:32,574
SPEAKER_0:  Like.

02:22:33,090 --> 02:22:35,006
SPEAKER_0:  We cannot violate

02:22:35,426 --> 02:22:37,278
SPEAKER_0:  these rules around

02:22:37,602 --> 02:22:39,038
SPEAKER_0:  how much money we're willing to commit.

02:22:39,522 --> 02:22:41,022
SPEAKER_0:  in an errant personality.

02:22:41,634 --> 02:22:42,014
SPEAKER_0:  You know?

02:22:42,658 --> 02:22:47,134
SPEAKER_0:  The second is I ask myself, of all the other top VCs in Silicon Valley, name them all.

02:22:47,394 --> 02:22:47,742
SPEAKER_0:  You know?

02:22:48,290 --> 02:22:48,638
SPEAKER_0:  Um.

02:22:48,898 --> 02:22:50,014
SPEAKER_0:  What's our correlation?

02:22:50,594 --> 02:22:50,974
SPEAKER_0:  Meaning...

02:22:51,810 --> 02:22:52,510
SPEAKER_0:  When I do a deal...

02:22:53,026 --> 02:22:57,150
SPEAKER_0:  How often does anybody from Sequoia, Excel, Benchmark, beat symmetrically?

02:22:58,050 --> 02:22:59,678
SPEAKER_0:  Do it at the same time or after.

02:23:00,450 --> 02:23:01,406
SPEAKER_0:  and vice versa.

02:23:02,114 --> 02:23:02,558
SPEAKER_0:  And then.

02:23:03,106 --> 02:23:05,950
SPEAKER_0:  then I look at the data to see how much they do amongst themselves.

02:23:06,882 --> 02:23:09,086
SPEAKER_0:  What's a good sign? Well, I'm at zero.

02:23:09,410 --> 02:23:12,606
SPEAKER_0:  as virtually close to zero as possible. And that's a good thing. Well.

02:23:13,410 --> 02:23:16,254
SPEAKER_0:  It's not a good thing when the markets are way, way up.

02:23:16,994 --> 02:23:18,238
SPEAKER_0:  because it creates.

02:23:19,234 --> 02:23:20,990
SPEAKER_0:  an enormous amount of momentum,

02:23:21,250 --> 02:23:22,782
SPEAKER_0:  So I have to make money the hard way.

02:23:23,522 --> 02:23:26,814
SPEAKER_0:  I have to, you know, because I'm trafficking in things that are highly uncorrelated.

02:23:27,906 --> 02:23:30,654
SPEAKER_0:  to the Gestalt of Silicon Valley.

02:23:31,234 --> 02:23:32,510
SPEAKER_0:  which can be a lonely business.

02:23:33,538 --> 02:23:35,774
SPEAKER_0:  but it's really valuable in moments where markets get crushed.

02:23:36,450 --> 02:23:41,758
SPEAKER_0:  because correlation is the first thing that causes massive destruction of capital.

02:23:42,114 --> 02:23:42,814
SPEAKER_0:  Massive.

02:23:43,266 --> 02:23:46,846
SPEAKER_0:  because one person all of a sudden with one blow up in one company

02:23:47,522 --> 02:23:49,278
SPEAKER_0:  Boom, the contagion hits everybody.

02:23:49,602 --> 02:23:51,294
SPEAKER_0:  except the person that was, you know.

02:23:51,874 --> 02:23:52,638
SPEAKER_0:  Not. And so.

02:23:53,762 --> 02:23:57,694
SPEAKER_0:  Those are like more sophisticated elements of risk management, which is again this.

02:23:58,306 --> 02:24:04,318
SPEAKER_0:  that I inflict on my nobody asks me to do that nobody actually at some level when the markets are up really care.

02:24:04,610 --> 02:24:07,550
SPEAKER_0:  when markets are sideways or when markets are down, I think that...

02:24:08,610 --> 02:24:10,590
SPEAKER_0:  That allows me to feel proud of our process.

02:24:11,522 --> 02:24:12,647
SPEAKER_0:  But that requires you to.

02:24:12,647 --> 02:24:13,214
SPEAKER_1:  think.

02:24:13,858 --> 02:24:18,590
SPEAKER_1:  a lot outside of the box. It's lonely because you're taking risks. Also,

02:24:19,138 --> 02:24:21,566
SPEAKER_1:  your public personality so you say stuff.

02:24:22,050 --> 02:24:24,675
SPEAKER_1:  that if it's wrong, you get yelled at for.

02:24:24,675 --> 02:24:25,150
SPEAKER_0:  Constantly.

02:24:25,506 --> 02:24:26,942
SPEAKER_1:  for being.

02:24:27,394 --> 02:24:28,519
SPEAKER_1:  I mean, your mistakes are.

02:24:28,519 --> 02:24:29,150
SPEAKER_0:  private.

02:24:29,538 --> 02:24:31,646
SPEAKER_0:  No, and that's something that...

02:24:32,194 --> 02:24:34,014
SPEAKER_0:  has been a really really

02:24:34,434 --> 02:24:34,878
SPEAKER_0:  healthy.

02:24:35,170 --> 02:24:36,062
SPEAKER_0:  moment of growth.

02:24:36,802 --> 02:24:37,758
SPEAKER_0:  It's like an athlete.

02:24:38,178 --> 02:24:38,558
SPEAKER_0:  You know.

02:24:39,586 --> 02:24:42,590
SPEAKER_0:  If you really want to be a winner, you gotta hit the shot.

02:24:43,490 --> 02:24:44,862
SPEAKER_0:  in front of the fans.

02:24:45,890 --> 02:24:46,814
SPEAKER_0:  And if you miss it.

02:24:47,138 --> 02:24:50,878
SPEAKER_0:  You have to be willing to take the responsibility of the fact that you bricked it.

02:24:52,354 --> 02:24:57,566
SPEAKER_0:  And over time, hopefully there's a body of work that says you've generally hit more than you've missed.

02:24:58,466 --> 02:25:01,694
SPEAKER_0:  But if you look at even the best shooters, what are they? Skeletons, they're 50% sometimes against 50%.

02:25:02,594 --> 02:25:05,406
SPEAKER_0:  So these are razor thin margins at the end of the day.

02:25:05,954 --> 02:25:08,158
SPEAKER_0:  which is really, so then what can you control?

02:25:08,994 --> 02:25:10,366
SPEAKER_0:  I can't control the defense.

02:25:10,690 --> 02:25:12,382
SPEAKER_0:  I can't control what they throw at me.

02:25:12,962 --> 02:25:17,150
SPEAKER_0:  I can just control my preparation and whether I'm in the best position to launch a reasonable shot.

02:25:18,850 --> 02:25:23,358
SPEAKER_1:  You said that the world's first trillionaire would be somebody in climate change in the past.

02:25:24,034 --> 02:25:25,566
SPEAKER_1:  Let's update that.

02:25:25,986 --> 02:25:31,134
SPEAKER_1:  What's today as we stand here today, what sector will the world's first trillionaire come from?

02:25:31,554 --> 02:25:32,830
SPEAKER_1:  I think it's energy transition.

02:25:33,538 --> 02:25:35,358
SPEAKER_1:  So energy, so the things we've been talking about.

02:25:36,034 --> 02:25:37,159
SPEAKER_1:  Really? So isn't it...

02:25:37,159 --> 02:25:39,038
SPEAKER_0:  Okay. I think the way that I think about.

02:25:39,650 --> 02:25:42,430
SPEAKER_1:  So this is a single individual, sorry to interrupt. You see

02:25:42,818 --> 02:25:50,115
SPEAKER_1:  their ability to actually build a company that makes huge amount of money as opposed to this distributed idea that you've been talking to.

02:25:50,115 --> 02:25:53,150
SPEAKER_0:  Yeah, I'll give you my philosophy on wealth.

02:25:54,434 --> 02:25:54,814
SPEAKER_0:  Um.

02:25:55,778 --> 02:25:57,054
SPEAKER_0:  Most of it is not you.

02:25:58,370 --> 02:26:00,638
SPEAKER_0:  An enormous amount of it is

02:26:01,474 --> 02:26:05,502
SPEAKER_0:  genetic distribution of being born in the right place and blah blah blah, irrespective of

02:26:05,922 --> 02:26:07,486
SPEAKER_0:  the boundary conditions of how you were born.

02:26:08,290 --> 02:26:09,598
SPEAKER_0:  or where you were raised, right?

02:26:10,658 --> 02:26:12,958
SPEAKER_0:  At the end of the day, you and I ended up in the United States.

02:26:13,282 --> 02:26:14,398
SPEAKER_0:  It's a huge.

02:26:14,626 --> 02:26:15,326
SPEAKER_0:  Benefit to us.

02:26:16,194 --> 02:26:18,046
SPEAKER_0:  Second is the benefit of our age.

02:26:19,266 --> 02:26:20,350
SPEAKER_0:  It's much better.

02:26:20,674 --> 02:26:24,190
SPEAKER_0:  and much more likely to be successful as a 46-year-old in 2023.

02:26:24,578 --> 02:26:27,070
SPEAKER_0:  than a 26 year old in 2023.

02:26:27,394 --> 02:26:28,958
SPEAKER_0:  because in my case I have...

02:26:29,538 --> 02:26:30,558
SPEAKER_0:  demographics working.

02:26:30,786 --> 02:26:31,166
SPEAKER_0:  for me.

02:26:32,162 --> 02:26:33,182
SPEAKER_0:  for the 26 year old.

02:26:33,730 --> 02:26:36,355
SPEAKER_0:  or she has demographics working slightly against them.

02:26:36,355 --> 02:26:38,846
SPEAKER_1:  explain that a little bit. What are the demographics here?

02:26:39,778 --> 02:26:40,798
SPEAKER_0:  In the case of me...

02:26:42,754 --> 02:26:43,454
SPEAKER_0:  The...

02:26:44,130 --> 02:26:46,654
SPEAKER_0:  distribution of population in America looks like a pyramid.

02:26:47,618 --> 02:26:48,126
SPEAKER_0:  and

02:26:48,450 --> 02:26:49,374
SPEAKER_0:  In that pyramid,

02:26:50,050 --> 02:26:55,038
SPEAKER_0:  I'm wedged in between these two massive population cohorts, the boomers and then these

02:26:55,458 --> 02:26:57,086
SPEAKER_0:  you know, Gen Z and millennials.

02:26:57,922 --> 02:26:58,270
SPEAKER_0:  Um.

02:26:58,562 --> 02:27:03,486
SPEAKER_0:  And that's a very advantageous position. It's not dissimilar to the position that Buffett was, where he was—

02:27:03,842 --> 02:27:06,878
SPEAKER_0:  you know, packaged in between boomers beneath him.

02:27:07,202 --> 02:27:08,670
SPEAKER_0:  and the silent generation above it.

02:27:09,474 --> 02:27:12,862
SPEAKER_0:  and being in between two massive population cohorts.

02:27:13,154 --> 02:27:15,198
SPEAKER_0:  turns out to be extremely advantageous because.

02:27:15,586 --> 02:27:16,094
SPEAKER_0:  when the

02:27:16,610 --> 02:27:18,558
SPEAKER_0:  cohort above you transitions power and

02:27:18,882 --> 02:27:20,158
SPEAKER_0:  capital and all of this stuff.

02:27:20,706 --> 02:27:25,598
SPEAKER_0:  You're the next person that likely gets handed it. So we have a disproportionate likelihood to be.

02:27:25,922 --> 02:27:27,614
SPEAKER_0:  You know, we are lucky to be older.

02:27:28,066 --> 02:27:28,574
SPEAKER_0:  than younger.

02:27:29,442 --> 02:27:33,950
SPEAKER_0:  So that's an advantage. And then the other advantage that has nothing to do with me.

02:27:34,626 --> 02:27:40,030
SPEAKER_0:  is that I stumbled into technology, I got a degree in electrical engineering and I ended up coming to Silicon Valley.

02:27:40,930 --> 02:27:42,334
SPEAKER_0:  And it turned out that in that moment...

02:27:42,594 --> 02:27:44,542
SPEAKER_0:  with such a transformational wind of change.

02:27:45,122 --> 02:27:46,014
SPEAKER_0:  that was at my back.

02:27:47,490 --> 02:27:47,838
SPEAKER_0:  So.

02:27:48,770 --> 02:27:50,590
SPEAKER_0:  the wealth that one creates.

02:27:50,946 --> 02:27:51,294
SPEAKER_0:  is

02:27:52,162 --> 02:27:53,374
SPEAKER_0:  a huge part.

02:27:53,634 --> 02:27:54,974
SPEAKER_0:  of those variables.

02:27:55,490 --> 02:27:58,366
SPEAKER_0:  And then the last variable is your direct contributions.

02:27:59,586 --> 02:28:00,286
SPEAKER_0:  in that moment.

02:28:00,706 --> 02:28:01,630
SPEAKER_0:  And the reason why...

02:28:03,522 --> 02:28:04,446
SPEAKER_0:  that can create.

02:28:05,250 --> 02:28:06,334
SPEAKER_0:  Extreme wealth.

02:28:07,394 --> 02:28:10,206
SPEAKER_0:  is because when those things come together at the right.

02:28:11,330 --> 02:28:11,870
SPEAKER_0:  Moment.

02:28:12,802 --> 02:28:15,966
SPEAKER_0:  It's like a chemical reaction. I mean, it's just crazy. So by the way, so

02:28:18,562 --> 02:28:20,830
SPEAKER_0:  That was sort of part number one of what I wanted to say.

02:28:21,282 --> 02:28:25,214
SPEAKER_0:  The second thing is when you look then inside of these systems where you have all these

02:28:25,442 --> 02:28:27,102
SPEAKER_0:  sit tailwinds, right? So in tech

02:28:27,618 --> 02:28:29,886
SPEAKER_0:  I think I benefit from these three big tailwinds.

02:28:31,138 --> 02:28:34,590
SPEAKER_0:  If you build a company or are part of a company or a part of a movement.

02:28:36,002 --> 02:28:38,078
SPEAKER_0:  your economic participation.

02:28:38,946 --> 02:28:41,118
SPEAKER_0:  tends to be a direct byproduct.

02:28:42,882 --> 02:28:44,478
SPEAKER_0:  of the actual value.

02:28:44,994 --> 02:28:46,686
SPEAKER_0:  that that thing creates in the world.

02:28:49,154 --> 02:28:51,550
SPEAKER_0:  And the thing that that creates in the world...

02:28:52,546 --> 02:28:53,598
SPEAKER_0:  will be bigger.

02:28:54,658 --> 02:28:55,070
SPEAKER_0:  If...

02:28:55,618 --> 02:28:57,502
SPEAKER_0:  It is not just an economic system.

02:28:58,178 --> 02:28:59,870
SPEAKER_0:  but it's like a philosophical system.

02:29:00,706 --> 02:29:03,742
SPEAKER_0:  It changes the way that governance happens. It changes the way that people...

02:29:04,034 --> 02:29:06,078
SPEAKER_0:  Think about all kinds of other things about their lives.

02:29:06,978 --> 02:29:08,350
SPEAKER_0:  So there's a reason.

02:29:09,250 --> 02:29:11,070
SPEAKER_0:  I think, why database companies.

02:29:11,522 --> 02:29:14,046
SPEAKER_0:  are worth X, social companies are worth Y.

02:29:14,498 --> 02:29:18,206
SPEAKER_0:  But the military industrial complex is worth as much.

02:29:19,330 --> 02:29:20,990
SPEAKER_0:  And I think there is a reason why.

02:29:21,346 --> 02:29:24,286
SPEAKER_0:  that if you, for example, were to go off and build.

02:29:24,674 --> 02:29:28,542
SPEAKER_0:  some newfangled source of energy that's clean and hyper abundant.

02:29:29,474 --> 02:29:30,078
SPEAKER_0:  and safe.

02:29:31,202 --> 02:29:33,214
SPEAKER_0:  that what you're really going to displace

02:29:33,890 --> 02:29:34,878
SPEAKER_0:  or reshape its.

02:29:35,138 --> 02:29:36,734
SPEAKER_0:  trillions and trillions of dollars of

02:29:36,962 --> 02:29:39,230
SPEAKER_0:  worldwide GDP. So the global GDP.

02:29:39,586 --> 02:29:40,926
SPEAKER_0:  is I call it 85 trillion.

02:29:41,218 --> 02:29:42,814
SPEAKER_0:  Right, it's going at two to 3% a year.

02:29:43,778 --> 02:29:45,278
SPEAKER_0:  So in the next 10 years, we'll be dealing with

02:29:45,666 --> 02:29:47,550
SPEAKER_0:  $100 trillion of GDP.

02:29:49,090 --> 02:29:51,902
SPEAKER_0:  somebody who develops clean energy in 2035.

02:29:52,866 --> 02:29:53,982
SPEAKER_0:  will probably shift.

02:29:54,850 --> 02:29:55,998
SPEAKER_0:  10% of that around.

02:29:56,706 --> 02:29:57,598
SPEAKER_0:  $10 trillion.

02:29:59,810 --> 02:30:01,790
SPEAKER_0:  a company can easily capture.

02:30:02,402 --> 02:30:03,550
SPEAKER_0:  30% of the market.

02:30:03,810 --> 02:30:04,734
SPEAKER_0:  $3 trillion.

02:30:05,954 --> 02:30:09,534
SPEAKER_0:  A human being can typically own a third of one of these companies.

02:30:09,794 --> 02:30:10,462
SPEAKER_0:  $1 trillion.

02:30:11,938 --> 02:30:14,334
SPEAKER_0:  So you can kind of get to this answer where it's like.

02:30:14,722 --> 02:30:16,094
SPEAKER_0:  It's going to happen in our lifetime.

02:30:17,602 --> 02:30:22,910
SPEAKER_0:  But you have to, I think, find these systems that are so gargantuan and they exist today.

02:30:23,906 --> 02:30:26,686
SPEAKER_0:  It's more bounded because price discovery takes longer.

02:30:27,266 --> 02:30:31,934
SPEAKER_0:  And an existing thing, it's more unbounded because you know what it is. You know the tentacles that energy reaches.

02:30:32,738 --> 02:30:35,326
SPEAKER_0:  Right, of that $80 trillion of worldwide GDP.

02:30:35,682 --> 02:30:37,726
SPEAKER_0:  I bet you if you added up all the energy companies.

02:30:38,210 --> 02:30:40,094
SPEAKER_0:  but then you added up all of manufacturing.

02:30:40,802 --> 02:30:42,686
SPEAKER_0:  you know, if you added up all of transport.

02:30:42,946 --> 02:30:45,310
SPEAKER_0:  you'd probably get to like 60 of the 80.

02:30:46,402 --> 02:30:47,262
SPEAKER_0:  Do you have an idea of...

02:30:47,362 --> 02:30:47,870
SPEAKER_1:  which...

02:30:48,162 --> 02:30:48,830
SPEAKER_1:  energy.

02:30:49,538 --> 02:30:52,094
SPEAKER_1:  Which alternate energy sustainable energy?

02:30:53,218 --> 02:30:54,494
SPEAKER_1:  is the most promising.

02:30:54,658 --> 02:30:55,806
SPEAKER_0:  Well, I think that we...

02:30:57,890 --> 02:30:59,902
SPEAKER_0:  have to do a better job of exploring.

02:31:00,802 --> 02:31:01,758
SPEAKER_0:  what I call...

02:31:02,114 --> 02:31:03,806
SPEAKER_0:  the suburbs of the periodic table.

02:31:04,866 --> 02:31:05,310
SPEAKER_0:  So.

02:31:05,634 --> 02:31:11,454
SPEAKER_0:  You know, we're really good in Seattle, you know, the upper Northwest. Yes. We're kind of good in Portland.

02:31:12,130 --> 02:31:15,806
SPEAKER_0:  but we're non-existent in San Diego and we have zero plan.

02:31:16,290 --> 02:31:17,854
SPEAKER_0:  for North Carolina through Florida.

02:31:19,266 --> 02:31:20,391
SPEAKER_0:  And so...

02:31:20,391 --> 02:31:23,902
SPEAKER_1:  Is that a fancy way of saying nuclear should be part of the...

02:31:24,034 --> 02:31:25,694
SPEAKER_0:  discussion. I think nuclear

02:31:26,018 --> 02:31:28,222
SPEAKER_0:  I mean, room temperature semiconductors.

02:31:29,218 --> 02:31:33,086
SPEAKER_0:  I'm not convinced right now that the existing set of nuclear solutions

02:31:33,346 --> 02:31:35,550
SPEAKER_0:  We'll do a good job of scaling beyond bench scale.

02:31:35,874 --> 02:31:38,238
SPEAKER_0:  I think there is a lot of complicated technical problems that-

02:31:38,626 --> 02:31:42,142
SPEAKER_0:  make it work at a bench scale level even partially, but the energy equation.

02:31:43,394 --> 02:31:47,358
SPEAKER_0:  is going to be very difficult to overcome in the absence of some leaps in material science.

02:31:48,098 --> 02:31:53,723
SPEAKER_1:  Have you seen any leaps? Is there promising stuff like you're seeing a cutting edge from a company?

02:31:53,723 --> 02:31:54,174
SPEAKER_0:  Yeah.

02:31:54,594 --> 02:31:56,350
SPEAKER_0:  I would say not yet. I do���ב.

02:31:56,578 --> 02:31:57,918
SPEAKER_0:  But the precursor, yes.

02:31:58,306 --> 02:31:59,678
SPEAKER_0:  I have been spending...

02:32:00,098 --> 02:32:04,350
SPEAKER_0:  a fair amount of time. So talking about like a new framework that's in my mind.

02:32:04,930 --> 02:32:06,974
SPEAKER_0:  is around these room temp.

02:32:07,266 --> 02:32:08,190
SPEAKER_0:  superconductors.

02:32:08,930 --> 02:32:10,814
SPEAKER_0:  And so I've been kind of

02:32:11,234 --> 02:32:12,926
SPEAKER_0:  bumbling around in that forest.

02:32:13,794 --> 02:32:14,654
SPEAKER_0:  for about a year.

02:32:15,554 --> 02:32:17,630
SPEAKER_0:  I haven't really put together.

02:32:18,242 --> 02:32:20,958
SPEAKER_0:  any meaningful perspectives, but again, talking about like.

02:32:21,282 --> 02:32:22,366
SPEAKER_0:  trafficking in

02:32:22,658 --> 02:32:24,606
SPEAKER_0:  in companies and investments that are.

02:32:25,314 --> 02:32:27,710
SPEAKER_0:  very lonely, but they allow me to generate.

02:32:28,162 --> 02:32:30,494
SPEAKER_0:  returns that are relatively unique and independent?

02:32:31,106 --> 02:32:33,438
SPEAKER_0:  That's an area where I don't see anybody else when I'm there.

02:32:33,730 --> 02:32:34,750
SPEAKER_0:  I'll give you another area.

02:32:35,746 --> 02:32:36,510
SPEAKER_0:  You know, we...

02:32:37,282 --> 02:32:37,630
SPEAKER_0:  Um.

02:32:37,986 --> 02:32:41,054
SPEAKER_0:  I think are about to unleash in a world of zero energy and

02:32:41,698 --> 02:32:43,134
SPEAKER_0:  and zero compute costs.

02:32:45,506 --> 02:32:48,350
SPEAKER_0:  computational biology will replace white chemistry.

02:32:49,410 --> 02:32:50,430
SPEAKER_0:  And when you do that...

02:32:51,458 --> 02:32:53,502
SPEAKER_0:  you will be able to iterate on tools.

02:32:54,338 --> 02:32:56,830
SPEAKER_0:  that will be able to solve a lot of human disease.

02:32:57,730 --> 02:32:59,454
SPEAKER_0:  I think like if you look at the head...

02:33:00,098 --> 02:33:03,614
SPEAKER_0:  of like the top 400 most recurring rare diseases.

02:33:04,354 --> 02:33:06,590
SPEAKER_0:  I think like half the number, 200.

02:33:06,850 --> 02:33:09,342
SPEAKER_0:  is specific point mutation.

02:33:09,762 --> 02:33:12,190
SPEAKER_0:  as just the mis-methylation between C and T.

02:33:13,186 --> 02:33:15,390
SPEAKER_0:  I mean, that's like, whoa, wait, you're telling me in mid-

02:33:15,618 --> 02:33:16,958
SPEAKER_0:  billions of lines of code.

02:33:17,474 --> 02:33:19,390
SPEAKER_0:  I forgot a semicolon right there.

02:33:19,682 --> 02:33:23,614
SPEAKER_0:  That's causing this whole thing to miscompile. So I just gotta go in there and boop and it's all done.

02:33:24,194 --> 02:33:26,526
SPEAKER_0:  That's a crazy idea! That was a C++.

02:33:26,850 --> 02:33:36,318
SPEAKER_0:  see, see throwback for people that don't know what I said. There's two people who are clapping. Two people there. Everybody's like, what? This is not a pipe. What are you talking about? Makes perfect sense. Um, but, but, um.

02:33:36,546 --> 02:33:39,678
SPEAKER_1:  So that couldn't that be a source of a...

02:33:40,194 --> 02:33:42,819
SPEAKER_1:  Competition biology unlocks. I mean obviously medicine is

02:33:42,819 --> 02:33:46,366
SPEAKER_0:  The thing with energy though is that the...

02:33:46,882 --> 02:33:48,286
SPEAKER_0:  Groundwork is well laid.

02:33:49,570 --> 02:33:49,886
SPEAKER_0:  Um.

02:33:50,850 --> 02:33:53,534
SPEAKER_0:  and talking about sort of like the upper bound is well defined.

02:33:54,338 --> 02:33:57,406
SPEAKER_0:  The upper bound in medicine is not well defined because it is not.

02:33:58,594 --> 02:34:00,574
SPEAKER_0:  sum total of the market cap of the pharma industries.

02:34:00,994 --> 02:34:03,518
SPEAKER_0:  It is actually the sum total of the value of human life.

02:34:05,218 --> 02:34:08,222
SPEAKER_0:  And that's an extremely ethical and moral question.

02:34:08,706 --> 02:34:11,806
SPEAKER_1:  Isn't there a special interest that are resisting?

02:34:12,834 --> 02:34:13,342
SPEAKER_1:  moving.

02:34:13,602 --> 02:34:15,326
SPEAKER_1:  making progress on the energy side.

02:34:15,778 --> 02:34:17,886
SPEAKER_1:  So like governments and.

02:34:18,210 --> 02:34:20,835
SPEAKER_1:  How do you break through that? You have to acknowledge the reality of that.

02:34:20,835 --> 02:34:24,318
SPEAKER_0:  I think it's less governments. In fact, like I said, I think President Biden has done.

02:34:24,866 --> 02:34:28,158
SPEAKER_0:  really incredible job. Well Chuck Schumer really is that a really incredible job because

02:34:29,602 --> 02:34:31,902
SPEAKER_0:  So just to give you the math on this, right? Back to this.

02:34:32,322 --> 02:34:32,766
SPEAKER_0:  So.

02:34:32,994 --> 02:34:35,454
SPEAKER_0:  3% of everything is of a marketer's zealots.

02:34:36,290 --> 02:34:41,054
SPEAKER_0:  But when you get past 5%, things tend to just go nuclear to 50, 60%.

02:34:43,426 --> 02:34:44,990
SPEAKER_0:  The way that they wrote this last bill...

02:34:46,114 --> 02:34:46,622
SPEAKER_0:  the

02:34:47,234 --> 02:34:50,302
SPEAKER_0:  I'll just use the cars as an example. Cost them an average car.

02:34:50,786 --> 02:34:51,902
SPEAKER_0:  is 22 and a half thousand.

02:34:52,418 --> 02:34:55,390
SPEAKER_0:  The cost of the cheapest battery car is $30,000.

02:34:56,354 --> 02:34:59,518
SPEAKER_0:  And lo and behold, there's a $7,500 credit. And it's like.

02:34:59,938 --> 02:35:05,438
SPEAKER_0:  To think the invisible hand didn't know that that math was right, I think, is kind of a little bit malarkey.

02:35:06,082 --> 02:35:06,558
SPEAKER_0:  And so.

02:35:06,914 --> 02:35:11,486
SPEAKER_0:  The battery EV car is gonna be the same price as the thing and it's gonna go to 40-50%.

02:35:12,290 --> 02:35:12,670
SPEAKER_0:  Um.

02:35:12,930 --> 02:35:16,286
SPEAKER_0:  So we're already at this tipping point, so we're kind of ready to go.

02:35:17,186 --> 02:35:17,598
SPEAKER_0:  Um...

02:35:18,370 --> 02:35:25,950
SPEAKER_0:  in these other markets, it's a little bit more complicated because there's a lot of infrastructure that needs to get built. So the gene editing thing as an example.

02:35:26,466 --> 02:35:28,190
SPEAKER_0:  We have to build a tool chain.

02:35:29,122 --> 02:35:30,782
SPEAKER_0:  that looks more like.

02:35:31,490 --> 02:35:31,838
SPEAKER_0:  Um.

02:35:32,610 --> 02:35:33,694
SPEAKER_0:  code that you can write to.

02:35:34,114 --> 02:35:38,078
SPEAKER_1:  Facebook is written in, I think, PHP originally. PHP, yeah. which is.

02:35:38,466 --> 02:35:39,646
SPEAKER_1:  I'm still a big fan of.

02:35:39,970 --> 02:35:42,782
SPEAKER_1:  Sometimes you have to use the ugly solution.

02:35:43,138 --> 02:35:43,838
SPEAKER_1:  and make it.

02:35:44,194 --> 02:35:45,630
SPEAKER_1:  look good versus

02:35:45,986 --> 02:35:47,646
SPEAKER_1:  trying to come up with a good solution.

02:35:48,322 --> 02:35:50,174
SPEAKER_1:  which will be too late.

02:35:50,690 --> 02:35:51,486
SPEAKER_1:  Let me ask you.

02:35:51,874 --> 02:35:55,582
SPEAKER_1:  you consider a run for governor of California and then decided against it.

02:35:56,130 --> 02:35:58,750
SPEAKER_1:  What went into each of these decisions?

02:35:59,138 --> 02:36:02,302
SPEAKER_1:  And broadly, I just have maybe a selfish question about.

02:36:02,882 --> 02:36:03,870
SPEAKER_1:  Silicon Valley.

02:36:06,050 --> 02:36:07,486
SPEAKER_1:  Is it over?

02:36:07,714 --> 02:36:10,206
SPEAKER_1:  as a world leader for new tech companies.

02:36:10,978 --> 02:36:12,766
SPEAKER_1:  as this beacon.

02:36:13,442 --> 02:36:14,622
SPEAKER_1:  promise of.

02:36:15,330 --> 02:36:18,910
SPEAKER_1:  young minds stepping in and creating something that changes the world.

02:36:19,938 --> 02:36:21,758
SPEAKER_1:  I don't know if those two questions are connected.

02:36:22,306 --> 02:36:24,158
SPEAKER_0:  So it's not over.

02:36:24,578 --> 02:36:26,046
SPEAKER_0:  but I think it's definitely.

02:36:26,882 --> 02:36:28,126
SPEAKER_0:  or in a challenging moment.

02:36:29,762 --> 02:36:30,494
SPEAKER_0:  because...

02:36:33,442 --> 02:36:35,870
SPEAKER_0:  So back to that analogy of the demographics.

02:36:36,290 --> 02:36:37,342
SPEAKER_0:  If you think about the...

02:36:37,666 --> 02:36:38,814
SPEAKER_0:  Like if you bucketed.

02:36:39,106 --> 02:36:39,838
SPEAKER_0:  Forget like.

02:36:40,130 --> 02:36:41,662
SPEAKER_0:  our relative successes.

02:36:42,370 --> 02:36:44,190
SPEAKER_0:  but there's a bunch of us in this.

02:36:45,218 --> 02:36:48,318
SPEAKER_0:  mid 50s to mid 30s cohort of people.

02:36:48,962 --> 02:36:50,014
SPEAKER_0:  that have now been around.

02:36:50,274 --> 02:36:53,694
SPEAKER_0:  you know, for 20 years, 15 years to 25 years that have done stuff.

02:36:53,954 --> 02:36:54,334
SPEAKER_0:  Right?

02:36:55,170 --> 02:36:58,590
SPEAKER_0:  from Andreessen to Zuck to Jack Dorsey, et cetera.

02:36:58,978 --> 02:36:59,614
SPEAKER_0:  Elon.

02:37:00,002 --> 02:37:00,318
SPEAKER_0:  You know.

02:37:00,866 --> 02:37:03,678
SPEAKER_0:  Whatever, maybe you throw me in the mix, David Sachs, whatever, okay?

02:37:05,250 --> 02:37:07,006
SPEAKER_0:  None of us have done a really good job.

02:37:07,938 --> 02:37:09,246
SPEAKER_0:  of becoming a statesman.

02:37:10,498 --> 02:37:12,446
SPEAKER_0:  or a stateswoman, you know.

02:37:12,930 --> 02:37:13,374
SPEAKER_0:  Um

02:37:14,274 --> 02:37:15,646
SPEAKER_0:  and really showing.

02:37:15,970 --> 02:37:17,886
SPEAKER_0:  a broad empathy and awareness.

02:37:18,530 --> 02:37:19,742
SPEAKER_0:  the broader systems.

02:37:21,346 --> 02:37:23,422
SPEAKER_0:  So if Silicon Valley is to survive as a system...

02:37:24,354 --> 02:37:27,710
SPEAKER_0:  We need to know that we've transitioned from move fast and break things to

02:37:28,418 --> 02:37:31,038
SPEAKER_0:  Get to the right answer and take your time if that's what it means.

02:37:31,906 --> 02:37:34,014
SPEAKER_0:  And so we have to be a participant of the system.

02:37:35,266 --> 02:37:35,966
SPEAKER_0:  And I believe that.

02:37:36,258 --> 02:37:37,950
SPEAKER_0:  And I think that it's important to.

02:37:38,594 --> 02:37:39,934
SPEAKER_0:  not be a dilettante and.

02:37:40,290 --> 02:37:42,142
SPEAKER_0:  not be thumbing your face to.

02:37:42,530 --> 02:37:45,534
SPEAKER_0:  Washington or not push the boundaries and say, you know

02:37:45,762 --> 02:37:47,198
SPEAKER_0:  We'll deal with it after the fact.

02:37:48,098 --> 02:37:50,270
SPEAKER_0:  but to work with folks that are trying to do the best.

02:37:50,594 --> 02:37:51,038
SPEAKER_0:  Again.

02:37:51,586 --> 02:37:52,990
SPEAKER_0:  Steelman their point of view.

02:37:53,858 --> 02:37:54,302
SPEAKER_0:  You know?

02:37:54,434 --> 02:37:58,686
SPEAKER_1:  work with them, potentially run for office. So potentially like be, you know.

02:37:59,042 --> 02:38:03,294
SPEAKER_1:  Understand the system. It makes me sad that there's no...

02:38:04,258 --> 02:38:09,886
SPEAKER_1:  tech people or not many tech people in Congress and certainly not in the presidential level.

02:38:10,178 --> 02:38:12,382
SPEAKER_1:  Not many governors or senators.

02:38:12,706 --> 02:38:13,950
SPEAKER_0:  Well, I think that we also have.

02:38:14,434 --> 02:38:16,158
SPEAKER_0:  roughly, you know, our rules.

02:38:16,578 --> 02:38:21,918
SPEAKER_0:  will never allow some of the best and brightest folks to run for president because of just the rules against it. But you know.

02:38:22,370 --> 02:38:28,062
SPEAKER_0:  If, if. Oh, you mean, yeah. I mean, like, look, I think David Sacks would be an incredible presidential candidate. Now...

02:38:28,546 --> 02:38:31,230
SPEAKER_0:  I also think he'd be a great governor. No, he was born in South Africa.

02:38:32,322 --> 02:38:34,686
SPEAKER_0:  You know, I think he'd be a great governor. I think he'd be a great.

02:38:35,234 --> 02:38:35,710
SPEAKER_0:  Um.

02:38:36,002 --> 02:38:38,430
SPEAKER_0:  Secretary of State. I mean, he'd be great at whatever he wanted to do.

02:38:38,882 --> 02:38:39,198
SPEAKER_0:  Um.

02:38:39,618 --> 02:38:42,078
SPEAKER_0:  You know, Friedberg, you know, wasn't born here.

02:38:42,594 --> 02:38:44,894
SPEAKER_0:  So there's a lot of people that.

02:38:45,218 --> 02:38:46,014
SPEAKER_0:  could contribute.

02:38:46,466 --> 02:38:48,382
SPEAKER_0:  at different levels and I hope that.

02:38:49,506 --> 02:38:53,566
SPEAKER_0:  By the way, the other thing I like about the pod is like, I also think it helps normalize tech a little bit.

02:38:54,050 --> 02:38:55,966
SPEAKER_0:  because you just see like normal people.

02:38:56,354 --> 02:38:57,822
SPEAKER_0:  dealing with normal situations.

02:38:58,402 --> 02:38:58,974
SPEAKER_0:  Um...

02:38:59,458 --> 02:39:00,606
SPEAKER_0:  And I think that that's good.

02:39:00,962 --> 02:39:03,166
SPEAKER_0:  You know, it is a really normative place.

02:39:03,458 --> 02:39:05,790
SPEAKER_0:  It's not the caricature that it's made out to be, but...

02:39:06,242 --> 02:39:09,854
SPEAKER_0:  There is a small virulent strain of people that make it caricature-like.

02:39:10,498 --> 02:39:12,990
SPEAKER_1:  What, that's in one direction, what do you think about the whole...

02:39:13,986 --> 02:39:15,326
SPEAKER_1:  a culture of...

02:39:15,586 --> 02:39:15,966
SPEAKER_1:  Um...

02:39:16,482 --> 02:39:19,006
SPEAKER_1:  I don't know of better terms but woke activism.

02:39:19,586 --> 02:39:20,126
SPEAKER_1:  Sister of...

02:39:20,418 --> 02:39:21,310
SPEAKER_1:  Activism.

02:39:21,986 --> 02:39:26,046
SPEAKER_1:  which in some context is a powerful and important thing, but infiltrating companies.

02:39:26,370 --> 02:39:30,942
SPEAKER_0:  I'll answer this in the context of Rene Girard. So like, he says that people tend to copy each other.

02:39:31,906 --> 02:39:37,470
SPEAKER_0:  And then when they're copying each other, they're really what they're fighting, what they're doing is they're fighting over some scarce resource.

02:39:38,914 --> 02:39:39,422
SPEAKER_0:  and then

02:39:39,810 --> 02:39:41,662
SPEAKER_0:  you find a way to organize against.

02:39:42,018 --> 02:39:43,006
SPEAKER_0:  You know, the group of you.

02:39:43,938 --> 02:39:48,990
SPEAKER_0:  against a person or a thing that you think is the actual cause of all of this conflict and you try to expel them.

02:39:50,050 --> 02:39:51,998
SPEAKER_0:  The thing that wokeism doesn't understand.

02:39:52,994 --> 02:39:55,774
SPEAKER_0:  is that unless that person is truly to blame,

02:39:56,482 --> 02:39:57,822
SPEAKER_0:  The cycle just continues.

02:39:58,978 --> 02:40:00,670
SPEAKER_0:  And you know, that was a.

02:40:01,186 --> 02:40:03,070
SPEAKER_0:  That was a framework that he developed.

02:40:03,586 --> 02:40:08,862
SPEAKER_0:  you know, he's really conclusively proven to be true, and it's observable in humanity, in life.

02:40:10,018 --> 02:40:11,934
SPEAKER_0:  So these movements, I think.

02:40:12,386 --> 02:40:14,654
SPEAKER_0:  the extreme left and the extreme right.

02:40:15,842 --> 02:40:17,886
SPEAKER_0:  are trying to interpret a way.

02:40:18,562 --> 02:40:21,342
SPEAKER_0:  allow people to compete for some scarce resource.

02:40:23,458 --> 02:40:26,782
SPEAKER_0:  But I also think that in all of that, what they don't realize is that-

02:40:27,010 --> 02:40:28,766
SPEAKER_0:  they can scapegoat whoever they want.

02:40:29,346 --> 02:40:31,006
SPEAKER_0:  but it's not gonna work because.

02:40:31,682 --> 02:40:33,406
SPEAKER_0:  the bulwark of people in the middle.

02:40:33,986 --> 02:40:35,646
SPEAKER_0:  realize that it's just not true.

02:40:37,250 --> 02:40:42,526
SPEAKER_1:  Yeah, they realize, but they're still because in leadership positions, there's still momentum and they still.

02:40:42,946 --> 02:40:44,830
SPEAKER_1:  scapegoat and I continue.

02:40:45,538 --> 02:40:46,494
SPEAKER_1:  and it seems to hurt.

02:40:47,106 --> 02:40:48,981
SPEAKER_1:  the actual ability of those companies to be.

02:40:48,981 --> 02:40:53,470
SPEAKER_0:  But in fairness though, if you had to graph the effectiveness of that function,

02:40:53,730 --> 02:40:55,006
SPEAKER_0:  It's decaying rapidly.

02:40:55,490 --> 02:41:00,766
SPEAKER_0:  It's the least effective it's ever been. You're absolutely right. Being canceled five years ago was a huge deal.

02:41:01,858 --> 02:41:02,846
SPEAKER_0:  Today, I think it was.

02:41:03,202 --> 02:41:05,054
SPEAKER_0:  Jordan Peterson on your podcast.

02:41:05,570 --> 02:41:11,262
SPEAKER_0:  He said, I've been canceled and it was amazing. He said 38 times or 40. He said some number, which was a ginormous number.

02:41:11,618 --> 02:41:20,830
SPEAKER_0:  A, that he kept account of it and B, was able to classify it. I'm like, what classifier is going on in his mind where he's like, ah, that's an attempt to cancel me, but this one is not. My point is.

02:41:21,442 --> 02:41:22,526
SPEAKER_0:  Well it's clearly not working.

02:41:23,746 --> 02:41:27,358
SPEAKER_0:  And so the guy is still there and the guy is, you know, putting his view out into the world.

02:41:27,874 --> 02:41:31,710
SPEAKER_0:  And so it's not what not to judge whether what he says is right or wrong

02:41:32,450 --> 02:41:36,062
SPEAKER_0:  It's just to observe that this mechanism of action has now weakened.

02:41:36,834 --> 02:41:38,366
SPEAKER_0:  but it's weakened because it's not.

02:41:38,594 --> 02:41:40,638
SPEAKER_0:  the thing that people think is really to blame.

02:41:41,858 --> 02:41:45,214
SPEAKER_1:  You've been canceled on a small scale a few times, so that's not sm-

02:41:45,474 --> 02:41:46,590
SPEAKER_1:  Sure didn't feel small.

02:41:46,850 --> 02:41:49,214
SPEAKER_1:  Actually, it wasn't small. I'm trying to minimize.

02:41:49,954 --> 02:41:53,726
SPEAKER_1:  Did that psychologically hurt you?

02:41:54,882 --> 02:41:55,422
SPEAKER_1:  It was tough.

02:41:55,810 --> 02:41:58,238
SPEAKER_0:  In the moment, you don't know what's going on.

02:41:58,658 --> 02:41:59,326
SPEAKER_0:  But I...

02:41:59,650 --> 02:42:01,438
SPEAKER_0:  would like to thank a certain CEO.

02:42:02,018 --> 02:42:03,326
SPEAKER_0:  of a certain well-known company.

02:42:05,026 --> 02:42:05,790
SPEAKER_0:  and he said

02:42:06,082 --> 02:42:06,910
SPEAKER_0:  Meeh.

02:42:08,034 --> 02:42:09,374
SPEAKER_0:  Basically like a...

02:42:10,082 --> 02:42:11,326
SPEAKER_0:  a step-by-step manual.

02:42:12,610 --> 02:42:13,735
SPEAKER_0:  Uh, and uh-

02:42:13,735 --> 02:42:15,235
SPEAKER_1:  Does it involve mushrooms? No.

02:42:15,235 --> 02:42:17,950
SPEAKER_0:  No, and he was right.

02:42:18,882 --> 02:42:19,230
SPEAKER_0:  You know?

02:42:19,874 --> 02:42:21,118
SPEAKER_0:  The storm passed and life went on.

02:42:21,858 --> 02:42:28,350
SPEAKER_1:  Is it, I don't know if you can share the list of steps, but is the fundamental core ideas that just.

02:42:28,898 --> 02:42:29,694
SPEAKER_1:  Life goes on.

02:42:30,498 --> 02:42:33,790
SPEAKER_0:  The core fundamental idea is like, you need to be willing.

02:42:35,074 --> 02:42:35,806
SPEAKER_0:  and able.

02:42:36,354 --> 02:42:37,342
SPEAKER_0:  to apologize.

02:42:38,402 --> 02:42:39,838
SPEAKER_0:  what is in your control.

02:42:40,418 --> 02:42:41,982
SPEAKER_0:  but not for other people's mistakes.

02:42:43,394 --> 02:42:44,478
SPEAKER_0:  Your mistakes, yes.

02:42:44,738 --> 02:42:46,302
SPEAKER_0:  and if you feel like there's something.

02:42:46,850 --> 02:42:48,766
SPEAKER_0:  then you should take accountability of that.

02:42:50,530 --> 02:42:52,542
SPEAKER_0:  to apologize for somebody else.

02:42:53,122 --> 02:42:54,686
SPEAKER_0:  something that they want to hear.

02:42:55,938 --> 02:42:57,374
SPEAKER_0:  isn't going to solve anything.

02:42:58,114 --> 02:43:01,406
SPEAKER_1:  Yeah, there's something about apologies if you do them. They should be.

02:43:01,858 --> 02:43:03,838
SPEAKER_1:  Authentic to what you actually want to say

02:43:04,450 --> 02:43:07,006
SPEAKER_1:  versus what somebody else wants to hear.

02:43:08,066 --> 02:43:09,406
SPEAKER_1:  Otherwise it doesn't ring true.

02:43:09,954 --> 02:43:13,182
SPEAKER_0:  Yeah, and people can see through that. And people can see through it. And also,

02:43:13,474 --> 02:43:15,326
SPEAKER_0:  What people see through is not just the fact that

02:43:15,682 --> 02:43:17,598
SPEAKER_0:  you know, your apology was somewhat hollow.

02:43:18,114 --> 02:43:21,790
SPEAKER_0:  but also that this entire majority of people now walked away. The mob was like, okay, thanks.

02:43:22,946 --> 02:43:23,614
SPEAKER_0:  And then people are like.

02:43:24,514 --> 02:43:25,438
SPEAKER_0:  Oh, so you didn't care at all.

02:43:25,794 --> 02:43:26,302
SPEAKER_0:  This is like.

02:43:27,234 --> 02:43:29,310
SPEAKER_0:  And so then it reflects more probably on them.

02:43:30,050 --> 02:43:30,462
SPEAKER_0:  Yeah.

02:43:32,706 --> 02:43:37,214
SPEAKER_1:  I know you said you don't like to give advice, but what advice would you give to a young person?

02:43:37,890 --> 02:43:38,878
SPEAKER_1:  You've lived.

02:43:39,106 --> 02:43:46,302
SPEAKER_1:  an incredible life from very humble beginnings, difficult childhood, and you're one of the most successful people in the world. So what advice?

02:43:46,914 --> 02:43:49,214
SPEAKER_1:  I mean, a lot of people look to you for inspiration.

02:43:50,690 --> 02:43:53,694
SPEAKER_1:  kids in high school or early college that are not.

02:43:54,018 --> 02:43:54,686
SPEAKER_1:  I'm doing good.

02:43:55,202 --> 02:43:56,190
SPEAKER_1:  Or, um...

02:43:56,706 --> 02:43:57,854
SPEAKER_1:  are trying to figure out.

02:43:59,266 --> 02:44:03,454
SPEAKER_1:  basically what to do when they have complete doubt in themselves.

02:44:04,162 --> 02:44:05,598
SPEAKER_1:  What advice would you give them?

02:44:12,546 --> 02:44:13,950
SPEAKER_0:  It is really important.

02:44:14,274 --> 02:44:15,614
SPEAKER_0:  that if somebody...

02:44:16,258 --> 02:44:17,502
SPEAKER_0:  that you respect and I'm gonna.

02:44:17,826 --> 02:44:21,310
SPEAKER_0:  just for the purpose of this, put myself in that bucket. And if you're listening to this.

02:44:22,530 --> 02:44:22,974
SPEAKER_0:  Um.

02:44:23,266 --> 02:44:24,830
SPEAKER_0:  I wish somebody had told this to me.

02:44:26,434 --> 02:44:26,782
SPEAKER_0:  Um.

02:44:27,170 --> 02:44:28,286
SPEAKER_0:  We are all equal.

02:44:30,690 --> 02:44:36,158
SPEAKER_0:  and you will fight this demon inside you that says you are less than

02:44:36,578 --> 02:44:37,694
SPEAKER_0:  lot of other people.

02:44:38,690 --> 02:44:41,950
SPEAKER_0:  for reasons that will be hard to see until you're much, much older.

02:44:43,586 --> 02:44:44,350
SPEAKER_0:  And so.

02:44:44,738 --> 02:44:46,270
SPEAKER_0:  you have to find.

02:44:47,522 --> 02:44:48,094
SPEAKER_0:  either.

02:44:48,322 --> 02:44:51,070
SPEAKER_0:  a set of people far, far away, like what I did.

02:44:52,194 --> 02:44:54,782
SPEAKER_0:  or one or two people really really close to you?

02:44:56,130 --> 02:44:57,246
SPEAKER_0:  Or maybe it's both?

02:44:58,370 --> 02:45:00,926
SPEAKER_0:  that will remind you in key moments of your life.

02:45:01,218 --> 02:45:02,014
SPEAKER_0:  that that is true.

02:45:02,402 --> 02:45:03,070
SPEAKER_0:  Otherwise...

02:45:03,874 --> 02:45:05,150
SPEAKER_0:  You will give in.

02:45:05,858 --> 02:45:06,334
SPEAKER_0:  to that.

02:45:06,658 --> 02:45:07,102
SPEAKER_0:  Peace.

02:45:08,354 --> 02:45:09,086
SPEAKER_0:  And...

02:45:09,602 --> 02:45:10,622
SPEAKER_0:  It's not the end of the world.

02:45:11,042 --> 02:45:12,350
SPEAKER_0:  and you'll recover from it.

02:45:12,898 --> 02:45:14,238
SPEAKER_0:  I've made a lot of mistakes.

02:45:15,682 --> 02:45:17,470
SPEAKER_0:  but it requires a lot of energy.

02:45:18,306 --> 02:45:21,662
SPEAKER_0:  And sometimes it's just easier to just stop and give up.

02:45:23,170 --> 02:45:28,606
SPEAKER_0:  So I think that if you're starting out in the world, if you've been lucky to have a wonderful life and you had wonderful parents,

02:45:29,474 --> 02:45:35,294
SPEAKER_0:  Man, you should go and give them a huge hug because they did you such a service that most folks don't do to most kids.

02:45:35,714 --> 02:45:36,702
SPEAKER_0:  unfortunately.

02:45:37,090 --> 02:45:38,718
SPEAKER_0:  And it's not the fault of these parents.

02:45:39,618 --> 02:45:41,662
SPEAKER_0:  But it's just tough. Life is tough.

02:45:42,498 --> 02:45:43,390
SPEAKER_0:  So give him a kiss.

02:45:44,034 --> 02:45:45,662
SPEAKER_0:  and then figure out a way where you can just.

02:45:45,890 --> 02:45:50,846
SPEAKER_0:  do work that validates you and where you feel like you're developing some kind of mastery.

02:45:51,362 --> 02:45:53,022
SPEAKER_0:  Who cares what anybody else thinks about it?

02:45:53,922 --> 02:45:56,670
SPEAKER_0:  Just do it because it feels good. Just do it because you like to get good at something.

02:45:57,634 --> 02:45:59,774
SPEAKER_0:  But if you're not one of those lucky people...

02:46:01,570 --> 02:46:01,982
SPEAKER_0:  Um.

02:46:02,338 --> 02:46:04,990
SPEAKER_0:  You can believe in your friends or you can just believe in me.

02:46:05,826 --> 02:46:07,806
SPEAKER_0:  I'm telling you, preserve optionality.

02:46:08,482 --> 02:46:10,526
SPEAKER_0:  How you do that is by regulating.

02:46:11,586 --> 02:46:13,822
SPEAKER_0:  your reactions to things.

02:46:15,874 --> 02:46:21,438
SPEAKER_0:  and your reactions are going to be largely guided in moments where you think that you are not the same as everybody else.

02:46:21,762 --> 02:46:24,702
SPEAKER_0:  and specifically that you are less than those people and you're not.

02:46:25,506 --> 02:46:26,174
SPEAKER_0:  So just.

02:46:26,594 --> 02:46:29,790
SPEAKER_0:  save this part of this podcast and just play it.

02:46:30,050 --> 02:46:31,550
SPEAKER_0:  on a loop if you need to.

02:46:32,450 --> 02:46:32,894
SPEAKER_0:  Um...

02:46:33,154 --> 02:46:35,838
SPEAKER_0:  But that is my biggest learning is I am.

02:46:36,450 --> 02:46:36,862
SPEAKER_0:  equal.

02:46:37,154 --> 02:46:39,038
SPEAKER_0:  I'm the same as all these other people.

02:46:39,522 --> 02:46:43,294
SPEAKER_0:  And you can imagine what that means to me to go out in the world to see people and think

02:46:43,842 --> 02:46:46,078
SPEAKER_0:  I'm the same as this person. I'm as good as them.

02:46:47,362 --> 02:46:50,846
SPEAKER_0:  And you could imagine what you're probably thinking of what I'm thinking is not that thing.

02:46:51,874 --> 02:46:54,974
SPEAKER_0:  You're probably thinking, man, this guy, yeah, this guy, I'm so much better.

02:46:55,234 --> 02:46:55,710
SPEAKER_0:  No.

02:46:56,546 --> 02:46:57,918
SPEAKER_0:  I am fighting this thing.

02:46:59,650 --> 02:47:00,478
SPEAKER_0:  all the time.

02:47:01,538 --> 02:47:03,806
SPEAKER_1:  Well, I've also met a bunch of folks.

02:47:04,386 --> 02:47:04,926
SPEAKER_1:  cool.

02:47:05,186 --> 02:47:08,894
SPEAKER_1:  I think is a counter reaction to that once they become successful.

02:47:09,570 --> 02:47:12,766
SPEAKER_1:  they start developing a philosophy that they are better.

02:47:13,058 --> 02:47:15,774
SPEAKER_1:  or even some people are better than others.

02:47:16,418 --> 02:47:17,566
SPEAKER_1:  which I understand.

02:47:18,082 --> 02:47:20,830
SPEAKER_1:  You know, there's LeBron James versus other people and so on.

02:47:21,314 --> 02:47:23,070
SPEAKER_1:  But I always really resisted that.

02:47:23,714 --> 02:47:24,222
SPEAKER_1:  thought.

02:47:25,154 --> 02:47:26,279
SPEAKER_1:  because I feel like it's a...

02:47:26,279 --> 02:47:27,038
SPEAKER_0:  Whistle

02:47:27,714 --> 02:47:29,310
SPEAKER_0:  They have mastery in a thing.

02:47:29,730 --> 02:47:31,070
SPEAKER_0:  that they've fallen in love with.

02:47:32,386 --> 02:47:34,718
SPEAKER_0:  I'm trying to develop mastery in a thing that I love.

02:47:35,906 --> 02:47:39,070
SPEAKER_0:  You know, I love investing. It's like solving puzzles.

02:47:39,970 --> 02:47:40,414
SPEAKER_0:  I love that.

02:47:40,962 --> 02:47:42,846
SPEAKER_0:  I love trying to develop mastery in poker.

02:47:43,842 --> 02:47:44,606
SPEAKER_0:  I really love that.

02:47:45,346 --> 02:47:45,662
SPEAKER_0:  Um.

02:47:45,986 --> 02:47:49,150
SPEAKER_0:  I'm learning how to be a parent to a teenager because I finally have one.

02:47:50,402 --> 02:47:52,158
SPEAKER_0:  It's all new stuff to me and I'm learning.

02:47:52,994 --> 02:47:53,470
SPEAKER_0:  Um...

02:47:55,202 --> 02:47:56,094
SPEAKER_0:  That's what it's all about.

02:47:57,346 --> 02:48:02,654
SPEAKER_1:  Yeah, so you don't want to think you're lesser than, and you don't want to think you're better than, because those...

02:48:02,946 --> 02:48:04,071
SPEAKER_1:  both lead you astray.

02:48:04,071 --> 02:48:05,982
SPEAKER_0:  I've never thought I was better than.

02:48:06,594 --> 02:48:08,254
SPEAKER_0:  I manifested better than.

02:48:09,666 --> 02:48:11,966
SPEAKER_0:  because I was trying to compensate for feeling less than.

02:48:13,314 --> 02:48:18,270
SPEAKER_0:  My goal is just to feel like everybody else feels on the presumption that everybody had like a normal life.

02:48:19,682 --> 02:48:22,590
SPEAKER_1:  Given your nickname is The Dictator, do you trust yourself with power?

02:48:22,850 --> 02:48:23,486
SPEAKER_1:  Like if I...

02:48:23,874 --> 02:48:26,654
SPEAKER_1:  if the world gave you absolute power for a month.

02:48:29,506 --> 02:48:30,526
SPEAKER_0:  No, because I think that.

02:48:30,882 --> 02:48:32,446
SPEAKER_0:  You know, I'm still riddled with bias.

02:48:32,834 --> 02:48:35,230
SPEAKER_0:  I don't deserve that position.

02:48:35,554 --> 02:48:37,598
SPEAKER_0:  and I would not want that weight on my shoulders.

02:48:38,946 --> 02:48:41,534
SPEAKER_0:  I had a spot actually where...

02:48:42,402 --> 02:48:43,134
SPEAKER_0:  It was a very...

02:48:44,514 --> 02:48:46,206
SPEAKER_0:  important and big poker game.

02:48:47,330 --> 02:48:49,694
SPEAKER_0:  and it was a spot where I was in the pot.

02:48:50,242 --> 02:48:50,782
SPEAKER_0:  and it was.

02:48:51,106 --> 02:48:52,990
SPEAKER_0:  A really large pot is like a million dollar pot.

02:48:53,890 --> 02:48:54,814
SPEAKER_0:  and uh

02:48:55,394 --> 02:48:59,134
SPEAKER_0:  I had to make a ruling and the ruling was in my favor.

02:49:01,538 --> 02:49:01,918
SPEAKER_0:  I was.

02:49:02,178 --> 02:49:03,198
SPEAKER_0:  just beside myself.

02:49:04,962 --> 02:49:10,526
SPEAKER_0:  I don't play, I play for the challenge. I like to get pushed to the limit of my capabilities. I want to see

02:49:11,522 --> 02:49:11,966
SPEAKER_0:  good night.

02:49:12,482 --> 02:49:14,398
SPEAKER_0:  Think at the same level of these folks.

02:49:14,722 --> 02:49:17,214
SPEAKER_0:  You know, because these guys are all experts, they're all pros.

02:49:18,466 --> 02:49:20,606
SPEAKER_0:  and I get enormous joy from that challenge.

02:49:22,402 --> 02:49:22,846
SPEAKER_0:  and

02:49:23,234 --> 02:49:23,966
SPEAKER_0:  I like to win.

02:49:24,258 --> 02:49:25,854
SPEAKER_0:  but I like to win just a small amount.

02:49:26,722 --> 02:49:27,262
SPEAKER_0:  You know what I mean?

02:49:27,970 --> 02:49:29,758
SPEAKER_0:  and then I never want it to win in that way.

02:49:30,498 --> 02:49:33,726
SPEAKER_0:  but because it was my game, I had to make this call.

02:49:34,594 --> 02:49:36,638
SPEAKER_0:  on a million dollar pot and I wanted to just

02:49:37,506 --> 02:49:38,110
SPEAKER_0:  Shoot myself.

02:49:38,562 --> 02:49:41,246
SPEAKER_0:  I just was like, this is gross and disgusting.

02:49:41,538 --> 02:49:42,942
SPEAKER_0:  and he was a complete gentleman.

02:49:44,386 --> 02:49:49,261
SPEAKER_0:  made it even worse. I'm sorry. So I do not want absolute power.

02:49:49,261 --> 02:49:53,342
SPEAKER_1:  Those are the people you do want to have power Is the ones that don't want it

02:49:53,762 --> 02:49:56,414
SPEAKER_1:  which is a weird system to have.

02:49:56,994 --> 02:49:59,934
SPEAKER_1:  because then you in that kind of system don't get the leaders.

02:50:00,962 --> 02:50:02,174
SPEAKER_1:  that you should have.

02:50:02,754 --> 02:50:06,942
SPEAKER_1:  Cause the ones that want power aren't the ones that should have power. That's a weird, weird system.

02:50:07,650 --> 02:50:11,582
SPEAKER_1:  What do you think, let me sneak this question in there, what do you think is the meaning of life?

02:50:13,506 --> 02:50:13,822
SPEAKER_1:  I don't.

02:50:15,074 --> 02:50:15,742
SPEAKER_1:  Why are we here?

02:50:16,962 --> 02:50:19,422
SPEAKER_1:  Give a look up at the stars and think about like the big...

02:50:20,994 --> 02:50:21,886
SPEAKER_1:  Why question?

02:50:23,810 --> 02:50:25,470
SPEAKER_0:  I think that it's a chance to just

02:50:26,786 --> 02:50:27,646
SPEAKER_0:  Enjoy the ride!

02:50:29,506 --> 02:50:30,974
SPEAKER_0:  I don't think it really like.

02:50:32,066 --> 02:50:34,686
SPEAKER_0:  I don't believe in this idea of legacy that much.

02:50:35,842 --> 02:50:36,766
SPEAKER_0:  I think it's a real.

02:50:37,506 --> 02:50:37,822
SPEAKER_0:  Trap.

02:50:38,946 --> 02:50:39,774
SPEAKER_1:  So do you think?

02:50:40,066 --> 02:50:42,366
SPEAKER_1:  You'll be forgotten by history. I hope so.

02:50:42,978 --> 02:50:44,126
SPEAKER_0:  I really, really hope so.

02:50:44,738 --> 02:50:48,638
SPEAKER_0:  Because if you think about it, there are two or three people that are remembered for positive things.

02:50:48,994 --> 02:50:50,654
SPEAKER_0:  everybody else it's all negative things.

02:50:51,234 --> 02:50:54,910
SPEAKER_0:  and the likelihood that you'll be remembered for a positive thing.

02:50:55,234 --> 02:50:58,750
SPEAKER_0:  is harder and harder and harder, and so the surface area of being remembered

02:50:59,202 --> 02:50:59,934
SPEAKER_0:  is negative.

02:51:00,418 --> 02:51:01,214
SPEAKER_0:  And then the second.

02:51:01,794 --> 02:51:02,974
SPEAKER_0:  What will it matter? I'll be gone.

02:51:04,514 --> 02:51:05,886
SPEAKER_0:  I really just wanna like...

02:51:06,530 --> 02:51:07,198
SPEAKER_0:  Have fun.

02:51:07,714 --> 02:51:08,702
SPEAKER_0:

02:51:09,442 --> 02:51:10,014
SPEAKER_0:  Learn.

02:51:11,042 --> 02:51:11,582
SPEAKER_0:  Get better.

02:51:12,866 --> 02:51:15,102
SPEAKER_0:  But I want to reward myself.

02:51:16,002 --> 02:51:17,086
SPEAKER_0:  by feeling like...

02:51:18,114 --> 02:51:18,814
SPEAKER_0:  That was awesome.

02:51:19,490 --> 02:51:21,534
SPEAKER_0:  I've told this story many times and

02:51:22,050 --> 02:51:23,038
SPEAKER_0:  I have put again.

02:51:23,426 --> 02:51:25,278
SPEAKER_0:  my own narrative fallacy on top of this, but.

02:51:26,818 --> 02:51:27,966
SPEAKER_0:  You know, Steve Jobs is.

02:51:28,258 --> 02:51:31,582
SPEAKER_0:  sister wrote this you know opit in the New York Times when he died

02:51:32,162 --> 02:51:35,358
SPEAKER_0:  And she ends it by saying his last words were, Oh, wow. Oh, wow. Oh, wow.

02:51:36,578 --> 02:51:38,078
SPEAKER_0:  That seems like an awesome way to die.

02:51:38,818 --> 02:51:42,046
SPEAKER_0:  You're surrounded by your friends and family, not the fact that he died obviously.

02:51:42,594 --> 02:51:44,670
SPEAKER_0:  but in a moment where what I read into it...

02:51:45,218 --> 02:51:46,270
SPEAKER_0:  Was your family there?

02:51:48,386 --> 02:51:49,278
SPEAKER_0:  Maybe you thought about.

02:51:50,690 --> 02:51:52,670
SPEAKER_0:  all the cool shit that you were able to do.

02:51:54,594 --> 02:51:57,182
SPEAKER_0:  And then, you know, you just started the simulation all over again.

02:51:58,082 --> 02:51:58,686
SPEAKER_0:  And so.

02:51:58,978 --> 02:52:03,166
SPEAKER_0:  Yeah. Just on the off chance that that's true, I don't want to take this thing too seriously.

02:52:04,322 --> 02:52:05,758
SPEAKER_0:  You know what I mean? Enjoy it!

02:52:06,114 --> 02:52:07,166
SPEAKER_1:  so you're not afraid of it.

02:52:07,458 --> 02:52:07,902
SPEAKER_0:  The end.

02:52:11,010 --> 02:52:12,190
SPEAKER_0:  Couldn't tomorrow, couldn't right now.

02:52:13,730 --> 02:52:17,502
SPEAKER_1:  So every day you can go and you're happy. You're happy with the things you've done.

02:52:18,722 --> 02:52:21,438
SPEAKER_0:  You know, there are obviously things I want to do that I haven't done.

02:52:23,202 --> 02:52:23,582
SPEAKER_0:  Um.

02:52:24,194 --> 02:52:26,398
SPEAKER_0:  but there are no gaping things.

02:52:27,714 --> 02:52:29,566
SPEAKER_0:  I've really, really, really been in love.

02:52:32,002 --> 02:52:32,574
SPEAKER_0:  Total gift.

02:52:33,570 --> 02:52:36,734
SPEAKER_0:  There have been moments where I've really, really felt.

02:52:37,954 --> 02:52:38,750
SPEAKER_0:  like everybody else.

02:52:41,058 --> 02:52:41,950
SPEAKER_0:  There have been moments where I've.

02:52:42,210 --> 02:52:43,646
SPEAKER_0:  Deep, deep, deep joy.

02:52:44,418 --> 02:52:45,630
SPEAKER_0:  and connection with my children.

02:52:46,754 --> 02:52:50,142
SPEAKER_0:  There are moments where I've had incredible giggling fun with my friends.

02:52:51,362 --> 02:52:56,126
SPEAKER_0:  There's moments where I've been able to enjoy really incredible experiences, wine, food, all that stuff.

02:52:57,602 --> 02:52:58,142
SPEAKER_0:  I mean

02:52:58,658 --> 02:53:02,302
SPEAKER_0:  What more do you want? I could keep asking for more.

02:53:03,106 --> 02:53:05,118
SPEAKER_0:  but I would just be a really.

02:53:06,018 --> 02:53:07,710
SPEAKER_0:  Proppy human being at some point.

02:53:08,642 --> 02:53:09,886
SPEAKER_0:  You know what I mean? It's enough.

02:53:10,146 --> 02:53:10,526
SPEAKER_0:  Yeah.

02:53:11,170 --> 02:53:12,318
SPEAKER_0:  Yeah. Yeah.

02:53:12,866 --> 02:53:13,502
SPEAKER_0:  It's enough.

02:53:13,634 --> 02:53:17,877
SPEAKER_1:  This life is pretty beautiful if you allow yourself to see it.

02:53:17,877 --> 02:53:20,542
SPEAKER_0:  It's really great and it's better than it's ever been.

02:53:21,506 --> 02:53:21,982
SPEAKER_0:  Um...

02:53:22,562 --> 02:53:24,222
SPEAKER_0:  For most of us, actually.

02:53:25,218 --> 02:53:27,486
SPEAKER_0:  Pretty nice. And all of the, like, you know.

02:53:27,906 --> 02:53:29,278
SPEAKER_0:  Millennials and Gen Zs?

02:53:29,986 --> 02:53:31,006
SPEAKER_0:  You're about to get...

02:53:32,322 --> 02:53:33,950
SPEAKER_0:  boatload of money from your parents.

02:53:35,874 --> 02:53:37,886
SPEAKER_0:  And you better figure out.

02:53:39,266 --> 02:53:41,598
SPEAKER_0:  how to be happy before you get that money.

02:53:43,746 --> 02:53:46,302
SPEAKER_0:  because otherwise you will.

02:53:46,562 --> 02:53:46,942
SPEAKER_0:  be.

02:53:47,106 --> 02:53:47,774
SPEAKER_1:  miserable.

02:53:49,314 --> 02:53:50,718
SPEAKER_1:  get a lot of Dairy Queen.

02:53:51,490 --> 02:53:53,694
SPEAKER_1:  No, that only worked the first time.

02:53:54,050 --> 02:53:59,454
SPEAKER_0:  I worked two times in grade five and grade six. My God, that next year, flex, I work my ass off.

02:54:00,066 --> 02:54:05,854
SPEAKER_0:  But I could never bring myself to ask her. And then she did it. And I was like, man, this woman's a Miss Bruni.

02:54:06,242 --> 02:54:06,942
SPEAKER_0:  The moon was a gem.

02:54:07,170 --> 02:54:07,838
SPEAKER_1:  Yeah.

02:54:08,130 --> 02:54:09,822
SPEAKER_1:  but the third time it faded.

02:54:10,626 --> 02:54:12,062
SPEAKER_1:  Isn't that the sad thing about life?

02:54:12,578 --> 02:54:13,726
SPEAKER_1:  You know.

02:54:13,986 --> 02:54:16,126
SPEAKER_1:  The finiteness of it, the scarcity of it.

02:54:17,666 --> 02:54:32,190
SPEAKER_1:  Without that, we perhaps wouldn't ice cream wouldn't be so damn delicious. Jamat, the incredible human. Um, I definitely recommend that people listen to on all, all platforms. Just we're very lucky to be able to get your wisdom. I agree with the.

02:54:32,706 --> 02:54:36,478
SPEAKER_1:  I've talked a lot about you with Andre Capati, who's somebody I really respect.

02:54:36,994 --> 02:54:37,598
SPEAKER_1:  and he just...

02:54:38,178 --> 02:54:50,206
SPEAKER_1:  loves the shit out of you in how much you, how deeply you understand the world. That's a huge honor. He's an incredible human being, so that's- On a different, yeah, speaking of semi-colons, there's some human beings that understand everything.

02:54:50,946 --> 02:54:51,294
SPEAKER_1:  Very-

02:54:51,650 --> 02:54:54,878
SPEAKER_1:  low level and at the very high level and those people are also

02:54:55,490 --> 02:54:55,966
SPEAKER_1:  Um...

02:54:56,482 --> 02:55:02,238
SPEAKER_1:  Very rare. So it's a huge honor and also a huge honor that you would be so kind to me.

02:55:02,658 --> 02:55:04,094
SPEAKER_1:  just like in subtle ways.

02:55:04,514 --> 02:55:06,462
SPEAKER_1:  offline that you would

02:55:06,754 --> 02:55:07,838
SPEAKER_1:  make me feel like I'm-

02:55:08,898 --> 02:55:09,630
SPEAKER_1:  worthwhile.

02:55:09,762 --> 02:55:12,702
SPEAKER_0:  Can I just say something as just a layman listener?

02:55:13,634 --> 02:55:13,982
SPEAKER_0:  Um...

02:55:14,594 --> 02:55:15,486
SPEAKER_0:  what you do.

02:55:15,874 --> 02:55:16,382
SPEAKER_0:  Just so.

02:55:16,610 --> 02:55:17,822
SPEAKER_0:  I could give you my version.

02:55:18,754 --> 02:55:19,294
SPEAKER_0:  is that

02:55:20,002 --> 02:55:21,246
SPEAKER_0:  You take things.

02:55:21,922 --> 02:55:22,686
SPEAKER_0:  and people.

02:55:23,138 --> 02:55:24,542
SPEAKER_0:  So ideas and people.

02:55:25,634 --> 02:55:27,262
SPEAKER_0:  that are mostly behind a rope.

02:55:28,674 --> 02:55:30,078
SPEAKER_0:  and you demystify it.

02:55:31,330 --> 02:55:32,574
SPEAKER_0:  and what that does.

02:55:32,930 --> 02:55:34,046
SPEAKER_0:  for all of us is.

02:55:34,306 --> 02:55:35,774
SPEAKER_0:  It makes me feel...

02:55:36,834 --> 02:55:37,150
SPEAKER_0:  like.

02:55:38,914 --> 02:55:40,094
SPEAKER_0:  I can be a part of that.

02:55:41,250 --> 02:55:45,950
SPEAKER_0:  And that's a really inspiring thing because you're not giving advice, you're not telling us how to solve the problem.

02:55:46,658 --> 02:55:49,150
SPEAKER_0:  but you're allowing it to be understood.

02:55:49,602 --> 02:55:51,070
SPEAKER_0:  in a way that's really...

02:55:52,130 --> 02:55:52,894
SPEAKER_0:  Accessible?

02:55:53,954 --> 02:55:56,382
SPEAKER_0:  and then you're intellectually curious in ways that...

02:55:56,834 --> 02:56:01,374
SPEAKER_0:  you know, some of us would never expect that we were and then you kind of end up in this rabbit hole.

02:56:02,082 --> 02:56:05,566
SPEAKER_0:  And then you have the courage to go and talk to people that are really all over the map.

02:56:06,434 --> 02:56:08,638
SPEAKER_0:  Like for example, like I when I saw your

02:56:09,602 --> 02:56:12,254
SPEAKER_0:  Jordan Peterson example like

02:56:12,898 --> 02:56:17,598
SPEAKER_0:  you went there, like you talked about Nazism, and I was just like, man, this is a complicated.

02:56:18,146 --> 02:56:20,190
SPEAKER_0:  argument these guys are going to tackle and

02:56:20,994 --> 02:56:23,198
SPEAKER_0:  It's just, it's really, um...

02:56:23,810 --> 02:56:27,550
SPEAKER_0:  really impressive, so I have an enormous amount of respect for what you do. I think it's very

02:56:28,002 --> 02:56:30,174
SPEAKER_0:  to do what you do so consistently.

02:56:30,850 --> 02:56:34,590
SPEAKER_0:  And so I look at you as somebody I respect because it's a

02:56:35,522 --> 02:56:36,510
SPEAKER_0:  It just shows like...

02:56:37,442 --> 02:56:39,230
SPEAKER_0:  somebody who's immersed in something and who's...

02:56:40,834 --> 02:56:42,686
SPEAKER_0:  special. So thank you for including me in this.

02:56:42,914 --> 02:56:52,894
SPEAKER_1:  I'm gonna play that clip to myself privately over and over just when I feel low and self-critical about myself. Chamath, thank you so much, brother. This is incredible. Thanks, man.

02:56:54,018 --> 02:56:57,150
SPEAKER_1:  Thank you for listening to this conversation My name is Delhi rain for Jamat Bal boarding Hello to all fit des extraordinaires

02:56:57,858 --> 02:56:58,942
SPEAKER_1:  to support this podcast.

02:56:59,170 --> 02:57:01,374
SPEAKER_1:  Please check out our sponsors in the description.

02:57:01,858 --> 02:57:02,334
SPEAKER_1:  And now.

02:57:02,594 --> 02:57:04,894
SPEAKER_1:  Let me leave you with some words from Jonathan Swift.

02:57:05,858 --> 02:57:08,702
SPEAKER_1:  A wise person should have money in their head.

02:57:09,282 --> 02:57:10,686
SPEAKER_1:  but not in their heart.

02:57:11,746 --> 02:57:13,502
SPEAKER_1:  Thank you for listening and hope to see you.

02:57:13,762 --> 02:57:14,270
SPEAKER_1:  next time.
