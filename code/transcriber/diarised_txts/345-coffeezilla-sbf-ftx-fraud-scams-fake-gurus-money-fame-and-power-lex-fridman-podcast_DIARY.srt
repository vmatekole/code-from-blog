00:00:00,066 --> 00:00:03,742
SPEAKER_1:  Do you think he is incompetent, insane, or evil?

00:00:06,178 --> 00:00:08,926
SPEAKER_1:  The following is a conversation with Coffeezilla.

00:00:09,314 --> 00:00:13,790
SPEAKER_1:  an investigator and journalist exposing frauds, scams, and fake gurus.

00:00:14,210 --> 00:00:17,886
SPEAKER_1:  He's one of the most important journalistic voices we have working today.

00:00:18,306 --> 00:00:22,462
SPEAKER_1:  both in terms of his integrity and fearlessness in the pursuit of truth.

00:00:23,362 --> 00:00:25,214
SPEAKER_1:  Please follow, watch, and support his work.

00:00:25,538 --> 00:00:28,062
SPEAKER_1:  at youtube.com slash coffeezilla.

00:00:28,706 --> 00:00:31,262
SPEAKER_1:  This is the Lex Friedman Podcast. Thanks for watching.

00:00:31,490 --> 00:00:33,854
SPEAKER_1:  please check out our sponsors in the description.

00:00:34,338 --> 00:00:35,710
SPEAKER_1:  And now, dear friends.

00:00:36,002 --> 00:00:36,766
SPEAKER_1:  Here's coffee.

00:00:37,026 --> 00:00:37,406
SPEAKER_1:  So long.

00:00:38,594 --> 00:00:39,678
SPEAKER_1:  How do you like your coffee?

00:00:40,322 --> 00:00:41,534
SPEAKER_1:  Dark and soul crushing.

00:00:42,146 --> 00:00:44,222
SPEAKER_1:  That was the number one question on the internet.

00:00:44,706 --> 00:00:50,206
SPEAKER_1:  Do you like your coffee to reverberate deeply through the worst of human nature? Is that how you drink your coffee?

00:00:50,434 --> 00:00:53,566
SPEAKER_0:  I've gone through a lot of phases on coffee. I used to...

00:00:53,954 --> 00:00:55,326
SPEAKER_0:  In college I would go.

00:00:55,618 --> 00:00:57,726
SPEAKER_0:  super deep into, you know.

00:00:58,050 --> 00:01:02,942
SPEAKER_0:  Grinding fresh beans all of that kind of stuff water temperature exactly right

00:01:03,618 --> 00:01:07,134
SPEAKER_0:  And then I hit a phase where I was just, it was the maintenance dose.

00:01:07,714 --> 00:01:10,910
SPEAKER_0:  Then I went to like espresso because I could get a lot more in.

00:01:11,138 --> 00:01:15,134
SPEAKER_0:  And now I go through phases of like, sometimes I like it with a little oat milk.

00:01:15,650 --> 00:01:18,275
SPEAKER_0:  Sometimes a little half and half in sugar. Have you got some candle ready just don quantity one minute a day for the

00:01:18,275 --> 00:01:19,025
SPEAKER_1:  soft in your old age.

00:01:19,025 --> 00:01:20,926
SPEAKER_0:  I've gone a little- I- I have.

00:01:21,378 --> 00:01:27,102
SPEAKER_0:  But hey, if I'm doing a SBF interview, it's black that day, nothing less. Yeah. The lights go down.

00:01:27,362 --> 00:01:31,678
SPEAKER_1:  What do you actually do in those situations, like leading up to a show, do you get...

00:01:31,970 --> 00:01:32,446
SPEAKER_1:  hyped up.

00:01:32,674 --> 00:01:36,958
SPEAKER_1:  Like how do you put yourself in the right mind space to explore some of these really difficult topics?

00:01:39,042 --> 00:01:44,446
SPEAKER_0:  I think a lot of it's preparation and then once it happens, it's mostly fueled by

00:01:44,802 --> 00:01:46,142
SPEAKER_0:  Sort of adrenaline, I would say.

00:01:46,370 --> 00:01:47,038
SPEAKER_0:  Um...

00:01:47,970 --> 00:01:50,526
SPEAKER_0:  I really deeply care about getting to like.

00:01:50,818 --> 00:01:53,502
SPEAKER_0:  the root cause of some of these issues because I think

00:01:53,890 --> 00:01:57,022
SPEAKER_0:  So often people in positions of power are led off the hook.

00:01:57,634 --> 00:01:58,174
SPEAKER_0:  So.

00:01:58,722 --> 00:02:01,854
SPEAKER_0:  I really care about holding their feet to the fire and it translates into like...

00:02:02,786 --> 00:02:06,430
SPEAKER_0:  a lot of energy the day of. So I never find myself like funny enough.

00:02:07,202 --> 00:02:10,590
SPEAKER_0:  I usually drink a lot of caffeine leading up to the interview.

00:02:10,946 --> 00:02:15,710
SPEAKER_0:  And then I try to drink like minimum the day of because I have so much adrenaline, I don't want to be like.

00:02:16,066 --> 00:02:17,918
SPEAKER_0:  hyper stimulated. I have to say.

00:02:18,498 --> 00:02:25,022
SPEAKER_1:  of all the recent guests I've had, the energy you had when you walked into the door.

00:02:25,186 --> 00:02:27,774
SPEAKER_0:  I'm excited! Are people not excited to be here?

00:02:28,706 --> 00:02:33,343
SPEAKER_0:  I don't know. I think they're scared. I think they're scared. I don't know if you know.

00:02:33,343 --> 00:02:35,806
SPEAKER_1:  down the door or something you were very excited.

00:02:36,386 --> 00:02:37,822
SPEAKER_1:  Like that just energy.

00:02:38,050 --> 00:02:41,630
SPEAKER_1:  It was terrifying because I'm terrified of social interaction anyway

00:02:42,018 --> 00:02:43,143
SPEAKER_1:  uh... speaking of terry

00:02:43,143 --> 00:02:45,534
SPEAKER_0:  You chose a good living of interviewing people.

00:02:45,858 --> 00:02:47,390
SPEAKER_1:  Face your fears, my friend.

00:02:48,130 --> 00:02:51,902
SPEAKER_1:  So let's talk about SPF and FTX, who is...

00:02:52,482 --> 00:02:55,038
SPEAKER_1:  Sam Banquinfried. Can you tell a story?

00:02:55,522 --> 00:02:57,022
SPEAKER_1:  from the beginning as you understand it.

00:02:57,570 --> 00:03:00,030
SPEAKER_0:  Yeah, so Sam Beckman Fried is...

00:03:00,610 --> 00:03:01,918
SPEAKER_0:  A kid who grew up.

00:03:02,146 --> 00:03:04,190
SPEAKER_0:  sort of from a position of huge privilege.

00:03:04,546 --> 00:03:05,438
SPEAKER_0:  both his parents.

00:03:05,666 --> 00:03:08,318
SPEAKER_0:  Our lawyers, I believe both of them were from Harvard.

00:03:08,674 --> 00:03:13,918
SPEAKER_0:  He went to MIT, went to like, or sorry, backing up a bit more, went to like this top prep high school.

00:03:14,338 --> 00:03:15,390
SPEAKER_0:  then to MIT.

00:03:15,810 --> 00:03:22,558
SPEAKER_0:  Then he went to Jane Street. And after that, he started a trading firm in I think 2017 called Alameda Research.

00:03:22,978 --> 00:03:26,974
SPEAKER_0:  with a few friends, some of them were from Jane Street, some of them worked at Google.

00:03:27,394 --> 00:03:30,878
SPEAKER_0:  and they were sort of the smartest kids on the block.

00:03:31,170 --> 00:03:32,126
SPEAKER_0:  or that's what everyone thought.

00:03:32,578 --> 00:03:37,822
SPEAKER_0:  They made a lot of their money on something called the kimchi premium, or at least the story goes, which just to explain that.

00:03:38,370 --> 00:03:43,518
SPEAKER_0:  The price of Bitcoin in Korea was substantially higher than in the rest of the world.

00:03:43,810 --> 00:03:48,574
SPEAKER_0:  And so you could arbitrage that by buying Bitcoin elsewhere and selling it on a Korean exchange.

00:03:49,698 --> 00:03:50,526
SPEAKER_0:  They made their money early.

00:03:51,170 --> 00:03:52,926
SPEAKER_0:  doing kind of smart trades like that.

00:03:53,186 --> 00:03:55,966
SPEAKER_0:  they flipped that into market making, which they were.

00:03:56,194 --> 00:03:57,182
SPEAKER_0:  pretty early on that.

00:03:57,730 --> 00:03:58,366
SPEAKER_0:  Um...

00:03:58,690 --> 00:04:02,558
SPEAKER_0:  just providing liquidity to an exchange. And it's a strategy that is

00:04:02,850 --> 00:04:05,022
SPEAKER_0:  considered delta neutral, which means.

00:04:05,378 --> 00:04:06,014
SPEAKER_0:  Basically...

00:04:06,242 --> 00:04:07,902
SPEAKER_0:  If you take kind of both sides of the trade.

00:04:08,386 --> 00:04:13,086
SPEAKER_0:  and you're making a spread, like a fee on that, you make money whether it goes up or down.

00:04:13,538 --> 00:04:16,030
SPEAKER_0:  So in theory, there shouldn't be that much risk associated with it.

00:04:16,578 --> 00:04:18,654
SPEAKER_0:  So Alameda kind of blew up.

00:04:18,882 --> 00:04:20,606
SPEAKER_0:  because they would offer these people.

00:04:20,962 --> 00:04:30,334
SPEAKER_0:  you know, people who are giving out loans, they say, hey, we'll give you this really attractive rate of return and we're doing strategies that seemingly are low risk. So we're a low risk bet.

00:04:30,786 --> 00:04:34,430
SPEAKER_0:  We're these smart kids from Jane Street and you can kind of trust us to be.

00:04:35,586 --> 00:04:36,478
SPEAKER_0:  smarter than everyone else.

00:04:37,602 --> 00:04:39,326
SPEAKER_0:  around 2019.

00:04:39,842 --> 00:04:41,662
SPEAKER_0:  Sam started FTX.

00:04:42,082 --> 00:04:42,814
SPEAKER_0:  which is...

00:04:43,074 --> 00:04:43,934
SPEAKER_0:  and exchange.

00:04:44,354 --> 00:04:48,574
SPEAKER_0:  Specifically, it specialized in derivatives, so like margins.

00:04:48,962 --> 00:04:51,262
SPEAKER_0:  kind of more sophisticated crypto products.

00:04:52,130 --> 00:04:52,670
SPEAKER_0:  and

00:04:53,474 --> 00:05:04,990
SPEAKER_0:  It got in with Binance early on. So Binance actually has a prior relationship to FTX, which we'll explore in a second because they're gonna play a role in FTX's collapse actually. Binance is the number one crypto exchange.

00:05:05,378 --> 00:05:10,654
SPEAKER_0:  And they're led by, uh, he's called CZ on Twitter. I don't want to butcher his full name.

00:05:10,978 --> 00:05:13,694
SPEAKER_0:  But really smart guy has.

00:05:13,954 --> 00:05:16,062
SPEAKER_0:  played his hand really well and built up a...

00:05:16,674 --> 00:05:18,142
SPEAKER_0:  quite large exchange.

00:05:18,690 --> 00:05:23,998
SPEAKER_0:  And Binance was funding a bunch of different like startups. So they funded, they helped invest into.

00:05:24,290 --> 00:05:26,206
SPEAKER_0:  FTX, early on they invested 100 million.

00:05:26,594 --> 00:05:30,206
SPEAKER_0:  So these guys were kind of like teammates early on, SBF and CZ.

00:05:30,818 --> 00:05:31,422
SPEAKER_0:  and

00:05:32,002 --> 00:05:34,942
SPEAKER_0:  FTX quickly grew. They got like, especially in 2020, 2020.

00:05:35,170 --> 00:05:35,838
SPEAKER_0:  21.

00:05:36,162 --> 00:05:40,094
SPEAKER_0:  They got a lot of endorsements. They got a lot of credibility in the space.

00:05:40,770 --> 00:05:45,758
SPEAKER_0:  And eventually FTX actually bought out Binance. They gave him $2 billion, so...

00:05:46,050 --> 00:05:48,446
SPEAKER_0:  pretty good investment for CZ in a couple of years.

00:05:48,994 --> 00:05:49,502
SPEAKER_0:  Um...

00:05:50,050 --> 00:05:53,182
SPEAKER_0:  And now lead that up to 2022, what happens.

00:05:53,794 --> 00:05:54,686
SPEAKER_0:  Luna Collapse.

00:05:54,978 --> 00:05:56,510
SPEAKER_0:  three hours capital collapse.

00:05:56,834 --> 00:06:00,286
SPEAKER_0:  which if you don't know, there's just these kind of cataclysmic events in crypto.

00:06:00,578 --> 00:06:09,566
SPEAKER_0:  led by some pretty risky behavior whether Luna was a token that promised really attractive returns that were unsustainable ultimately and it just kind of spiraled

00:06:09,954 --> 00:06:14,174
SPEAKER_0:  It did what's called a stable coin death spiral, which we can talk about if we need to.

00:06:14,498 --> 00:06:16,574
SPEAKER_1:  stable coin death spiral. I can't wait.

00:06:16,866 --> 00:06:29,758
SPEAKER_1:  till that actually enters the lexicon, like a Wikipedia page on it, like economic students are learning in a school, that's like a chapter in a book. Anyway, I mean, this is the reality of our world, because this is a really big part of our...

00:06:30,210 --> 00:06:31,262
SPEAKER_1:  of the economic system.

00:06:31,554 --> 00:06:34,179
SPEAKER_1:  is cryptocurrency and stablecoin is part of that.

00:06:34,179 --> 00:06:37,854
SPEAKER_0:  Yeah, it's weird because on the one hand, cryptocurrency is supposed to somewhat

00:06:38,274 --> 00:06:41,630
SPEAKER_0:  simplify or add transparency to the financial markets.

00:06:41,858 --> 00:06:47,710
SPEAKER_0:  The idea is for the first time, you don't have to wait for an SEC filing from some corporate business. You can look at what they're doing on chain, right?

00:06:48,066 --> 00:06:55,262
SPEAKER_0:  So that's good because a lot of big financial problems are caused by lack of transparency and lack of understanding risk.

00:06:55,778 --> 00:06:56,798
SPEAKER_0:  But ironically...

00:06:57,282 --> 00:07:01,022
SPEAKER_0:  you get some people creating these arbitrarily complicated.

00:07:01,314 --> 00:07:06,078
SPEAKER_0:  financial products like algorithmic stablecoins, which then introduce more risk and blow everything up. So.

00:07:06,370 --> 00:07:08,478
SPEAKER_0:  Anyways, Three Arrows Capital blew up.

00:07:09,282 --> 00:07:14,078
SPEAKER_0:  and all of a sudden this crypto industry, which everyone thought was going to the moon, went from $100,000 to $100,000.

00:07:14,466 --> 00:07:15,422
SPEAKER_0:  is in some trouble.

00:07:15,778 --> 00:07:19,198
SPEAKER_0:  and FTX seems like the only people who

00:07:19,522 --> 00:07:22,302
SPEAKER_0:  besides like Binance, who's also really big and stable.

00:07:22,626 --> 00:07:26,878
SPEAKER_0:  Coinbase. They seemed like they were doing fine. In fact, they were bailing out companies.

00:07:27,202 --> 00:07:27,742
SPEAKER_0:  in the summer.

00:07:28,002 --> 00:07:31,806
SPEAKER_0:  I don't know if you remember that. SBF was likened to like Jamie Diamond.

00:07:32,162 --> 00:07:34,238
SPEAKER_0:  who's the CEO of Chase.

00:07:34,498 --> 00:07:36,318
SPEAKER_0:  who like kind of was like the buck stops here.

00:07:36,610 --> 00:07:37,406
SPEAKER_0:  uh... you know

00:07:38,466 --> 00:07:39,390
SPEAKER_0:  I'm like the backstop.

00:07:40,386 --> 00:07:43,838
SPEAKER_0:  So SPF was supporting the industry. He was like the stable guy.

00:07:44,450 --> 00:07:50,142
SPEAKER_0:  So come to like around October and November, there's all this talk about regulation. Everything's been blowing up.

00:07:50,722 --> 00:07:52,926
SPEAKER_0:  SBF's leading the charge on regulation.

00:07:53,474 --> 00:07:59,230
SPEAKER_0:  And CZ, the CEO of Binance gets word that maybe SBF is kind of like.

00:07:59,522 --> 00:08:03,006
SPEAKER_0:  cutting them out or making regulation that would maybe impact this business.

00:08:04,034 --> 00:08:06,430
SPEAKER_0:  and uh... he doesn't like that too much

00:08:06,882 --> 00:08:08,798
SPEAKER_0:  they start kind of feuding a little bit on Twitter.

00:08:09,314 --> 00:08:12,990
SPEAKER_0:  So when it comes out, a CoinDesk report came out that...

00:08:13,890 --> 00:08:17,246
SPEAKER_0:  FTX's balance sheet wasn't looking that good. Like it looked pretty weak.

00:08:17,538 --> 00:08:18,206
SPEAKER_0:  They had a lot of.

00:08:18,498 --> 00:08:19,102
SPEAKER_0:  coins.

00:08:19,458 --> 00:08:22,686
SPEAKER_0:  that in theory had value if you looked at their market price.

00:08:23,330 --> 00:08:23,998
SPEAKER_0:  but for a

00:08:24,802 --> 00:08:31,070
SPEAKER_0:  variety of reasons if you tried to sell them they'd collapse in value. So it's sort of like this thing, a house built on sand.

00:08:31,650 --> 00:08:33,566
SPEAKER_0:  and a friend of mine.

00:08:34,178 --> 00:08:37,630
SPEAKER_0:  On Twitter, he goes by Dirty Bubble Media. He released a report.

00:08:38,082 --> 00:08:41,630
SPEAKER_0:  And he basically said, I think these guys are insolvent.

00:08:41,954 --> 00:08:43,006
SPEAKER_0:  Well, CZ saw that.

00:08:43,426 --> 00:08:46,942
SPEAKER_0:  and he retweeted it and started adding fuel to the fire of like the speculation.

00:08:47,330 --> 00:08:54,078
SPEAKER_0:  Cause up to this point, everyone thought FTX is super safe, super secure. There's no reason to not keep your money there. Tom Brady keeps his money there, whatever.

00:08:54,850 --> 00:08:55,582
SPEAKER_0:  And...

00:08:55,938 --> 00:08:58,750
SPEAKER_0:  CZ kind of adds fuel to the fire by saying not only.

00:08:59,202 --> 00:09:03,358
SPEAKER_0:  Am I retweeting this adding kind of like validity to this speculation?

00:09:03,618 --> 00:09:06,526
SPEAKER_0:  but also I'm going to take the FTT that I got.

00:09:07,074 --> 00:09:10,270
SPEAKER_0:  which part of their balance sheet was this FTT token, which is

00:09:10,498 --> 00:09:12,798
SPEAKER_0:  FTX is like proprietary token.

00:09:13,314 --> 00:09:13,886
SPEAKER_0:  and

00:09:14,274 --> 00:09:17,566
SPEAKER_0:  Alameda and FTX control a lot of it.

00:09:18,146 --> 00:09:23,838
SPEAKER_0:  They were using this token to basically be a large amount of collateral for their whole

00:09:24,130 --> 00:09:24,734
SPEAKER_0:  balance sheet.

00:09:25,026 --> 00:09:26,686
SPEAKER_0:  So it accounted for this huge amount.

00:09:27,042 --> 00:09:28,030
SPEAKER_0:  of their value?

00:09:28,482 --> 00:09:28,862
SPEAKER_0:  and

00:09:29,250 --> 00:09:33,342
SPEAKER_0:  The CEO of Binance had a huge chunk of it as well, and he said, I'm going to sell all of it.

00:09:34,114 --> 00:09:36,702
SPEAKER_0:  and the fuel that that introduced to the market is.

00:09:36,930 --> 00:09:38,590
SPEAKER_0:  if he sells all this FTT.

00:09:38,946 --> 00:09:43,551
SPEAKER_0:  And this FTT is underwriting a lot of the value of FTX. This FT-

00:09:43,551 --> 00:09:44,222
SPEAKER_1:  See you next time.

00:09:44,706 --> 00:09:48,254
SPEAKER_1:  almost approximate like similar things if you were to buy a stock

00:09:48,514 --> 00:09:49,470
SPEAKER_1:  in a public company.

00:09:49,826 --> 00:09:51,701
SPEAKER_1:  Is that kind of like a stock in FTX?

00:09:51,701 --> 00:09:53,246
SPEAKER_0:  It sort of was this-

00:09:53,474 --> 00:09:54,942
SPEAKER_0:  proxy because

00:09:55,234 --> 00:09:58,014
SPEAKER_0:  what FTX was committed to doing was sort of like.

00:09:58,338 --> 00:09:59,422
SPEAKER_0:  buying back.

00:09:59,682 --> 00:10:04,958
SPEAKER_0:  FTT tokens, they would do this thing called the buy and burn. I think there was some amount of sharing in the

00:10:05,250 --> 00:10:06,910
SPEAKER_0:  revenue fees of FTX.

00:10:07,234 --> 00:10:08,574
SPEAKER_0:  It was kind of this convoluted thing.

00:10:09,186 --> 00:10:14,590
SPEAKER_0:  In my opinion, the exact value of FTT was speculated from the beginning, and it was clear that it was

00:10:15,042 --> 00:10:16,254
SPEAKER_0:  Very tied.

00:10:16,578 --> 00:10:18,686
SPEAKER_0:  to the performance of FTX.

00:10:19,042 --> 00:10:20,638
SPEAKER_0:  which is important because...

00:10:21,058 --> 00:10:22,366
SPEAKER_0:  we'll get to later.

00:10:22,690 --> 00:10:25,022
SPEAKER_0:  FTX sort of built their whole scaffold.

00:10:25,602 --> 00:10:28,542
SPEAKER_0:  on FTT, which meant that this scaffold was very wobbly.

00:10:28,898 --> 00:10:29,374
SPEAKER_0:  because.

00:10:30,018 --> 00:10:31,838
SPEAKER_0:  FTX loses a little bit of confidence.

00:10:32,130 --> 00:10:34,590
SPEAKER_0:  then your value goes down. i parents

00:10:34,882 --> 00:10:36,126
SPEAKER_0:  you lose more confidence.

00:10:36,386 --> 00:10:41,726
SPEAKER_0:  and this goes down. So it was kind of like this thing that this flywheel that when it was going well.

00:10:42,082 --> 00:10:44,862
SPEAKER_0:  You got huge amounts of growth when it's going bad.

00:10:45,186 --> 00:10:48,894
SPEAKER_0:  you get a exchange death spiral, so to speak.

00:10:49,314 --> 00:10:50,526
SPEAKER_1:  Actually, this structure.

00:10:50,946 --> 00:10:52,574
SPEAKER_1:  It's a pretty non-standard structure.

00:10:53,218 --> 00:10:56,670
SPEAKER_1:  did the architects of its initial design.

00:10:57,538 --> 00:10:59,326
SPEAKER_1:  anticipate the wobbliness of the whole.

00:10:59,618 --> 00:11:00,062
SPEAKER_1:  system.

00:11:00,578 --> 00:11:04,734
SPEAKER_1:  So putting fraud and all those things that happen later aside, do you think it was?

00:11:04,994 --> 00:11:06,174
SPEAKER_1:  difficult to anticipate.

00:11:06,786 --> 00:11:09,534
SPEAKER_1:  this kind of FTT, FTX, Alameda research.

00:11:10,178 --> 00:11:10,942
SPEAKER_1:  weird dynamic.

00:11:11,586 --> 00:11:13,086
SPEAKER_0:  No, because I think...

00:11:13,346 --> 00:11:14,846
SPEAKER_0:  sophisticated traders.

00:11:15,362 --> 00:11:18,526
SPEAKER_0:  Always think in terms of diversification and correlation.

00:11:19,170 --> 00:11:23,518
SPEAKER_0:  So if you're trying to, the way to think about risk in investing is like.

00:11:23,810 --> 00:11:24,990
SPEAKER_0:  If I invest in...

00:11:25,634 --> 00:11:28,894
SPEAKER_0:  you Lex Friedman and then I also invest in

00:11:29,154 --> 00:11:33,150
SPEAKER_0:  some product you produce. The performance of those two things will be pretty correlated.

00:11:33,506 --> 00:11:37,886
SPEAKER_0:  So whether I invest in you or I invest in this product that you like are completely behind

00:11:38,818 --> 00:11:44,350
SPEAKER_0:  I'm not de-risking, I'm basically counting all on you doing well, right? And if you do bad, my investments do very bad.

00:11:44,738 --> 00:11:50,366
SPEAKER_0:  So if I'm trying to build a stable thing, I shouldn't put all my eggs in the Lex Friedman basket.

00:11:50,690 --> 00:11:54,065
SPEAKER_0:  unless I'm positive that you're gonna do well, right? And these people...

00:11:54,065 --> 00:11:58,599
SPEAKER_1:  financial advisor would definitely recommend you do not put all your eggs in this basket.

00:11:58,599 --> 00:12:09,886
SPEAKER_0:  Right. And so you can think about it like if I know that these people were trained to think like this and so the idea that you could start this exchange you're worth billions of dollars.

00:12:10,242 --> 00:12:12,830
SPEAKER_0:  and you underwrite your whole system by betting.

00:12:13,570 --> 00:12:15,454
SPEAKER_0:  putting most of it on your own token is.

00:12:15,682 --> 00:12:17,566
SPEAKER_0:  is insane. And what's crazy-

00:12:17,954 --> 00:12:23,262
SPEAKER_0:  is we'll later find out that they were basically taking customer assets, which were real things.

00:12:23,874 --> 00:12:25,214
SPEAKER_0:  Bitcoin and Ethereum with

00:12:25,986 --> 00:12:28,702
SPEAKER_0:  with risks that were not so correlated to FDX.

00:12:28,962 --> 00:12:32,510
SPEAKER_0:  and they were swapping them out. They were using to go basically gamble those.

00:12:33,026 --> 00:12:34,558
SPEAKER_0:  and putting FTT.

00:12:34,946 --> 00:12:37,150
SPEAKER_0:  in its place as, quote, value.

00:12:37,602 --> 00:12:40,926
SPEAKER_0:  So they were increasing the risk of the system in order to bet big.

00:12:41,538 --> 00:12:45,406
SPEAKER_0:  with the idea that if they bet big and won, we'd all be singing their praises.

00:12:45,666 --> 00:12:47,870
SPEAKER_0:  if we bet big and lost.

00:12:48,802 --> 00:12:53,822
SPEAKER_0:  I don't know if they had a plan, but I think they were being extremely risky and there's no way to avoid.

00:12:54,210 --> 00:12:55,335
SPEAKER_0:  their knowledge of that.

00:12:55,335 --> 00:12:56,894
SPEAKER_1:  So when you say customer assets is.

00:12:57,154 --> 00:12:58,654
SPEAKER_1:  I come to this crypto exchange.

00:12:59,010 --> 00:13:01,150
SPEAKER_1:  I have Bitcoin or some other cryptocurrency.

00:13:01,378 --> 00:13:02,494
SPEAKER_1:  And this is a.

00:13:02,946 --> 00:13:04,126
SPEAKER_1:  A thing that has...

00:13:05,250 --> 00:13:06,366
SPEAKER_1:  pretty stable value.

00:13:06,626 --> 00:13:11,678
SPEAKER_1:  Over time. I mean, yeah, relatively relatively so. And I'm going to store it.

00:13:12,194 --> 00:13:13,342
SPEAKER_1:  on this crypto exchange.

00:13:13,794 --> 00:13:15,966
SPEAKER_1:  And that's the whole point. This is a

00:13:16,962 --> 00:13:20,510
SPEAKER_1:  So this thing to the degree that crypto holds value.

00:13:21,346 --> 00:13:23,390
SPEAKER_1:  is supposed to continue holding value.

00:13:23,618 --> 00:13:24,286
SPEAKER_1:  There's not any.

00:13:24,674 --> 00:13:27,454
SPEAKER_1:  there's not supposed to be an extra risk inserted into the thing.

00:13:27,746 --> 00:13:32,286
SPEAKER_0:  Right. And FTX was pretty clear from the beginning that they wouldn't invest your

00:13:32,610 --> 00:13:36,222
SPEAKER_0:  assets and anything else. They wouldn't do anything else with it. They wouldn't trade it.

00:13:37,218 --> 00:13:38,910
SPEAKER_0:  That's what made FTX.

00:13:39,234 --> 00:13:39,838
SPEAKER_0:  So...

00:13:40,194 --> 00:13:45,150
SPEAKER_0:  such like a horror story for investor confidence is basically they made every

00:13:45,570 --> 00:13:46,206
SPEAKER_0:  Signal.

00:13:46,466 --> 00:13:49,374
SPEAKER_0:  that they would not do anything nefarious with your tokens.

00:13:49,634 --> 00:13:50,174
SPEAKER_0:  They would just.

00:13:50,530 --> 00:13:58,462
SPEAKER_0:  put them into the side, put them in a separate account that they don't have access to, and they just kind of wait there until the day that you're ready to withdraw them.

00:13:59,458 --> 00:14:02,622
SPEAKER_0:  That's explicitly what they told their customers.

00:14:03,138 --> 00:14:05,022
SPEAKER_0:  So going back to the story a little bit.

00:14:05,474 --> 00:14:09,278
SPEAKER_0:  CZ then says, hey, I'm selling this token that underwrites the value of FTX.

00:14:09,922 --> 00:14:11,006
SPEAKER_0:  There's a total panic.

00:14:11,938 --> 00:14:16,158
SPEAKER_0:  SPF during this time makes set says several lies such as.

00:14:16,674 --> 00:14:18,014
SPEAKER_0:  FTX assets are fine.

00:14:18,306 --> 00:14:20,510
SPEAKER_0:  We have enough money to cover all withdrawals.

00:14:21,026 --> 00:14:28,798
SPEAKER_0:  And a day later, he basically admits that that wasn't the case. They don't have the money, they're shutting down. And then a few days later after that...

00:14:29,058 --> 00:14:30,206
SPEAKER_0:  They declared bankruptcy.

00:14:31,106 --> 00:14:34,014
SPEAKER_0:  There's, I should be clear, there's Alameda research.

00:14:34,498 --> 00:14:38,878
SPEAKER_0:  FTX International and FTX US, which is the US side of things.

00:14:39,106 --> 00:14:40,478
SPEAKER_0:  These are three different entities.

00:14:41,666 --> 00:14:42,974
SPEAKER_0:  All of them are in bankruptcy.

00:14:43,330 --> 00:14:45,566
SPEAKER_0:  and it's not clear to the extent.

00:14:45,826 --> 00:14:47,582
SPEAKER_0:  that they were co-mingling funds.

00:14:48,034 --> 00:14:53,502
SPEAKER_0:  but it's clear that they were commingling funds to some extent. They kind of were taking from each other.

00:14:54,050 --> 00:14:56,894
SPEAKER_0:  And that is where the fraud happens, right? Because

00:14:57,602 --> 00:15:00,926
SPEAKER_0:  Going back to our earlier analogy, if you're supposed to set funds aside.

00:15:01,282 --> 00:15:07,358
SPEAKER_0:  and I find out you were using it to go make all these arbitrage trades or do market making or all these activities.

00:15:07,618 --> 00:15:11,742
SPEAKER_0:  you were known for for your like hedge fund trading firm thing, that's a huge problem because

00:15:12,482 --> 00:15:13,726
SPEAKER_0:  He basically lied about this.

00:15:14,050 --> 00:15:16,958
SPEAKER_0:  And especially when he's saying explicitly that.

00:15:17,250 --> 00:15:20,798
SPEAKER_0:  We have these things, we have these funds, and these things turn out to be lies.

00:15:21,218 --> 00:15:24,094
SPEAKER_0:  Well, again, the question of fraud comes in and it's just like...

00:15:24,354 --> 00:15:25,534
SPEAKER_0:  There's no way he didn't know.

00:15:25,922 --> 00:15:29,374
SPEAKER_0:  So the obvious question might be, well, why isn't he locked up?

00:15:29,730 --> 00:15:33,566
SPEAKER_0:  why is he running around? And it's because...

00:15:34,658 --> 00:15:36,606
SPEAKER_0:  Really, his story is that he didn't know any of it.

00:15:37,218 --> 00:15:38,014
SPEAKER_0:  He found out.

00:15:38,626 --> 00:15:39,358
SPEAKER_0:  They had.

00:15:39,746 --> 00:15:41,502
SPEAKER_0:  to steal man's position, he would say...

00:15:41,730 --> 00:15:42,238
SPEAKER_0:  He was.

00:15:42,626 --> 00:15:45,406
SPEAKER_0:  totally disconnected from what Alameda was doing.

00:15:45,890 --> 00:15:49,886
SPEAKER_0:  he had no idea that they had such a large margin position.

00:15:50,402 --> 00:15:52,414
SPEAKER_0:  that they had an accounting quirk.

00:15:52,674 --> 00:15:55,198
SPEAKER_0:  and that accounting quirk hit $8 billion.

00:15:55,554 --> 00:15:56,222
SPEAKER_0:  from um...

00:15:57,954 --> 00:15:58,782
SPEAKER_0:  his view.

00:15:59,266 --> 00:16:01,790
SPEAKER_0:  And so when he was saying that they had money to cover it.

00:16:02,050 --> 00:16:02,942
SPEAKER_0:  He was saying that.

00:16:03,330 --> 00:16:08,638
SPEAKER_0:  truthfully to the best of his ability, and he just was so distracted at the time that he made a series

00:16:08,930 --> 00:16:11,070
SPEAKER_0:  of increasingly embarrassing mistakes.

00:16:11,394 --> 00:16:13,822
SPEAKER_0:  And now he owes it to the people.

00:16:14,146 --> 00:16:16,030
SPEAKER_0:  to right those wrongs.

00:16:16,290 --> 00:16:19,614
SPEAKER_0:  by publicly making this huge apology tour. You might have seen him on.

00:16:19,970 --> 00:16:21,854
SPEAKER_0:  I mean, he's been talking to nearly everyone.

00:16:22,274 --> 00:16:22,814
SPEAKER_0:  Um...

00:16:23,714 --> 00:16:25,534
SPEAKER_0:  about basically how he's just.

00:16:25,794 --> 00:16:27,838
SPEAKER_0:  didn't know what he was doing, he's the stupidest man alive.

00:16:28,546 --> 00:16:31,710
SPEAKER_1:  So what are some interesting things you've learned from those interviews?

00:16:34,434 --> 00:16:34,974
SPEAKER_0:  I think.

00:16:35,490 --> 00:16:42,718
SPEAKER_0:  I've appreciated why you don't talk in that position. Most people wouldn't talk. Most people would listen to their legal counsel andâ€”

00:16:42,946 --> 00:16:44,510
SPEAKER_0:  and not talk, I do not think he's.

00:16:45,122 --> 00:16:47,838
SPEAKER_0:  any lawyer worth their salt would tell him to talk because right now...

00:16:48,226 --> 00:16:51,614
SPEAKER_0:  I think the danger of what he's doing is he's locking himself into a story.

00:16:52,034 --> 00:16:52,734
SPEAKER_0:  of how things.

00:16:53,218 --> 00:16:53,694
SPEAKER_0:  happened?

00:16:53,922 --> 00:16:56,446
SPEAKER_0:  And I don't think that story is going to hold up in the coming months.

00:16:56,802 --> 00:16:58,302
SPEAKER_0:  because I think it's impossible.

00:16:58,914 --> 00:17:04,126
SPEAKER_0:  from the insider conversations I've had with Alameda research employees, with FTX employees.

00:17:04,450 --> 00:17:06,238
SPEAKER_0:  It's impossible to square.

00:17:06,530 --> 00:17:07,838
SPEAKER_0:  what they are telling me.

00:17:08,194 --> 00:17:09,022
SPEAKER_0:  with no

00:17:09,698 --> 00:17:11,422
SPEAKER_0:  like incentive to lie.

00:17:11,906 --> 00:17:13,950
SPEAKER_0:  with what SBF is telling me.

00:17:14,178 --> 00:17:17,214
SPEAKER_0:  with every incentive to lie, which is fundamentally

00:17:17,474 --> 00:17:22,014
SPEAKER_0:  that he didn't know they were commingling funds. He didn't know they were gambling with customer money.

00:17:22,306 --> 00:17:22,942
SPEAKER_0:  and

00:17:23,202 --> 00:17:24,638
SPEAKER_0:  It was basically this huge mistake and-

00:17:25,090 --> 00:17:28,350
SPEAKER_0:  It's Alameda's fault, but he wasn't involved in Alameda, a company here.

00:17:28,546 --> 00:17:30,910
SPEAKER_1:  So like a compassionate but heart.

00:17:31,330 --> 00:17:32,830
SPEAKER_1:  hidden gangster that you are.

00:17:33,506 --> 00:17:38,878
SPEAKER_1:  uh... we saw a very recently you interact with sbf on uh... title a he

00:17:39,106 --> 00:17:42,270
SPEAKER_1:  the suspenders as you're saying this.

00:17:42,914 --> 00:17:45,982
SPEAKER_1:  You interact on Twitter spaces with SBF.

00:17:47,426 --> 00:17:48,286
SPEAKER_1:  and uh...

00:17:49,058 --> 00:17:50,590
SPEAKER_1:  really put his feet to the fire.

00:17:51,010 --> 00:17:53,054
SPEAKER_1:  with some hard hitting questions.

00:17:53,442 --> 00:17:55,966
SPEAKER_1:  What did you ask and what did you learn from that interaction?

00:17:56,706 --> 00:17:57,950
SPEAKER_0:  Sure I should save first.

00:17:58,210 --> 00:18:07,774
SPEAKER_0:  This was not a willing interaction. I mean, I thought that was kind of the funny part of it because I've been asking him for an interview for a while. He's been giving interviews to nearly everyone who wants one, big channels, small channels.

00:18:08,322 --> 00:18:15,710
SPEAKER_0:  Um, he didn't give me one, but I managed to get some by sneaking up on some Twitter spaces and DMing the people and like being like, Hey, can I come up?

00:18:16,418 --> 00:18:16,894
SPEAKER_0:  So.

00:18:17,154 --> 00:18:22,494
SPEAKER_0:  I didn't get him to ask everything that I wanted because he like would leave sometimes.

00:18:22,818 --> 00:18:25,342
SPEAKER_0:  uh... you know after i asked some of the questions but

00:18:25,730 --> 00:18:29,214
SPEAKER_0:  Really, what I asked was about this 8 billion and...

00:18:29,954 --> 00:18:32,190
SPEAKER_0:  Zooming in on the improbability

00:18:32,418 --> 00:18:33,918
SPEAKER_0:  of his lack of knowledge.

00:18:34,370 --> 00:18:38,910
SPEAKER_0:  It's sort of like if you run a company and you know...

00:18:39,266 --> 00:18:41,278
SPEAKER_0:  the insides and outs, and you're the top.

00:18:41,506 --> 00:18:42,174
SPEAKER_0:  of your field.

00:18:43,138 --> 00:18:43,902
SPEAKER_0:  Top in class.

00:18:44,674 --> 00:18:47,550
SPEAKER_0:  and all of a sudden it all goes bust and you say, I had no idea how any of this works.

00:18:48,322 --> 00:19:00,190
SPEAKER_0:  I didn't know, it's like the guy who runs Water Burger saying, I didn't know where we sourced our beef. I didn't know where we, that's a Texas example actually. Thank you, I appreciate that. Let's take it like worldwide, Walmart, like.

00:19:00,418 --> 00:19:04,350
SPEAKER_0:  I didn't know we used Chinese manufacturers. It's like, that's impossible.

00:19:04,770 --> 00:19:06,974
SPEAKER_0:  to become Walmart, you have to know.

00:19:07,330 --> 00:19:12,222
SPEAKER_0:  how your supply chain works. You have to know, even if you're at a high level, you know how this stuff works.

00:19:12,418 --> 00:19:16,574
SPEAKER_1:  Can I do a hard turn on that and go as one must to Hitler?

00:19:16,994 --> 00:19:21,694
SPEAKER_1:  Hitler's writing is not on any of the documents around as far as I know.

00:19:22,114 --> 00:19:23,518
SPEAKER_1:  on the final solution.

00:19:23,970 --> 00:19:24,542
SPEAKER_1:  So...

00:19:24,866 --> 00:19:26,782
SPEAKER_1:  in some crazy world.

00:19:27,074 --> 00:19:29,118
SPEAKER_1:  He could theoretically say, I knew.

00:19:29,890 --> 00:19:32,062
SPEAKER_1:  I didn't know anything about death camps.

00:19:32,994 --> 00:19:33,438
SPEAKER_1:  Uh...

00:19:33,698 --> 00:19:35,486
SPEAKER_1:  So there's this plausible deniability.

00:19:35,810 --> 00:19:36,318
SPEAKER_1:  in theory.

00:19:36,674 --> 00:19:37,022
SPEAKER_1:  So.

00:19:37,250 --> 00:19:39,966
SPEAKER_1:  That's, but that most people would look at that and say.

00:19:40,194 --> 00:19:40,734
SPEAKER_1:  Uhhh

00:19:41,250 --> 00:19:43,070
SPEAKER_1:  It's very unlikely, you know.

00:19:43,330 --> 00:19:48,414
SPEAKER_0:  No. Especially if all the insiders are coming out and saying, no, no, no, of course he knew. He was directing us from the top.

00:19:48,674 --> 00:19:49,598
SPEAKER_0:  I mean, um...

00:19:49,826 --> 00:19:54,718
SPEAKER_0:  What was clear, what's interesting about the structure and like, I love the nitty-gritty. We're back to SPF.

00:19:55,106 --> 00:20:01,854
SPEAKER_0:  Yeah, sorry. We went to Hitler, now we're back to the SBL. I wanted to turn us as fast as possible away from Hitler. Yeah.

00:20:02,114 --> 00:20:02,878
SPEAKER_1:  Bye!

00:20:03,522 --> 00:20:05,397
SPEAKER_1:  So the insiders in what I'll make.

00:20:05,397 --> 00:20:07,838
SPEAKER_0:  Alameda research. What was interesting...

00:20:08,162 --> 00:20:10,846
SPEAKER_0:  is that there was this sort of one-way window going on.

00:20:11,074 --> 00:20:12,094
SPEAKER_0:  between Alameda?

00:20:12,354 --> 00:20:16,286
SPEAKER_0:  and FTX, where FTX employees didn't know a lot of what was going on.

00:20:16,738 --> 00:20:18,110
SPEAKER_0:  Alameda insiders.

00:20:19,106 --> 00:20:20,574
SPEAKER_0:  I would say by design.

00:20:20,802 --> 00:20:23,614
SPEAKER_0:  knew almost everything that was going on at FTX.

00:20:24,098 --> 00:20:24,670
SPEAKER_0:  Um...

00:20:25,090 --> 00:20:25,566
SPEAKER_0:  and

00:20:26,210 --> 00:20:30,174
SPEAKER_0:  So I think that was really interesting from the perspective of a lot of.

00:20:30,466 --> 00:20:34,782
SPEAKER_0:  the so-called, like what you could, what he's trying to ascribe to as like.

00:20:35,234 --> 00:20:38,590
SPEAKER_0:  failures or mistakes or ignorance and negligence.

00:20:39,170 --> 00:20:40,958
SPEAKER_0:  When looked at closely,

00:20:41,186 --> 00:20:43,134
SPEAKER_0:  are much more designed.

00:20:43,362 --> 00:20:46,334
SPEAKER_0:  and they sort of don't arise spontaneously.

00:20:46,594 --> 00:20:50,142
SPEAKER_0:  Because like, let's say, so there's this thing in banking and like trading where

00:20:50,370 --> 00:20:57,278
SPEAKER_0:  If I run a bank and you run like a trading firm, we need to have informational walls between us because there's huge conflicts of interest that can arise.

00:20:57,698 --> 00:20:58,110
SPEAKER_0:  Right?

00:20:58,402 --> 00:21:00,478
SPEAKER_0:  So the negligent argument might be that like.

00:21:00,770 --> 00:21:05,822
SPEAKER_0:  Oh, we just didn't know. We're sort of these dumb kids in the Bahamas. So we shared information equally.

00:21:06,690 --> 00:21:16,990
SPEAKER_0:  But when you see a one-way wall, that starts to look a lot different, right? If I have a backend source of looking at, or sorry, you're the trading firm, so you have a backend way to look at all my accounts.

00:21:17,442 --> 00:21:19,166
SPEAKER_0:  and I have no idea that you're doing that.

00:21:19,714 --> 00:21:22,270
SPEAKER_0:  that all of a sudden looks like a much more designed thing.

00:21:23,490 --> 00:21:28,382
SPEAKER_0:  It would be plausible, let's say, going to use another analogy too.

00:21:28,738 --> 00:21:32,894
SPEAKER_0:  If you're saying, look, I co-mingled funds because I was so bad at corporate structures.

00:21:33,314 --> 00:21:34,174
SPEAKER_0:  you'd expect.

00:21:34,530 --> 00:21:36,126
SPEAKER_0:  those companies to have a very.

00:21:36,674 --> 00:21:39,198
SPEAKER_0:  simple corporate structure because you didn't know what you're doing, right?

00:21:39,458 --> 00:21:41,630
SPEAKER_0:  But what we see with FTX and Alameda.

00:21:42,402 --> 00:21:43,518
SPEAKER_0:  is they had something like

00:21:43,810 --> 00:21:46,366
SPEAKER_0:  50 companies and subsidiaries and it's inc...

00:21:47,074 --> 00:21:49,022
SPEAKER_0:  impossibly complicated web.

00:21:49,506 --> 00:21:50,878
SPEAKER_0:  of corporate activity.

00:21:51,810 --> 00:21:53,438
SPEAKER_0:  You don't get there by accident.

00:21:53,666 --> 00:22:00,830
SPEAKER_0:  You don't wake up and go, oh, I designed like this watch that ticked a very specific way, but it was all accidental.

00:22:01,186 --> 00:22:04,286
SPEAKER_0:  If you really didn't know what you were doing, you'd end up with a simple structure.

00:22:04,674 --> 00:22:08,510
SPEAKER_0:  So even just like from a fundamental perspective.

00:22:08,962 --> 00:22:12,478
SPEAKER_0:  what SBF was doing and like the activities they were engaging in.

00:22:12,706 --> 00:22:14,238
SPEAKER_0:  We're so complicated and-

00:22:14,722 --> 00:22:20,062
SPEAKER_0:  purposely designed to obfuscate what they were doing, it's impossible to subscribe to the negligence.

00:22:20,450 --> 00:22:21,118
SPEAKER_0:  argument.

00:22:21,762 --> 00:22:23,134
SPEAKER_0:  And I wanna quickly say too, like...

00:22:23,842 --> 00:22:27,582
SPEAKER_0:  I don't think a lot of people have honed in on this. There was insider trading going on.

00:22:28,450 --> 00:22:30,622
SPEAKER_0:  from Alameda's perspective, where...

00:22:31,746 --> 00:22:35,582
SPEAKER_0:  they would know what coins FTX was going to list on their exchange.

00:22:35,970 --> 00:22:37,406
SPEAKER_0:  There's a famous effect where.

00:22:37,794 --> 00:22:41,214
SPEAKER_0:  Let's say you're this legitimate exchange. You list a coin, the price spikes.

00:22:42,274 --> 00:22:46,814
SPEAKER_0:  Insiders told me it was a regular practice for Alameda insiders.

00:22:47,234 --> 00:22:49,502
SPEAKER_0:  to know that FTX was going to list a coin.

00:22:49,730 --> 00:22:51,774
SPEAKER_0:  and as a company buy up that coin.

00:22:52,066 --> 00:22:53,534
SPEAKER_0:  so they could sell it after it listed.

00:22:54,018 --> 00:22:56,254
SPEAKER_0:  and they made millions of dollars. How do you do that accidentally?

00:22:56,962 --> 00:22:57,534
SPEAKER_1:  And that's.

00:22:58,050 --> 00:22:58,846
SPEAKER_1:  That's illegal.

00:22:59,266 --> 00:23:00,126
SPEAKER_0:  Totally illegal.

00:23:01,058 --> 00:23:04,958
SPEAKER_0:  That's illegal from like, and if an individual does it, it's illegal, it's fraud.

00:23:05,250 --> 00:23:07,902
SPEAKER_0:  What if a company is systematically doing it?

00:23:08,418 --> 00:23:11,134
SPEAKER_0:  And you can't tell me that FTX.

00:23:11,810 --> 00:23:14,846
SPEAKER_0:  or somewhat at FTX wasn't feeding that information about.

00:23:15,170 --> 00:23:15,870
SPEAKER_0:  to Alameda.

00:23:16,194 --> 00:23:17,758
SPEAKER_0:  or somehow giving them.

00:23:18,146 --> 00:23:24,606
SPEAKER_0:  to know that. And that would happen at the highest level. It would happen at SPS level. And this is why his arguments of...

00:23:25,058 --> 00:23:27,998
SPEAKER_0:  I was dumb, I was naive, I was sort of ignorant.

00:23:28,290 --> 00:23:35,262
SPEAKER_0:  are so preposterous because he's dumb and ignorant the second it becomes criminal to be smart and sophisticated, right?

00:23:35,970 --> 00:23:38,846
SPEAKER_1:  but then also coming out and talking about it, which is...

00:23:39,714 --> 00:23:41,534
SPEAKER_1:  That's a bizarre move. That's a bizarre move.

00:23:41,858 --> 00:23:43,230
SPEAKER_1:  almost a dark move.

00:23:43,970 --> 00:23:48,703
SPEAKER_1:  Can you tell the story of the 8 billion? You mentioned 8 billion. What's the 8 billion? What's the missing 8 billion? Yeah.

00:23:48,703 --> 00:23:49,278
SPEAKER_0:  So

00:23:49,570 --> 00:23:53,534
SPEAKER_0:  It's really interesting because it's sort of like wire fraud. You sort of-

00:23:54,146 --> 00:24:00,382
SPEAKER_0:  He's sort of copping to like smaller crimes to avoid the big crime. The big crime is you knew everything and you were behind it, right?

00:24:01,154 --> 00:24:07,326
SPEAKER_0:  The smaller crimes are like a little wire fraud here, little wire fraud there. So what the 8 billion is.

00:24:07,650 --> 00:24:15,166
SPEAKER_0:  is that FTX didn't always have banking. It's hard to get banking as a crypto exchange. There's all these questions of like, where's the money coming from? Is it coming from money launderer?

00:24:16,066 --> 00:24:20,350
SPEAKER_0:  For a variety of reasons, it's always been hard for exchanges to get bank accounts. So before...

00:24:20,802 --> 00:24:25,054
SPEAKER_0:  when FTX was just getting started, they didn't have a bank account. So how do you put money on FTX? Well.

00:24:25,666 --> 00:24:28,510
SPEAKER_0:  they would have you wire your money to their trading firm.

00:24:28,770 --> 00:24:32,574
SPEAKER_0:  their wiring instructions would go to their trading firm, it's easier to get banking as a trading firm.

00:24:33,378 --> 00:24:36,606
SPEAKER_0:  So you'd put your money with the trading firm and then they'd credit you the money.

00:24:37,122 --> 00:24:38,046
SPEAKER_0:  on FTX.

00:24:38,818 --> 00:24:43,230
SPEAKER_0:  Okay, first of all, this is a whole circumvention of all these banking guidelines and regulations.

00:24:44,002 --> 00:24:45,054
SPEAKER_0:  That's the first like.

00:24:45,538 --> 00:24:46,846
SPEAKER_0:  that I think is legal, but...

00:24:48,866 --> 00:24:50,174
SPEAKER_0:  basically what SPF argued.

00:24:50,722 --> 00:24:51,166
SPEAKER_0:  is that.

00:24:51,682 --> 00:24:52,766
SPEAKER_0:  There was an accounting.

00:24:53,218 --> 00:24:54,910
SPEAKER_0:  glitch error problem.

00:24:55,458 --> 00:24:57,406
SPEAKER_0:  where when you'd send money to Alameda.

00:24:57,986 --> 00:24:59,934
SPEAKER_0:  even though they'd credit you on FTX.

00:25:00,258 --> 00:25:04,990
SPEAKER_0:  They wouldn't safeguard your deposits. Like your deposits would go into what he called a stub account.

00:25:05,378 --> 00:25:06,398
SPEAKER_0:  which is just like some.

00:25:07,202 --> 00:25:08,606
SPEAKER_0:  account that's not very well labeled.

00:25:09,154 --> 00:25:10,782
SPEAKER_0:  kind of like a placeholder account.

00:25:11,554 --> 00:25:12,094
SPEAKER_0:  and

00:25:13,282 --> 00:25:17,502
SPEAKER_0:  he didn't realize that those were Alameda's funds or they were playing with those funds.

00:25:17,762 --> 00:25:21,790
SPEAKER_0:  and that they basically should have safeguarded that for customers. That's his explanation.

00:25:22,210 --> 00:25:24,798
SPEAKER_0:  It's preposterous because it's $8 billion, but anyways.

00:25:25,154 --> 00:25:25,662
SPEAKER_0:  uh...

00:25:25,826 --> 00:25:27,326
SPEAKER_1:  Just poor labeling of accounts.

00:25:27,746 --> 00:25:29,662
SPEAKER_0:  of an eight billion dollar account.

00:25:29,890 --> 00:25:32,515
SPEAKER_1:  What's a billion between... A billion between...

00:25:32,515 --> 00:25:39,262
SPEAKER_0:  This is like what- I do this all the time in programming. This is the craziest thing. Like he was talking to me and at one point in the conversation, he's like-

00:25:39,554 --> 00:25:43,742
SPEAKER_0:  Yeah, I didn't have precise, because he said I didn't have knowledge of Alameda.

00:25:43,970 --> 00:25:48,318
SPEAKER_0:  And I said, well, Forbes a month ago was getting detailed accounting of Alameda.

00:25:48,674 --> 00:25:49,470
SPEAKER_0:  And he goes, oh.

00:25:49,954 --> 00:25:53,598
SPEAKER_0:  That wasn't detailed accounting. I just knew I was right within 10 billion or so.

00:25:55,234 --> 00:25:58,430
SPEAKER_0:  What is that error margin? $10 Billion?

00:25:58,978 --> 00:26:02,750
SPEAKER_0:  for a company that is arguably never worth more than 100 million.

00:26:03,586 --> 00:26:05,918
SPEAKER_0:  Probably never even worth more than 50 billion.

00:26:06,722 --> 00:26:12,126
SPEAKER_0:  Your error margin is $10 billion. You have to be, this is a guy who is sending around $10 billion.

00:26:12,770 --> 00:26:15,262
SPEAKER_0:  statements that like there was no risk involved.

00:26:15,522 --> 00:26:16,734
SPEAKER_0:  And you're telling me he had a...

00:26:17,026 --> 00:26:24,062
SPEAKER_0:  error margin of $10 billion, that is the difference between a healthy company and a company so deep underwater you're going to jail.

00:26:24,674 --> 00:26:25,086
SPEAKER_0:  So.

00:26:26,210 --> 00:26:27,678
SPEAKER_0:  You have to believe.

00:26:28,098 --> 00:26:30,238
SPEAKER_0:  that he is impossibly stupid.

00:26:30,562 --> 00:26:36,187
SPEAKER_0:  and square that with the sophistication that he brought to the table. I think it's an impossible argument. I don't even think it's...

00:26:36,187 --> 00:26:39,966
SPEAKER_1:  Do you think he is incompetent, insane, or evil?

00:26:41,282 --> 00:26:42,142
SPEAKER_1:  if you were to bet.

00:26:44,482 --> 00:26:45,607
SPEAKER_1:  money on each of those.

00:26:45,607 --> 00:26:48,607
SPEAKER_0:  Incompetent, insane, or evil.

00:26:48,607 --> 00:26:50,558
SPEAKER_1:  Insane meaning he's lying.

00:26:50,818 --> 00:26:52,542
SPEAKER_1:  to everyone but also to himself.

00:26:53,698 --> 00:26:54,206
SPEAKER_1:  Uh...

00:26:54,530 --> 00:26:55,134
SPEAKER_1:  which you could.

00:26:55,426 --> 00:26:57,406
SPEAKER_1:  which is a little bit different than incompetence.

00:26:57,826 --> 00:26:58,910
SPEAKER_0:  He's not incompetent.

00:27:00,514 --> 00:27:04,638
SPEAKER_0:  So the, I think he's some combination of insane and evil.

00:27:05,282 --> 00:27:08,446
SPEAKER_0:  but it's impossible to know unless we know deep inside his heart.

00:27:08,738 --> 00:27:09,150
SPEAKER_0:  How?

00:27:09,474 --> 00:27:10,110
SPEAKER_0:  self.

00:27:10,786 --> 00:27:12,254
SPEAKER_0:  like diluted he is.

00:27:12,546 --> 00:27:14,558
SPEAKER_0:  versus a calculated strategy.

00:27:15,170 --> 00:27:18,238
SPEAKER_0:  And I think if you look at SBF, he's such a...

00:27:18,594 --> 00:27:20,702
SPEAKER_0:  I think he's a fascinating individual.

00:27:20,962 --> 00:27:21,662
SPEAKER_0:  Just, I mean.

00:27:22,146 --> 00:27:24,574
SPEAKER_0:  You know, he's a horrible human being. Let's start there.

00:27:24,802 --> 00:27:25,822
SPEAKER_0:  but he's also.

00:27:26,402 --> 00:27:27,550
SPEAKER_0:  somewhat. Uma Gata

00:27:28,386 --> 00:27:31,006
SPEAKER_0:  interesting from a psychology perspective because

00:27:31,234 --> 00:27:33,406
SPEAKER_0:  He's very open about the fact that he...

00:27:33,730 --> 00:27:35,230
SPEAKER_0:  understands image.

00:27:35,554 --> 00:27:37,246
SPEAKER_0:  and he understands how to.

00:27:37,602 --> 00:27:39,454
SPEAKER_0:  cultivate image, the importance of image.

00:27:39,938 --> 00:27:40,830
SPEAKER_0:  so well.

00:27:41,346 --> 00:27:43,998
SPEAKER_0:  that I think a lot of people, even though they've talked about it.

00:27:44,994 --> 00:27:46,494
SPEAKER_0:  emphasizing that enough.

00:27:47,170 --> 00:27:50,334
SPEAKER_0:  when interacting with him. This is a man whose entire history.

00:27:50,690 --> 00:27:51,454
SPEAKER_0:  is about.

00:27:51,938 --> 00:27:55,614
SPEAKER_0:  Cultivating the right opinions at the right time to achieve the right effect

00:27:56,130 --> 00:27:58,686
SPEAKER_0:  Why do you think he would suddenly change that approach?

00:27:59,074 --> 00:28:01,438
SPEAKER_0:  when he has all the more reason to cultivate an image.

00:28:01,826 --> 00:28:02,590
SPEAKER_1:  So he is...

00:28:03,266 --> 00:28:05,598
SPEAKER_1:  extremely good naturally or

00:28:06,402 --> 00:28:09,950
SPEAKER_0:  I don't know if he's good, but he's like, he's a hyper aware.

00:28:10,210 --> 00:28:14,270
SPEAKER_1:  So he's deliberate in cultivating a public image and controlling the public image.

00:28:14,914 --> 00:28:21,374
SPEAKER_0:  You know about the like Democrat donations. Like he he knew to donate to the right people forty million dollars.

00:28:21,666 --> 00:28:25,022
SPEAKER_0:  He says on a call that we released with Tiffany Fong.

00:28:25,826 --> 00:28:26,878
SPEAKER_0:  He says on a call that.

00:28:27,586 --> 00:28:32,510
SPEAKER_0:  He donated the same amount to Republicans. There's speculation on whether this is true because he's a liar or whatever.

00:28:32,738 --> 00:28:35,870
SPEAKER_0:  So, caveat there. But he said he donated to Republicans the same amount.

00:28:36,162 --> 00:28:37,150
SPEAKER_0:  but he donated dark.

00:28:37,442 --> 00:28:38,398
SPEAKER_0:  because he knew.

00:28:39,298 --> 00:28:42,750
SPEAKER_0:  most journalists are liberal and they would kind of hold that against him.

00:28:43,202 --> 00:28:45,438
SPEAKER_0:  So he wanted all the...

00:28:46,050 --> 00:28:49,214
SPEAKER_0:  all the sides to be on in his favor in his pocket.

00:28:49,666 --> 00:28:53,342
SPEAKER_0:  while simultaneously understanding the entire media landscape.

00:28:53,730 --> 00:28:55,006
SPEAKER_0:  and playing them like a fiddle.

00:28:56,002 --> 00:28:58,782
SPEAKER_0:  cultivating this image of I'm this progressive woke.

00:28:59,170 --> 00:29:01,214
SPEAKER_0:  billionaire who wants to give it all away.

00:29:01,442 --> 00:29:06,334
SPEAKER_0:  I do everything for charity. I drive a Corolla while living in a million dollar print house, multi-million.

00:29:06,626 --> 00:29:07,006
SPEAKER_0:  Um...

00:29:07,746 --> 00:29:11,326
SPEAKER_0:  But that was sort of the angle. He understood so well how to play the media.

00:29:11,842 --> 00:29:12,606
SPEAKER_0:  and um...

00:29:13,410 --> 00:29:16,478
SPEAKER_0:  I think he underestimated when he did this.

00:29:17,090 --> 00:29:18,622
SPEAKER_0:  how much people would.

00:29:18,882 --> 00:29:20,574
SPEAKER_0:  put him under a deeper microscope?

00:29:21,058 --> 00:29:23,294
SPEAKER_0:  and I don't think he has achieved.

00:29:23,874 --> 00:29:25,214
SPEAKER_0:  the same level of success.

00:29:25,602 --> 00:29:29,374
SPEAKER_0:  in cultivating this new image, because I think people are so skeptical now, no one's buying it.

00:29:29,922 --> 00:29:32,725
SPEAKER_0:  But I think he's trying it, he's doing it to the best of his ability.

00:29:32,725 --> 00:29:35,134
SPEAKER_1:  has work leading up to this particular.

00:29:35,682 --> 00:29:37,182
SPEAKER_1:  wobbly situation.

00:29:37,570 --> 00:29:40,862
SPEAKER_1:  So before that, wasn't there a public perception of him being?

00:29:42,402 --> 00:29:44,277
SPEAKER_1:  force for good, a financial force for good.

00:29:44,277 --> 00:29:45,214
SPEAKER_0:  Yeah

00:29:45,442 --> 00:29:54,110
SPEAKER_0:  Somebody from Sequoia Capital, you know, wrote this glowing review that he's gonna be the world's first trillionaire. There's so many pieces done on he's the most generous billionaire in the world.

00:29:54,402 --> 00:29:55,134
SPEAKER_0:  That um

00:29:55,746 --> 00:29:56,606
SPEAKER_0:  He was sort of like.

00:29:56,866 --> 00:29:57,470
SPEAKER_0:  The...

00:29:58,082 --> 00:30:02,014
SPEAKER_0:  steel man of, you know, it's possible to make tons of money.

00:30:02,434 --> 00:30:06,878
SPEAKER_0:  This is like the effect of altruism movement. Make as much money as you can, as fast as you can, and give it all away.

00:30:07,394 --> 00:30:10,270
SPEAKER_0:  And he was sort of like the poster child for that.

00:30:10,786 --> 00:30:14,686
SPEAKER_0:  and he did give some of it away and got a lot of press for it.

00:30:15,266 --> 00:30:18,142
SPEAKER_0:  And I think that was kind of by design. I want to address a real quick point.

00:30:18,786 --> 00:30:21,662
SPEAKER_0:  A lot of people have said that like finance played a role.

00:30:22,082 --> 00:30:23,966
SPEAKER_0:  And while they catalyzed this...

00:30:25,218 --> 00:30:26,430
SPEAKER_0:  insolvency.

00:30:27,682 --> 00:30:30,622
SPEAKER_0:  is a problem that will eventually manifest either way.

00:30:30,946 --> 00:30:33,758
SPEAKER_0:  So I don't put any blame on CZ for...

00:30:34,210 --> 00:30:35,678
SPEAKER_0:  basically causing this.

00:30:35,906 --> 00:30:36,670
SPEAKER_0:  meltdown.

00:30:36,898 --> 00:30:42,910
SPEAKER_0:  the underlying foundation was unstable and it was gonna fall apart at the next push. I mean, he just happened to be the final.

00:30:43,394 --> 00:30:44,222
SPEAKER_0:  Kind of like.

00:30:45,186 --> 00:30:45,566
SPEAKER_0:  Uh.

00:30:46,114 --> 00:30:48,821
SPEAKER_0:  I don't know, the straw that broke the camel's back. The meet and greet.

00:30:48,821 --> 00:30:49,571
SPEAKER_1:  That was the review.

00:30:49,571 --> 00:30:56,638
SPEAKER_0:  But yeah, but it's like I don't I don't think he's culpable for FTX is like malfeasance and how they handled

00:30:57,154 --> 00:30:59,029
SPEAKER_0:  Accounts if that makes sense. So what?

00:30:59,029 --> 00:30:59,998
SPEAKER_1:  What role?

00:31:00,482 --> 00:31:01,982
SPEAKER_1:  Did they play? Could they have help?

00:31:02,914 --> 00:31:05,182
SPEAKER_1:  alleviate some of the pain of

00:31:06,050 --> 00:31:06,462
SPEAKER_1:  uh

00:31:06,722 --> 00:31:07,454
SPEAKER_1:  investors.

00:31:07,810 --> 00:31:09,278
SPEAKER_1:  of people that held funds there.

00:31:09,794 --> 00:31:10,814
SPEAKER_0:  Yeah, I mean...

00:31:12,098 --> 00:31:13,342
SPEAKER_0:  Probably.

00:31:13,602 --> 00:31:16,862
SPEAKER_0:  I don't know, I would see some kind of...

00:31:17,314 --> 00:31:17,950
SPEAKER_0:  weird

00:31:18,498 --> 00:31:20,830
SPEAKER_0:  obligation like with the two billion they made.

00:31:21,250 --> 00:31:25,150
SPEAKER_0:  on FTX. Remember they got two billion, some of it in cash, some of it in-

00:31:25,410 --> 00:31:28,670
SPEAKER_0:  some of it in FTT tokens. I don't know how much actual cash they have from that deal.

00:31:29,026 --> 00:31:35,102
SPEAKER_0:  But they have billions from the success of what seems to be a fraud, seems to have been a fraud from early on. They had the back door.

00:31:35,522 --> 00:31:35,934
SPEAKER_0:  as

00:31:36,226 --> 00:31:39,349
SPEAKER_0:  early as 20, early 2020 from what I can tell. So the

00:31:39,349 --> 00:31:45,022
SPEAKER_1:  the back door between FTX and Alameda. Alameda, yes. Alameda research. Yes. Do you think CZ saw?

00:31:45,282 --> 00:31:46,494
SPEAKER_1:  who SPF is.

00:31:48,386 --> 00:31:49,278
SPEAKER_1:  What is he doing?

00:31:50,050 --> 00:31:50,590
SPEAKER_0:  No.

00:31:50,882 --> 00:31:51,326
SPEAKER_0:  I think

00:31:52,578 --> 00:31:57,022
SPEAKER_0:  I think CZ is like, he's a shark. I think he's good at building a big business.

00:31:57,474 --> 00:31:58,014
SPEAKER_0:  Um...

00:31:58,146 --> 00:32:00,021
SPEAKER_1:  Like a good truck or a bad truck?

00:32:00,021 --> 00:32:02,686
SPEAKER_0:  I don't know. I think sharks just eat. I mean, I don't

00:32:02,946 --> 00:32:04,071
SPEAKER_0:  I don't know, I think...

00:32:04,071 --> 00:32:07,422
SPEAKER_1:  My relationship with shark has like a finding Nemo. There's a shark in that.

00:32:07,874 --> 00:32:10,270
SPEAKER_0:  I don't know. Like Jeff Bezos is a shark.

00:32:10,690 --> 00:32:13,246
SPEAKER_0:  So whether people have loaded connotations of like.

00:32:13,474 --> 00:32:14,878
SPEAKER_0:  how they feel about Jeff Bezos.

00:32:15,138 --> 00:32:18,270
SPEAKER_0:  I mean, I would say like, I think CZ is a ruthless businessman.

00:32:18,946 --> 00:32:22,046
SPEAKER_0:  I think he's cold, he's calculated, he's very...

00:32:22,850 --> 00:32:23,902
SPEAKER_0:  deliberate and

00:32:24,802 --> 00:32:30,334
SPEAKER_0:  I think what he should do in this position is forfeit the funds that he profited from that investment.

00:32:30,722 --> 00:32:33,150
SPEAKER_0:  because largely I think it was.

00:32:33,666 --> 00:32:38,974
SPEAKER_0:  It's owed to the customers. There's so much hurting out there. So I think they could do a lot of good around that.

00:32:39,426 --> 00:32:40,734
SPEAKER_0:  Um, I don't know if they will.

00:32:41,122 --> 00:32:45,438
SPEAKER_0:  because I don't know if he sees it in his best interest. I think that's probably how he's thinking.

00:32:45,826 --> 00:32:46,270
SPEAKER_0:  but...

00:32:46,562 --> 00:32:48,318
SPEAKER_0:  Yeah, I think they could have.

00:32:49,346 --> 00:32:50,014
SPEAKER_0:  or if they s-

00:32:50,146 --> 00:32:52,670
SPEAKER_1:  could still help there. Who do you think suffered the most?

00:32:53,442 --> 00:32:54,014
SPEAKER_1:  so far.

00:32:55,938 --> 00:32:57,982
SPEAKER_0:  the little account holders, this is always true.

00:32:58,242 --> 00:33:00,958
SPEAKER_0:  So one of the big temptations with fraud.

00:33:01,218 --> 00:33:02,846
SPEAKER_0:  covered a lot of scams, frauds.

00:33:03,458 --> 00:33:04,926
SPEAKER_0:  is everyone looks at the big number.

00:33:05,282 --> 00:33:06,686
SPEAKER_0:  Everyone, that's the headline.

00:33:07,138 --> 00:33:10,302
SPEAKER_0:  billions of dollars, the top 50 creditors, or whatever one thinks at first.

00:33:11,010 --> 00:33:18,686
SPEAKER_0:  But quickly when you dig down, you realize that most people who lost $10 million, I mean, I'm sure that's terrible for them I wish them to get their money back, but...

00:33:18,978 --> 00:33:20,414
SPEAKER_0:  It's usually the people with like...

00:33:20,866 --> 00:33:24,958
SPEAKER_0:  50,000 or less that are most impacted. Usually they do not have the money.

00:33:25,186 --> 00:33:28,798
SPEAKER_0:  to spare, usually they're not diversified in a sophisticated way.

00:33:29,250 --> 00:33:29,758
SPEAKER_0:  Um...

00:33:30,018 --> 00:33:35,166
SPEAKER_0:  So I think it's those people, I think it's the small account holders that I feel the worst for, and unfortunately they often get the least.

00:33:35,490 --> 00:33:36,670
SPEAKER_0:  press time or air time.

00:33:36,834 --> 00:33:41,886
SPEAKER_1:  That's the really difficult truth of this is that especially in the culture of cryptocurrency this

00:33:42,210 --> 00:33:43,742
SPEAKER_1:  a lot of young people who are.

00:33:44,386 --> 00:33:45,950
SPEAKER_1:  not diversified their...

00:33:46,466 --> 00:33:48,478
SPEAKER_1:  basically all in on a particular crypto.

00:33:49,410 --> 00:33:56,254
SPEAKER_1:  and it just breaks my heart to think that there's somebody with 50,000 or 30,000 or 20,000, but the point is that money.

00:33:56,802 --> 00:33:58,398
SPEAKER_1:  is everything they own.

00:33:59,874 --> 00:34:00,510
SPEAKER_1:  And now...

00:34:01,570 --> 00:34:03,806
SPEAKER_1:  Now what? This level has aimm carbohydrate bar, but was fats up Intra- 101e3 specific limit.

00:34:05,026 --> 00:34:08,574
SPEAKER_1:  Like, you know, imagine you're 18, 19, 20, 21 years old.

00:34:09,378 --> 00:34:11,774
SPEAKER_1:  You saved up, you've been working, you saved up.

00:34:12,610 --> 00:34:15,198
SPEAKER_1:  And this is basically destroying a life.

00:34:16,130 --> 00:34:18,206
SPEAKER_0:  What's so brutal about this is that.

00:34:18,786 --> 00:34:21,502
SPEAKER_0:  This all comes on the back, the entire crypto market.

00:34:21,986 --> 00:34:23,390
SPEAKER_0:  comes on the back of.

00:34:24,674 --> 00:34:28,286
SPEAKER_0:  comes from the deepest distrust of traditional finance.

00:34:28,610 --> 00:34:29,694
SPEAKER_0:  Right, yeah, 2008.

00:34:30,722 --> 00:34:32,670
SPEAKER_0:  Everybody lost trust in the banking systems.

00:34:33,026 --> 00:34:33,982
SPEAKER_0:  and they lost trust.

00:34:34,466 --> 00:34:37,182
SPEAKER_0:  that if those banking systems acted in a corrupt way.

00:34:37,890 --> 00:34:42,366
SPEAKER_0:  they would receive the justice. It turned out that the banks received favorable treatment. People didn't.

00:34:42,978 --> 00:34:43,614
SPEAKER_0:  So people.

00:34:44,930 --> 00:34:46,334
SPEAKER_0:  lost faith in the...

00:34:47,202 --> 00:34:52,350
SPEAKER_0:  the structure of our financial system in a way that we're still feeling the reverberations of it.

00:34:52,802 --> 00:34:55,614
SPEAKER_0:  And so when crypto came along, it was like kind of this way to reinvent the wheel.

00:34:55,938 --> 00:34:56,958
SPEAKER_0:  reinvent the world.

00:34:57,346 --> 00:34:57,950
SPEAKER_0:  for the.

00:34:58,530 --> 00:35:01,374
SPEAKER_0:  the sort of lowly and the less powerful.

00:35:01,602 --> 00:35:03,166
SPEAKER_0:  and kind of level the playing field.

00:35:03,714 --> 00:35:05,758
SPEAKER_0:  So it's so sad about events like this.

00:35:06,178 --> 00:35:07,230
SPEAKER_0:  is you see that.

00:35:07,842 --> 00:35:09,118
SPEAKER_0:  fundamentally a lot of the

00:35:09,794 --> 00:35:12,446
SPEAKER_0:  the power structures are the same where the people at the top.

00:35:12,962 --> 00:35:17,246
SPEAKER_0:  face little repercussions for what they do. The people at the bottom are still getting screwed.

00:35:17,602 --> 00:35:19,326
SPEAKER_0:  people at the bottom are still getting lied to.

00:35:19,650 --> 00:35:22,110
SPEAKER_0:  and law enforcement is way behind the ball.

00:35:23,298 --> 00:35:25,438
SPEAKER_1:  Do you think this really...

00:35:26,530 --> 00:35:29,278
SPEAKER_1:  damaged people trust in cryptocurrency. For sure.

00:35:29,442 --> 00:35:32,510
SPEAKER_0:  way bigger than Luna, way bigger than Three Arrows Capital.

00:35:33,026 --> 00:35:37,406
SPEAKER_0:  It's because of who SBF was. It's not just the dollar figure behind it.

00:35:37,954 --> 00:35:42,942
SPEAKER_0:  It's because he wooed so many of our media elites who should have been

00:35:43,234 --> 00:35:44,062
SPEAKER_0:  calling him out.

00:35:44,546 --> 00:35:47,902
SPEAKER_0:  or at least investigating him and not rubber stamping him.

00:35:48,962 --> 00:35:58,878
SPEAKER_0:  It's an indictment of our financial system, even our most sophisticated people in BlackRock, in Sequoia, who didn't see this coming, who also rubber stamped him.

00:35:59,202 --> 00:35:59,774
SPEAKER_0:  Um...

00:36:00,546 --> 00:36:02,910
SPEAKER_0:  and you just wonder like if you can't trust.

00:36:03,490 --> 00:36:05,918
SPEAKER_0:  the top people in crypto who are supposedly.

00:36:06,210 --> 00:36:09,342
SPEAKER_0:  the good guys, the guys saving crypto.

00:36:09,634 --> 00:36:12,190
SPEAKER_0:  month, just a month ago or two months ago.

00:36:12,450 --> 00:36:22,270
SPEAKER_0:  He was the guy on Capitol Hill that was talking to Gary Gensler to all the top people in Washington. He was orchestrating the regulation of crypto. With that guy...

00:36:22,882 --> 00:36:28,414
SPEAKER_0:  is a complete fraudster, liar, psychopath, and nobody knew it until it was too late.

00:36:28,770 --> 00:36:31,966
SPEAKER_0:  What does that mean about the system itself that we're building?

00:36:32,450 --> 00:36:34,526
SPEAKER_1:  So you are one of not the best.

00:36:35,330 --> 00:36:36,606
SPEAKER_1:  Like, fraudster.

00:36:37,218 --> 00:36:38,686
SPEAKER_1:  investigators in the world.

00:36:39,074 --> 00:36:43,742
SPEAKER_1:  Did you sense, was this on your radar at all, SBF in the?

00:36:44,290 --> 00:36:45,566
SPEAKER_1:  over the past couple years.

00:36:46,274 --> 00:36:49,255
SPEAKER_1:  Were any red flags going off for you? Yeah.

00:36:49,255 --> 00:36:50,046
SPEAKER_0:  So...

00:36:50,274 --> 00:36:50,942
SPEAKER_0:  Funny enough, like...

00:36:51,202 --> 00:36:53,118
SPEAKER_0:  one of my videos from six months ago or so.

00:36:53,570 --> 00:36:54,942
SPEAKER_0:  blew up because, uh...

00:36:55,906 --> 00:36:59,774
SPEAKER_0:  I gotta give a lot of credit to Matt Levine of Bloomberg, great journalist, great finance journalist.

00:37:00,354 --> 00:37:02,366
SPEAKER_0:  And I want to say when I like talk about Media Elite.

00:37:03,874 --> 00:37:05,118
SPEAKER_0:  people doing great work.

00:37:05,634 --> 00:37:15,934
SPEAKER_0:  in these mainstream institutions. It's not a monolith. Just like independent media isn't all doing great work and all the corporate media is bad or whatever. There's like these overarching narratives that I don't subscribe to.

00:37:16,162 --> 00:37:19,774
SPEAKER_0:  So Matt Levine's a great journalist. He did an interview with SBF where-

00:37:20,418 --> 00:37:21,054
SPEAKER_0:  He got.

00:37:21,410 --> 00:37:25,246
SPEAKER_0:  Sam to basically describe a lot of what was going on in DeFi.

00:37:25,538 --> 00:37:27,838
SPEAKER_0:  but it kind of a larger philosophy around crypto.

00:37:28,098 --> 00:37:29,566
SPEAKER_0:  He described a Ponzi scheme.

00:37:29,858 --> 00:37:32,414
SPEAKER_0:  where you just described this black box, it does nothing.

00:37:32,738 --> 00:37:42,686
SPEAKER_0:  But if we ascribe it value, then we can create more value and more value and more value. And it kind of was this ridiculous description of a Ponzi scheme, but there was no moral judgment on it. It was like, oh yeah, this is great. We can make a lot of money.

00:37:43,458 --> 00:37:47,966
SPEAKER_0:  And Matt is like, well, it sounds like you're in the Ponzi business and business is good.

00:37:48,482 --> 00:37:51,934
SPEAKER_0:  I made a video about that. I said, this is ridiculous, this is absurd, whatever.

00:37:52,194 --> 00:37:52,798
SPEAKER_0:  obscene.

00:37:54,818 --> 00:37:55,390
SPEAKER_0:  um

00:37:56,546 --> 00:37:58,974
SPEAKER_0:  I didn't explicitly call SPF a fraud there.

00:37:59,842 --> 00:38:02,462
SPEAKER_0:  And I think if I'm being...

00:38:02,690 --> 00:38:03,742
SPEAKER_0:  I think I saw some of it.

00:38:04,322 --> 00:38:04,638
SPEAKER_0:  but.

00:38:04,930 --> 00:38:06,398
SPEAKER_0:  like many people.

00:38:06,882 --> 00:38:07,582
SPEAKER_0:  I think.

00:38:08,066 --> 00:38:10,110
SPEAKER_0:  A lot of us were kind of like.

00:38:14,722 --> 00:38:15,934
SPEAKER_0:  I think a lot of us missed.

00:38:16,386 --> 00:38:17,374
SPEAKER_0:  How wrong.

00:38:17,602 --> 00:38:19,486
SPEAKER_0:  everyone could be at the same time.

00:38:20,610 --> 00:38:22,782
SPEAKER_0:  I did notice leading up to the crash.

00:38:23,010 --> 00:38:27,678
SPEAKER_0:  what was happening and I caught it out a day or a day and a half before it happened.

00:38:28,066 --> 00:38:30,526
SPEAKER_0:  because I saw my friends post a dirty bubble media.

00:38:31,106 --> 00:38:36,222
SPEAKER_0:  And this was the first real look into the heart of their finances, because they're this black box.

00:38:36,482 --> 00:38:38,110
SPEAKER_0:  You just kind of had to evaluate them.

00:38:39,298 --> 00:38:40,798
SPEAKER_0:  without knowing much.

00:38:41,858 --> 00:38:42,526
SPEAKER_0:  and

00:38:43,074 --> 00:38:45,950
SPEAKER_0:  Once we got a peek under the hood of what their finances were...

00:38:47,042 --> 00:38:50,302
SPEAKER_0:  I realized, oh my gosh, these guys might be completely insolvent, so I made a tweet about it.

00:38:50,914 --> 00:38:52,894
SPEAKER_0:  I hope some people saw it and got their money out.

00:38:53,218 --> 00:38:53,790
SPEAKER_0:  Um

00:38:54,690 --> 00:38:56,766
SPEAKER_0:  But pretty quickly after that, I...

00:38:57,314 --> 00:38:59,870
SPEAKER_0:  taught the narrative of what was really going on at Alameda.

00:39:00,802 --> 00:39:01,758
SPEAKER_0:  that it was basically this.

00:39:02,370 --> 00:39:04,327
SPEAKER_0:  the ponzi scheme that they had built.

00:39:04,327 --> 00:39:07,870
SPEAKER_1:  sit like Batman in the dark since he fight crime.

00:39:08,194 --> 00:39:08,958
SPEAKER_1:  and wonder.

00:39:09,410 --> 00:39:13,438
SPEAKER_1:  like sad just staring into the darkness and thinking I should have caught this earlier.

00:39:16,962 --> 00:39:17,822
SPEAKER_1:  Yeah, I think...

00:39:18,146 --> 00:39:18,910
SPEAKER_1:  in your in your

00:39:19,362 --> 00:39:23,486
SPEAKER_1:  uh... ten billion dollars to ten million dollars ten million dollars we're working our way there

00:39:23,874 --> 00:39:24,999
SPEAKER_1:  Um... wut wut who borr 55 finish

00:39:24,999 --> 00:39:28,158
SPEAKER_0:  Sure, like, it's never enough. It's never enough.

00:39:28,610 --> 00:39:31,134
SPEAKER_0:  Like you always could be catching stuff sooner.

00:39:31,362 --> 00:39:33,118
SPEAKER_0:  You always could be doing more.

00:39:33,506 --> 00:39:36,094
SPEAKER_1:  I mean, the fascinating thing you said is that.

00:39:36,962 --> 00:39:38,590
SPEAKER_1:  One of the lessons here is.

00:39:38,882 --> 00:39:40,574
SPEAKER_1:  that a large number of people

00:39:40,834 --> 00:39:43,998
SPEAKER_1:  influential smart people could all be wrong at the same time.

00:39:44,546 --> 00:39:45,470
SPEAKER_1:  in terms of their.

00:39:45,762 --> 00:39:47,358
SPEAKER_1:  Evaluation of SBF.

00:39:47,906 --> 00:39:48,382
SPEAKER_1:  This is-

00:39:48,930 --> 00:39:51,390
SPEAKER_0:  This is one thing that I don't understand too, is like...

00:39:51,746 --> 00:39:53,566
SPEAKER_0:  I think it's one thing to not see something.

00:39:54,178 --> 00:39:58,622
SPEAKER_0:  I think it's another thing to like rubber stamp or explicitly endorse.

00:39:59,138 --> 00:39:59,838
SPEAKER_0:  I feel like.

00:40:00,962 --> 00:40:04,894
SPEAKER_0:  A lot of people didn't look too close at SBF because I think...

00:40:05,186 --> 00:40:06,782
SPEAKER_0:  A lot of the warning signs were there.

00:40:07,330 --> 00:40:10,654
SPEAKER_0:  But my feeling is, if you're a Sequoia, if you're a Black Rock...

00:40:11,394 --> 00:40:14,270
SPEAKER_0:  Wouldn't you do that due diligence? I mean like-

00:40:14,850 --> 00:40:16,990
SPEAKER_0:  Like before just endorsing something

00:40:17,410 --> 00:40:21,214
SPEAKER_0:  especially in the crypto space. This is just why I don't do any deals in the crypto space ever.

00:40:21,602 --> 00:40:24,542
SPEAKER_0:  because it's impossible to know which ones are going to be the like.

00:40:24,866 --> 00:40:27,038
SPEAKER_0:  big hits or the big frauds or whatever.

00:40:27,362 --> 00:40:27,742
SPEAKER_0:  Um.

00:40:28,034 --> 00:40:30,526
SPEAKER_0:  But if you're gonna make that bet, if you're gonna make that play,

00:40:30,786 --> 00:40:31,838
SPEAKER_0:  You would think...

00:40:32,706 --> 00:40:36,990
SPEAKER_0:  that you would do all the research in the world and you would get sophisticated looks.

00:40:37,218 --> 00:40:39,614
SPEAKER_0:  at their liabilities, at how they were structured.

00:40:39,906 --> 00:40:40,670
SPEAKER_0:  All that stuff.

00:40:41,026 --> 00:40:42,686
SPEAKER_0:  And that is the most shocking part.

00:40:43,074 --> 00:40:44,190
SPEAKER_0:  is not that.

00:40:44,610 --> 00:40:46,814
SPEAKER_0:  you know, people missed it because you can miss fraud.

00:40:47,170 --> 00:40:48,446
SPEAKER_0:  but that there were so much.

00:40:48,930 --> 00:40:57,502
SPEAKER_0:  So many glowing endorsements like, this guy is not gonna be that thing. We explicitly endorse him. I saw a Fortune magazine. He was called the next Warren Buffett.

00:40:58,210 --> 00:40:58,878
SPEAKER_0:  It's just crazy.

00:40:59,202 --> 00:41:01,694
SPEAKER_1:  Do you think it's possible to have enough like Tom Brady?

00:41:02,466 --> 00:41:09,091
SPEAKER_1:  endorsements that you don't really investigate. So like, there's a kind of momentum, like societal social momentum.

00:41:09,091 --> 00:41:10,590
SPEAKER_0:  I think that's the problem.

00:41:11,042 --> 00:41:12,606
SPEAKER_0:  I actually think that's hugely.

00:41:12,866 --> 00:41:14,270
SPEAKER_0:  a blinds like a

00:41:14,946 --> 00:41:18,014
SPEAKER_0:  a blind spot of our society as we have all these.

00:41:18,338 --> 00:41:19,230
SPEAKER_0:  Heuristics?

00:41:19,778 --> 00:41:20,958
SPEAKER_0:  that can be...

00:41:21,250 --> 00:41:22,142
SPEAKER_0:  points of failure.

00:41:22,530 --> 00:41:23,422
SPEAKER_0:  where like

00:41:23,714 --> 00:41:26,590
SPEAKER_0:  A rule of thumb is if you go to an Ivy League, well, you must be smart.

00:41:27,266 --> 00:41:33,854
SPEAKER_0:  A rule of thumb is if you're both your parents or Harvard lawyers, you must know the law. You must, like, kind of be sophisticated.

00:41:34,274 --> 00:41:39,614
SPEAKER_0:  The rule of thumb is if you're running a billion dollar exchange, you must be somehow somewhat ethical, right?

00:41:39,970 --> 00:41:43,710
SPEAKER_0:  And all of these heuristics can lead to giant blind spots where

00:41:44,066 --> 00:41:48,446
SPEAKER_0:  you kind of just go, oh, we'll check. Like I don't really, it's a lot of energy to look into people.

00:41:48,834 --> 00:41:53,598
SPEAKER_0:  And if enough of those rules of thumb are met, we just kind of check them off and put them through the system. So...

00:41:53,954 --> 00:41:56,702
SPEAKER_0:  Yeah, it's been hugely exposing for sort of like

00:41:57,346 --> 00:41:58,814
SPEAKER_1:  And you don't know wha-

00:41:59,138 --> 00:42:02,014
SPEAKER_1:  maybe hard to look at, for example, there's a few assumptions.

00:42:02,242 --> 00:42:06,750
SPEAKER_1:  Now there's a lot of people are very skeptical of institutions of government and so on, but for, um,

00:42:07,042 --> 00:42:07,486
SPEAKER_1:  Perhaps.

00:42:07,810 --> 00:42:10,974
SPEAKER_1:  too much so I agree but for some part of history

00:42:11,298 --> 00:42:12,158
SPEAKER_1:  There was a...

00:42:12,578 --> 00:42:13,726
SPEAKER_1:  too much faith in government.

00:42:14,018 --> 00:42:18,750
SPEAKER_1:  So right now I think there's faith in certain large companies.

00:42:19,042 --> 00:42:20,670
SPEAKER_1:  There's distrust in certain ones and...

00:42:21,090 --> 00:42:24,030
SPEAKER_1:  trust in others. Like people seem to distrust Facebook.

00:42:24,354 --> 00:42:26,270
SPEAKER_1:  extremely skeptical of Facebook.

00:42:26,850 --> 00:42:27,678
SPEAKER_1:  but they trust.

00:42:27,970 --> 00:42:29,374
SPEAKER_1:  I think Google with their data?

00:42:29,634 --> 00:42:32,894
SPEAKER_1:  I think they trust Apple with their data, much more so.

00:42:33,186 --> 00:42:33,694
SPEAKER_1:  Search.

00:42:34,306 --> 00:42:36,350
SPEAKER_1:  People don't seem to be Google search like.

00:42:36,610 --> 00:42:45,118
SPEAKER_1:  I'm just gonna, I'm gonna put... Throw it in there. Have you ever looked at your Google search history? Your Google search history has gotta be some of the darkest things. Oh!

00:42:45,314 --> 00:42:50,238
SPEAKER_0:  I don't think I've ever looked at my Google search history. You should. I mean it's full with like

00:42:51,170 --> 00:42:52,958
SPEAKER_0:  browser hygiene and

00:42:53,506 --> 00:42:55,646
SPEAKER_0:  uh... stuff like that because i think it's

00:42:56,386 --> 00:43:02,654
SPEAKER_1:  Well, Google search history, unless you explicitly delete is there. I recommend you look at it. It's fascinating. Look because it goes back to.

00:43:03,138 --> 00:43:05,470
SPEAKER_1:  the first days of you using Google search history.

00:43:05,666 --> 00:43:11,102
SPEAKER_0:  Fun fact actually about that. No, no, no, I am aware of that. I just mean for like

00:43:11,394 --> 00:43:17,150
SPEAKER_0:  certain sensitive topics where like, I'm investigating some fraud and I go sign into their website, right? So I log in and secure that iodine.

00:43:17,474 --> 00:43:22,398
SPEAKER_0:  I won't use a traditional browser, I'll use a VPN and I'll put it on Brave or something like that.

00:43:22,498 --> 00:43:24,670
SPEAKER_1:  You log in, you create an account is Lex Friedman.

00:43:24,994 --> 00:43:29,182
SPEAKER_1:  Yeah, exactly. Exactly. Exactly. You mentioned effective altruism.

00:43:29,442 --> 00:43:29,822
SPEAKER_1:  Yes.

00:43:30,082 --> 00:43:32,734
SPEAKER_1:  you know as the others been associated with this effect of altruism

00:43:32,994 --> 00:43:34,590
SPEAKER_1:  which made me look twice at

00:43:34,850 --> 00:43:35,358
SPEAKER_1:  EA.

00:43:36,450 --> 00:43:37,310
SPEAKER_1:  see like wait

00:43:37,826 --> 00:43:38,334
SPEAKER_1:  Um...

00:43:39,042 --> 00:43:40,702
SPEAKER_1:  I ID what's.

00:43:41,090 --> 00:43:42,366
SPEAKER_1:  What's going on here?

00:43:43,682 --> 00:43:48,766
SPEAKER_1:  Uh, is this, was this used by SBF to give himself a good public image or

00:43:49,058 --> 00:43:53,502
SPEAKER_1:  Is there something about effective altruism that makes it easy to misuse?

00:43:54,114 --> 00:43:54,974
SPEAKER_1:  by bad people.

00:43:56,098 --> 00:43:56,670
SPEAKER_1:  What do you think?

00:43:56,802 --> 00:44:02,142
SPEAKER_0:  Yeah, it's interesting. He could have endorsed a wide range of philosophies, and I guess you just have to wonder.

00:44:02,946 --> 00:44:06,142
SPEAKER_0:  Are all those, would those philosophies also be tainted if...

00:44:06,882 --> 00:44:07,358
SPEAKER_0:  Um...

00:44:07,842 --> 00:44:08,798
SPEAKER_0:  he had gone bad.

00:44:09,122 --> 00:44:13,470
SPEAKER_0:  I guess Effective Altruism is sort of unique because he used it as part of his brand.

00:44:13,890 --> 00:44:17,662
SPEAKER_0:  It wasn't like he described himself as a consequentialist and like

00:44:18,370 --> 00:44:19,326
SPEAKER_0:  ended up mattering.

00:44:19,650 --> 00:44:20,094
SPEAKER_0:  It was like.

00:44:20,994 --> 00:44:27,390
SPEAKER_0:  He described himself as an effective altruist, and he used that part of the brand to lift himself up. I guess that's why it's getting so much scrutiny.

00:44:27,842 --> 00:44:29,790
SPEAKER_0:  I think the merits of it

00:44:30,306 --> 00:44:35,134
SPEAKER_0:  should speak for themselves. I mean, I don't personally, I'm not personally an effective altruist.

00:44:35,650 --> 00:44:36,126
SPEAKER_0:  um...

00:44:36,802 --> 00:44:39,742
SPEAKER_0:  I personally am motivated by giving in part emotionally.

00:44:40,194 --> 00:44:40,734
SPEAKER_0:  and

00:44:41,122 --> 00:44:43,390
SPEAKER_0:  for some reason that I can't exactly describe.

00:44:43,842 --> 00:44:47,518
SPEAKER_0:  I think that's somewhat important. I don't think you should detach giving.

00:44:47,938 --> 00:44:49,662
SPEAKER_0:  from some personal connection.

00:44:50,882 --> 00:44:52,190
SPEAKER_0:  I find trouble with that.

00:44:52,898 --> 00:44:57,118
SPEAKER_0:  And like I said, it's for reasons I can't describe because effective altruism is sort of the most

00:44:57,442 --> 00:45:07,966
SPEAKER_0:  logical ivory tower position you could possibly take. It's like, strip all humanity away from giving, let's treat it like a business, and how many people can we serve through the McDonald's line of charity?

00:45:08,290 --> 00:45:09,278
SPEAKER_0:  for like the dollar.

00:45:10,306 --> 00:45:10,846
SPEAKER_0:  uh...

00:45:11,458 --> 00:45:13,086
SPEAKER_0:  I just personally don't resonate with that.

00:45:13,410 --> 00:45:15,486
SPEAKER_0:  but I don't think the entire movement.

00:45:15,938 --> 00:45:16,542
SPEAKER_0:  is like.

00:45:17,250 --> 00:45:18,494
SPEAKER_0:  indicted because of it.

00:45:18,754 --> 00:45:20,222
SPEAKER_0:  typically most people who

00:45:20,610 --> 00:45:21,374
SPEAKER_0:  care about.

00:45:21,986 --> 00:45:23,390
SPEAKER_0:  giving and charity.

00:45:24,418 --> 00:45:25,406
SPEAKER_0:  On the whole.

00:45:25,634 --> 00:45:26,558
SPEAKER_0:  are nice people.

00:45:27,010 --> 00:45:33,566
SPEAKER_0:  And so I can't speak for the whole movement. I certainly don't think SBF indicts the whole movement, even though I personally don't subscribe to it.

00:45:33,826 --> 00:45:35,966
SPEAKER_1:  Yeah, it made me pause.

00:45:36,450 --> 00:45:38,558
SPEAKER_1:  reflect and step back like.

00:45:39,042 --> 00:45:41,022
SPEAKER_1:  about the movement and about anything.

00:45:41,474 --> 00:45:45,054
SPEAKER_1:  that has a strong ideology. So if there's anything in your life.

00:45:45,346 --> 00:45:46,462
SPEAKER_1:  There's a strong.

00:45:46,946 --> 00:45:49,598
SPEAKER_1:  set of ideas behind it, be careful.

00:45:50,178 --> 00:45:51,262
SPEAKER_0:  Yeah, I mean, look-

00:45:51,810 --> 00:45:52,798
SPEAKER_0:  I kinda feel like.

00:45:53,922 --> 00:45:57,150
SPEAKER_0:  teaches me and what I kind of think about.

00:45:57,474 --> 00:45:58,878
SPEAKER_0:  when I think about systems.

00:45:59,330 --> 00:46:01,662
SPEAKER_0:  is that no system saves you from the individual.

00:46:02,466 --> 00:46:04,478
SPEAKER_0:  No system saves you from the individual.

00:46:05,122 --> 00:46:06,206
SPEAKER_0:  their intentions.

00:46:06,530 --> 00:46:07,006
SPEAKER_0:  their

00:46:07,362 --> 00:46:09,790
SPEAKER_0:  their lust for power or greed.

00:46:10,114 --> 00:46:10,590
SPEAKER_0:  I mean...

00:46:10,946 --> 00:46:13,022
SPEAKER_0:  I think one of the great ideas.

00:46:13,634 --> 00:46:15,454
SPEAKER_0:  is the decentralization.

00:46:15,778 --> 00:46:18,014
SPEAKER_0:  of power and like this is why.

00:46:18,914 --> 00:46:21,950
SPEAKER_0:  I think democracies are so great is because they decentralize.

00:46:22,370 --> 00:46:22,846
SPEAKER_0:  power.

00:46:23,522 --> 00:46:25,662
SPEAKER_0:  across a wide range of

00:46:26,018 --> 00:46:27,710
SPEAKER_0:  like interests and groups.

00:46:28,130 --> 00:46:30,334
SPEAKER_0:  and that being an effective way to kind of

00:46:30,626 --> 00:46:32,222
SPEAKER_0:  try as best as you can.

00:46:32,642 --> 00:46:35,070
SPEAKER_0:  to spread out the impact of one individual.

00:46:35,490 --> 00:46:36,222
SPEAKER_0:  because...

00:46:36,642 --> 00:46:39,006
SPEAKER_0:  One bad individual can do a lot of harm.

00:46:39,330 --> 00:46:41,598
SPEAKER_0:  as clearly as seen here.

00:46:41,986 --> 00:46:42,718
SPEAKER_0:  But.

00:46:43,074 --> 00:46:47,198
SPEAKER_0:  Now I don't think it has anything to do with ideology because it's not like being an effective altruist.

00:46:47,426 --> 00:46:49,310
SPEAKER_0:  made Sam Bankman free to fraud.

00:46:49,762 --> 00:46:53,137
SPEAKER_0:  He was a fraud who happened to be an effective altruist. Lord has power.

00:46:53,137 --> 00:46:57,758
SPEAKER_1:  sense. So there is something about yes no system protects you from an individual by some system.

00:46:58,594 --> 00:46:59,870
SPEAKER_1:  enable or service.

00:47:00,482 --> 00:47:02,590
SPEAKER_1:  better catalyst than others for

00:47:03,106 --> 00:47:03,582
SPEAKER_1:  of

00:47:03,810 --> 00:47:05,726
SPEAKER_1:  for the worst aspects of human nature.

00:47:06,082 --> 00:47:07,966
SPEAKER_1:  So for example, communist ideology.

00:47:08,674 --> 00:47:11,998
SPEAKER_1:  I don't know if it's the ideology or its implementation in the...

00:47:12,290 --> 00:47:13,438
SPEAKER_1:  in the 20th century.

00:47:13,986 --> 00:47:15,998
SPEAKER_1:  It seemed like such a sexy and

00:47:16,258 --> 00:47:20,062
SPEAKER_1:  powerful and viral ideology that it somehow allows

00:47:20,290 --> 00:47:23,198
SPEAKER_1:  the evil bad people to like sneak into the very top.

00:47:23,842 --> 00:47:28,190
SPEAKER_1:  And so like, that's what I mean about certain ideas Sounds so nice

00:47:28,994 --> 00:47:34,846
SPEAKER_1:  that allow you, like the lower classes, the workers, the people that do all the work, they should have power.

00:47:35,330 --> 00:47:39,038
SPEAKER_1:  They have been screwed over for far too long. They need to take power back.

00:47:39,394 --> 00:47:41,374
SPEAKER_1:  That sounds like a really powerful idea.

00:47:41,794 --> 00:47:44,382
SPEAKER_1:  And then it just seems like with those powerful ideas.

00:47:45,154 --> 00:47:46,590
SPEAKER_1:  Evil people sneak in.

00:47:46,850 --> 00:47:48,725
SPEAKER_1:  to the top and start to abuse that power.

00:47:48,725 --> 00:47:49,694
SPEAKER_0:  Yeah, I think...

00:47:50,434 --> 00:47:51,902
SPEAKER_0:  I mean, I don't have a lot of.

00:47:52,130 --> 00:47:53,950
SPEAKER_0:  probably big brain political takes.

00:47:54,402 --> 00:47:59,646
SPEAKER_0:  But what I can say is that you can never get away from both the system and the individual mattering.

00:48:00,066 --> 00:48:00,734
SPEAKER_0:  For sure.

00:48:00,994 --> 00:48:04,222
SPEAKER_0:  Some systems incentivize some behaviors in certain ways.

00:48:04,802 --> 00:48:09,694
SPEAKER_0:  But some people will take that and go, okay, all we need to do is design the perfect system and then these individuals will act.

00:48:10,274 --> 00:48:12,254
SPEAKER_0:  completely rationally or responsibly.

00:48:12,514 --> 00:48:14,910
SPEAKER_0:  in accordance to what our incentives say. That's not true.

00:48:15,458 --> 00:48:18,718
SPEAKER_0:  You could also say all we have to do is focus on the individual.

00:48:19,010 --> 00:48:30,238
SPEAKER_0:  And all we have to do is just create a society which raises very well adjusted people, and then we can throw them into any system with any incentives, and they will act like responsibly, ethically, morally, and I also don't think that's true.

00:48:30,530 --> 00:48:32,542
SPEAKER_0:  So incentives are real, but also.

00:48:33,570 --> 00:48:38,782
SPEAKER_0:  the individual ultimately plays a large role too. So yeah, I don't know. I come down sort of in the middle there.

00:48:39,170 --> 00:48:39,870
SPEAKER_1:  and some of.

00:48:40,482 --> 00:48:40,894
SPEAKER_1:  that.

00:48:41,602 --> 00:48:44,862
SPEAKER_1:  It's just accidents of history too. Which individual finds which system.

00:48:45,410 --> 00:48:47,230
SPEAKER_1:  You know. Come the face of that.

00:48:47,970 --> 00:48:50,878
SPEAKER_1:  Yeah, with FTX versus Coinbase versus...

00:48:51,138 --> 00:48:51,838
SPEAKER_1:  Binance.

00:48:52,322 --> 00:48:55,998
SPEAKER_1:  or which individual, which kinds of ideas and.

00:48:56,450 --> 00:48:57,950
SPEAKER_1:  life story

00:48:58,434 --> 00:48:59,102
SPEAKER_1:  come to power.

00:48:59,458 --> 00:49:01,758
SPEAKER_1:  things that that matters it's kind of fascinating.

00:49:02,114 --> 00:49:04,446
SPEAKER_1:  that history turns on these small little events.

00:49:04,930 --> 00:49:05,662
SPEAKER_1:  Bye bye.

00:49:06,114 --> 00:49:07,454
SPEAKER_1:  small little individuals.

00:49:07,874 --> 00:49:12,606
SPEAKER_1:  that Hitler's a failed artist or you have FDR or you have.

00:49:13,090 --> 00:49:19,422
SPEAKER_1:  all these different characters that do good or do evil onto the world. And it's like single individuals and they have a life story.

00:49:19,746 --> 00:49:21,182
SPEAKER_1:  and it could have turned out completely different.

00:49:21,858 --> 00:49:24,286
SPEAKER_1:  It's the flap of the butterfly wings.

00:49:24,610 --> 00:49:26,366
SPEAKER_1:  So yeah, you're right, we should.

00:49:27,138 --> 00:49:30,910
SPEAKER_1:  be skeptical as attributing too much to the system or the individual.

00:49:31,234 --> 00:49:32,670
SPEAKER_1:  It's all like a beautiful mess.

00:49:37,442 --> 00:49:45,755
SPEAKER_0:  That's like a that was like a Lex line. I've heard I've heard quite a few episodes and that's like such a Lex line It's a beautiful man. All right, beautifully said. All right. I'm a fan

00:49:45,755 --> 00:49:47,998
SPEAKER_1:  Oh, okay, alright, I love you too.

00:49:48,418 --> 00:49:49,118
SPEAKER_1:  Alright

00:49:50,274 --> 00:49:52,670
SPEAKER_1:  Can you think of possible trajectories how this...

00:49:54,082 --> 00:49:56,990
SPEAKER_1:  FTX SBF Saga ends.

00:49:57,762 --> 00:49:58,174
SPEAKER_1:  Uh...

00:49:58,722 --> 00:50:00,158
SPEAKER_1:  And which one do you hope for?

00:50:00,418 --> 00:50:02,238
SPEAKER_1:  Do you hope that SPF goes to jail?

00:50:03,394 --> 00:50:10,654
SPEAKER_1:  that's the individual and in terms of the investors and the customers, what do you hope happens and what do you think are the possible things that can happen?

00:50:12,098 --> 00:50:14,302
SPEAKER_0:  So A, yeah, I definitely think SPF.

00:50:14,530 --> 00:50:15,454
SPEAKER_0:  should go to jail.

00:50:15,682 --> 00:50:16,190
SPEAKER_0:  Um

00:50:16,674 --> 00:50:19,742
SPEAKER_0:  for nothing else, for a semblance of justice.

00:50:20,258 --> 00:50:23,294
SPEAKER_0:  facsimile of justice to occur for all the investors.

00:50:23,906 --> 00:50:26,270
SPEAKER_0:  I also think there are people probably...

00:50:26,914 --> 00:50:27,518
SPEAKER_0:  several

00:50:28,002 --> 00:50:31,934
SPEAKER_0:  steps down the chain that probably knew, at least Caroline Ellison.

00:50:32,290 --> 00:50:33,918
SPEAKER_0:  you can have questions about sort of their.

00:50:34,242 --> 00:50:37,054
SPEAKER_0:  you know, Dan Friedberg, who I'd love to talk about as well.

00:50:37,474 --> 00:50:40,990
SPEAKER_0:  Um, there were a lot of people in that room who I think knew, I think.

00:50:41,442 --> 00:50:43,006
SPEAKER_0:  We do so much of like.

00:50:43,266 --> 00:50:46,366
SPEAKER_0:  The one guy is all to blame. Let's throw everything at him.

00:50:46,882 --> 00:50:48,414
SPEAKER_0:  when clearly this was a

00:50:48,834 --> 00:50:49,438
SPEAKER_0:  company.

00:50:49,698 --> 00:50:50,462
SPEAKER_0:  wide issue.

00:50:51,106 --> 00:50:53,886
SPEAKER_0:  So everyone who knew, I think should face...

00:50:54,786 --> 00:50:58,014
SPEAKER_0:  the same punishment, which I think should be jail for all of those people.

00:50:58,818 --> 00:50:59,358
SPEAKER_0:  um...

00:51:00,290 --> 00:51:03,390
SPEAKER_1:  in part to send a signal to anybody that tries this kind of stuff in the future.

00:51:04,066 --> 00:51:08,286
SPEAKER_0:  Yeah, absolutely. I mean, one of the big things that you saw, like, okay,

00:51:08,802 --> 00:51:11,422
SPEAKER_0:  Take a microcosm of all of this action.

00:51:11,842 --> 00:51:13,630
SPEAKER_0:  and just look at like the influencer space.

00:51:14,754 --> 00:51:18,334
SPEAKER_0:  There's a ton of deals that were done that I've covered ad nauseum.

00:51:18,722 --> 00:51:19,230
SPEAKER_0:  about.

00:51:20,002 --> 00:51:23,742
SPEAKER_0:  Influencer finds out they can make a lot of money selling a crypto coin

00:51:24,130 --> 00:51:26,718
SPEAKER_0:  The first thing they wonder is, am I gonna get caught?

00:51:27,618 --> 00:51:28,702
SPEAKER_0:  If I do this...

00:51:29,058 --> 00:51:30,238
SPEAKER_0:  Is there a consequence?

00:51:30,658 --> 00:51:32,062
SPEAKER_0:  And if the answer is no...

00:51:32,450 --> 00:51:34,910
SPEAKER_0:  then it's a pretty easy decision as long as you don't.

00:51:35,266 --> 00:51:39,294
SPEAKER_0:  like have any moral scruples about it, which apparently none of them did, or a lot of them didn't, I should say.

00:51:40,322 --> 00:51:40,702
SPEAKER_0:  So.

00:51:41,826 --> 00:51:44,318
SPEAKER_0:  As soon as somebody steps in and regulates that...

00:51:44,578 --> 00:51:48,990
SPEAKER_0:  math changes and all of a sudden there's a self-interest reason to not go do the bad thing.

00:51:49,442 --> 00:51:51,710
SPEAKER_0:  So, for example, and I can give a concrete example of this.

00:51:53,282 --> 00:51:56,926
SPEAKER_0:  There was a NFT, the first ever NFT sort of like.

00:51:57,890 --> 00:51:58,782
SPEAKER_0:  official

00:51:59,074 --> 00:52:02,078
SPEAKER_0:  indictment or the DOJ released this press release.

00:52:02,466 --> 00:52:05,214
SPEAKER_0:  that they're charging these guys who ran a NFT project.

00:52:05,730 --> 00:52:09,726
SPEAKER_0:  that they didn't follow through on their promises. They made all these promises, lied and then ran away with the money.

00:52:10,466 --> 00:52:12,894
SPEAKER_0:  first ever consequence for anyone in the NFT space.

00:52:13,474 --> 00:52:16,862
SPEAKER_0:  That day that that press release came out, I saw several NFT.

00:52:17,314 --> 00:52:17,822
SPEAKER_0:  Um...

00:52:18,114 --> 00:52:19,998
SPEAKER_0:  projects come back to life from the dead.

00:52:20,802 --> 00:52:23,870
SPEAKER_0:  Why? Because all those founders are freaking out.

00:52:24,226 --> 00:52:31,486
SPEAKER_0:  and they realized we scammed people, we have to go at least make it look like we're doing the right thing, right? Even just, so that's on the optic side, but there's also...

00:52:31,714 --> 00:52:33,246
SPEAKER_0:  tons of people who now go, oh.

00:52:34,498 --> 00:52:36,126
SPEAKER_0:  Basically, law enforcement is on the scene.

00:52:36,610 --> 00:52:37,886
SPEAKER_0:  We can't do the same thing, so.

00:52:38,594 --> 00:52:41,406
SPEAKER_0:  There is a very pragmatic reason to-

00:52:41,794 --> 00:52:44,094
SPEAKER_0:  for this punishment. It's very much just because.

00:52:44,322 --> 00:52:45,694
SPEAKER_0:  people work it into their math of.

00:52:46,018 --> 00:52:47,070
SPEAKER_0:  Should I commit fraud?

00:52:47,426 --> 00:52:50,366
SPEAKER_0:  and the last several years have been very...

00:52:50,914 --> 00:52:51,646
SPEAKER_0:  What has it been like?

00:52:51,906 --> 00:52:52,830
SPEAKER_0:  a little bit of a...

00:52:53,154 --> 00:52:54,142
SPEAKER_0:  Nihilistic.

00:52:54,786 --> 00:52:57,118
SPEAKER_0:  landscape where no one was getting punished.

00:52:57,410 --> 00:52:58,558
SPEAKER_0:  And so there's this question of.

00:52:58,882 --> 00:53:00,862
SPEAKER_0:  You're almost an idiot if you didn't take the deals.

00:53:01,346 --> 00:53:04,926
SPEAKER_0:  uh... so i think it's really important extremely important for

00:53:05,378 --> 00:53:05,726
SPEAKER_0:  kind of.

00:53:06,114 --> 00:53:07,006
SPEAKER_0:  Law enforcement.

00:53:07,426 --> 00:53:08,318
SPEAKER_0:  to play a role.

00:53:08,674 --> 00:53:12,574
SPEAKER_0:  regulation to play a role to make it harder to commit those crimes, and if you commit those crimes-

00:53:12,866 --> 00:53:15,198
SPEAKER_0:  there's actual real world punishment for it.

00:53:16,386 --> 00:53:20,062
SPEAKER_0:  Your point about like what's gonna happen to the investors. I think that was kind of your question.

00:53:21,090 --> 00:53:21,598
SPEAKER_0:  It's tough.

00:53:21,858 --> 00:53:25,694
SPEAKER_0:  because if the money's not there, the money's not there. I mean, there's going to be the guy.

00:53:26,018 --> 00:53:28,894
SPEAKER_0:  They got the best in class guy. It's the guy who ran the-

00:53:29,250 --> 00:53:32,606
SPEAKER_0:  dissolving of Enron, so I mean, I can't imagine someone better equipped.

00:53:33,058 --> 00:53:35,262
SPEAKER_0:  to run a complicated corporate fraud like.

00:53:36,002 --> 00:53:37,118
SPEAKER_0:  dissolution but.

00:53:38,082 --> 00:53:43,774
SPEAKER_0:  Yeah, it's tough because everyone's going to get probably, I don't know, 10 cents on the dollar, maybe less.

00:53:44,162 --> 00:53:48,350
SPEAKER_1:  I wonder if there's a way to do a progressive redistribution of funds.

00:53:48,578 --> 00:53:52,382
SPEAKER_1:  I'm just really worried about the pain that small investors feel.

00:53:52,834 --> 00:53:53,310
SPEAKER_1:  I think.

00:53:53,602 --> 00:53:55,998
SPEAKER_0:  Yeah, I think there's a lot of.

00:53:56,290 --> 00:53:57,310
SPEAKER_0:  thought around that.

00:53:58,050 --> 00:53:58,910
SPEAKER_0:  I forget if...

00:54:00,674 --> 00:54:03,486
SPEAKER_0:  If they actually do do this, I mean, I know there's a lot of law about like-

00:54:03,810 --> 00:54:04,830
SPEAKER_0:  You can't treat.

00:54:05,826 --> 00:54:07,934
SPEAKER_0:  predators differently, you have to treat them all the same.

00:54:08,290 --> 00:54:08,894
SPEAKER_0:  So.

00:54:09,250 --> 00:54:11,486
SPEAKER_0:  I think it'll be some kind of proportional.

00:54:11,906 --> 00:54:13,630
SPEAKER_0:  payback. It's certainly not going to be that

00:54:13,986 --> 00:54:18,590
SPEAKER_0:  the guys at the top get a significant amount of their money back and the rest get nothing.

00:54:18,882 --> 00:54:20,830
SPEAKER_0:  Unfortunately, I think there's such a...

00:54:21,858 --> 00:54:24,766
SPEAKER_0:  small amount of assets that back this whole thing in the end.

00:54:25,154 --> 00:54:28,414
SPEAKER_0:  And that value is actually declining every day because

00:54:28,674 --> 00:54:29,150
SPEAKER_0:  It was.

00:54:29,538 --> 00:54:34,750
SPEAKER_0:  inextricably tied to FSPF. It was like the FTT tokens, which now what are those worth?

00:54:35,298 --> 00:54:38,206
SPEAKER_0:  The serum tokens that was his project or the project they made

00:54:38,626 --> 00:54:40,798
SPEAKER_0:  What is that worth? Basically nothing.

00:54:41,538 --> 00:54:46,430
SPEAKER_0:  You know, it's a very, it's a hard situation. And you know, there's a bigger ethical concern.

00:54:46,786 --> 00:54:48,446
SPEAKER_0:  which is FTX US.

00:54:49,410 --> 00:54:52,478
SPEAKER_0:  It's unclear how backed it was, but it was clearly more backed.

00:54:52,930 --> 00:54:54,142
SPEAKER_0:  than FTX International.

00:54:55,074 --> 00:54:56,318
SPEAKER_0:  Do you take all that money?

00:54:56,610 --> 00:54:59,006
SPEAKER_0:  and throw it into a big pot and give people money back?

00:54:59,490 --> 00:54:59,934
SPEAKER_0:  Or...

00:55:00,226 --> 00:55:00,606
SPEAKER_0:  Do you?

00:55:00,994 --> 00:55:02,590
SPEAKER_0:  give the US people back.

00:55:03,074 --> 00:55:07,966
SPEAKER_0:  their amount of money, which is probably going to be significantly more and leave everyone internationally out in the cold.

00:55:08,866 --> 00:55:13,726
SPEAKER_0:  To add to that ethical issue, let's say you're a liquidator and you're US based.

00:55:14,722 --> 00:55:16,158
SPEAKER_0:  There's a tremendous.

00:55:16,642 --> 00:55:18,686
SPEAKER_0:  question like legal questions about

00:55:19,170 --> 00:55:21,630
SPEAKER_0:  You know, how do you ethically do that? It's not clear.

00:55:22,018 --> 00:55:27,998
SPEAKER_0:  There's tremendous incentives to just favor the US people over everyone else, because it's our country, America, whatever.

00:55:28,386 --> 00:55:30,558
SPEAKER_0:  But I don't know if that's necessarily fair.

00:55:30,818 --> 00:55:32,693
SPEAKER_0:  It's really hard. It's like, it's impossible.

00:55:32,693 --> 00:55:43,006
SPEAKER_1:  And some I forget where you said this but one of the I mean it probably permeates a lot of the investigations you do Which is this idea that

00:55:43,234 --> 00:55:47,870
SPEAKER_1:  It's really sad that the middle class in most situations like this get fucked over.

00:55:48,418 --> 00:55:50,110
SPEAKER_1:  So the IRS.

00:55:50,658 --> 00:55:54,910
SPEAKER_1:  go after the middle class, then go after the rich. is basically

00:55:55,362 --> 00:55:58,334
SPEAKER_1:  everyone who doesn't have a lot of leverage in terms of

00:55:58,626 --> 00:55:59,518
SPEAKER_1:  lawyers.

00:56:00,002 --> 00:56:00,638
SPEAKER_1:  Money.

00:56:00,898 --> 00:56:01,662
SPEAKER_1:  Get fucked over.

00:56:02,498 --> 00:56:03,582
SPEAKER_0:  Yes. And then.

00:56:04,098 --> 00:56:05,150
SPEAKER_0:  They're the ones.

00:56:05,826 --> 00:56:11,006
SPEAKER_0:  Like it's always the rich and powerful who get the favorable treatment. Is it like a microcosm of this funny story?

00:56:11,234 --> 00:56:11,742
SPEAKER_0:  So.

00:56:12,802 --> 00:56:14,590
SPEAKER_0:  One of the big criticisms of crypto.

00:56:14,946 --> 00:56:16,126
SPEAKER_0:  And I think rightly so.

00:56:16,386 --> 00:56:18,846
SPEAKER_0:  is the irreversibility of the transaction. Thanks again, on behalf of wishedCenter exactly 50 dollars a month, and local delivery Cheryl

00:56:19,138 --> 00:56:22,238
SPEAKER_0:  I accidentally send a transaction somewhere, it's gone.

00:56:23,266 --> 00:56:23,710
SPEAKER_0:  So.

00:56:24,002 --> 00:56:27,166
SPEAKER_0:  Crypto.com accidentally sent a lady $10 million.

00:56:28,354 --> 00:56:30,206
SPEAKER_0:  and now they want the money back and they're suing her.

00:56:30,754 --> 00:56:34,846
SPEAKER_0:  But the funny thing is, is if you are on Crypto.com and you send

00:56:35,074 --> 00:56:39,614
SPEAKER_0:  Let's say I accidentally send you money and I come knocking on your door. Let's say I didn't mean to send you-

00:56:39,874 --> 00:56:40,606
SPEAKER_0:  You know, like.

00:56:40,994 --> 00:56:43,390
SPEAKER_0:  uh... a thousand dollars i need my money back

00:56:44,418 --> 00:56:47,870
SPEAKER_0:  Or if I go to crypto.com and I said, hey, I sent that to the wrong person, can you reverse it? That's right, after take 3, Put me in. Type.

00:56:48,130 --> 00:56:49,438
SPEAKER_0:  Screw off, no way.

00:56:49,858 --> 00:56:51,614
SPEAKER_0:  If I go to court, they'll kill me in court.

00:56:52,098 --> 00:56:53,918
SPEAKER_0:  Cause they're going to go, look, this is how the blockchain works.

00:56:54,146 --> 00:56:57,278
SPEAKER_0:  But then they do it, they do the exact same thing. I send this lady 10 million dollars.

00:56:57,698 --> 00:57:02,238
SPEAKER_0:  They're suing Arnold, they're gonna win. Now what's in court is not whether they get the money back. It's.

00:57:02,530 --> 00:57:04,446
SPEAKER_0:  Should she be liable for theft, I believe.

00:57:04,994 --> 00:57:05,470
SPEAKER_0:  So.

00:57:06,434 --> 00:57:08,382
SPEAKER_0:  And that's just another case of.

00:57:09,634 --> 00:57:15,198
SPEAKER_0:  The same rules apply differently to different people, whether you have the money to back you or not. It's a very sad thing.

00:57:15,618 --> 00:57:18,046
SPEAKER_0:  And that's why I think people like, you need.

00:57:18,978 --> 00:57:19,774
SPEAKER_0:  Journalists

00:57:20,034 --> 00:57:21,054
SPEAKER_0:  fighting for.

00:57:21,858 --> 00:57:22,814
SPEAKER_0:  the little person.

00:57:23,874 --> 00:57:24,702
SPEAKER_0:  We really need it.

00:57:25,058 --> 00:57:29,950
SPEAKER_0:  And it's kind of like this unfortunate thing where that's the most risky thing to do, like legally. You should.

00:57:30,178 --> 00:57:31,806
SPEAKER_0:  not be doing that but um...

00:57:32,642 --> 00:57:35,646
SPEAKER_1:  I think it's important to do. It's the ethical thing. It's the right thing to do.

00:57:36,290 --> 00:57:43,070
SPEAKER_1:  What do you think about influencers and celebrities that supported FTX and SBF? Should they be punished?

00:57:43,362 --> 00:57:48,286
SPEAKER_0:  Yeah, I think they should take a huge reputational hit. I mean, I think they should be embarrassed.

00:57:48,674 --> 00:57:49,662
SPEAKER_0:  I think they should be.

00:57:49,986 --> 00:57:51,326
SPEAKER_0:  ashamed of themselves.

00:57:51,746 --> 00:57:55,326
SPEAKER_1:  but it was really hard to know, sorry to interrupt, for them to know.

00:57:55,842 --> 00:57:58,718
SPEAKER_1:  Like for example, I think about this a lot. Yeah.

00:58:00,162 --> 00:58:00,990
SPEAKER_1:  Who do I?

00:58:01,794 --> 00:58:04,190
SPEAKER_1:  Because I don't investigate, you know, like, uh...

00:58:04,994 --> 00:58:06,398
SPEAKER_1:  Sponsored by Athletic Greens.

00:58:06,658 --> 00:58:08,382
SPEAKER_1:  Okay, see nutritional drink.

00:58:08,898 --> 00:58:10,398
SPEAKER_1:  Should I investigate them deeply?

00:58:10,946 --> 00:58:15,614
SPEAKER_1:  I don't know, you just kinda use reputational, like it seems to work for me, should I?

00:58:15,842 --> 00:58:17,511
SPEAKER_1:  Like I think I think.

00:58:17,511 --> 00:58:18,750
SPEAKER_0:  really have pins on...

00:58:19,074 --> 00:58:19,518
SPEAKER_0:  I think.

00:58:19,970 --> 00:58:23,582
SPEAKER_0:  your credibility hit will depend on what domain you're an expert in.

00:58:23,938 --> 00:58:25,758
SPEAKER_0:  if you're sponsored by a robotics company.

00:58:26,530 --> 00:58:27,838
SPEAKER_0:  and you're an expert in robotics.

00:58:28,386 --> 00:58:31,102
SPEAKER_0:  If that company turns out to be a disaster and fraud.

00:58:31,458 --> 00:58:32,766
SPEAKER_0:  then you should have looked more deeply.

00:58:32,994 --> 00:58:34,334
SPEAKER_0:  We're talking mostly about.

00:58:34,754 --> 00:58:37,054
SPEAKER_0:  Like I hold Tom Brady a lot less accountable.

00:58:37,442 --> 00:58:40,574
SPEAKER_0:  than financial advisors, financial influencers, because...

00:58:40,898 --> 00:58:45,822
SPEAKER_0:  That is their world of expertise. And you treat their recommendation differently.

00:58:46,146 --> 00:58:48,478
SPEAKER_0:  proportionally to what you think their expertise is.

00:58:48,898 --> 00:58:50,398
SPEAKER_0:  So in some ways I don't actually think.

00:58:50,786 --> 00:58:52,126
SPEAKER_0:  Tom Brady, I'm sure he reached a lot of people.

00:58:52,610 --> 00:58:56,254
SPEAKER_0:  I personally didn't feel it all moved by his recommendation, because you know it's just money.

00:58:57,122 --> 00:58:59,806
SPEAKER_0:  But when you hear somebody who should be an expert in that thing...

00:59:00,706 --> 00:59:02,846
SPEAKER_0:  endorse a product in that space.

00:59:03,170 --> 00:59:03,934
SPEAKER_0:  You hold that.

00:59:04,546 --> 00:59:07,934
SPEAKER_0:  opinion to a higher standard and when they're completely cat is

00:59:08,386 --> 00:59:09,694
SPEAKER_0:  cataclysmically wrong?

00:59:10,338 --> 00:59:13,342
SPEAKER_0:  it's gonna be a different level of accountability. And I think rightfully so.

00:59:13,602 --> 00:59:14,302
SPEAKER_0:  when um...

00:59:14,594 --> 00:59:15,390
SPEAKER_0:  Jim Cramer.

00:59:16,066 --> 00:59:20,286
SPEAKER_0:  was saying Bear Stearns is fine. He made that terrible call with Bear Stearns in 2008.

00:59:20,706 --> 00:59:22,014
SPEAKER_0:  He was rightfully-

00:59:22,498 --> 00:59:23,230
SPEAKER_0:  reamed.

00:59:23,490 --> 00:59:24,030
SPEAKER_0:  for all of that.

00:59:24,450 --> 00:59:27,134
SPEAKER_0:  even though it could be considered that like, well.

00:59:27,490 --> 00:59:29,726
SPEAKER_0:  You know, did he have all the information? Maybe not.

00:59:30,402 --> 00:59:33,438
SPEAKER_0:  He's a financial advisor. He does this for a living.

00:59:33,762 --> 00:59:38,462
SPEAKER_0:  If you go on and you make a big call and you turn out to be wrong and people lose tons of money,

00:59:39,330 --> 00:59:44,205
SPEAKER_0:  you are going to take a hit, and I think rightfully so. But no, I don't think these people should go to jail or anything like that. I don't think you should be out there again.

00:59:44,205 --> 00:59:47,742
SPEAKER_1:  It's such a complicated thing. I mean, I just feel it personally myself. I get it

00:59:48,258 --> 00:59:48,830
SPEAKER_1:  But...

00:59:49,282 --> 00:59:51,454
SPEAKER_1:  You still feel the burden of the fact that you're

00:59:52,194 --> 00:59:53,534
SPEAKER_1:  opinion has influence.

00:59:53,858 --> 00:59:54,814
SPEAKER_1:  I know it shouldn't.

00:59:55,106 --> 01:00:01,214
SPEAKER_1:  I know Tom Brady's opinion on financial investment should not have influence, but it does. That's just the reality of it.

01:00:01,506 --> 01:00:02,494
SPEAKER_1:  That's a real burden.

01:00:02,914 --> 01:00:07,422
SPEAKER_1:  I didn't know anything about SBF or FTX. It wasn't on my radar at all.

01:00:07,906 --> 01:00:09,854
SPEAKER_1:  Um, but I could see myself.

01:00:10,786 --> 01:00:13,278
SPEAKER_1:  taking them on as a sponsor. I've seen a lot of people I respect.

01:00:13,666 --> 01:00:14,046
SPEAKER_1:  Bye.

01:00:14,466 --> 01:00:15,838
SPEAKER_1:  Sam Harris and others, like.

01:00:16,866 --> 01:00:18,526
SPEAKER_1:  talk with SPF.

01:00:19,170 --> 01:00:20,542
SPEAKER_1:  Mike, he's doing good for the world.

01:00:20,866 --> 01:00:25,950
SPEAKER_1:  So I could see myself being hoodwinked, having not done research. And the same thing makes me wonder.

01:00:26,562 --> 01:00:28,382
SPEAKER_1:  Like, I don't want to become cynical.

01:00:29,154 --> 01:00:32,702
SPEAKER_1:  But it makes you wonder who are the people in your life you trust that are like.

01:00:33,186 --> 01:00:34,942
SPEAKER_1:  that could be the next.

01:00:35,234 --> 01:00:37,822
SPEAKER_1:  SPF or worse.

01:00:38,146 --> 01:00:40,574
SPEAKER_1:  big powerful leaders hitler and all that kind of stuff

01:00:41,058 --> 01:00:41,470
SPEAKER_1:  Um.

01:00:42,402 --> 01:00:44,382
SPEAKER_1:  To what degree do you want to investigate?

01:00:44,802 --> 01:00:45,342
SPEAKER_1:  Do you want to?

01:00:46,082 --> 01:00:47,582
SPEAKER_1:  Hold their feet to the fire

01:00:48,098 --> 01:00:54,270
SPEAKER_1:  see through their bullshit, call them on their bullshit. And also as a friend, if you happen to be friends or have a connection how to help them.

01:00:54,690 --> 01:00:56,414
SPEAKER_1:  not slip into the

01:00:56,770 --> 01:00:57,854
SPEAKER_1:  Land of fraud.

01:00:58,434 --> 01:01:00,126
SPEAKER_1:  I don't know, all of it is just overwhelming.

01:01:00,674 --> 01:01:05,310
SPEAKER_0:  Yeah, I mean, I mean we should be clear like finance is sort of a special space

01:01:05,954 --> 01:01:06,590
SPEAKER_0:  where

01:01:08,098 --> 01:01:09,438
SPEAKER_0:  You're talking about people's money.

01:01:09,794 --> 01:01:12,222
SPEAKER_0:  You're not talking about whether someone takes a bad supplement.

01:01:12,578 --> 01:01:15,390
SPEAKER_0:  or like a supplement that is just, they're $50 out.

01:01:16,898 --> 01:01:20,094
SPEAKER_0:  I think the scale of harm and therefore responsibility.

01:01:20,450 --> 01:01:23,102
SPEAKER_0:  escalates depending on what field you're in. Just like-

01:01:23,650 --> 01:01:25,438
SPEAKER_0:  I wouldn't hold Tom Brady as

01:01:25,858 --> 01:01:27,614
SPEAKER_0:  Like if he gives a bad football opinion, right?

01:01:27,842 --> 01:01:28,830
SPEAKER_0:  and he should have known better.

01:01:29,442 --> 01:01:30,942
SPEAKER_0:  That is a different scale of harm.

01:01:31,266 --> 01:01:33,054
SPEAKER_0:  than a doctor giving bad advice.

01:01:33,282 --> 01:01:36,478
SPEAKER_0:  Right, like life's it, like he tells you a pill works and the pill.

01:01:36,706 --> 01:01:37,886
SPEAKER_0:  kills you or something like that.

01:01:38,274 --> 01:01:42,110
SPEAKER_0:  There's just different levels of accountability depending on the field you're in and you have to be aware of it.

01:01:42,530 --> 01:01:47,454
SPEAKER_0:  Finance is an extreme. You have to be extremely conservative if you're going to give financial advice.

01:01:47,682 --> 01:01:55,806
SPEAKER_0:  because you're playing with people's lives and you cannot play with them haphazardly, you cannot gamble with them, you cannot play with them on a bet because you're getting paid a lot of money.

01:01:57,410 --> 01:02:04,254
SPEAKER_0:  It's just the nature of the space. And so with the space comes the responsibility and the accountability. And I don't think you can get around that.

01:02:04,610 --> 01:02:10,590
SPEAKER_1:  Who was Dan Friedberg that you mentioned? Some of these figures in the SBF realm that are interesting to you.

01:02:10,690 --> 01:02:11,582
SPEAKER_0:  super interesting.

01:02:11,842 --> 01:02:14,014
SPEAKER_0:  kind of subject because Dan Friedberg.

01:02:14,274 --> 01:02:17,630
SPEAKER_0:  is the former general counsel for ultimate bet.

01:02:19,010 --> 01:02:22,014
SPEAKER_0:  Ultimate Bet was a poker site.

01:02:22,338 --> 01:02:25,598
SPEAKER_0:  where famously they got in a scandal because...

01:02:25,826 --> 01:02:29,854
SPEAKER_0:  The owner, Russ Hamilton, was cheating with a little software.

01:02:30,274 --> 01:02:31,870
SPEAKER_0:  piece of code they call God Mode.

01:02:32,098 --> 01:02:33,566
SPEAKER_0:  God mode allowed you to see.

01:02:34,210 --> 01:02:35,646
SPEAKER_0:  the guy across from you's hand.

01:02:35,938 --> 01:02:40,158
SPEAKER_0:  Obviously you can imagine you can win pretty consistently if you know exactly what your opponent has.

01:02:40,674 --> 01:02:41,822
SPEAKER_0:  Very unethical.

01:02:42,530 --> 01:02:43,646
SPEAKER_0:  They, I should be clear.

01:02:44,898 --> 01:02:47,166
SPEAKER_0:  for some inexplicable reason. I don't think they were ever-

01:02:47,426 --> 01:02:49,182
SPEAKER_0:  charged and convicted of a crime.

01:02:49,602 --> 01:02:53,758
SPEAKER_0:  but they were investigated by a gambling commission that found they made tens of millions of dollars this way.

01:02:54,242 --> 01:02:54,846
SPEAKER_0:  for sure.

01:02:56,738 --> 01:02:59,294
SPEAKER_0:  Dan Friedberg is the general counsel. He's caught on a call.

01:02:59,682 --> 01:03:02,078
SPEAKER_0:  basically conspiring with Russ to hide.

01:03:02,434 --> 01:03:02,942
SPEAKER_0:  This.

01:03:03,234 --> 01:03:03,550
SPEAKER_0:  Fraud.

01:03:04,034 --> 01:03:12,030
SPEAKER_0:  He's saying we should blame it on a consultant third party. And Russ Hamilton famously says, It was me. I did it. I don't want to give the money back.

01:03:12,770 --> 01:03:14,206
SPEAKER_0:  find basically a way to get rid of this.

01:03:14,594 --> 01:03:16,318
SPEAKER_0:  So that's Dan Friedberg's big achievement.

01:03:16,642 --> 01:03:18,846
SPEAKER_0:  Like that's what he's known for, he's most known for.

01:03:19,394 --> 01:03:22,686
SPEAKER_0:  And this is the guy they pick as their chief regulatory officer.

01:03:23,170 --> 01:03:24,318
SPEAKER_0:  for FTX.

01:03:24,610 --> 01:03:26,334
SPEAKER_0:  Why do you hire somebody who...

01:03:26,850 --> 01:03:35,038
SPEAKER_0:  I get it, not formally charged and convicted, investigated, there's all the, and there's tape out there. So I want to be clear about what's actually available evidence.

01:03:35,874 --> 01:03:40,318
SPEAKER_0:  but someone whose seemingly only achievement is hiding fraud.

01:03:40,706 --> 01:03:41,854
SPEAKER_0:  Why do you hire that guy?

01:03:42,242 --> 01:03:44,286
SPEAKER_0:  if the intention is not to hire.

01:03:44,738 --> 01:03:45,726
SPEAKER_0:  is not to hide fraud.

01:03:46,146 --> 01:03:50,590
SPEAKER_0:  So this is a question I put to Sam Bankman Fried and his answer was...

01:03:51,394 --> 01:03:57,470
SPEAKER_0:  Well, we have a lot of lawyers. And I said, well, it's your chief regulatory officer. He's like, well, we did regulate a lot.

01:03:57,794 --> 01:04:00,222
SPEAKER_0:  And it was just this big dance of, you know.

01:04:00,578 --> 01:04:01,310
SPEAKER_0:  Basically...

01:04:01,666 --> 01:04:03,422
SPEAKER_0:  He's done great work, he's a great guy.

01:04:03,970 --> 01:04:04,606
SPEAKER_0:  and

01:04:05,410 --> 01:04:06,910
SPEAKER_0:  I think that tells you everything you need to know.

01:04:07,298 --> 01:04:12,173
SPEAKER_1:  And there's figures like that probably even at the lower levels, like just infiltrate the entire organization.

01:04:12,173 --> 01:04:18,590
SPEAKER_0:  Well, it's just like, why, yeah, why wasn't there a CFA? Why wasn't there anyone in that space who could seemingly-

01:04:19,842 --> 01:04:21,854
SPEAKER_0:  be the eyes that goes holy

01:04:22,274 --> 01:04:22,942
SPEAKER_0:  Whatever.

01:04:23,362 --> 01:04:26,302
SPEAKER_0:  We need to, we were in dangerous territory here, right?

01:04:26,850 --> 01:04:31,358
SPEAKER_0:  Um, so yeah, it seems very deliberate. I mean, I talked to one FTX employee that they talked about.

01:04:31,618 --> 01:04:32,798
SPEAKER_0:  who's told me they talked about.

01:04:33,634 --> 01:04:34,366
SPEAKER_0:  taking.

01:04:34,850 --> 01:04:36,830
SPEAKER_0:  I think it was taking FTX US public.

01:04:37,346 --> 01:04:39,646
SPEAKER_0:  and Sam was very against the idea.

01:04:40,354 --> 01:04:42,686
SPEAKER_0:  and the employee in retrospect.

01:04:43,266 --> 01:04:46,334
SPEAKER_0:  speculated that it might have been because you'd faced so much scrutiny.

01:04:46,658 --> 01:04:48,830
SPEAKER_0:  like regulation-wise, like you'd have to, you know, go through.

01:04:49,058 --> 01:04:49,438
SPEAKER_0:  a lot.

01:04:50,018 --> 01:04:53,982
SPEAKER_0:  like more thorough audits, all that kind of stuff, that basically he knew they would never pass.

01:04:54,914 --> 01:04:55,454
SPEAKER_0:  Um...

01:04:56,194 --> 01:04:58,718
SPEAKER_0:  So yeah, I mean, it's red flags all the way down with that guy.

01:04:59,458 --> 01:05:01,182
SPEAKER_1:  and you hope all of them get.

01:05:01,474 --> 01:05:01,886
SPEAKER_1:  punished.

01:05:02,722 --> 01:05:03,422
SPEAKER_0:  Everyone who knew.

01:05:03,714 --> 01:05:04,222
SPEAKER_0:  I mean, I think.

01:05:04,450 --> 01:05:06,750
SPEAKER_0:  For sure, there are people at FTX who didn't know.

01:05:07,138 --> 01:05:08,702
SPEAKER_0:  I think there are some people at Alameda.

01:05:08,994 --> 01:05:09,662
SPEAKER_0:  who didn't know.

01:05:10,498 --> 01:05:14,590
SPEAKER_1:  There's degrees, sorry to interrupt, but there's degrees in not knowing. Yes! There's a-

01:05:14,914 --> 01:05:15,870
SPEAKER_1:  looking away.

01:05:16,130 --> 01:05:18,558
SPEAKER_1:  When you kind of know shady stuff.

01:05:19,042 --> 01:05:20,670
SPEAKER_1:  That's still the same as knowing, right?

01:05:20,898 --> 01:05:22,023
SPEAKER_1:  That's might be even worse.

01:05:22,023 --> 01:05:24,350
SPEAKER_0:  Well, yeah, like I was talking to one insider.

01:05:24,738 --> 01:05:26,398
SPEAKER_0:  and we're talking about the inside of trading.

01:05:26,690 --> 01:05:28,222
SPEAKER_0:  They were telling me about this insider trading.

01:05:28,834 --> 01:05:29,438
SPEAKER_0:  and

01:05:30,210 --> 01:05:31,326
SPEAKER_0:  I said, do you think this was?

01:05:31,618 --> 01:05:31,966
SPEAKER_0:  criminal.

01:05:32,898 --> 01:05:36,222
SPEAKER_0:  and they said it was probably criminal in hindsight, yes.

01:05:37,378 --> 01:05:39,710
SPEAKER_0:  And the question is someone who answers a question like that.

01:05:40,226 --> 01:05:44,094
SPEAKER_0:  What does that mean? It was probably criminal. so

01:05:44,770 --> 01:05:46,974
SPEAKER_0:  You're right, there are different degrees. I mean-

01:05:47,266 --> 01:05:51,614
SPEAKER_0:  I'll say at the most basic, I would be very happy if everyone who had direct knowledge

01:05:51,970 --> 01:05:55,838
SPEAKER_0:  went to jail, which I don't think will happen to be clear. I think a lot of people are going to cut deals.

01:05:56,098 --> 01:06:00,734
SPEAKER_0:  prosecutors are going to cut deals so they actually nail Sam Bankman Fried. I think that's their only focus.

01:06:01,026 --> 01:06:03,902
SPEAKER_1:  What about his reputation waiting about all these interviews.

01:06:05,410 --> 01:06:09,246
SPEAKER_1:  Do you think they are helping him? Do you think they are good for the world?

01:06:09,570 --> 01:06:12,542
SPEAKER_1:  Do you think they're bad for the world? Like what's your sense and-

01:06:12,770 --> 01:06:14,526
SPEAKER_1:  Like say you get to sit down.

01:06:15,010 --> 01:06:16,446
SPEAKER_1:  interview with him for three hours.

01:06:18,114 --> 01:06:19,646
SPEAKER_1:  and I'm holding the door closed.

01:06:20,034 --> 01:06:23,966
SPEAKER_1:  What, is that a useful conversation or not? Or at this point?

01:06:24,418 --> 01:06:25,342
SPEAKER_1:  It should be legal.

01:06:26,466 --> 01:06:26,942
SPEAKER_1:  And that's it.

01:06:27,746 --> 01:06:28,638
SPEAKER_0:  I think it's useful.

01:06:29,026 --> 01:06:35,134
SPEAKER_0:  I mean, I think it's all about how you interview him. You can interview someone responsibly, you can interview him.

01:06:35,394 --> 01:06:36,382
SPEAKER_0:  irresponsibly.

01:06:36,642 --> 01:06:38,366
SPEAKER_0:  I think we've seen examples.

01:06:38,914 --> 01:06:39,422
SPEAKER_0:  of both.

01:06:39,810 --> 01:06:43,715
SPEAKER_1:  What's an irresponsible? I keep interrupting you rudely. That's okay. No, no, no.

01:06:43,715 --> 01:06:45,694
SPEAKER_0:  No, no, no, I think it's fine.

01:06:45,954 --> 01:06:47,806
SPEAKER_0:  There was like a New York Times interview which...

01:06:48,674 --> 01:06:51,262
SPEAKER_0:  spends any amount of time talking about his sleep.

01:06:51,490 --> 01:06:52,574
SPEAKER_0:  And he's like, yeah, I'm sleeping great.

01:06:52,994 --> 01:06:55,038
SPEAKER_0:  I mean, I think that's so deeply disrespectful.

01:06:55,362 --> 01:06:56,126
SPEAKER_0:  to the victims.

01:06:56,354 --> 01:06:57,406
SPEAKER_0:  and especially when you're...

01:06:57,698 --> 01:07:02,142
SPEAKER_0:  You're not even releasing an interview live. It's like you have time to triage what you're going to talk about.

01:07:02,434 --> 01:07:04,958
SPEAKER_0:  Why would you spend any amount of time talking about the sleep?

01:07:05,218 --> 01:07:05,662
SPEAKER_0:  that I-

01:07:05,954 --> 01:07:06,686
SPEAKER_0:  fraudster.

01:07:07,330 --> 01:07:08,958
SPEAKER_0:  It's just so weird.

01:07:09,314 --> 01:07:11,454
SPEAKER_1:  and well it's a cast your man that case

01:07:12,258 --> 01:07:16,830
SPEAKER_1:  I don't think it turned out well. I think that's... I think...

01:07:18,594 --> 01:07:20,574
SPEAKER_1:  I could see myself talking while somebody sleeps.

01:07:20,962 --> 01:07:22,878
SPEAKER_1:  or getting in somebody's mind.

01:07:23,106 --> 01:07:25,246
SPEAKER_1:  if i knew have a moment time

01:07:25,794 --> 01:07:30,686
SPEAKER_1:  I knew I had like four hours because you get into the mind the person how they think how they see the world

01:07:31,138 --> 01:07:33,374
SPEAKER_1:  because I think that ultimately reveals.

01:07:34,114 --> 01:07:35,550
SPEAKER_1:  if they're actually really good at lying.

01:07:37,090 --> 01:07:38,078
SPEAKER_1:  It reveals.

01:07:38,466 --> 01:07:43,902
SPEAKER_1:  the depths, the complexity of the mind, that through like osmosis, you get to understand like this person.

01:07:44,226 --> 01:07:49,982
SPEAKER_1:  This person is not as trivial as you realize. Also, it makes you maybe realize that this person is.

01:07:50,210 --> 01:07:51,102
SPEAKER_1:  has a lot of hope.

01:07:51,394 --> 01:07:52,126
SPEAKER_1:  has a lot of.

01:07:52,354 --> 01:07:53,342
SPEAKER_1:  Positive ambition.

01:07:53,794 --> 01:07:54,558
SPEAKER_1:  That's like...

01:07:55,138 --> 01:07:59,902
SPEAKER_1:  that has developed over their life and then certain interesting ways things went wrong.

01:08:00,130 --> 01:08:02,005
SPEAKER_1:  become corrupt and all that kind of stuff.

01:08:02,005 --> 01:08:03,710
SPEAKER_0:  You just, that's all fine.

01:08:04,642 --> 01:08:10,206
SPEAKER_0:  This conversation was not properly contextualized in the world of what he did.

01:08:11,938 --> 01:08:16,446
SPEAKER_0:  And I've asked about this interview because I was like so curious. It was out of the New York Times.

01:08:17,090 --> 01:08:23,678
SPEAKER_0:  and there was not much mention of fraud or jail or the big crimes like misappropriation of even client assets.

01:08:24,002 --> 01:08:25,278
SPEAKER_0:  It was just sort of this.

01:08:25,602 --> 01:08:27,198
SPEAKER_0:  You know, Sam sat down with me.

01:08:27,490 --> 01:08:34,334
SPEAKER_0:  he's under investigation, but there's not much specifics. And then it's like, yeah, he's playing storybook brawl. He's sleeping, he's...

01:08:34,562 --> 01:08:37,937
SPEAKER_0:  And it's just like, okay, this isn't adding to the conversation.

01:08:37,937 --> 01:08:39,774
SPEAKER_1:  Especially when they're in New York Times, it's like a...

01:08:40,226 --> 01:08:41,351
SPEAKER_1:  You should be grilling.

01:08:41,351 --> 01:08:43,486
SPEAKER_0:  Right, right, exactly. So topic six two, we definitely, we're gonna focus on times and for rough purposes what

01:08:43,874 --> 01:08:49,342
SPEAKER_0:  But as I've said, I mean, it's all arranged the gamut and some interviews like some of it's okay and then some of it's weird like.

01:08:49,666 --> 01:08:51,070
SPEAKER_0:  the Andrew Sorkin interview.

01:08:51,586 --> 01:08:54,110
SPEAKER_0:  He asked some hard-hitting questions, which I really appreciated.

01:08:54,626 --> 01:08:59,326
SPEAKER_0:  And then at the end he goes, ladies and gentlemen, Sam Bankman Friede, and everyone gives like an ovation.

01:08:59,778 --> 01:09:00,126
SPEAKER_0:  for.

01:09:00,962 --> 01:09:01,342
SPEAKER_0:  Sam.

01:09:01,762 --> 01:09:04,702
SPEAKER_0:  I mean, the steel man of that of course is like, they're actually applauding.

01:09:05,154 --> 01:09:05,918
SPEAKER_0:  Andrew Sorkin.

01:09:06,210 --> 01:09:09,342
SPEAKER_0:  But the way you like lay it up, I wouldn't go like, ladies and gentlemen,

01:09:09,666 --> 01:09:12,478
SPEAKER_0:  It's like an applause line. Ladies and gentlemen, the Eagles Elton John.

01:09:12,802 --> 01:09:16,030
SPEAKER_0:  Lex Friedman. And so to go to, so you have this like.

01:09:16,258 --> 01:09:17,150
SPEAKER_0:  Dealbook Summit.

01:09:17,506 --> 01:09:21,150
SPEAKER_0:  where you have all these important figures that are positively important.

01:09:21,410 --> 01:09:26,302
SPEAKER_0:  And at the end you have Sam Bankman Fried, a fraudster. And yo, ladies and gentlemen, this is Sam Bankman Fried, everyone's applauding.

01:09:26,786 --> 01:09:30,206
SPEAKER_0:  That I think is a net, like I think that's a negative. I think the way that

01:09:30,498 --> 01:09:32,638
SPEAKER_0:  The optics of that just were all wrong.

01:09:32,898 --> 01:09:35,550
SPEAKER_0:  And so I think, yeah, you have to be very responsible.

01:09:36,290 --> 01:09:39,678
SPEAKER_0:  I think it's useful, going back to how you can usefully do this.

01:09:40,322 --> 01:09:43,358
SPEAKER_0:  You can, even when somebody's determined to lie to you.

01:09:44,738 --> 01:09:46,558
SPEAKER_0:  always important to...

01:09:47,490 --> 01:09:50,238
SPEAKER_0:  pin them down to an accounting of events.

01:09:50,498 --> 01:09:51,166
SPEAKER_0:  because that is.

01:09:51,522 --> 01:09:55,390
SPEAKER_0:  unimaginably helpful when it comes to a prosecutor trying to prove this guy's guilty.

01:09:55,842 --> 01:09:56,382
SPEAKER_0:  is

01:09:57,282 --> 01:10:01,278
SPEAKER_0:  If you say you didn't do a crime, but you don't tell me any details about it,

01:10:02,562 --> 01:10:05,022
SPEAKER_0:  Day of the trial, you can basically make up any story.

01:10:05,954 --> 01:10:08,766
SPEAKER_0:  But if you tell me in detail where you were that day...

01:10:09,154 --> 01:10:14,590
SPEAKER_0:  I can go hunt down you say you were with Joe. I go hunt down Joe and he says he wasn't with you. Boom, you've lost credibility and now...

01:10:14,914 --> 01:10:16,990
SPEAKER_0:  you're much more, you're much more.

01:10:17,282 --> 01:10:18,334
SPEAKER_0:  likely to be convicted.

01:10:18,626 --> 01:10:23,742
SPEAKER_0:  So it's really important to get SBF's exact accounting of how things went wrong.

01:10:24,130 --> 01:10:24,638
SPEAKER_0:  because

01:10:24,962 --> 01:10:27,454
SPEAKER_0:  Right now, he's positioning himself to throw his...

01:10:27,810 --> 01:10:31,262
SPEAKER_0:  Alameda CEO Caroline Ellison under the bus like she did everything

01:10:31,490 --> 01:10:33,054
SPEAKER_0:  She knew everything, I knew nothing.

01:10:33,858 --> 01:10:39,934
SPEAKER_0:  Well, is Caroline Ellison gonna take the stand and go, well, I have all these text messages and this is all a lie, then Sam Bankman Fried is gonna be completely.

01:10:40,770 --> 01:10:41,118
SPEAKER_0:  You know.

01:10:41,922 --> 01:10:44,990
SPEAKER_0:  ruined, like self-ruined by his own design. so

01:10:45,122 --> 01:10:47,454
SPEAKER_1:  I think it's more like a legal type of uh...

01:10:47,714 --> 01:10:51,089
SPEAKER_1:  I get the details of where he was, what he was thinking, what the... I think it's...

01:10:51,089 --> 01:10:56,766
SPEAKER_0:  It's like, yeah, I think the public probably cares to get to know what happened to. And again, I think.

01:10:57,154 --> 01:10:58,782
SPEAKER_0:  If you're s- if you're careful

01:10:59,458 --> 01:11:02,590
SPEAKER_0:  you can expose someone for as they lie to you.

01:11:02,978 --> 01:11:03,390
SPEAKER_0:  without.

01:11:04,002 --> 01:11:06,814
SPEAKER_0:  giving into those lies, right? Like without capitulating.

01:11:07,042 --> 01:11:07,518
SPEAKER_0:  to.

01:11:08,002 --> 01:11:09,726
SPEAKER_0:  Oh, I'm just going to assume you're correct.

01:11:10,146 --> 01:11:20,286
SPEAKER_0:  I think you can point to, well, Lex, you say it happened this way, but you've lied about X, Y, and Z. Why should we believe you? That's suddenly a totally different conversation than just being like, okay, that's how it happened.

01:11:20,770 --> 01:11:21,822
SPEAKER_1:  The thing I caught.

01:11:22,850 --> 01:11:23,870
SPEAKER_1:  Bothered me.

01:11:24,610 --> 01:11:26,878
SPEAKER_1:  And the thing I hope to do in interviews is if.

01:11:28,514 --> 01:11:29,086
SPEAKER_1:  uh...

01:11:29,666 --> 01:11:34,142
SPEAKER_1:  if I eventually get good at this thing, is the human aspect of it, which is like.

01:11:34,498 --> 01:11:35,870
SPEAKER_1:  which I think you have to do in person.

01:11:36,866 --> 01:11:40,190
SPEAKER_1:  is he seems a bit nonchalant about the pain and the suffering of people.

01:11:41,090 --> 01:11:42,878
SPEAKER_1:  I have read flags about...

01:11:43,586 --> 01:11:44,382
SPEAKER_1:  the way.

01:11:45,794 --> 01:11:46,110
SPEAKER_1:  He's-

01:11:46,434 --> 01:11:48,478
SPEAKER_1:  He communicates about...

01:11:48,962 --> 01:11:52,638
SPEAKER_1:  the loss of money, the pain that people are feeling about the money.

01:11:53,122 --> 01:11:55,006
SPEAKER_1:  I get red flags, like you're not...

01:11:55,650 --> 01:11:58,526
SPEAKER_1:  uh... forget if you're involved in that pain or not you're not

01:11:59,362 --> 01:12:00,542
SPEAKER_1:  feeling that pain.

01:12:01,250 --> 01:12:06,247
SPEAKER_0:  Well, he'll say he is, but he'll be playing a game of League of Legends while doing it.

01:12:06,247 --> 01:12:08,497
SPEAKER_1:  I just see from his face the dynamic. I know.

01:12:08,497 --> 01:12:10,747
SPEAKER_0:  And that needs to be grilled.

01:12:10,747 --> 01:12:13,758
SPEAKER_1:  that little human dance there. That's why I mean I.

01:12:14,178 --> 01:12:15,454
SPEAKER_1:  I considered.

01:12:16,322 --> 01:12:17,214
SPEAKER_1:  I talked to him.

01:12:17,570 --> 01:12:19,582
SPEAKER_1:  I considered doing an in-person interview with him.

01:12:20,930 --> 01:12:21,406
SPEAKER_1:  Um.

01:12:23,298 --> 01:12:25,246
SPEAKER_1:  And in that- Are you still considering it?

01:12:27,586 --> 01:12:30,398
SPEAKER_1:  I don't know, do you think I should, in person?

01:12:30,914 --> 01:12:35,039
SPEAKER_0:  I think it depends if you think you have anything to add to the conversation. A lot of people have.

01:12:35,039 --> 01:12:37,726
SPEAKER_1:  has been already, you did an incredible job. Thanks.

01:12:39,714 --> 01:12:42,430
SPEAKER_1:  I think I would like to grill the shit out of him.

01:12:42,658 --> 01:12:45,283
SPEAKER_1:  as a fellow human, but not investigated.

01:12:45,283 --> 01:12:46,033
SPEAKER_0:  He's ill-investigated.

01:12:46,033 --> 01:12:46,654
SPEAKER_1:  Yeah, yeah

01:12:46,914 --> 01:12:47,390
SPEAKER_1:  Like.

01:12:47,842 --> 01:12:49,534
SPEAKER_1:  Like another human being.

01:12:49,858 --> 01:12:52,190
SPEAKER_1:  another human being who I can have compassion for.

01:12:52,578 --> 01:12:54,782
SPEAKER_1:  who has caused a lot of suffering in the world.

01:12:55,906 --> 01:12:57,406
SPEAKER_1:  Like that, that grilling.

01:12:57,698 --> 01:12:58,718
SPEAKER_1:  Like basically...

01:13:00,066 --> 01:13:03,422
SPEAKER_1:  convey the anger that people and the pain that people are feeling.

01:13:04,098 --> 01:13:05,118
SPEAKER_1:  Right, like that.

01:13:06,466 --> 01:13:07,006
SPEAKER_0:  I think.

01:13:08,770 --> 01:13:15,486
SPEAKER_0:  I think it'd be really hard. I mean, like that guy is sort of a master dancer and what he would say at the end of it, because I've listened to so many-

01:13:16,002 --> 01:13:17,022
SPEAKER_0:  Interviews of him.

01:13:17,378 --> 01:13:20,062
SPEAKER_0:  I probably am like a GPT model for Sam.

01:13:20,770 --> 01:13:23,390
SPEAKER_0:  I think he would do some kind of thing about like...

01:13:24,098 --> 01:13:24,414
SPEAKER_0:  Yeah.

01:13:24,674 --> 01:13:25,342
SPEAKER_0:  I really, um...

01:13:25,602 --> 01:13:30,878
SPEAKER_0:  I really hear you and it's just terrible. I feel such an obligation to the people who've lost money and-

01:13:31,138 --> 01:13:33,150
SPEAKER_0:  You know, it's just, it's a lot of money. It's a lot of money.

01:13:33,410 --> 01:13:34,430
SPEAKER_0:  You know, he'd do something like that.

01:13:34,818 --> 01:13:36,510
SPEAKER_0:  and it would be very superficially like.

01:13:36,738 --> 01:13:37,406
SPEAKER_0:  Okay?

01:13:38,018 --> 01:13:38,430
SPEAKER_0:  But...

01:13:38,850 --> 01:13:42,046
SPEAKER_0:  When you drill down to the details of what he did.

01:13:42,402 --> 01:13:44,350
SPEAKER_0:  It's just impossible that he didn't know.

01:13:44,674 --> 01:13:46,782
SPEAKER_0:  And one of the things that I wish I had asked.

01:13:47,042 --> 01:13:48,094
SPEAKER_0:  Maybe I can talk about like.

01:13:48,418 --> 01:13:52,670
SPEAKER_0:  I wish I had gone on this. It's just so hard when you're doing a live interview to kind of focus on one thing.

01:13:53,442 --> 01:13:56,702
SPEAKER_0:  Everyone's asked about the terms of service. So in the terms of service, there was like...

01:13:58,018 --> 01:14:00,638
SPEAKER_0:  We can't touch your funds, your funds are safe. We're never going to do anything with that.

01:14:00,866 --> 01:14:02,686
SPEAKER_0:  Anytime anyone brings that up, he says, oh.

01:14:03,106 --> 01:14:03,582
SPEAKER_0:  Well, there's this.

01:14:03,842 --> 01:14:08,574
SPEAKER_0:  other terms of service over here with margin trading accounts. Remember we talked about it's a derivatives platform.

01:14:09,154 --> 01:14:10,558
SPEAKER_0:  If you're in our derivative side,

01:14:11,234 --> 01:14:16,030
SPEAKER_0:  you're subject to different terms of service, which kind of lets us like move your money around with everyone else.

01:14:17,218 --> 01:14:18,718
SPEAKER_0:  So we treat it as one big pool of funds.

01:14:19,170 --> 01:14:24,446
SPEAKER_0:  And that's sort of the explanation of how this all happened is we had this huge leverage position and we lost everything.

01:14:25,218 --> 01:14:28,862
SPEAKER_0:  but what no one has sort of done a good enough job getting to the heart of.

01:14:29,282 --> 01:14:29,726
SPEAKER_0:  is that.

01:14:30,146 --> 01:14:32,990
SPEAKER_0:  This pool of funds never was segregated properly.

01:14:33,218 --> 01:14:36,670
SPEAKER_0:  It was all treated under the same umbrella of we can use your funds.

01:14:37,314 --> 01:14:43,102
SPEAKER_0:  There was no amount of we have the client deposits which were just deposited with us and not like used.

01:14:43,362 --> 01:14:45,310
SPEAKER_0:  to margin trade or do anything over here.

01:14:45,954 --> 01:14:48,510
SPEAKER_0:  These funds over here, we have saved. They didn't.

01:14:48,962 --> 01:14:58,366
SPEAKER_0:  Fundamentally, they lied from the get-go about how they were treating the most precious assets, which is your customer deposits that you said you didn't invest.

01:14:58,658 --> 01:15:03,454
SPEAKER_0:  Clearly, you put them all over here, you yolo-gambled them, and then when everyone starts to rep-

01:15:03,746 --> 01:15:05,054
SPEAKER_0:  withdrawing from here.

01:15:05,506 --> 01:15:06,718
SPEAKER_0:  They don't have any money over here.

01:15:06,978 --> 01:15:09,406
SPEAKER_0:  So that is like one of the most fundamental things.

01:15:10,306 --> 01:15:11,934
SPEAKER_0:  I haven't seen anyone grill him on.

01:15:12,450 --> 01:15:14,302
SPEAKER_0:  And the next time if I get the chance to...

01:15:14,914 --> 01:15:19,710
SPEAKER_0:  Ambush him again. That's that's what I'm going to drill down on because it's impossible for that not to be fraud

01:15:21,218 --> 01:15:27,486
SPEAKER_0:  There's no world where you had a pool of funds over here and now you don't have them without you somehow

01:15:27,970 --> 01:15:28,734
SPEAKER_0:  Borrowing.

01:15:29,282 --> 01:15:29,886
SPEAKER_0:  over here.

01:15:30,178 --> 01:15:33,502
SPEAKER_0:  Because if you deposited one bitcoin and I never sold that bitcoin and it's earmarked...

01:15:33,794 --> 01:15:34,590
SPEAKER_0:  Lex Friedman.

01:15:34,914 --> 01:15:37,886
SPEAKER_0:  and you come and it's not there, something had to happen.

01:15:39,202 --> 01:15:41,374
SPEAKER_1:  Well, so this is so interesting. So for me.

01:15:42,850 --> 01:15:43,582
SPEAKER_1:  The...

01:15:44,034 --> 01:15:44,894
SPEAKER_1:  Approach that.

01:15:45,474 --> 01:15:47,710
SPEAKER_1:  Like you said, the most important question.

01:15:48,418 --> 01:15:50,046
SPEAKER_1:  of, uh, cause for you it's like-

01:15:50,370 --> 01:15:51,646
SPEAKER_1:  with those funds segregated.

01:15:53,570 --> 01:15:54,942
SPEAKER_1:  For me the question is...

01:15:55,298 --> 01:15:56,446
SPEAKER_1:  as a human being.

01:15:57,026 --> 01:15:59,390
SPEAKER_1:  How would you feel if you were observing that?

01:15:59,842 --> 01:16:00,318
SPEAKER_1:  Sike.

01:16:01,218 --> 01:16:03,678
SPEAKER_1:  You know, that like marshmallow test with the babies.

01:16:04,034 --> 01:16:07,070
SPEAKER_1:  Like it's the human thing, it's the human nature question.

01:16:07,618 --> 01:16:09,982
SPEAKER_1:  I can understand there's a pile of money.

01:16:10,594 --> 01:16:11,230
SPEAKER_1:  and you

01:16:11,842 --> 01:16:12,446
SPEAKER_1:  Uh...

01:16:13,282 --> 01:16:18,910
SPEAKER_1:  the good faith interpretation is like, well I know what to do with that pile of money, to grow that pile of money, let me just take a little bit of that.

01:16:19,938 --> 01:16:26,430
SPEAKER_1:  Like how willing are you to do that kind of thing? How able are you to do that kind of thing? And when shit goes wrong?

01:16:27,010 --> 01:16:28,446
SPEAKER_1:  What goes through your mind?

01:16:28,770 --> 01:16:31,742
SPEAKER_1:  How does it become corrupted? How do you begin to delude yourself?

01:16:32,034 --> 01:16:32,862
SPEAKER_1:  How do you, uh...

01:16:33,154 --> 01:16:35,454
SPEAKER_1:  delegate responsibility for the failures.

01:16:35,682 --> 01:16:36,030
SPEAKER_1:  Like.

01:16:36,546 --> 01:16:38,110
SPEAKER_1:  as opposed to getting facts?

01:16:38,370 --> 01:16:39,294
SPEAKER_1:

01:16:39,746 --> 01:16:40,606
SPEAKER_1:  try to sneak.

01:16:41,026 --> 01:16:44,830
SPEAKER_1:  into the human mind of a person when they're thinking of that. Because the facts-

01:16:45,282 --> 01:16:47,294
SPEAKER_1:  they're gonna start waffling.

01:16:47,746 --> 01:16:48,510
SPEAKER_1:  They're gonna

01:16:48,898 --> 01:16:53,534
SPEAKER_1:  start like trying to make sure they don't say anything, they get some incriminated. right Hendrick

01:16:53,794 --> 01:16:56,190
SPEAKER_1:  but I just, I want to understand the human being.

01:16:56,706 --> 01:16:57,214
SPEAKER_1:  there.

01:16:57,442 --> 01:17:01,182
SPEAKER_1:  Because I think that indirectly gives you a sense of where were you in this big picture?

01:17:01,346 --> 01:17:03,262
SPEAKER_0:  I think I've talked to so many people.

01:17:03,746 --> 01:17:04,510
SPEAKER_0:  who have sort of.

01:17:04,962 --> 01:17:09,022
SPEAKER_0:  committed some range of like outright fraud to like misleading marketing.

01:17:10,018 --> 01:17:11,998
SPEAKER_0:  No one thinks they're a bad person.

01:17:12,802 --> 01:17:13,726
SPEAKER_0:  Nobody.

01:17:14,050 --> 01:17:17,790
SPEAKER_0:  admits that they did it and they knew they did, or almost nobody does.

01:17:18,434 --> 01:17:20,446
SPEAKER_0:  There's actually one funny exception, but.

01:17:21,890 --> 01:17:24,446
SPEAKER_0:  I had a guy who admitted like, yeah, I did it. It was wrong.

01:17:24,674 --> 01:17:27,902
SPEAKER_0:  And, you know, but I did it and I wanted the money, which was kind of like.

01:17:28,290 --> 01:17:29,918
SPEAKER_0:  almost refreshing in its honesty.

01:17:30,146 --> 01:17:30,782
SPEAKER_0:  But, um...

01:17:31,490 --> 01:17:33,598
SPEAKER_0:  The reason I focus on like the facts.

01:17:33,858 --> 01:17:34,590
SPEAKER_0:  is because

01:17:35,266 --> 01:17:37,278
SPEAKER_0:  Unless you find a bright red line.

01:17:38,082 --> 01:17:39,710
SPEAKER_0:  humans can rationalize anything.

01:17:39,970 --> 01:17:53,534
SPEAKER_0:  I can rationalize any level of like, well, I did this because I had the best of intentions. And if you play the intention game, you'll never convict anyone because everyone has good intentions. Everyone's honest. Everyone's doing the best they can and got misleaded and da da da da.

01:17:53,986 --> 01:17:57,662
SPEAKER_0:  Ultimately, you have to drill down to the concrete and go look.

01:17:59,010 --> 01:17:59,518
SPEAKER_0:  I get it.

01:17:59,746 --> 01:18:05,822
SPEAKER_0:  You're just like the last 50 guys that I interviewed. You had the best of intentions. It all went wrong. I'm very sorry for you.

01:18:06,114 --> 01:18:10,622
SPEAKER_0:  But at the end of the day, there's people hurting and there's people that have significant damage to their life because of you.

01:18:11,074 --> 01:18:13,950
SPEAKER_0:  What did you actually do and what can we prove?

01:18:14,274 --> 01:18:20,638
SPEAKER_0:  taking intention out of it, taking motivation out, what can we prove that you did that was unethical, illegal or immoral?

01:18:21,026 --> 01:18:22,174
SPEAKER_0:  And like that is.

01:18:22,882 --> 01:18:25,118
SPEAKER_0:  sort of what usually I try to go to because

01:18:25,506 --> 01:18:28,222
SPEAKER_0:  I will do those human interviews, but...

01:18:28,930 --> 01:18:30,174
SPEAKER_0:  You know, it's just like, it's just a re-

01:18:30,754 --> 01:18:32,629
SPEAKER_0:  like the same record on repeat. I mean, a lot.

01:18:32,629 --> 01:18:38,494
SPEAKER_1:  I got it. Same. I'm with you, I'm with you on everything you said, but there is ways to do.

01:18:39,394 --> 01:18:44,286
SPEAKER_1:  to avoid the record on repeat. I mean, those are different skill sets. You're exceptionally good at the investigative.

01:18:44,674 --> 01:18:45,726
SPEAKER_1:  like investigating.

01:18:46,210 --> 01:19:03,326
SPEAKER_1:  I do believe there's a way to break through the repeat. There's different techniques to it. One of which is like taking outside of their particular story. Yes, when everyone looks at their own story, they can see themselves as a good player doing good. But you can do other thought experiments.

01:19:03,650 --> 01:19:04,775
SPEAKER_1:  I mean, there's a...

01:19:04,775 --> 01:19:07,775
SPEAKER_0:  But they'll follow you, they'll know what the thought experiment is.

01:19:07,775 --> 01:19:10,206
SPEAKER_1:  Well, it depends. It depends, my friend.

01:19:10,434 --> 01:19:12,894
SPEAKER_1:  I mean, the, like, uh...

01:19:13,378 --> 01:19:14,494
SPEAKER_1:  You know, to me...

01:19:14,754 --> 01:19:16,350
SPEAKER_1:  There's a million of them, but...

01:19:16,770 --> 01:19:17,150
SPEAKER_1:  of

01:19:17,538 --> 01:19:19,262
SPEAKER_1:  just exploring your ethics.

01:19:19,682 --> 01:19:21,950
SPEAKER_1:  Would you kill somebody to protect your family?

01:19:22,754 --> 01:19:23,966
SPEAKER_1:  and you explore that.

01:19:24,418 --> 01:19:26,814
SPEAKER_1:  You start to sneak into like, what's your sense?

01:19:27,426 --> 01:19:28,382
SPEAKER_1:  uh... of

01:19:28,802 --> 01:19:30,334
SPEAKER_1:  the in-group versus the out-group.

01:19:31,266 --> 01:19:34,206
SPEAKER_1:  how much damage you can do to the R group and who is the R group.

01:19:34,754 --> 01:19:37,054
SPEAKER_1:  and you start to build that sense of the person.

01:19:37,378 --> 01:19:39,870
SPEAKER_1:  Are we like the two mobsters that we're dressed as?

01:19:40,130 --> 01:19:42,974
SPEAKER_1:  Do we protect the family and fuck everyone else?

01:19:43,298 --> 01:19:46,142
SPEAKER_1:  You're with us and the ones who are against us, fuck them.

01:19:46,466 --> 01:19:50,078
SPEAKER_1:  Or do we have a sense that human beings are all?

01:19:50,498 --> 01:19:57,150
SPEAKER_1:  have value, equal value, and we want to, that we're a joint humanity. There's ways to get to that. You start to build up this sense.

01:19:57,410 --> 01:19:58,078
SPEAKER_1:  of like

01:19:59,202 --> 01:20:03,646
SPEAKER_1:  Some people that make a lot of money are better than others. They deserve to be at the top.

01:20:04,002 --> 01:20:05,310
SPEAKER_1:  If you have that feeling...

01:20:05,634 --> 01:20:07,774
SPEAKER_1:  You start to get a sense of like...

01:20:08,162 --> 01:20:16,222
SPEAKER_1:  Yeah, the poor people are the dumbasses, they're the idiots. If you believe that, then you start to understand that this person may have been at the core of the school corrupt.

01:20:16,642 --> 01:20:17,470
SPEAKER_1:  organization.

01:20:18,018 --> 01:20:19,454
SPEAKER_0:  Yes, two things.

01:20:19,746 --> 01:20:20,222
SPEAKER_0:  One.

01:20:21,250 --> 01:20:26,686
SPEAKER_0:  I think you should join me on this side of the table. We'll put SBF over here. Well, good guy, bad guy, human. Okay.

01:20:26,978 --> 01:20:28,103
SPEAKER_0:  it facts like you're the

01:20:28,103 --> 01:20:30,855
SPEAKER_1:  You're the bad guy. I'm like, no, no, no, slow down coffee

01:20:30,855 --> 01:20:32,958
SPEAKER_0:  What is your feeling about humanity?

01:20:33,794 --> 01:20:34,302
SPEAKER_0:  Yeah, I-

01:20:34,466 --> 01:20:35,591
SPEAKER_1:  Have you been getting enough?

01:20:35,591 --> 01:20:40,382
SPEAKER_0:  Yeah, right. So I think there's a lot of truth to what you said.

01:20:41,538 --> 01:20:43,998
SPEAKER_0:  One thing I've noticed that is hard to combat.

01:20:44,354 --> 01:20:45,214
SPEAKER_0:  is sort of like.

01:20:45,602 --> 01:20:47,774
SPEAKER_0:  preference falsification and just like

01:20:48,386 --> 01:20:51,134
SPEAKER_0:  Just the outright lying about those things.

01:20:51,490 --> 01:20:59,358
SPEAKER_0:  is tough to kind of pin down. But yeah, you're absolutely right. There's ways to interview people. There's all sorts of interesting techniques. And yeah, I don't disagree.

01:20:59,618 --> 01:21:03,422
SPEAKER_1:  Good cop, bad cop. We should do this, this would be like a sitcom. Okay....

01:21:03,682 --> 01:21:06,494
SPEAKER_1:  You did an incredible documentary on SafeMoon.

01:21:07,234 --> 01:21:11,006
SPEAKER_1:  The title is, I uncovered a billion dollar fraud.

01:21:11,394 --> 01:21:13,694
SPEAKER_1:  Akin, you tell me the story of SafeMoon.

01:21:14,594 --> 01:21:16,318
SPEAKER_0:  So, safe moon.

01:21:16,802 --> 01:21:20,030
SPEAKER_0:  was a crypto coin that exploded on the scene.

01:21:20,450 --> 01:21:21,182
SPEAKER_0:  in a

01:21:22,242 --> 01:21:23,582
SPEAKER_0:  2021, I think at this point.

01:21:24,162 --> 01:21:27,870
SPEAKER_0:  Sorry, I'm losing track of my years. One year in crypto is like five years in real life.

01:21:28,290 --> 01:21:33,342
SPEAKER_0:  But it kind of gained a huge amount of popularity because of this idea.

01:21:33,570 --> 01:21:33,982
SPEAKER_0:  that.

01:21:34,210 --> 01:21:36,350
SPEAKER_0:  It's in the name. You go safely to the moon.

01:21:36,578 --> 01:21:40,894
SPEAKER_0:  How they were gonna do this is with sort of a sophisticated smart contract idea.

01:21:41,250 --> 01:21:41,854
SPEAKER_0:  where

01:21:42,786 --> 01:21:43,230
SPEAKER_0:  There's.

01:21:43,650 --> 01:21:45,694
SPEAKER_0:  I kind of have to explain the way some...

01:21:46,018 --> 01:21:48,446
SPEAKER_0:  Contracts get rug pulled for a second or

01:21:48,674 --> 01:21:49,694
SPEAKER_0:  there's scams happen.

01:21:50,370 --> 01:21:51,902
SPEAKER_0:  So in the...

01:21:52,258 --> 01:21:58,366
SPEAKER_0:  Sometimes it's called like the shit coin space, the alt coin space, anything like below Bitcoin, Ethereum and maybe the top five or ten.

01:21:58,850 --> 01:22:03,102
SPEAKER_0:  is kind of seen as this wasteland of gambling and like, you know, you don't know if they're-

01:22:04,034 --> 01:22:05,726
SPEAKER_0:  developers are going to become anything or not.

01:22:06,178 --> 01:22:06,910
SPEAKER_0:  You're kind of like.

01:22:07,330 --> 01:22:08,926
SPEAKER_0:  reading the white paper, trying to figure it out.

01:22:09,474 --> 01:22:13,022
SPEAKER_0:  So there's this big question about like, how can you get scammed? How can-

01:22:13,730 --> 01:22:15,774
SPEAKER_0:  back to the interests you don't want.

01:22:16,610 --> 01:22:18,206
SPEAKER_0:  the developer to have some like.

01:22:18,850 --> 01:22:20,702
SPEAKER_0:  parachute cord where they can pull all the money out.

01:22:21,314 --> 01:22:21,662
SPEAKER_0:  So.

01:22:22,434 --> 01:22:25,726
SPEAKER_0:  One way this happens is that in decentralized

01:22:25,954 --> 01:22:27,198
SPEAKER_0:  decentralized finance.

01:22:27,522 --> 01:22:29,374
SPEAKER_0:  There's something called the liquidity pool.

01:22:30,690 --> 01:22:31,902
SPEAKER_0:  Basically this big pot of money.

01:22:32,130 --> 01:22:33,950
SPEAKER_0:  that allows people to trade.

01:22:34,178 --> 01:22:34,846
SPEAKER_0:  between

01:22:35,074 --> 01:22:37,694
SPEAKER_0:  two different currencies. So let's say like SafeMoon.

01:22:37,986 --> 01:22:42,206
SPEAKER_0:  and Bitcoin, right? Or Ethereum or it's actually on the Binance Smart Chain. So it'd be...

01:22:42,466 --> 01:22:43,038
SPEAKER_0:  BNB.

01:22:43,618 --> 01:22:45,470
SPEAKER_0:  Um, and this pool of money.

01:22:46,050 --> 01:22:50,110
SPEAKER_0:  can be controlled by the developers in such a way they can steal it all.

01:22:50,434 --> 01:22:51,550
SPEAKER_0:  Right? They can just grab it.

01:22:52,354 --> 01:22:56,094
SPEAKER_0:  I don't want to go too much into details because I feel like I'll lose people here, but the point of SafeMoon was.

01:22:56,546 --> 01:22:57,470
SPEAKER_0:  The core idea.

01:22:57,730 --> 01:22:59,134
SPEAKER_0:  was we're locking this money up.

01:23:00,162 --> 01:23:00,862
SPEAKER_0:  You can't touch it.

01:23:01,538 --> 01:23:03,678
SPEAKER_0:  And actually every transaction.

01:23:03,906 --> 01:23:05,278
SPEAKER_0:  that you buy Safemoon with?

01:23:05,698 --> 01:23:07,326
SPEAKER_0:  We'll take a 5% tax of that.

01:23:07,874 --> 01:23:09,886
SPEAKER_0:  We'll do a 10% tax, but 5% of it.

01:23:10,338 --> 01:23:12,606
SPEAKER_0:  We'll go back to all the holders of Safeman.

01:23:13,282 --> 01:23:16,062
SPEAKER_0:  Okay. And 5% of it will go back into this little pool of money.

01:23:17,186 --> 01:23:19,166
SPEAKER_0:  So the idea is as you trade.

01:23:19,586 --> 01:23:21,470
SPEAKER_0:  As this token becomes more viral.

01:23:22,338 --> 01:23:28,478
SPEAKER_0:  Two things will happen. One, the people who are holding it long-term will be rewarded for holding it long-term by receiving this 5% tax.

01:23:28,738 --> 01:23:29,854
SPEAKER_0:  that's distributed to everyone.

01:23:30,274 --> 01:23:32,894
SPEAKER_0:  And two, you can kind of trust that you're.

01:23:33,154 --> 01:23:35,294
SPEAKER_0:  your money's gonna have this stable value because.

01:23:35,554 --> 01:23:42,238
SPEAKER_0:  This pool of money here in the middle, that's kind of guaranteeing you can get your safe moon out into this actually valuable currency.

01:23:42,658 --> 01:23:43,614
SPEAKER_0:  It's not gonna move.

01:23:44,706 --> 01:23:46,142
SPEAKER_0:  So the story of SafeMoon was that.

01:23:46,946 --> 01:23:55,486
SPEAKER_0:  Fundamentally, this was not the case. They promised that this money was gonna be locked up. It was not actually locked up at all. They said it was automatically locked up. You don't have to worry about it.

01:23:55,714 --> 01:23:58,974
SPEAKER_0:  Well, it was very manually locked up, and they didn't actually lock a lot of it up.

01:23:59,490 --> 01:24:03,102
SPEAKER_0:  They took a lot of it for themselves, for the developers.

01:24:03,458 --> 01:24:05,790
SPEAKER_0:  There's a lot of players in this.

01:24:06,018 --> 01:24:11,166
SPEAKER_0:  Some of the, a lot of them have left by now. There's kind of this main CEO that everyone knows John Coroney now.

01:24:11,586 --> 01:24:12,350
SPEAKER_0:  And...

01:24:13,058 --> 01:24:19,486
SPEAKER_0:  you know, despite saying that they were gonna lock up all the funds for four years, somehow he's gone from as everyone else in the-

01:24:19,842 --> 01:24:23,294
SPEAKER_0:  and the token has lost 99% of the value of the token.

01:24:23,554 --> 01:24:24,958
SPEAKER_0:  So they've lost 99%.

01:24:25,922 --> 01:24:27,134
SPEAKER_0:  He's gotten.

01:24:27,778 --> 01:24:28,574
SPEAKER_0:  uh... like

01:24:29,538 --> 01:24:31,518
SPEAKER_0:  a $6 million crypto portfolio.

01:24:31,810 --> 01:24:34,270
SPEAKER_0:  multi-million dollar real estate portfolio.

01:24:34,498 --> 01:24:37,022
SPEAKER_0:  invested millions into various companies.

01:24:37,506 --> 01:24:39,806
SPEAKER_0:  So he's accrued this huge wealth.

01:24:40,162 --> 01:24:43,710
SPEAKER_0:  And so I made a video basically exposing that and showing how this coin which-

01:24:43,938 --> 01:24:51,838
SPEAKER_0:  once had a $4 billion market cap, it was just viral everywhere. Everyone was talking about it because of these viral ideas. It is sort of a-

01:24:52,290 --> 01:24:53,278
SPEAKER_0:  captivating idea that...

01:24:53,570 --> 01:24:54,718
SPEAKER_0:  By holding it, you could get.

01:24:55,138 --> 01:24:58,078
SPEAKER_0:  returns right like you just hold on to it you automatically get money

01:24:58,306 --> 01:25:02,366
SPEAKER_0:  And it's a viral idea that this money in the middle in the pot isn't going to leave you.

01:25:03,234 --> 01:25:04,958
SPEAKER_0:  when those things turned out to be false.

01:25:05,794 --> 01:25:08,062
SPEAKER_0:  This community has had a slow death.

01:25:08,386 --> 01:25:10,174
SPEAKER_0:  as a lot of people realized it was a scam.

01:25:10,658 --> 01:25:12,606
SPEAKER_0:  and there's been a core part of the community.

01:25:13,218 --> 01:25:16,062
SPEAKER_0:  which gets to an interesting dynamic we can talk about if you want to.

01:25:16,770 --> 01:25:20,222
SPEAKER_0:  where they have like doubled down on the belief in Karony.

01:25:20,738 --> 01:25:25,502
SPEAKER_0:  And so part of it was out of a hope to let those people know what was really going on in their coin.

01:25:25,730 --> 01:25:28,062
SPEAKER_0:  and like hopefully save some of them.

01:25:29,346 --> 01:25:31,262
SPEAKER_0:  Not in like some altruistic sense, but like.

01:25:31,490 --> 01:25:34,590
SPEAKER_0:  or not in some like, I'm like a hero sense, but in the sense of, um,

01:25:35,426 --> 01:25:39,358
SPEAKER_0:  I think a lot of them didn't know, like literally didn't know. So just sort of like as a public service.

01:25:39,810 --> 01:25:40,670
SPEAKER_0:  letting them know.

01:25:41,442 --> 01:25:44,094
SPEAKER_0:  so they could get their money out and hopefully save themselves.

01:25:44,610 --> 01:25:46,398
SPEAKER_0:  a lot of pain and suffering.

01:25:46,850 --> 01:25:48,606
SPEAKER_1:  So yeah. They really dug in.

01:25:49,218 --> 01:25:56,446
SPEAKER_0:  So there's- Some did, some did, some did, some left. I mean, a lot of people have left, but the people who are left are people with large amounts of-

01:25:56,674 --> 01:25:57,534
SPEAKER_0:  Safe moon hoardings.

01:25:57,954 --> 01:26:01,694
SPEAKER_0:  that are down immensely, and you can imagine at a certain point in losses...

01:26:03,042 --> 01:26:06,430
SPEAKER_0:  There's a tremendous psychological pressure to go, look, I'm in it.

01:26:06,978 --> 01:26:08,158
SPEAKER_0:  I gotta go for the long haul.

01:26:08,738 --> 01:26:12,798
SPEAKER_0:  and then you want to believe that this thing is legitimate and will succeed.

01:26:13,058 --> 01:26:18,238
SPEAKER_0:  Because A, there's an ego component around, I haven't been scammed, I'm too smart to get scammed.

01:26:18,626 --> 01:26:19,582
SPEAKER_0:  It's tremendously.

01:26:19,938 --> 01:26:20,318
SPEAKER_0:  Uh.

01:26:20,578 --> 01:26:23,870
SPEAKER_0:  You know, it hurts psychologically to acknowledge you've been taken for a ride.

01:26:24,866 --> 01:26:31,422
SPEAKER_0:  And also you just want this thing to succeed for your financial wellbeing. So you like want to believe it. So there's tremendous psychological pressure to build.

01:26:31,906 --> 01:26:34,942
SPEAKER_0:  cult-like communities around these tokens.

01:26:35,650 --> 01:26:38,462
SPEAKER_0:  And I've noticed with the incentive of like.

01:26:38,754 --> 01:26:40,030
SPEAKER_0:  community built.

01:26:40,610 --> 01:26:42,430
SPEAKER_0:  sort of new to finance. There's like these.

01:26:42,658 --> 01:26:43,902
SPEAKER_0:  meme coins or these...

01:26:44,226 --> 01:26:45,246
SPEAKER_0:  These cults.

01:26:45,826 --> 01:26:49,918
SPEAKER_0:  I don't want to, it's not really fair to call all of them cults, like some of them are open to criticism, but

01:26:50,434 --> 01:26:53,214
SPEAKER_0:  One of the things that defines cults is they're not open to...

01:26:53,570 --> 01:26:54,750
SPEAKER_0:  sunlight or criticism.

01:26:55,746 --> 01:26:57,790
SPEAKER_0:  there's these financial communities that are opening up.

01:26:58,050 --> 01:26:58,494
SPEAKER_0:  with

01:26:58,946 --> 01:27:00,734
SPEAKER_0:  crypto with a few stocks.

01:27:00,994 --> 01:27:03,134
SPEAKER_0:  where if you criticize them, you are attacked.

01:27:03,522 --> 01:27:06,398
SPEAKER_0:  and the entire community has every incentive to kind of like...

01:27:06,658 --> 01:27:09,470
SPEAKER_0:  downplay your legitimate criticisms or kind of

01:27:09,890 --> 01:27:10,430
SPEAKER_0:  Um...

01:27:11,266 --> 01:27:12,830
SPEAKER_0:  go after you. Start intro-

01:27:13,154 --> 01:27:15,806
SPEAKER_0:  It creates this interesting dynamic that's so fascinating.

01:27:16,162 --> 01:27:17,694
SPEAKER_1:  What do you think about?

01:27:18,850 --> 01:27:19,774
SPEAKER_1:  Bitcoin then.

01:27:20,898 --> 01:27:29,246
SPEAKER_1:  Do you think it's one of those communities that does attack you when criticized? So which, I guess which coins do you think are open to criticism and which are not?

01:27:29,922 --> 01:27:30,846
SPEAKER_0:  It's kinda tough, like...

01:27:31,202 --> 01:27:34,334
SPEAKER_0:  No, community is a monolith. So just like, it's just.

01:27:34,946 --> 01:27:36,638
SPEAKER_0:  a spectrum of how open.

01:27:37,026 --> 01:27:40,414
SPEAKER_0:  They are, there's just like, there's always this core contingent.

01:27:40,898 --> 01:27:42,622
SPEAKER_0:  of extreme believers.

01:27:42,914 --> 01:27:43,422
SPEAKER_0:  who will.

01:27:43,746 --> 01:27:45,758
SPEAKER_0:  Go after anyone who criticizes them.

01:27:46,082 --> 01:27:50,718
SPEAKER_0:  And it's just about how wide of a band that makes up the entire token.

01:27:51,426 --> 01:27:58,846
SPEAKER_1:  how intensely, how active that small community is. So it's in Bitcoin, they're called Bitcoin maximalists, but you can also call.

01:27:59,170 --> 01:27:59,614
SPEAKER_1:  and you.

01:27:59,874 --> 01:28:01,054
SPEAKER_1:  Any communities.

01:28:01,602 --> 01:28:05,150
SPEAKER_1:  subgroup like that maximalist whatever the belief is right i don't know

01:28:05,474 --> 01:28:07,358
SPEAKER_1:  uh... don't condones maximus

01:28:07,810 --> 01:28:13,534
SPEAKER_1:  That community is probably small in terms of attacking you online. You know which community has a very intense?

01:28:14,146 --> 01:28:15,070
SPEAKER_1:  following.

01:28:16,162 --> 01:28:17,822
SPEAKER_1:  I got attacked on the internet.

01:28:18,434 --> 01:28:20,638
SPEAKER_1:  when I said Messi's better than Ronaldo.

01:28:21,474 --> 01:28:21,854
SPEAKER_1:  Oh yeah.

01:28:22,402 --> 01:28:23,198
SPEAKER_1:  uh...

01:28:23,714 --> 01:28:26,942
SPEAKER_1:  And so that's a very intense maximalist community there.

01:28:27,202 --> 01:28:29,086
SPEAKER_1:  Uh, the other one that surprised me...

01:28:29,378 --> 01:28:30,718
SPEAKER_1:  is when I said...

01:28:31,586 --> 01:28:33,886
SPEAKER_1:  Now I did it in jest.

01:28:34,402 --> 01:28:35,230
SPEAKER_1:  Okay, folks?

01:28:35,522 --> 01:28:38,142
SPEAKER_1:  I said Emacs is a better ID than Vim.

01:28:38,626 --> 01:28:39,934
SPEAKER_0:  I love you, Max. I agree.

01:28:41,474 --> 01:28:41,790
SPEAKER_1:  Listen.

01:28:42,082 --> 01:28:43,390
SPEAKER_1:  I have trauma, I wake up.

01:28:43,618 --> 01:28:45,493
SPEAKER_1:  sweating sometimes at night thinking.

01:28:45,493 --> 01:28:46,993
SPEAKER_0:  That's Emax Master X.

01:28:46,993 --> 01:28:53,854
SPEAKER_1:  The Vim people are after me, they're everywhere. They're in the shadows. Vim is an amazing and it's actually.

01:28:54,114 --> 01:28:56,318
SPEAKER_1:  Surprise, I've recently learned that it's.

01:28:56,930 --> 01:28:57,502
SPEAKER_1:  But still.

01:28:57,922 --> 01:29:01,297
SPEAKER_1:  even more so than before, an incredibly active community. So a lot of people.

01:29:01,297 --> 01:29:03,710
SPEAKER_0:  But do you use space max? It's just emax and vim.

01:29:04,482 --> 01:29:05,022
SPEAKER_1:  No, I haven't.

01:29:05,506 --> 01:29:13,662
SPEAKER_1:  I use raw. Old school Emacs? But hold on a second. I actually recently, I have recently said, you know what?

01:29:14,242 --> 01:29:14,782
SPEAKER_1:  uh...

01:29:15,042 --> 01:29:18,398
SPEAKER_1:  Let's make love not war. I went to VS code.

01:29:19,106 --> 01:29:22,590
SPEAKER_1:  I went to a more modern ID. attend hands, because I would beæœ to everyone right now.

01:29:22,914 --> 01:29:23,390
SPEAKER_1:  Uh...

01:29:23,714 --> 01:29:27,358
SPEAKER_1:  because I did most of my programming in Emacs. I did most of anything as one does in Emacs.

01:29:27,618 --> 01:29:31,326
SPEAKER_1:  just because I also love Lisp, so I can customize everything. Then I realized like-

01:29:32,322 --> 01:29:37,694
SPEAKER_1:  Like how long will Vim and Emacs be around really? I was thinking as a programmer...

01:29:38,722 --> 01:29:40,702
SPEAKER_1:  looking like 10, 20 years out.

01:29:42,082 --> 01:29:44,286
SPEAKER_1:  You know, I should challenge myself to learn new ideas.

01:29:44,642 --> 01:29:45,374
SPEAKER_1:  to learn.

01:29:45,826 --> 01:29:48,574
SPEAKER_1:  the new tools that the majority of the community is using.

01:29:48,866 --> 01:29:54,750
SPEAKER_1:  so that I can understand what are the benefits and the costs, I found myself getting a little too comfortable with the tools that I grew up with.

01:29:55,074 --> 01:29:59,870
SPEAKER_1:  I think one of the fundamental ways of being as a programmer, as anyone involved with technology,

01:30:01,186 --> 01:30:04,350
SPEAKER_1:  based on how quickly it's evolving is to keep learning new tools like

01:30:04,674 --> 01:30:06,654
SPEAKER_1:  The way of life should be constantly learning.

01:30:06,946 --> 01:30:09,374
SPEAKER_1:  You're not a mathematician or a physicist or.

01:30:09,730 --> 01:30:15,550
SPEAKER_1:  and you have those disciplines that are more stable. This is like everything is changing. Crypto is, like you said, a perfect example of that.

01:30:15,810 --> 01:30:18,110
SPEAKER_1:  You have to constantly update your understanding.

01:30:18,530 --> 01:30:19,326
SPEAKER_1:  of the...

01:30:19,970 --> 01:30:25,406
SPEAKER_1:  of digital finance constantly in order to be able to function, in order to be able to criticize it.

01:30:25,794 --> 01:30:30,974
SPEAKER_1:  uh... in order to be able to know what to invest in so yeah that that was why i did uh...

01:30:31,522 --> 01:30:37,086
SPEAKER_1:  I tried Partcharm a bunch, the whole JetBrains infrastructure and then...

01:30:37,570 --> 01:30:41,214
SPEAKER_1:  Also VS Code, because that's really popular, and you know, Adam and...

01:30:42,082 --> 01:30:47,715
SPEAKER_1:  Sublime all of those I've been I've been exploring I've been exploring yes code is amazing. You should check out

01:30:47,715 --> 01:30:56,446
SPEAKER_0:  I'm just going to give one more pitch for it. It's just basically like a customizable configuration. Well, Emacs is already customizable, but it's a...

01:30:57,634 --> 01:30:59,678
SPEAKER_0:  It's pretty useful. Not even much of a coder.

01:31:00,034 --> 01:31:01,694
SPEAKER_0:  but for like certain.

01:31:02,530 --> 01:31:05,758
SPEAKER_0:  journaling applications or like time management, I find it really useful.

01:31:07,106 --> 01:31:15,646
SPEAKER_0:  Anyway, we're so like, I feel like half this podcast is what it should have been and then half of it's just us nerding out our own engineering like idiosyncrasies.

01:31:15,874 --> 01:31:16,999
SPEAKER_0:  Sorry guys.

01:31:16,999 --> 01:31:18,238
SPEAKER_1:  All right.

01:31:18,466 --> 01:31:21,214
SPEAKER_1:  So what were we talking about? Safe moon.

01:31:22,498 --> 01:31:25,182
SPEAKER_1:  and Bitcoin, Bitcoin, what do you think? Is there a-

01:31:26,498 --> 01:31:27,550
SPEAKER_1:  Have you made enemies?

01:31:28,194 --> 01:31:30,270
SPEAKER_1:  in certain communities. What do you think about Bitcoin?

01:31:30,722 --> 01:31:31,038
SPEAKER_0:  So.

01:31:32,098 --> 01:31:39,966
SPEAKER_0:  I've made certain enemies in the sort of crypto skeptics space because there's sort of this range of skepticism you can have about cryptocurrency.

01:31:40,290 --> 01:31:42,590
SPEAKER_0:  I'm obviously a skeptic of a lot of it.

01:31:42,946 --> 01:31:43,422
SPEAKER_0:  Um

01:31:44,930 --> 01:31:51,070
SPEAKER_0:  There are certain aspects of crypto that I think are inevitable, and I'm going to do my best to kind of describe those here.

01:31:51,490 --> 01:31:53,854
SPEAKER_0:  but I'm not committed to any crypto specifically, but.

01:31:54,114 --> 01:31:54,718
SPEAKER_0:  There are some.

01:31:55,010 --> 01:32:01,566
SPEAKER_0:  I've taken a lot of heat, ironically, for not being skeptical enough. There's some people who believe that, like, the entire thing is a complete waste of time.

01:32:01,826 --> 01:32:06,974
SPEAKER_0:  They're rslashbuttcoin on Reddit. It's an amazing community, actually. It's very funny.

01:32:07,266 --> 01:32:15,262
SPEAKER_0:  They have. What's a buck coin? It's like a play on Bitcoin. They're like, they're just like, at least we admit it's a scam. Very funny guys.

01:32:15,522 --> 01:32:16,862
SPEAKER_0:  uh... very funny people there

01:32:17,282 --> 01:32:19,550
SPEAKER_0:  So, but they like, but they'll, they'll be like, you know.

01:32:19,778 --> 01:32:24,030
SPEAKER_0:  Coffee's delicious, just admit that all of it's a giant Ponzi scheme, all of it's a basically like.

01:32:24,258 --> 01:32:24,574
SPEAKER_0:  NOT.

01:32:24,674 --> 01:32:26,462
SPEAKER_1:  real.

01:32:26,658 --> 01:32:30,398
SPEAKER_0:  Yeah, it's all basically all the Ponzi-nomics. It's all, it's-

01:32:30,658 --> 01:32:32,478
SPEAKER_0:  It's Ponzinomics all the way down. It's like.

01:32:32,738 --> 01:32:34,814
SPEAKER_0:  There is no fundamental use case that.

01:32:35,266 --> 01:32:36,894
SPEAKER_0:  Is that useful? I don't know if-

01:32:37,506 --> 01:32:39,326
SPEAKER_0:  I guess I don't want to strawman them here.

01:32:39,586 --> 01:32:40,414
SPEAKER_0:  I don't want to say that.

01:32:40,834 --> 01:32:41,950
SPEAKER_0:  I don't know if they're saying that.

01:32:42,690 --> 01:32:44,030
SPEAKER_0:  It's all useless.

01:32:44,290 --> 01:32:45,598
SPEAKER_0:  At minimum, they're saying.

01:32:46,146 --> 01:32:48,670
SPEAKER_0:  the level of interest in cryptocurrencies.

01:32:49,666 --> 01:32:50,334
SPEAKER_0:  FAR

01:32:50,754 --> 01:32:52,926
SPEAKER_0:  The actual usefulness of it is far less.

01:32:53,474 --> 01:32:54,142
SPEAKER_0:  then

01:32:54,658 --> 01:33:00,798
SPEAKER_0:  the amount of attention and time and money that's being poured into it. So like the revolutionariness of this technology is not at all revolutionary.

01:33:01,442 --> 01:33:02,014
SPEAKER_0:  Let me-

01:33:02,242 --> 01:33:05,950
SPEAKER_0:  kind of steel man what I think the pro crypto take is.

01:33:07,010 --> 01:33:07,774
SPEAKER_0:  I think.

01:33:09,762 --> 01:33:11,870
SPEAKER_0:  Technologies are sort of this inert thing.

01:33:12,386 --> 01:33:12,926
SPEAKER_0:  and

01:33:13,154 --> 01:33:15,902
SPEAKER_0:  The success of them, in my opinion, is not based on

01:33:16,258 --> 01:33:18,078
SPEAKER_0:  PR, it's not based on marketing.

01:33:18,306 --> 01:33:20,126
SPEAKER_0:  It's based on cheaper, faster, better.

01:33:20,962 --> 01:33:24,030
SPEAKER_0:  Fundamentally, the success of any technology relies on those three things.

01:33:24,450 --> 01:33:25,310
SPEAKER_0:  and longevity of it.

01:33:26,306 --> 01:33:26,622
SPEAKER_0:  So.

01:33:27,106 --> 01:33:28,254
SPEAKER_0:  I have two employees.

01:33:28,674 --> 01:33:31,230
SPEAKER_0:  and both of them are out of the country.

01:33:31,842 --> 01:33:35,070
SPEAKER_0:  So I have to frequently make international wire payments to them.

01:33:35,714 --> 01:33:36,222
SPEAKER_0:  Um...

01:33:36,418 --> 01:33:40,254
SPEAKER_1:  Is one of them SPF just, as a reporter I have to ask. No. Well, I can explain the spf just as fx, so the spf just, the spec file re persisting

01:33:40,546 --> 01:33:41,886
SPEAKER_1:  He's not an apparel.

01:33:42,498 --> 01:33:43,623
SPEAKER_0:  Yeah, I think we'd have to pay.

01:33:43,623 --> 01:33:46,398
SPEAKER_1:  me.

01:33:46,722 --> 01:33:47,847
SPEAKER_1:  hard hitting.

01:33:47,847 --> 01:33:48,958
SPEAKER_0:  to get your questions.

01:33:49,442 --> 01:33:49,790
SPEAKER_0:  So.

01:33:50,242 --> 01:33:52,990
SPEAKER_0:  With these international payments, you face all sorts of...

01:33:53,634 --> 01:33:54,654
SPEAKER_0:  Slow.

01:33:55,202 --> 01:33:58,430
SPEAKER_0:  fees and you face like kind of like this time thing.

01:33:59,170 --> 01:34:00,990
SPEAKER_0:  And it's this painful process.

01:34:02,690 --> 01:34:03,038
SPEAKER_0:  So.

01:34:04,514 --> 01:34:09,342
SPEAKER_0:  If I use different cryptocurrencies, some of them are like really fast, some of them have really low fees.

01:34:09,794 --> 01:34:11,390
SPEAKER_0:  I just believe in a world where

01:34:12,802 --> 01:34:16,318
SPEAKER_0:  digital currencies with fast payments with cheap payments.

01:34:16,642 --> 01:34:17,886
SPEAKER_0:  Revolutionize.

01:34:18,722 --> 01:34:20,734
SPEAKER_0:  the global exchange of currency.

01:34:21,282 --> 01:34:22,430
SPEAKER_0:  And I don't know if this.

01:34:22,786 --> 01:34:24,894
SPEAKER_0:  if this is going to include the blockchain.

01:34:25,538 --> 01:34:33,150
SPEAKER_0:  It's just that the blockchain is the first thing that's really embraced truly digital currency, which doesn't need to go through this complicated

01:34:33,538 --> 01:34:36,126
SPEAKER_0:  system of wire transfers and just happens.

01:34:36,418 --> 01:34:39,998
SPEAKER_0:  So I can send you, let's say I wanna send you Ethereum or Bitcoin.

01:34:40,386 --> 01:34:42,014
SPEAKER_0:  I can send it to you just as fast.

01:34:42,434 --> 01:34:43,326
SPEAKER_0:  If I send you...

01:34:43,586 --> 01:34:44,286
SPEAKER_0:  A dollar?

01:34:44,962 --> 01:34:45,374
SPEAKER_0:  or

01:34:45,698 --> 01:34:48,542
SPEAKER_0:  a billion dollars and I can send it to you just as fast.

01:34:48,834 --> 01:34:51,934
SPEAKER_0:  if you're across from me or if you're across the world from me.

01:34:52,386 --> 01:34:53,886
SPEAKER_0:  That I think is a...

01:34:54,306 --> 01:34:56,798
SPEAKER_0:  step change and easier, faster, better.

01:34:57,442 --> 01:34:58,910
SPEAKER_0:  in terms of like, just this.

01:34:59,202 --> 01:35:00,222
SPEAKER_0:  really basic.

01:35:00,578 --> 01:35:05,918
SPEAKER_0:  international payments kind of idea. I think at like its core, if the lowest...

01:35:06,146 --> 01:35:07,998
SPEAKER_0:  form use case of cryptocurrencies is that.

01:35:08,418 --> 01:35:09,438
SPEAKER_0:  I think it will.

01:35:10,018 --> 01:35:10,430
SPEAKER_0:  Um...

01:35:11,106 --> 01:35:17,694
SPEAKER_0:  change the world in some variety. It's just kind of the larger question is, is that technology going to include the blockchain specifically?

01:35:18,722 --> 01:35:19,294
SPEAKER_0:  or not.

01:35:19,586 --> 01:35:20,702
SPEAKER_0:  The other benefit.

01:35:21,058 --> 01:35:22,334
SPEAKER_0:  is transparency.

01:35:22,658 --> 01:35:24,606
SPEAKER_0:  which I personally like as an investigator.

01:35:25,090 --> 01:35:25,534
SPEAKER_0:  It's just that.

01:35:26,626 --> 01:35:29,054
SPEAKER_0:  Previously, it's like hard to describe how...

01:35:29,666 --> 01:35:30,398
SPEAKER_0:  Opaque

01:35:30,626 --> 01:35:32,286
SPEAKER_0:  our financial system is.

01:35:32,546 --> 01:35:35,198
SPEAKER_0:  until you've tried to investigate someone or something.

01:35:36,546 --> 01:35:43,454
SPEAKER_0:  Understanding finances, unless you have a subpoena, unless you're like the FBI or like the SEC and you can get a subpoena for someone's finances.

01:35:43,746 --> 01:35:44,894
SPEAKER_0:  or you're going through discovery.

01:35:45,282 --> 01:35:46,462
SPEAKER_0:  You don't know what someone has.

01:35:46,690 --> 01:35:49,662
SPEAKER_0:  You're basically playing poker with everyone and the cards are face down.

01:35:50,466 --> 01:35:51,582
SPEAKER_0:  For the first time.

01:35:51,842 --> 01:35:55,134
SPEAKER_0:  the blockchain to some extent because there are ways to obfuscate it.

01:35:55,522 --> 01:35:57,918
SPEAKER_0:  and in some ways cryptocurrency has enabled more fraud.

01:35:58,274 --> 01:35:59,454
SPEAKER_0:  which is kind of this irony.

01:35:59,778 --> 01:36:02,142
SPEAKER_0:  But in some ways, it's enabled people to also audit.

01:36:02,402 --> 01:36:03,198
SPEAKER_0:  a lot better.

01:36:03,426 --> 01:36:06,526
SPEAKER_0:  and in real time, and I think that is a structural change.

01:36:07,650 --> 01:36:09,726
SPEAKER_0:  that is fundamentally for the better.

01:36:10,530 --> 01:36:14,238
SPEAKER_0:  The question of all this is, do those betters?

01:36:14,530 --> 01:36:15,358
SPEAKER_0:  Outway.

01:36:15,586 --> 01:36:16,638
SPEAKER_0:  the cons.

01:36:17,026 --> 01:36:18,174
SPEAKER_0:  that this introduces.

01:36:18,594 --> 01:36:22,046
SPEAKER_0:  and how much can regulation mitigate those cons?

01:36:22,306 --> 01:36:26,110
SPEAKER_0:  some of those cons being like fraud, money laundering, all these negative.

01:36:26,434 --> 01:36:29,059
SPEAKER_0:  externalities that are easier with cryptocurrency.

01:36:29,059 --> 01:36:31,518
SPEAKER_1:  What do you think cryptocurrency in particular seems to attract?

01:36:32,322 --> 01:36:33,214
SPEAKER_1:  fraudulent people.

01:36:33,858 --> 01:36:37,095
SPEAKER_1:  like scammers and fraudsters.

01:36:37,095 --> 01:36:42,078
SPEAKER_0:  Because it's unregulated, it's the Wild West, and you can transmit large amounts of money very quickly across the world.

01:36:42,498 --> 01:36:43,623
SPEAKER_0:  What about with very little?

01:36:43,623 --> 01:36:46,750
SPEAKER_1:  creating new crypto projects like new coins

01:36:46,946 --> 01:36:53,822
SPEAKER_0:  uh, because you have to show very little actual use case. You can just promise. This is like true of any emerging technology.

01:36:54,082 --> 01:36:57,278
SPEAKER_0:  So much vaporware happens at the beginning when it's all promise.

01:36:57,634 --> 01:37:00,670
SPEAKER_0:  because fundamentally, let's say you're legitimate, I'm illegitimate.

01:37:02,210 --> 01:37:06,622
SPEAKER_0:  we look the same at the start of a technology because both of us are promising what this can do. And in fact,

01:37:07,010 --> 01:37:15,422
SPEAKER_0:  the less scruples and morals I have, in some ways I can out-compete you. Cause I can say, mine does what Lexus does, but like way better and way faster, and it's gonna happen in a year rather than 10 years.

01:37:15,778 --> 01:37:18,846
SPEAKER_0:  You're being honest, I'm playing a dishonest game, I look better.

01:37:19,522 --> 01:37:22,430
SPEAKER_0:  Once this space matures and you actually have some people.

01:37:22,658 --> 01:37:25,246
SPEAKER_0:  doing the things that they say they're going to do.

01:37:25,634 --> 01:37:30,622
SPEAKER_0:  Suddenly this equation changes. Now you're Amazon, you're delivering in two days. I can say whatever I want.

01:37:31,458 --> 01:37:35,198
SPEAKER_0:  you do the thing you do and I have no credibility. So I think that like.

01:37:35,650 --> 01:37:36,254
SPEAKER_0:  part of.

01:37:36,546 --> 01:37:37,886
SPEAKER_0:  Part of the fraud is.

01:37:38,530 --> 01:37:41,982
SPEAKER_0:  You know, just the ability to transmit so much money so quickly with such little oversight.

01:37:42,306 --> 01:37:45,406
SPEAKER_0:  Part of it is like, this just happens with any emerging technology.

01:37:45,890 --> 01:37:48,382
SPEAKER_0:  Vaporware is a real thing and hopefully...

01:37:48,802 --> 01:37:51,198
SPEAKER_0:  as this space matures, as regulation comes in.

01:37:52,706 --> 01:37:53,374
SPEAKER_0:  Things will improve.

01:37:54,786 --> 01:37:56,926
SPEAKER_1:  Let me ask you your own psychology.

01:37:58,018 --> 01:37:59,230
SPEAKER_1:  You're going after...

01:37:59,874 --> 01:38:03,806
SPEAKER_1:  some of the richest, some of the most powerful people in the world, do you worry about?

01:38:04,258 --> 01:38:07,230
SPEAKER_1:  your own financial, legal, and psychological well-being.

01:38:07,938 --> 01:38:08,670
SPEAKER_1:  Uh...

01:38:08,962 --> 01:38:09,598
SPEAKER_0:  Yes.

01:38:10,210 --> 01:38:12,254
SPEAKER_0:  Yeah, I do. I mean, I'm not totally oblivious.

01:38:12,642 --> 01:38:13,950
SPEAKER_0:  to the precariousness.

01:38:15,010 --> 01:38:15,614
SPEAKER_0:  of like

01:38:16,066 --> 01:38:18,334
SPEAKER_0:  any kind of journalism like this?

01:38:19,266 --> 01:38:20,350
SPEAKER_0:  Obviously there's risks.

01:38:20,674 --> 01:38:21,758
SPEAKER_0:  I've always believed.

01:38:22,562 --> 01:38:25,982
SPEAKER_0:  There's a quote and I'm going to butcher it, but I hope you guys understand the spirit of it.

01:38:26,498 --> 01:38:27,006
SPEAKER_0:  Um...

01:38:28,066 --> 01:38:32,158
SPEAKER_0:  You know, news is when you print something someone else doesn't want you to print, everything else is public relations.

01:38:32,802 --> 01:38:35,550
SPEAKER_0:  I really believe to do meaningful journalism.

01:38:36,290 --> 01:38:38,750
SPEAKER_0:  You have to go after people. Like it's not.

01:38:39,074 --> 01:38:40,382
SPEAKER_0:  inherently a safe profession.

01:38:40,802 --> 01:38:42,174
SPEAKER_0:  I mean, if you're gonna do important work.

01:38:42,498 --> 01:38:44,382
SPEAKER_0:  you have to have risk tolerances.

01:38:44,770 --> 01:38:48,158
SPEAKER_0:  And I think everyone has a line of what that risk tolerance is.

01:38:49,314 --> 01:38:50,334
SPEAKER_0:  And it's different for everyone.

01:38:50,914 --> 01:38:53,246
SPEAKER_0:  I don't think I could do what Edward Snowden did.

01:38:53,602 --> 01:38:56,446
SPEAKER_0:  I think that would be my bright red line, is going against my own government.

01:38:57,282 --> 01:38:58,750
SPEAKER_0:  It's such a...

01:38:59,522 --> 01:39:02,910
SPEAKER_0:  In my opinion, I really see him as a hero. Like it's such a selfless act.

01:39:03,202 --> 01:39:05,054
SPEAKER_0:  of self destruction, you know?

01:39:05,442 --> 01:39:05,822
SPEAKER_0:  that the-

01:39:06,146 --> 01:39:09,598
SPEAKER_0:  the party you're going after has all the power and will CRUSH you!

01:39:11,010 --> 01:39:12,574
SPEAKER_0:  and you do it anyway out of the like-

01:39:12,962 --> 01:39:13,758
SPEAKER_0:  the true.

01:39:14,146 --> 01:39:18,622
SPEAKER_0:  I don't know, platonic ideal of journalism. I think that's beautiful. I don't think I could do that. I think I need-

01:39:19,138 --> 01:39:23,038
SPEAKER_0:  some ability to live and subsist in the society that I...

01:39:23,426 --> 01:39:24,094
SPEAKER_0:  MN

01:39:25,474 --> 01:39:31,038
SPEAKER_0:  And I think my bright red line would be like, if I'm forced to flee the country for my work, I think I'd finally have to say...

01:39:31,458 --> 01:39:31,934
SPEAKER_0:  No.

01:39:33,346 --> 01:39:35,678
SPEAKER_0:  for as journalists go, I'm pretty risk.

01:39:36,802 --> 01:39:37,694
SPEAKER_0:  take risk pretty well.

01:39:38,146 --> 01:39:42,302
SPEAKER_0:  I especially think risk is important to take when you're young.

01:39:42,786 --> 01:39:44,542
SPEAKER_0:  And when you can do that, I think...

01:39:45,026 --> 01:39:49,598
SPEAKER_0:  I mean, I'm married, so when I have a family, I think I will probably dial this risk.

01:39:50,146 --> 01:39:50,846
SPEAKER_0:  Think down.

01:39:52,002 --> 01:39:54,270
SPEAKER_0:  being honest, I mean, I think you kind of have to.

01:39:54,818 --> 01:39:55,294
SPEAKER_0:  uh...

01:39:56,130 --> 01:39:59,742
SPEAKER_0:  But right now, I mean, I'm kind of like running on all cylinders. I'm willing to take on quite a-

01:40:00,578 --> 01:40:01,662
SPEAKER_0:  Quite a range of people.

01:40:02,082 --> 01:40:02,846
SPEAKER_0:  But, um...

01:40:02,978 --> 01:40:04,286
SPEAKER_1:  Well, you're also- I think a lot about it.

01:40:04,610 --> 01:40:05,758
SPEAKER_1:  Wolfpack of one.

01:40:06,562 --> 01:40:07,038
SPEAKER_1:  small.

01:40:07,298 --> 01:40:08,158
SPEAKER_1:  Yeah, Wolfpack.

01:40:08,418 --> 01:40:11,102
SPEAKER_1:  as opposed to having like a New York Times behind you or.

01:40:11,394 --> 01:40:15,550
SPEAKER_1:  a huge organizations with lawyers, with a team, with a history with

01:40:15,714 --> 01:40:16,702
SPEAKER_0:  These people are less

01:40:16,962 --> 01:40:19,550
SPEAKER_0:  This is the dirty truth.

01:40:20,066 --> 01:40:25,726
SPEAKER_0:  The bigger the organization, the more conservative a lot of them are. It's true that sometimes they like

01:40:26,114 --> 01:40:29,758
SPEAKER_0:  And this is not to bash big organizations. I'm just saying this as an observation.

01:40:30,114 --> 01:40:31,486
SPEAKER_0:  of someone who's talked to a lot of.

01:40:31,842 --> 01:40:32,318
SPEAKER_0:  people.

01:40:32,674 --> 01:40:34,878
SPEAKER_0:  and especially in the world of fraud.

01:40:35,234 --> 01:40:37,406
SPEAKER_0:  A lot of them are scared to engage.

01:40:38,242 --> 01:40:42,110
SPEAKER_0:  in fraud that is obvious but hasn't been litigated yet.

01:40:42,722 --> 01:40:46,590
SPEAKER_0:  This is why you'll never see documentaries about ongoing fraud on Netflix.

01:40:46,818 --> 01:40:48,030
SPEAKER_0:  It's too much of a liability.

01:40:48,258 --> 01:40:49,406
SPEAKER_0:  They'll sue Netflix to hell.

01:40:49,698 --> 01:40:52,510
SPEAKER_0:  and they know that if they win, Netflix has the money to pay it.

01:40:53,058 --> 01:40:53,438
SPEAKER_0:  So.

01:40:53,698 --> 01:40:56,638
SPEAKER_0:  corporations like the New York Times, a lot of these.

01:40:56,930 --> 01:41:03,390
SPEAKER_0:  Some of them are very like they're as courageous as they can be but at the bottom line if someone sues you to hell and back

01:41:03,650 --> 01:41:05,630
SPEAKER_0:  and you have to pay up, you will disappear.

01:41:06,146 --> 01:41:10,430
SPEAKER_0:  and you're relying on liability insurance, which you're already paying out the ass for.

01:41:10,690 --> 01:41:17,438
SPEAKER_0:  to try to cover you if you get sued. But if you get sued, even if you win, that liability insurance now goes up in price the next year.

01:41:17,762 --> 01:41:19,486
SPEAKER_0:  And if you're the New York Times, it goes up by a lot.

01:41:19,810 --> 01:41:20,286
SPEAKER_0:  So.

01:41:20,514 --> 01:41:20,830
SPEAKER_0:  I mean.

01:41:21,634 --> 01:41:22,142
SPEAKER_0:  uh...

01:41:22,434 --> 01:41:25,438
SPEAKER_0:  I think there's work that independent journalists can do.

01:41:25,858 --> 01:41:27,294
SPEAKER_0:  uniquely that

01:41:28,450 --> 01:41:30,654
SPEAKER_0:  they can actually take like in some ways more risk.

01:41:31,042 --> 01:41:38,069
SPEAKER_0:  than a giant institution, which has a lot more, in my sense, to lose, even though it would appear like they have more in terms of defense too.

01:41:38,069 --> 01:41:38,974
SPEAKER_1:  Get, uh...

01:41:39,266 --> 01:41:41,374
SPEAKER_1:  You can be bullied legally. Yeah.

01:41:41,858 --> 01:41:42,302
SPEAKER_1:  You get.

01:41:42,594 --> 01:41:43,486
SPEAKER_1:  Afraid of that?

01:41:44,066 --> 01:41:44,798
SPEAKER_0:  Sure, I mean...

01:41:45,602 --> 01:41:46,750
SPEAKER_0:  i'd just uh...

01:41:47,746 --> 01:41:50,974
SPEAKER_0:  All these things are things you have to be aware of and then forget to do your job.

01:41:51,490 --> 01:41:56,254
SPEAKER_0:  Like you have to be, you know, it's like, it's like being like a snowboarder and it's like, do you realize you could hit your head?

01:41:56,674 --> 01:42:01,950
SPEAKER_0:  And it's like, yeah, of course, but in order to go do the, like the flip or whatever, you have to just accept the risk.

01:42:02,658 --> 01:42:05,182
SPEAKER_0:  mitigate the risk as much as possible and move on. So I wanted toã… ã… 

01:42:05,474 --> 01:42:07,134
SPEAKER_0:  We have like

01:42:07,554 --> 01:42:08,222
SPEAKER_0:  Insurance

01:42:08,450 --> 01:42:09,022
SPEAKER_0:  We keep.

01:42:09,442 --> 01:42:11,742
SPEAKER_0:  like a pool of funds for that kind of thing.

01:42:12,066 --> 01:42:16,510
SPEAKER_0:  Like I'm very conservative with how I spend my money basically all on.

01:42:16,930 --> 01:42:18,174
SPEAKER_0:  production and like

01:42:18,498 --> 01:42:21,118
SPEAKER_0:  trying to make my life as secure as I can.

01:42:21,602 --> 01:42:23,102
SPEAKER_0:  And then I just do the work that I...

01:42:23,330 --> 01:42:23,710
SPEAKER_0:  You know?

01:42:24,130 --> 01:42:25,534
SPEAKER_0:  I want to do because...

01:42:26,914 --> 01:42:30,846
SPEAKER_1:  So 99% of your fund goes into the studio.

01:42:31,234 --> 01:42:36,798
SPEAKER_1:  and then into that elaborate space of yours. Yeah, of course.

01:42:38,210 --> 01:42:44,190
SPEAKER_1:  How many kittens had to die to manufacture that studio? But anyway, that's my investigation for later.

01:42:45,858 --> 01:42:48,734
SPEAKER_1:  What keeps you mentally strong?

01:42:49,122 --> 01:42:49,854
SPEAKER_1:  all of this.

01:42:50,242 --> 01:42:54,462
SPEAKER_1:  What's your source of mental strength, of your psychological strength through this?

01:42:55,234 --> 01:42:55,966
SPEAKER_1:  Uhhh...

01:42:56,162 --> 01:42:59,998
SPEAKER_0:  I think there was a time when I was getting a lot of cease and desists.

01:43:00,578 --> 01:43:02,078
SPEAKER_0:  Some people were like actually like.

01:43:02,434 --> 01:43:04,862
SPEAKER_0:  like saying like they're gonna show up to my house, other kind of stuff.

01:43:05,154 --> 01:43:09,566
SPEAKER_0:  I don't think I was that. I think I was pretty worried about that for a while. My wife was.

01:43:10,210 --> 01:43:11,710
SPEAKER_0:  huge source of strength here.

01:43:12,194 --> 01:43:14,110
SPEAKER_0:  where she was like, hey.

01:43:14,754 --> 01:43:16,862
SPEAKER_0:  If you're not comfortable with it, you need to get out of the game.

01:43:17,154 --> 01:43:17,918
SPEAKER_0:  or you need to.

01:43:18,338 --> 01:43:19,678
SPEAKER_0:  basically like suck it up and

01:43:19,970 --> 01:43:21,022
SPEAKER_0:  Like this is what it is.

01:43:21,314 --> 01:43:22,654
SPEAKER_0:  if you're gonna go after these people.

01:43:23,010 --> 01:43:24,062
SPEAKER_0:  You have to.

01:43:24,418 --> 01:43:25,182
SPEAKER_0:  Basically...

01:43:25,730 --> 01:43:27,678
SPEAKER_0:  um, be mentally strong around this.

01:43:28,034 --> 01:43:29,150
SPEAKER_0:  And seeing her...

01:43:30,146 --> 01:43:33,182
SPEAKER_0:  have that realization helped me have the same realization.

01:43:33,666 --> 01:43:37,182
SPEAKER_0:  and I really deeply admire and respect that about her.

01:43:37,602 --> 01:43:37,918
SPEAKER_0:  And it

01:43:38,818 --> 01:43:40,990
SPEAKER_0:  solved a lot of my concerns around that.

01:43:41,346 --> 01:43:43,006
SPEAKER_0:  It's just, it just made me realize.

01:43:43,810 --> 01:43:45,310
SPEAKER_0:  Every profession has risks.

01:43:45,538 --> 01:43:47,422
SPEAKER_0:  It is what it is, you mitigate and then you move on.

01:43:48,578 --> 01:43:50,622
SPEAKER_1:  Why do you think there are so few journalists like you?

01:43:51,618 --> 01:43:56,798
SPEAKER_1:  You're basically the embodiment, at least in the space you operate, of what great journalism should be.

01:43:58,274 --> 01:43:59,806
SPEAKER_1:  Why do you think there's very few like you?

01:44:02,690 --> 01:44:03,198
SPEAKER_0:  That's.

01:44:03,426 --> 01:44:06,430
SPEAKER_0:  Such an enormous compliment and probably overstatement.

01:44:06,978 --> 01:44:07,998
SPEAKER_0:  But...

01:44:10,786 --> 01:44:12,990
SPEAKER_0:  I first want to pay respect.

01:44:13,666 --> 01:44:16,062
SPEAKER_0:  are a lot of great journalists, and a lot of them

01:44:16,930 --> 01:44:17,278
SPEAKER_0:  are

01:44:17,954 --> 01:44:19,198
SPEAKER_0:  I don't wanna just kind of.

01:44:19,458 --> 01:44:23,102
SPEAKER_0:  take it and go, yeah, you know, it's just me. There's so many great journalists.

01:44:25,218 --> 01:44:27,998
SPEAKER_0:  Matt Levine, Kelsey Piper.

01:44:28,226 --> 01:44:33,182
SPEAKER_0:  You've got anonymous journalists like Dirty Bubble. You've got citizen journalists like Tiffany Fong.

01:44:33,826 --> 01:44:34,951
SPEAKER_0:  But! But!

01:44:34,951 --> 01:44:35,518
SPEAKER_1:  Yeah.

01:44:35,682 --> 01:44:36,094
SPEAKER_0:  But.

01:44:37,730 --> 01:44:38,430
SPEAKER_0:  I think.

01:44:39,106 --> 01:44:43,134
SPEAKER_0:  If you're gonna be in this space in the long term, you do need to accept certain risks.

01:44:43,650 --> 01:44:46,014
SPEAKER_0:  And I think in the long term, it's like.

01:44:46,882 --> 01:44:49,982
SPEAKER_0:  I don't know how easy it is to play that game for a long period of time.

01:44:50,786 --> 01:44:52,318
SPEAKER_0:  because you make.

01:44:54,402 --> 01:44:58,174
SPEAKER_0:  To do great journalism, you don't get paid a lot, compared to what you could get paid if you did.

01:44:58,466 --> 01:44:59,998
SPEAKER_0:  press pieces or anything like that.

01:45:00,706 --> 01:45:04,286
SPEAKER_0:  You take a lot of risks legally, you take physical risks, you take...

01:45:04,962 --> 01:45:05,758
SPEAKER_0:  It's just like.

01:45:06,178 --> 01:45:07,646
SPEAKER_0:  If you care about money,

01:45:08,610 --> 01:45:09,662
SPEAKER_0:  It's not the profession.

01:45:10,722 --> 01:45:11,646
SPEAKER_0:  and I feel like...

01:45:12,898 --> 01:45:17,022
SPEAKER_0:  A lot of people, when they get notoriety, they move to like, well, I can just maximize.

01:45:17,538 --> 01:45:19,038
SPEAKER_0:  the money security side of things?

01:45:19,458 --> 01:45:20,254
SPEAKER_0:  And I think it.

01:45:20,642 --> 01:45:22,846
SPEAKER_0:  takes out a lot of would-be great journalists.

01:45:23,682 --> 01:45:26,526
SPEAKER_1:  And also, so first of all, comfort of all.

01:45:27,106 --> 01:45:31,902
SPEAKER_1:  of physical and mental wellbeing. Yes. Also being invited to parties with powerful people.

01:45:32,354 --> 01:45:33,918
SPEAKER_1:  You

01:45:35,362 --> 01:45:38,686
SPEAKER_1:  You make enemies, rich and powerful enemies doing this.

01:45:40,194 --> 01:45:40,510
SPEAKER_1:  Yes.

01:45:41,794 --> 01:45:42,814
SPEAKER_1:  But that's why I mix it.

01:45:44,674 --> 01:45:45,694
SPEAKER_1:  That's why it's admirable.

01:45:46,306 --> 01:45:46,750
SPEAKER_1:  I mean...

01:45:47,010 --> 01:45:49,278
SPEAKER_1:  You know it's it's an interesting case study.

01:45:49,794 --> 01:45:51,486
SPEAKER_1:  that you've been doing it as long as you have.

01:45:52,386 --> 01:45:55,614
SPEAKER_1:  and I hope you keep doing it, but it's just interesting that it's rare.

01:45:57,122 --> 01:45:57,950
SPEAKER_0:  I'll say.

01:45:58,914 --> 01:46:00,478
SPEAKER_0:  I wanna make a call like.

01:46:00,866 --> 01:46:02,558
SPEAKER_0:  I think societies can.

01:46:03,234 --> 01:46:03,774
SPEAKER_0:  Create.

01:46:04,898 --> 01:46:06,846
SPEAKER_0:  better journalists and worse journalists.

01:46:07,202 --> 01:46:09,022
SPEAKER_0:  in so far as they...

01:46:09,570 --> 01:46:11,870
SPEAKER_0:  support the journalists who are doing great work.

01:46:12,130 --> 01:46:15,102
SPEAKER_0:  And I want to call out Edward Snowden specifically.

01:46:15,586 --> 01:46:18,270
SPEAKER_0:  because what we have done to him is such a travesty.

01:46:18,658 --> 01:46:21,790
SPEAKER_0:  And the only lesson you can learn if you're a logical human being

01:46:22,050 --> 01:46:26,270
SPEAKER_0:  is that you should never whistle blow on the United States government after looking at what they did to Snowden.

01:46:26,978 --> 01:46:27,358
SPEAKER_0:  So.

01:46:28,322 --> 01:46:29,630
SPEAKER_0:  As a society.

01:46:30,370 --> 01:46:34,686
SPEAKER_0:  We can put pressure on lawmakers to make it easier for people to do the great work.

01:46:35,682 --> 01:46:40,350
SPEAKER_0:  by not punishing the people who do great work, if that makes sense, and de-risking it for them.

01:46:40,770 --> 01:46:44,350
SPEAKER_0:  because we shouldn't expect journalists to be martyrs to do great work.

01:46:44,770 --> 01:46:46,110
SPEAKER_0:  right? To do important work.

01:46:46,530 --> 01:46:49,150
SPEAKER_0:  And part of that comes from protecting whistleblowers.

01:46:49,410 --> 01:46:51,710
SPEAKER_0:  There's like very common sense things.

01:46:51,938 --> 01:46:52,862
SPEAKER_0:  I love like-

01:46:53,282 --> 01:46:54,046
SPEAKER_0:  It's great to.

01:46:54,498 --> 01:47:00,542
SPEAKER_0:  Heroicize, you know people like Edwards known and stuff like that, but we shouldn't expect them to be heroes to do that work

01:47:01,218 --> 01:47:02,654
SPEAKER_1:  Do you ever think about going?

01:47:03,266 --> 01:47:04,990
SPEAKER_1:  even focused on financial fraud.

01:47:05,858 --> 01:47:09,214
SPEAKER_1:  Do you ever think about going after other centers of power?

01:47:10,146 --> 01:47:11,582
SPEAKER_1:  Uh, like.

01:47:12,706 --> 01:47:13,982
SPEAKER_1:  government Excerpts

01:47:14,434 --> 01:47:15,198
SPEAKER_1:  Politics.

01:47:15,938 --> 01:47:18,558
SPEAKER_0:  Politics, it seems to me, you can't do good work.

01:47:19,266 --> 01:47:19,742
SPEAKER_0:  um...

01:47:20,130 --> 01:47:23,102
SPEAKER_0:  Like everybody doing good work in politics is to some extent.

01:47:23,746 --> 01:47:26,782
SPEAKER_0:  from my limited perspective, as I said, not that into it.

01:47:27,234 --> 01:47:27,806
SPEAKER_0:  It seems like.

01:47:28,354 --> 01:47:29,918
SPEAKER_0:  Everyone has to take a side.

01:47:30,338 --> 01:47:31,806
SPEAKER_0:  Because even if you do great work...

01:47:32,418 --> 01:47:33,822
SPEAKER_0:  whoever you're exposing.

01:47:34,562 --> 01:47:39,582
SPEAKER_0:  Half the other people, no matter how good your work is, are going to claim it's just for partisan hackery.

01:47:39,938 --> 01:47:41,278
SPEAKER_0:  and they're going to malign you?

01:47:41,666 --> 01:47:42,558
SPEAKER_0:  So it seems like.

01:47:43,458 --> 01:47:45,214
SPEAKER_0:  A lot of journalists have to take.

01:47:45,538 --> 01:47:48,382
SPEAKER_0:  a slant, even if it's not explicit like bias.

01:47:48,738 --> 01:47:53,054
SPEAKER_0:  They have to take a slant on who they expose. I hate that. I would really like a world where-

01:47:53,314 --> 01:47:54,782
SPEAKER_0:  you could freely expose.

01:47:55,426 --> 01:47:56,414
SPEAKER_0:  both sides.

01:47:56,674 --> 01:47:58,302
SPEAKER_0:  without having a constant.

01:47:58,690 --> 01:48:00,542
SPEAKER_0:  malignment of like, you know

01:48:02,626 --> 01:48:06,366
SPEAKER_0:  who are you working for or you did this for XYZ or whatever like

01:48:06,594 --> 01:48:07,358
SPEAKER_0:  I really find that.

01:48:07,650 --> 01:48:09,982
SPEAKER_0:  deeply problematic about our current, like.

01:48:11,234 --> 01:48:13,374
SPEAKER_0:  journalism in the political sphere.

01:48:13,634 --> 01:48:14,910
SPEAKER_0:  As far as government stuff.

01:48:15,202 --> 01:48:18,174
SPEAKER_0:  I think it's easy to do, not easy, but like it's.

01:48:18,658 --> 01:48:19,870
SPEAKER_0:  much more.

01:48:20,770 --> 01:48:22,814
SPEAKER_0:  enticing to do foreign journalism?

01:48:23,074 --> 01:48:25,150
SPEAKER_0:  than to do local journalism.

01:48:25,378 --> 01:48:26,430
SPEAKER_0:  on positions of power.

01:48:26,786 --> 01:48:27,998
SPEAKER_0:  Because if you question...

01:48:28,930 --> 01:48:30,270
SPEAKER_0:  It's so easy to just get.

01:48:30,754 --> 01:48:34,622
SPEAKER_0:  The bigger cases you expose locally, your...

01:48:35,010 --> 01:48:36,030
SPEAKER_0:  you get in danger.

01:48:36,514 --> 01:48:38,206
SPEAKER_0:  because it's just very clear cut.

01:48:38,562 --> 01:48:39,326
SPEAKER_0:  bigger the case.

01:48:40,002 --> 01:48:45,566
SPEAKER_0:  the more your financial wellbeing, your access to your entire life is like sort of in jeopardy.

01:48:45,826 --> 01:48:47,870
SPEAKER_0:  Whereas if you do foreign journalism, you can do great work.

01:48:48,162 --> 01:48:50,302
SPEAKER_0:  and largely you're protected by your own.

01:48:50,530 --> 01:48:50,910
SPEAKER_0:  government.

01:48:51,362 --> 01:48:54,206
SPEAKER_0:  So it's kind of this weird thing where if you want great journalism on America...

01:48:54,530 --> 01:48:56,158
SPEAKER_0:  Sometimes going abroad might be...

01:48:57,122 --> 01:49:01,598
SPEAKER_1:  But the politician thing that's interesting, you mentioned that and going abroad.

01:49:02,850 --> 01:49:09,118
SPEAKER_1:  I think the way you think about your current work, I think applies in great journalism and in politics as well.

01:49:09,506 --> 01:49:11,966
SPEAKER_1:  So what happens, I have that sense.

01:49:13,058 --> 01:49:15,678
SPEAKER_1:  because I aspire to be like you in the sort of.

01:49:15,938 --> 01:49:20,990
SPEAKER_1:  in the conversation space of like with politicians, I tried to talk to people on the left and the right.

01:49:21,538 --> 01:49:25,278
SPEAKER_1:  and do so in a nonpartisan way and criticize but also steelman their cases.

01:49:25,602 --> 01:49:27,166
SPEAKER_1:  What happens of learned?

01:49:27,586 --> 01:49:28,958
SPEAKER_1:  As you can talk to somebody on the right.

01:49:30,242 --> 01:49:33,886
SPEAKER_1:  the right kind of brings you in. Like yes, we'll keep you comfortable.

01:49:34,114 --> 01:49:36,158
SPEAKER_1:  Come with us and then the left attacks you.

01:49:36,802 --> 01:49:38,014
SPEAKER_1:  It's so.

01:49:38,530 --> 01:49:43,486
SPEAKER_1:  uh... in the same happens on life talk a lot the right attacks you you know left they come with us

01:49:43,746 --> 01:49:44,638
SPEAKER_1:  So like there's a.

01:49:44,898 --> 01:49:50,526
SPEAKER_1:  there's a temptation, a momentum to staying to that one side, whatever that side is.

01:49:50,914 --> 01:49:54,878
SPEAKER_1:  I'm the same with foreign journalism. You can cover Putin critically.

01:49:55,330 --> 01:49:57,566
SPEAKER_1:  there's a strong pull to being.

01:49:57,954 --> 01:50:00,606
SPEAKER_1:  pro Ukraine, pro Zelensky, pro...

01:50:00,834 --> 01:50:07,038
SPEAKER_1:  basically really covering in a favorable way to the point of propaganda, to the point of PR.

01:50:07,394 --> 01:50:08,702
SPEAKER_1:  the Zelensky regime.

01:50:08,994 --> 01:50:11,998
SPEAKER_1:  If you criticize the Lensky regime, there's a strong pull.

01:50:12,386 --> 01:50:14,110
SPEAKER_1:  towards then being supportive of.

01:50:14,370 --> 01:50:18,558
SPEAKER_1:  not necessarily the Putin regime, but a very different perspective on it, which is like

01:50:18,818 --> 01:50:20,030
SPEAKER_1:  NATO is the one that-

01:50:20,258 --> 01:50:26,014
SPEAKER_1:  created that war. There's narratives that pull you and what I think a great journalist does.

01:50:26,370 --> 01:50:28,030
SPEAKER_1:  is make enemies and plus size.

01:50:28,738 --> 01:50:31,678
SPEAKER_1:  and walk through that fire and not get...

01:50:32,322 --> 01:50:34,974
SPEAKER_1:  pulled in to the protection of anyone's side.

01:50:35,298 --> 01:50:38,503
SPEAKER_1:  because they get so harshly attacked. Anytime they deviate.

01:50:38,503 --> 01:50:40,574
SPEAKER_0:  the center. I think also like.

01:50:41,666 --> 01:50:43,870
SPEAKER_0:  There's a criticism of all centrists.

01:50:44,258 --> 01:50:47,838
SPEAKER_0:  which I think in some way is fair. And I say that to someone largely who's disinterested.

01:50:48,290 --> 01:50:50,270
SPEAKER_0:  which is that this what about is, or like this.

01:50:50,946 --> 01:50:52,510
SPEAKER_0:  What about the left? What about the right?

01:50:52,962 --> 01:50:53,950
SPEAKER_0:  can skew.

01:50:54,562 --> 01:50:57,214
SPEAKER_0:  when it's not a one, it's not a both sides issue.

01:50:57,858 --> 01:50:58,590
SPEAKER_0:  So...

01:50:59,042 --> 01:51:03,966
SPEAKER_0:  In the case of Russia, Ukraine, I think I'm strongly in favor of Ukraine.

01:51:04,386 --> 01:51:08,990
SPEAKER_0:  even though I tend to go like on both sides. And that might be partly because one of my employees is Ukrainian.

01:51:09,314 --> 01:51:09,694
SPEAKER_0:  Um.

01:51:10,146 --> 01:51:10,846
SPEAKER_0:  And I think...

01:51:11,810 --> 01:51:15,038
SPEAKER_0:  what a great journalist does, especially like in politics.

01:51:15,394 --> 01:51:16,990
SPEAKER_0:  is I think they criticize.

01:51:17,762 --> 01:51:19,774
SPEAKER_0:  the regime that's most in power.

01:51:20,258 --> 01:51:24,158
SPEAKER_0:  most of it controls the keys and is the most corrupt at that time.

01:51:24,610 --> 01:51:28,702
SPEAKER_0:  and they might appear to be like, let's say during the realm of Trump.

01:51:29,698 --> 01:51:31,582
SPEAKER_0:  a great journalist would criticize Trump.

01:51:31,842 --> 01:51:37,374
SPEAKER_0:  But that same journalist who held Trump's feet to the fire should be capable of holding Biden's feet to the fire.

01:51:37,730 --> 01:51:38,590
SPEAKER_0:  four years later.

01:51:38,946 --> 01:51:40,071
SPEAKER_0:  If that kind of makes sense.

01:51:40,071 --> 01:51:41,182
SPEAKER_1:  Exactly right, yeah. Yeah

01:51:41,442 --> 01:51:42,142
SPEAKER_1:  So any

01:51:42,498 --> 01:51:46,046
SPEAKER_1:  uh... revealing any so attacking any power center

01:51:46,274 --> 01:51:47,966
SPEAKER_1:  for the corruption for the flaws they have.

01:51:48,290 --> 01:51:49,415
SPEAKER_1:  uh... you respect

01:51:49,415 --> 01:51:50,174
SPEAKER_0:  of like your

01:51:50,402 --> 01:51:52,862
SPEAKER_0:  political agenda or your political ideas.

01:51:53,474 --> 01:51:56,894
SPEAKER_1:  Yeah, so that and that's what I mean about sort of the war in Ukraine. There's several

01:51:57,250 --> 01:51:58,014
SPEAKER_1:  players.

01:51:58,658 --> 01:51:59,294
SPEAKER_1:  NATO.

01:52:00,098 --> 01:52:00,862
SPEAKER_1:  Russia.

01:52:01,282 --> 01:52:02,078
SPEAKER_1:  Ukraine

01:52:02,530 --> 01:52:03,262
SPEAKER_1:  China.

01:52:03,778 --> 01:52:04,158
SPEAKER_1:  Uh

01:52:05,378 --> 01:52:06,110
SPEAKER_1:  India.

01:52:06,882 --> 01:52:12,158
SPEAKER_1:  I mean, there's several less important players, maybe some of the like Iran and

01:52:12,578 --> 01:52:15,038
SPEAKER_1:  like Israel and maybe Africa.

01:52:15,906 --> 01:52:16,478
SPEAKER_1:  and

01:52:16,738 --> 01:52:18,238
SPEAKER_1:  what great journalism takes.

01:52:18,530 --> 01:52:23,294
SPEAKER_1:  requires is basically revealing the flaws of each one of those players.

01:52:23,554 --> 01:52:26,398
SPEAKER_1:  irrespective of the attacks you get. And you're right that-

01:52:26,754 --> 01:52:28,894
SPEAKER_1:  throughout any particular situation.

01:52:29,154 --> 01:52:29,886
SPEAKER_1:  There is some-

01:52:30,274 --> 01:52:32,734
SPEAKER_1:  some parties that are worse than others and you have to...

01:52:32,962 --> 01:52:33,566
SPEAKER_1:  uh...

01:52:34,306 --> 01:52:39,614
SPEAKER_1:  weigh your perspective accordingly. But also it requires you to be fearless in certain things. Like for example,

01:52:40,066 --> 01:52:41,022
SPEAKER_1:  I don't even know.

01:52:41,666 --> 01:52:43,870
SPEAKER_1:  what it's like to be a journalist covering China.

01:52:44,962 --> 01:52:47,582
SPEAKER_0:  Oh, that's an exact case of like

01:52:48,034 --> 01:52:51,070
SPEAKER_0:  China has made it so difficult to be a good journalist.

01:52:51,490 --> 01:52:54,238
SPEAKER_0:  that they've effectively squashed criticism because

01:52:54,562 --> 01:52:58,014
SPEAKER_0:  To be a journalist in China means constantly risking.

01:52:58,306 --> 01:53:00,350
SPEAKER_0:  your life every single day.

01:53:00,674 --> 01:53:01,950
SPEAKER_0:  to criticize that government.

01:53:02,306 --> 01:53:05,438
SPEAKER_0:  And so the best journalists are a lot of times outside the country.

01:53:05,826 --> 01:53:09,182
SPEAKER_0:  or they have sources inside the country who are like there's like this

01:53:09,410 --> 01:53:09,822
SPEAKER_0:  You know.

01:53:10,978 --> 01:53:13,790
SPEAKER_0:  different, there's layers to the journalism where there's insiders.

01:53:14,018 --> 01:53:17,726
SPEAKER_0:  who are leaking information, but they themselves cannot publish because it's like, it's-

01:53:17,954 --> 01:53:18,398
SPEAKER_0:  You know it's.

01:53:18,914 --> 01:53:20,190
SPEAKER_0:  It's extremely risky, so.

01:53:21,026 --> 01:53:23,102
SPEAKER_0:  Yeah, I think as a society...

01:53:23,394 --> 01:53:25,406
SPEAKER_0:  one measure of

01:53:25,634 --> 01:53:26,494
SPEAKER_0:  how healthy.

01:53:27,234 --> 01:53:29,406
SPEAKER_0:  the political structure is.

01:53:29,762 --> 01:53:33,118
SPEAKER_0:  is how well you can criticize it without fearing for your safety.

01:53:34,978 --> 01:53:39,966
SPEAKER_1:  In that sense, the chaos and the bickering going on in the United States politics is a good thing.

01:53:40,546 --> 01:53:41,790
SPEAKER_1:  that people can.

01:53:42,146 --> 01:53:46,750
SPEAKER_1:  criticized very harshly. Very harsh. And be, in terms of safety, are pretty safe.

01:53:46,882 --> 01:53:48,030
SPEAKER_0:  Yes, absolutely.

01:53:48,322 --> 01:53:50,462
SPEAKER_0:  I think our only challenge is like...

01:53:50,882 --> 01:53:54,398
SPEAKER_0:  where it gets dangerous is around like top secret information.

01:53:54,754 --> 01:53:56,734
SPEAKER_0:  The government comes down so hard.

01:53:57,154 --> 01:53:57,598
SPEAKER_0:  that

01:53:58,850 --> 01:54:01,758
SPEAKER_0:  The danger in covering politics here is...

01:54:02,210 --> 01:54:05,150
SPEAKER_0:  You can expose something that's top secret that should be exposed.

01:54:05,698 --> 01:54:06,526
SPEAKER_1:  and they'll ruin you.

01:54:07,106 --> 01:54:09,918
SPEAKER_1:  So that's where you again give props to Snowden.

01:54:10,562 --> 01:54:11,687
SPEAKER_1:  for stepping up. 100.

01:54:11,687 --> 01:54:12,094
SPEAKER_0:  percent.

01:54:12,450 --> 01:54:13,054
SPEAKER_0:  100%.

01:54:13,570 --> 01:54:15,966
SPEAKER_1:  What's the origin of...

01:54:17,058 --> 01:54:18,622
SPEAKER_1:  the suspender wearing Batman.

01:54:18,882 --> 01:54:25,662
SPEAKER_1:  How did you come to do what you do? Like we talked about where you are and how your mind works, but how did it start?

01:54:26,274 --> 01:54:28,510
SPEAKER_0:  kind of always been interested in fraud or...

01:54:28,834 --> 01:54:33,598
SPEAKER_0:  Or at least I saw fraud early on and I was just like curious about what is this? I didn't know what I was really looking at.

01:54:34,082 --> 01:54:34,718
SPEAKER_0:  So.

01:54:35,042 --> 01:54:36,926
SPEAKER_0:  Basically, my mom got cancer when I was...

01:54:37,314 --> 01:54:38,878
SPEAKER_0:  in high school and

01:54:39,298 --> 01:54:41,918
SPEAKER_0:  It was pretty traumatic. I mean, she's fine. I mean, she's got thyroid cancer, which is-

01:54:42,146 --> 01:54:44,222
SPEAKER_0:  We didn't know it at the time. It's like cancer's cancer.

01:54:45,026 --> 01:54:46,654
SPEAKER_0:  fairly easily treatable with surgery.

01:54:46,882 --> 01:54:48,286
SPEAKER_0:  It's one of the better.

01:54:48,578 --> 01:54:49,854
SPEAKER_0:  you know, survivable ones.

01:54:50,434 --> 01:54:54,782
SPEAKER_0:  And I just watched her get like bombarded with all these like phony health scams of, you know.

01:54:55,138 --> 01:54:58,142
SPEAKER_0:  like colloidal silver, all these different remedies.

01:54:58,498 --> 01:55:01,502
SPEAKER_0:  And she was very into, you know, all the...

01:55:02,210 --> 01:55:06,942
SPEAKER_0:  different ways that she might treat her cancer. Obviously surgery is very daunting.

01:55:07,458 --> 01:55:08,126
SPEAKER_0:  and

01:55:08,578 --> 01:55:11,486
SPEAKER_0:  You know, I was just confused. I was like, why are we doing so many different...

01:55:11,906 --> 01:55:15,006
SPEAKER_0:  remedies that all seem a very dubious health value.

01:55:15,714 --> 01:55:19,870
SPEAKER_0:  Later I'd find out that these are like all grifters. I mean, they take advantage of...

01:55:20,226 --> 01:55:23,262
SPEAKER_0:  free speech in America to advertise their products as

01:55:23,554 --> 01:55:26,398
SPEAKER_0:  you know, life-saving miracles, whatever, when they're, of course, not.

01:55:26,818 --> 01:55:29,054
SPEAKER_0:  Eventually she got the surgery, thank God, but...

01:55:29,378 --> 01:55:31,966
SPEAKER_0:  I know people in my life who...

01:55:33,474 --> 01:55:37,502
SPEAKER_0:  Parents passed away because they didn't have the surgery. They instead...

01:55:38,882 --> 01:55:40,958
SPEAKER_0:  took the alternative option. i know Deepak and I think that was the only option.

01:55:41,538 --> 01:55:45,086
SPEAKER_0:  I don't want to go into specifics because I don't want to mention their specific case, but-

01:55:45,410 --> 01:55:46,558
SPEAKER_0:  They're...

01:55:46,786 --> 01:55:52,126
SPEAKER_0:  Family member went to Mexico for some alternate treatment, health treatment, instead of getting an easy surgery, and they died.

01:55:52,610 --> 01:55:53,214
SPEAKER_0:  And so it's like.

01:55:54,498 --> 01:55:57,566
SPEAKER_0:  I realized, you know, where is the outrage about this? Where's the-

01:55:57,954 --> 01:56:03,102
SPEAKER_0:  who covers this stuff and I realized, well, not many people do. Then I went to college, I was getting a chemical engineering degree.

01:56:03,490 --> 01:56:04,862
SPEAKER_0:  and all my friends were like telling me.

01:56:05,090 --> 01:56:06,398
SPEAKER_0:  you know, hey, you should come to this meeting.

01:56:06,786 --> 01:56:07,678
SPEAKER_0:  You know, we don't need this.

01:56:08,130 --> 01:56:11,710
SPEAKER_0:  You're doing this engineering stuff, that's great. You're going to make like 70k a year.

01:56:12,034 --> 01:56:16,670
SPEAKER_0:  Don't you want to get like rich now? Like why wait till you're 60 years old to retire? Like you can be rich now Lex.

01:56:17,154 --> 01:56:17,502
SPEAKER_0:  So.

01:56:18,274 --> 01:56:19,678
SPEAKER_0:  I'd go show up to a hotel.

01:56:20,162 --> 01:56:21,502
SPEAKER_0:  and there'd be an MLM.

01:56:21,794 --> 01:56:24,126
SPEAKER_0:  like multi-level marketing pitch for.

01:56:24,546 --> 01:56:24,958
SPEAKER_0:  Uh...

01:56:25,378 --> 01:56:27,102
SPEAKER_0:  Amway or whatever it was that day.

01:56:27,618 --> 01:56:28,414
SPEAKER_0:  And...

01:56:29,282 --> 01:56:35,518
SPEAKER_0:  I was once again fascinated. I didn't know what I was looking at, but I was like, what is this weird game we're all playing where we sit in this room?

01:56:35,938 --> 01:56:40,702
SPEAKER_0:  We're looking at the speaker who says he's so successful, but why is he taking a Friday?

01:56:40,994 --> 01:56:43,454
SPEAKER_0:  or a Saturday to do this pitch at night.

01:56:43,842 --> 01:56:47,294
SPEAKER_0:  And they're gonna telling me I'm gonna be financially free, but they're working on their Saturday and Sunday.

01:56:47,778 --> 01:56:49,278
SPEAKER_0:  And so it's like, how financially free are they?

01:56:49,730 --> 01:56:54,718
SPEAKER_0:  So I was just like confused. I was like, you know, none of my friends were rich. They all said they were gonna be rich. No one ever seemed to get rich.

01:56:55,202 --> 01:56:57,886
SPEAKER_0:  And so I was sort of baffled by what I was looking at.

01:56:58,370 --> 01:56:59,710
SPEAKER_0:  Later, I graduate.

01:56:59,938 --> 01:57:01,886
SPEAKER_0:  I had no interest in doing engineering.

01:57:02,274 --> 01:57:05,054
SPEAKER_0:  which we can kind of get into, but I want to do something in media.

01:57:05,602 --> 01:57:06,238
SPEAKER_0:  Um...

01:57:06,562 --> 01:57:09,118
SPEAKER_0:  and I started covering a variety of topics, but eventually...

01:57:09,506 --> 01:57:12,670
SPEAKER_0:  I sort of revisited this interest in fraud and I started.

01:57:12,930 --> 01:57:16,382
SPEAKER_0:  talking about these kind of get-rich-quick grifters that were online.

01:57:16,802 --> 01:57:20,734
SPEAKER_0:  sort of the Tai Lopez variety, you know, 67 steps or whatever.

01:57:20,994 --> 01:57:24,574
SPEAKER_0:  5 steps to get rich, 5 coins to 5 million, you know, these get rich quick schemes.

01:57:25,858 --> 01:57:27,038
SPEAKER_0:  A lot of people were interested in.

01:57:27,490 --> 01:57:32,670
SPEAKER_0:  No one seemed to get rich once again except for the people at the tippity tippity top selling the get rich quick thing.

01:57:32,994 --> 01:57:37,918
SPEAKER_0:  And I was like fascinated by the structure of it. And I was like, does nobody see what this is? Like, does nobody get it?

01:57:38,370 --> 01:57:40,190
SPEAKER_0:  So I started making a series of videos on that.

01:57:40,866 --> 01:57:45,662
SPEAKER_0:  And the response was palpable. I mean, it was like, I've made a lot of stuff before that. I had made stuff that got-

01:57:45,890 --> 01:57:46,878
SPEAKER_0:  A million views.

01:57:47,170 --> 01:57:48,798
SPEAKER_0:  I'd had some marginal success.

01:57:50,050 --> 01:57:51,326
SPEAKER_0:  The response.

01:57:51,554 --> 01:57:53,630
SPEAKER_0:  of like the emails that came in, the...

01:57:53,858 --> 01:57:55,198
SPEAKER_0:  I could tell this work.

01:57:55,522 --> 01:57:57,118
SPEAKER_0:  even though it had far less

01:57:57,346 --> 01:57:58,462
SPEAKER_0:  views at the time.

01:57:58,914 --> 01:58:00,574
SPEAKER_0:  was having a different level of impact.

01:58:00,962 --> 01:58:02,430
SPEAKER_0:  That's what I was really interested in.

01:58:02,754 --> 01:58:03,486
SPEAKER_0:  One of my.

01:58:03,778 --> 01:58:05,374
SPEAKER_0:  problems with engineering was

01:58:05,698 --> 01:58:06,302
SPEAKER_0:  from my.

01:58:06,530 --> 01:58:08,798
SPEAKER_0:  standpoint, I did chemical engineering at Texas A&M.

01:58:09,666 --> 01:58:14,302
SPEAKER_0:  And like, I was like, is my future just gonna be in a chemical plant improving some process by 2%?

01:58:14,626 --> 01:58:15,230
SPEAKER_0:  And it's like my-

01:58:15,746 --> 01:58:16,862
SPEAKER_0:  gift to the world. Just you

01:58:17,090 --> 01:58:18,846
SPEAKER_0:  I didn't see the hard impact.

01:58:19,394 --> 01:58:22,782
SPEAKER_0:  And that maybe that's a lack of imagination because chemicals matter, but-

01:58:23,330 --> 01:58:26,238
SPEAKER_0:  I needed, I wanted to see an impact in the world.

01:58:26,594 --> 01:58:27,390
SPEAKER_0:  And so when like...

01:58:27,618 --> 01:58:29,086
SPEAKER_0:  I did start doing this fraud stuff.

01:58:29,346 --> 01:58:31,358
SPEAKER_0:  exposing fraud, I clicked in my brain, I was like, whoa.

01:58:31,938 --> 01:58:34,142
SPEAKER_0:  This is kind of doing what I want to do.

01:58:34,690 --> 01:58:35,422
SPEAKER_0:  And so...

01:58:36,002 --> 01:58:39,134
SPEAKER_0:  I started posting videos. At first, it really focused on like...

01:58:39,458 --> 01:58:42,270
SPEAKER_0:  Get Rich, Quick Scheme, Grifty Advertising.

01:58:42,658 --> 01:58:45,182
SPEAKER_0:  which I think is super predatory and we can go into.

01:58:45,442 --> 01:58:46,686
SPEAKER_0:  Why? But, um...

01:58:47,106 --> 01:58:48,862
SPEAKER_0:  It eventually graduated to crypto and

01:58:49,698 --> 01:58:52,670
SPEAKER_0:  It snowballed, I guess, because now we're talking Samrsambhackinstbutton.

01:58:53,730 --> 01:58:55,678
SPEAKER_1:  Okay, grifty advertising.

01:58:56,194 --> 01:59:00,030
SPEAKER_1:  So actually, just to step back, what is a multi-level marketing scheme?

01:59:01,474 --> 01:59:01,822
SPEAKER_1:  What?

01:59:02,786 --> 01:59:06,334
SPEAKER_1:  because I've experienced a similar thing. I remember,

01:59:06,562 --> 01:59:09,310
SPEAKER_1:  I worked at, I sold women's shoes at Sears.

01:59:09,666 --> 01:59:12,350
SPEAKER_1:  uh, and a bank and I just remember like.

01:59:12,866 --> 01:59:18,878
SPEAKER_1:  Some kind of forgot the name of the company, but you'd like you can sell like knives or whatever. Like that's a couple of come

01:59:19,586 --> 01:59:20,798
SPEAKER_0:  I know what you're talking about. I'm-

01:59:21,250 --> 01:59:25,534
SPEAKER_1:  I'm sure there's a lot of things like this, right? And I remember feeling a similar thing like why?

01:59:26,434 --> 01:59:29,406
SPEAKER_1:  To me, what was fascinating about it is like...

01:59:29,890 --> 01:59:32,062
SPEAKER_1:  Wow, like human civilization.

01:59:32,578 --> 01:59:34,718
SPEAKER_1:  is interesting like a pyramid scheme.

01:59:35,042 --> 01:59:37,278
SPEAKER_1:  Like I didn't maybe didn't know the words for that.

01:59:37,730 --> 01:59:39,614
SPEAKER_1:  But it's like, it's cool. Like you can like.

01:59:39,842 --> 01:59:46,302
SPEAKER_1:  get in a room, you convince each other of ideas, and you have these ambitions, there's a general desire, especially when you're young.

01:59:46,818 --> 01:59:47,422
SPEAKER_1:  to like.

01:59:47,778 --> 01:59:49,118
SPEAKER_1:  Like life sucks right now.

01:59:49,666 --> 01:59:51,678
SPEAKER_1:  Nobody respects you. You have no money.

01:59:52,066 --> 01:59:55,262
SPEAKER_1:  You want to do good and you want to be sold this dream of like

01:59:55,906 --> 02:00:02,398
SPEAKER_1:  If I work hard enough at this weird thing, I can shortcut and get to the very top. Yes. I don't know what that is and it was.

02:00:02,690 --> 02:00:06,270
SPEAKER_1:  I also in me felt that like life really sucks and I could.

02:00:06,658 --> 02:00:07,614
SPEAKER_1:  Do good.

02:00:08,002 --> 02:00:10,782
SPEAKER_1:  I'm lucky. I found a way to do good. I'm like.

02:00:11,458 --> 02:00:16,510
SPEAKER_1:  And I don't know, you connect with us somehow. I think there's like this weird fire inside people to like.

02:00:17,122 --> 02:00:20,542
SPEAKER_1:  to make better of themselves, right? I don't know if it's just an American thing or if it's-

02:00:20,994 --> 02:00:23,486
SPEAKER_1:  But anyway, that was fascinating to me from a human nature perspective.

02:00:23,778 --> 02:00:25,982
SPEAKER_0:  Grifters play on this though, right? Like this is-

02:00:26,274 --> 02:00:26,974
SPEAKER_0:  So the

02:00:27,618 --> 02:00:30,590
SPEAKER_0:  best salesman play on true narratives.

02:00:30,946 --> 02:00:32,062
SPEAKER_0:  that you already believe.

02:00:32,450 --> 02:00:33,694
SPEAKER_0:  So the true narrative is.

02:00:34,242 --> 02:00:35,550
SPEAKER_0:  You know, life is unfair.

02:00:36,034 --> 02:00:36,862
SPEAKER_0:  It is tough.

02:00:37,538 --> 02:00:38,014
SPEAKER_0:  Um

02:00:38,562 --> 02:00:41,918
SPEAKER_0:  The American Dream as described by GoToAJob.

02:00:42,178 --> 02:00:51,262
SPEAKER_0:  work at the same company for 40 years and then retire to a safety net that you're positive is gonna be there, that is largely dead. And so they like play on those fears.

02:00:51,618 --> 02:00:59,806
SPEAKER_0:  and those problems to then sell you a pill, a solution, a thing. And the problem is that the solution is usually worse.

02:01:00,066 --> 02:01:02,846
SPEAKER_0:  than even the problem they sketched out. Like you will do better.

02:01:03,170 --> 02:01:10,462
SPEAKER_0:  most of the time by going with the regular company than you will by going with these goofy multi-level marketing. But let me answer your question. What is a multi-level marketing?

02:01:10,882 --> 02:01:11,198
SPEAKER_0:  So.

02:01:12,034 --> 02:01:15,710
SPEAKER_0:  There's a criticism, first of all, that, well, let me get to what it is in theory.

02:01:16,322 --> 02:01:17,374
SPEAKER_0:  at its most ideal.

02:01:17,730 --> 02:01:18,750
SPEAKER_0:  Multi-level marketing.

02:01:19,106 --> 02:01:20,830
SPEAKER_0:  is where you have a product that you're selling.

02:01:21,346 --> 02:01:22,942
SPEAKER_0:  and one of the ways you help sell it.

02:01:23,330 --> 02:01:25,438
SPEAKER_0:  is by rather than going through traditional marketing.

02:01:25,890 --> 02:01:27,070
SPEAKER_0:  like where you go and you...

02:01:27,330 --> 02:01:28,542
SPEAKER_0:  put out print advertising.

02:01:28,962 --> 02:01:31,518
SPEAKER_0:  It's like sort of a social network of marketing.

02:01:31,778 --> 02:01:32,926
SPEAKER_0:  I sell to you.

02:01:33,218 --> 02:01:37,630
SPEAKER_0:  And then actually Lex, not only can I sell to you, you can then go sell this product and you'll make money selling it.

02:01:37,890 --> 02:01:42,846
SPEAKER_0:  And you know what, to incentivize me to get other salesmen, because when I get another salesman, I'm actually giving myself competition.

02:01:43,170 --> 02:01:43,806
SPEAKER_0:  So that's bad.

02:01:44,354 --> 02:01:47,518
SPEAKER_0:  So to incentivize me to do that, they'll pay me part of what you make.

02:01:48,610 --> 02:01:53,694
SPEAKER_0:  and then you go out and you go, okay, well I can sell this product, I also can get new salesmen to like sell for me.

02:01:53,954 --> 02:01:55,422
SPEAKER_0:  and I'm gonna make money from you, whatever.

02:01:55,778 --> 02:02:00,190
SPEAKER_0:  So it goes down the line of you create multiple levels where you can profit from their marketing.

02:02:00,546 --> 02:02:00,894
SPEAKER_0:  Right?

02:02:02,306 --> 02:02:03,614
SPEAKER_0:  problem with this system.

02:02:03,874 --> 02:02:06,206
SPEAKER_0:  is that however well intentioned it is.

02:02:06,658 --> 02:02:09,694
SPEAKER_0:  is that usually the emphasis of that selling.

02:02:09,954 --> 02:02:11,006
SPEAKER_0:  and making money?

02:02:11,330 --> 02:02:13,598
SPEAKER_0:  ends up not being about the product at all.

02:02:14,018 --> 02:02:15,550
SPEAKER_0:  and ends up entirely being about.

02:02:15,778 --> 02:02:18,462
SPEAKER_0:  Recruiting new people to recruit new people to recruit new people

02:02:18,722 --> 02:02:20,894
SPEAKER_0:  That's the real way to make money in multi-level marketing.

02:02:21,186 --> 02:02:24,062
SPEAKER_0:  This is where the very true criticism of

02:02:24,290 --> 02:02:28,286
SPEAKER_0:  Most multi-level marketing, if not all, are pyramid schemes in structure.

02:02:28,546 --> 02:02:31,262
SPEAKER_0:  because what a pyramid scheme is, is it's all about.

02:02:31,650 --> 02:02:32,958
SPEAKER_0:  I put in $500.

02:02:33,186 --> 02:02:41,406
SPEAKER_0:  and I recruit two people to put in $500 and that comes up to me and they get two people to put in $500 and it goes to them. And the reason it's a flawed business model is.

02:02:41,634 --> 02:02:45,598
SPEAKER_0:  In order for it to work and everyone to make money, you'd have to assume an infinite human race.

02:02:46,018 --> 02:02:51,358
SPEAKER_0:  And so that's not the case. Most people end up getting screwed in multi-level marketing and in pyramid schemes.

02:02:52,034 --> 02:02:53,854
SPEAKER_0:  That's what that is. That's that thing.

02:02:54,114 --> 02:02:57,246
SPEAKER_1:  and the quality of the product, it doesn't necessarily matter where you're selling.

02:02:57,858 --> 02:02:59,838
SPEAKER_0:  people who are financially incentivized to like

02:03:00,226 --> 02:03:00,894
SPEAKER_0:  Buy this thing.

02:03:01,474 --> 02:03:03,038
SPEAKER_1:  Yeah, and so you're...

02:03:03,970 --> 02:03:08,021
SPEAKER_1:  You're selling the dream of becoming rich to the people down in the pyramid.

02:03:08,021 --> 02:03:10,878
SPEAKER_0:  that's the real product of multi-level marketing. Unfortunately,

02:03:11,330 --> 02:03:14,622
SPEAKER_0:  And so you look at the statistics of these companies.

02:03:15,074 --> 02:03:18,526
SPEAKER_0:  and although they'll make it seem like it's so easy to be the top.

02:03:19,010 --> 02:03:21,086
SPEAKER_0:  you know, 0.1% who's making all this money.

02:03:21,378 --> 02:03:26,014
SPEAKER_0:  The statistics are that 97% make less than a minimum wage.

02:03:26,274 --> 02:03:28,446
SPEAKER_0:  doing this. They spend an enormous amount of time.

02:03:28,674 --> 02:03:32,094
SPEAKER_0:  And just what's so cruel about it is that's not advertised up front.

02:03:32,514 --> 02:03:35,038
SPEAKER_0:  I mean, it's like, if I go at work at McDonald's, I know what I'm getting.

02:03:35,394 --> 02:03:39,102
SPEAKER_0:  If I go work at Amway, I have visions of, they've sold me visions of...

02:03:39,426 --> 02:03:40,734
SPEAKER_0:  beaches and whatever and

02:03:40,994 --> 02:03:42,462
SPEAKER_0:  more than likely I'm losing money.

02:03:42,722 --> 02:03:47,390
SPEAKER_0:  So better than 50% of people lose money, but 97% of people make less than minimum wage. It's like-

02:03:47,810 --> 02:03:49,854
SPEAKER_0:  It's such a bad business.

02:03:50,306 --> 02:03:51,998
SPEAKER_0:  for the vast majority of people.

02:03:52,226 --> 02:03:52,894
SPEAKER_0:  who join it?

02:03:53,186 --> 02:03:53,534
SPEAKER_0:  and the

02:03:53,826 --> 02:03:54,750
SPEAKER_0:  people at the very top.

02:03:54,978 --> 02:03:58,046
SPEAKER_0:  who are lying to the people at the bottom saying they all can do it when they can't

02:03:58,786 --> 02:03:59,966
SPEAKER_0:  are making all the money. TIT Â° TITTO

02:04:00,258 --> 02:04:01,383
SPEAKER_0:  It's yeah, it's really messed up.

02:04:01,383 --> 02:04:10,334
SPEAKER_1:  And the interesting thing I've noticed, maybe myself too, because I've participated in the knife selling for like a short amount of time. That's probably the experience that most people have. Cutco, is it?

02:04:11,330 --> 02:04:13,214
SPEAKER_1:  I don't know, I don't think it was quite good.

02:04:13,538 --> 02:04:14,430
SPEAKER_0:  I know what you're talking about.

02:04:14,562 --> 02:04:19,230
SPEAKER_1:  But I think there's several variations of it. I think I was part of a

02:04:20,482 --> 02:04:21,854
SPEAKER_1:  uh... let less popular one

02:04:22,242 --> 02:04:22,750
SPEAKER_1:  It doesn't.

02:04:23,202 --> 02:04:25,886
SPEAKER_1:  I keep wanting to say it was called vector. yup

02:04:26,530 --> 02:04:34,957
SPEAKER_0:  Yes, something with a V was what I was gonna say. It might be Vector. Yeah, I get what you're saying though. It's a multi-level marketing knife selling.

02:04:34,957 --> 02:04:36,702
SPEAKER_1:  The thing is, I just remember...

02:04:37,154 --> 02:04:38,910
SPEAKER_1:  my own small experience with it.

02:04:39,330 --> 02:04:42,334
SPEAKER_1:  I was too embarrassed at myself for having like...

02:04:42,818 --> 02:04:43,614
SPEAKER_1:  Participate it.

02:04:44,578 --> 02:04:49,470
SPEAKER_1:  I think there's an embarrassment. That's why people down in the pyramid don't like.

02:04:49,954 --> 02:04:50,910
SPEAKER_1:  Speak about it, right?

02:04:51,458 --> 02:04:52,638
SPEAKER_1:  that your part like.

02:04:52,866 --> 02:04:53,310
SPEAKER_1:  I don't...

02:04:53,602 --> 02:04:56,734
SPEAKER_1:  I'm trying to understand the aspects of human nature that facilitate this.

02:04:57,026 --> 02:05:01,118
SPEAKER_0:  Well, this is one of the problems with fraud is there's a tremendous embarrassment to being had.

02:05:01,890 --> 02:05:03,486
SPEAKER_0:  Also, if you buy, so.

02:05:03,746 --> 02:05:07,998
SPEAKER_0:  slightly different human nature is that if you buy into a get rich quick scheme

02:05:08,322 --> 02:05:11,678
SPEAKER_0:  and then it doesn't deliver, you're more likely to blame yourself.

02:05:11,970 --> 02:05:24,926
SPEAKER_0:  than blame the product for not actually working. You go, well, there must be something flawed with me. That's true, yes, exactly. And they constantly reinforce this. They go, well, it's all about your hard work. The system works, look at me, I did it. So if you're failing, it must be some indictment of your character.

02:05:25,186 --> 02:05:29,662
SPEAKER_0:  and you have to always double down. The system can't be flawed, you must be flawed.

02:05:30,114 --> 02:05:31,166
SPEAKER_0:  And so yeah, it's.

02:05:31,650 --> 02:05:36,830
SPEAKER_0:  It's a really messed up system. It really preys on people's psychology to keep them in this loop.

02:05:37,250 --> 02:05:43,038
SPEAKER_0:  And that's why in some ways these things are so viral, even though they don't actually get most people a significant amount of wealth.

02:05:43,330 --> 02:05:44,894
SPEAKER_0:  and they cost most people money. So,

02:05:45,282 --> 02:05:46,407
SPEAKER_0:  It's very unfortunate.

02:05:46,407 --> 02:05:48,798
SPEAKER_1:  Most people do have the dream of becoming rich.

02:05:49,058 --> 02:05:49,982
SPEAKER_1:  most young people.

02:05:50,594 --> 02:05:51,134
SPEAKER_0:  Right, and-

02:05:51,426 --> 02:05:53,694
SPEAKER_0:  The thing is that everyone knows in business.

02:05:53,986 --> 02:05:54,494
SPEAKER_0:  What do you?

02:05:54,914 --> 02:05:56,734
SPEAKER_0:  You sell. You sell solutions to problems.

02:05:57,282 --> 02:05:59,166
SPEAKER_0:  of so many young people want to get rich.

02:05:59,746 --> 02:06:00,702
SPEAKER_0:  The product is.

02:06:01,442 --> 02:06:03,422
SPEAKER_0:  It's you sell them the dream.

02:06:04,098 --> 02:06:06,590
SPEAKER_0:  why this gets so grifty and so-

02:06:06,882 --> 02:06:08,318
SPEAKER_0:  cruel and predatory.

02:06:08,578 --> 02:06:13,182
SPEAKER_0:  is because there is no easy solution to this. There is no solution that people are going to buy.

02:06:13,538 --> 02:06:15,710
SPEAKER_0:  Because the real solution people want is...

02:06:16,002 --> 02:06:18,814
SPEAKER_0:  No work, no education, no skills required.

02:06:19,330 --> 02:06:20,734
SPEAKER_0:  No money upfront.

02:06:21,218 --> 02:06:21,630
SPEAKER_0:  and

02:06:22,338 --> 02:06:24,510
SPEAKER_0:  People will pay any price for that magic pill.

02:06:24,802 --> 02:06:26,782
SPEAKER_0:  and people are happy to sell that magic pill.

02:06:27,490 --> 02:06:29,822
SPEAKER_0:  And I think those people are very cruel.

02:06:30,082 --> 02:06:31,957
SPEAKER_0:  and I think deserve to get exposed.

02:06:31,957 --> 02:06:32,670
SPEAKER_1:  posed for it.

02:06:33,218 --> 02:06:34,558
SPEAKER_1:  So somebody...

02:06:35,010 --> 02:06:36,670
SPEAKER_1:  that's been criticized for.

02:06:37,090 --> 02:06:39,742
SPEAKER_1:  MLM type schemes is Andrew Tate.

02:06:40,322 --> 02:06:41,406
SPEAKER_1:  Yeah, somebody that I'm.

02:06:42,274 --> 02:06:43,038
SPEAKER_1:  very likely to.

02:06:43,330 --> 02:06:44,862
SPEAKER_1:  talk with people who have been.

02:06:46,050 --> 02:06:49,854
SPEAKER_1:  telling me that I'm too afraid to talk to Andrew Tate. First, let me just say...

02:06:50,466 --> 02:06:51,070
SPEAKER_1:  I'm not a f-

02:06:52,098 --> 02:06:53,950
SPEAKER_1:  afraid to talk to anyone.

02:06:54,562 --> 02:06:59,070
SPEAKER_1:  It's just that certain people require preparation and you have to allocate.

02:07:00,002 --> 02:07:05,342
SPEAKER_1:  your life in such a way that you want to prepare properly for them. Sure. And you have to kind of think.

02:07:05,602 --> 02:07:06,174
SPEAKER_1:  Um...

02:07:06,690 --> 02:07:11,102
SPEAKER_1:  who you want to prepare for because I have other folks that have more power.

02:07:11,618 --> 02:07:15,646
SPEAKER_1:  than this particular figure that I'm preparing for. So you have to make sure you, uh...

02:07:15,906 --> 02:07:16,926
SPEAKER_1:  allocate your time.

02:07:17,378 --> 02:07:20,382
SPEAKER_1:  wisely but i do think he's a very influential person

02:07:21,090 --> 02:07:25,214
SPEAKER_1:  that raises questions of what it means to be a man in the 21st century.

02:07:25,954 --> 02:07:26,494
SPEAKER_1:  uh...

02:07:27,330 --> 02:07:29,886
SPEAKER_1:  And that's a very important and interesting question.

02:07:30,178 --> 02:07:31,326
SPEAKER_1:  because young people look up.

02:07:32,098 --> 02:07:35,486
SPEAKER_1:  to philosophers, to influencers about what it means to be a man.

02:07:36,194 --> 02:07:42,110
SPEAKER_1:  They look up to Jordan Peterson, they look up to Andrew Tate, they look up to others, to other figures. I think it's important to...

02:07:43,010 --> 02:07:47,486
SPEAKER_1:  Talk about that to think what does it mean to be a good man in the society?

02:07:48,002 --> 02:07:51,870
SPEAKER_1:  Of course, in the other gender, there's the same question. What does it mean to be a good woman?

02:07:52,130 --> 02:07:54,494
SPEAKER_1:  I think obviously the bigger question is what does it mean to

02:07:54,786 --> 02:07:55,262
SPEAKER_1:  be a good

02:07:55,554 --> 02:07:55,998
SPEAKER_1:  person.

02:07:56,706 --> 02:07:57,470
SPEAKER_1:  But...

02:08:00,322 --> 02:08:00,990
SPEAKER_1:  Um...

02:08:01,410 --> 02:08:01,886
SPEAKER_1:  Hehehe

02:08:02,658 --> 02:08:04,702
SPEAKER_1:  Uh, did now intro. Okay.

02:08:06,082 --> 02:08:13,886
SPEAKER_1:  Uh, so on that said, one aspect of the criticism that Andrew's received is not just on massaging.

02:08:14,690 --> 02:08:16,350
SPEAKER_1:  is on the MLM aspect.

02:08:16,674 --> 02:08:18,110
SPEAKER_1:  of the multi-

02:08:18,434 --> 02:08:23,710
SPEAKER_1:  level marketing schemes. So is there some truth to that? Is there some fraudulent aspect to that?

02:08:24,834 --> 02:08:28,158
SPEAKER_0:  Yeah, I definitely think so. I mean, that's the main reason I criticized him.

02:08:28,898 --> 02:08:29,534
SPEAKER_0:  Um...

02:08:30,786 --> 02:08:31,198
SPEAKER_0:  So.

02:08:31,810 --> 02:08:32,478
SPEAKER_0:  Let's back up.

02:08:32,706 --> 02:08:34,206
SPEAKER_0:  there's a few clarifications I need to make.

02:08:34,594 --> 02:08:36,350
SPEAKER_0:  What Andrew Tate is selling is not.

02:08:36,738 --> 02:08:38,974
SPEAKER_0:  multi-level marketing, although he is selling the dream.

02:08:39,330 --> 02:08:42,110
SPEAKER_0:  he's selling an affiliate marketing thing, which is slightly different.

02:08:42,530 --> 02:08:42,974
SPEAKER_0:  So.

02:08:43,618 --> 02:08:50,078
SPEAKER_0:  In multi-level marketing, if I sell to you and then you go sell to two other people, I make money from those two other people down the chain. Multi-level.

02:08:50,402 --> 02:08:53,118
SPEAKER_0:  Affiliate marketing is sort of like one level. I only make-

02:08:53,378 --> 02:08:53,854
SPEAKER_0:  Money.

02:08:54,082 --> 02:08:58,302
SPEAKER_0:  So Andrew Tate had this affiliate program where, if you sold Hustlers University,

02:08:58,722 --> 02:08:59,902
SPEAKER_0:  to somebody else.

02:09:00,226 --> 02:09:06,439
SPEAKER_0:  which sounds like something people would, boomers would put on Facebook in like 2010, like I went to Hustlers University. School of Hardbite.

02:09:06,439 --> 02:09:07,422
SPEAKER_1:  By the way, you...

02:09:08,034 --> 02:09:09,159
SPEAKER_1:  Or hunterjobs.

02:09:09,159 --> 02:09:13,694
SPEAKER_0:  Yeah, I joined. I became a hustler. That's in large part due to my...

02:09:13,986 --> 02:09:16,990
SPEAKER_0:  Why I'm so successful is because of my Hustler University membership.

02:09:17,378 --> 02:09:18,878
SPEAKER_0:  I'm just kidding. Um, but-

02:09:19,298 --> 02:09:26,430
SPEAKER_0:  So it's an affiliate program. So you'd sell, like I sell to you this $50 course and I make like $5 and Andrew Tate.

02:09:26,658 --> 02:09:28,734
SPEAKER_0:  in perpetuity makes $50 a month off of you.

02:09:30,306 --> 02:09:35,742
SPEAKER_0:  What does this course actually sell, right? Because ultimately he's selling the dream. He's selling, hey,

02:09:35,970 --> 02:09:39,710
SPEAKER_0:  The Matrix has enslaved you. He's really gone down this like neo rabbit hole.

02:09:40,002 --> 02:09:42,014
SPEAKER_0:  Um, so the matrix has enslaved you.

02:09:42,274 --> 02:09:46,334
SPEAKER_0:  Your life is controlled by these people who want to keep you kind of weak.

02:09:46,754 --> 02:09:47,134
SPEAKER_0:  You know?

02:09:47,458 --> 02:09:50,526
SPEAKER_0:  lazy, whatever, you need a breakout and you need to achieve.

02:09:51,362 --> 02:09:53,086
SPEAKER_0:  the new dream which is sort of like.

02:09:53,378 --> 02:09:56,414
SPEAKER_0:  hustling your way to the top. You don't need the antiquated systems of.

02:09:56,674 --> 02:10:00,350
SPEAKER_0:  of school, you can just pay me $50 a month and I will teach you everything. Okay.

02:10:00,578 --> 02:10:01,342
SPEAKER_0:  So what do you actually get?

02:10:01,762 --> 02:10:10,206
SPEAKER_0:  Well, and why is it a scam? So you actually, I think it's just a scam in terms of like value and like you're selling based on these completely unrealistic things. Like let's get rich.

02:10:11,810 --> 02:10:13,950
SPEAKER_0:  Get a series of Discord rooms.

02:10:14,210 --> 02:10:18,334
SPEAKER_0:  You know what Discord, most people know what Discord is. It's like a bunch of chat rooms basically, right?

02:10:18,658 --> 02:10:20,533
SPEAKER_1:  So it's like AOL or is it like? Yeah, yeah.

02:10:20,533 --> 02:10:22,174
SPEAKER_0:  Right, right. Well, I'm talking to the guy who...

02:10:22,466 --> 02:10:24,318
SPEAKER_0:  to quit Emacs, so I don't know.

02:10:24,898 --> 02:10:28,190
SPEAKER_0:  There's Discord servers and in these, there's like seven.

02:10:28,802 --> 02:10:29,214
SPEAKER_0:  different.

02:10:29,602 --> 02:10:34,174
SPEAKER_0:  rooms you can go in, or there's several rooms, and each one is like a different field of making money.

02:10:35,106 --> 02:10:37,310
SPEAKER_0:  e-commerce, trading.

02:10:37,858 --> 02:10:39,102
SPEAKER_0:  cryptocurrency.

02:10:39,586 --> 02:10:40,190
SPEAKER_0:  Um...

02:10:40,930 --> 02:10:41,630
SPEAKER_0:  I think.

02:10:42,658 --> 02:10:44,286
SPEAKER_0:  fulfillment by Amazon.

02:10:45,058 --> 02:10:46,334
SPEAKER_0:  like copywriting.

02:10:47,458 --> 02:10:49,726
SPEAKER_0:  Okay, so I went to all of these, I checked them out.

02:10:50,018 --> 02:10:51,774
SPEAKER_0:  I checked all their money making tools.

02:10:52,162 --> 02:10:57,662
SPEAKER_0:  The first funny thing is that Andrew Tate is nowhere to be found. The supposed successful guy that you like bought into is nowhere to be found.

02:10:57,890 --> 02:10:59,102
SPEAKER_0:  It's these professors.

02:10:59,330 --> 02:11:03,742
SPEAKER_0:  that you have now, he has hired and said, these guys are super qualified.

02:11:04,482 --> 02:11:07,390
SPEAKER_0:  So like looked up some of what some of these guys have done.

02:11:07,906 --> 02:11:11,582
SPEAKER_0:  and some of them have launched like scammy crypto coins.

02:11:11,970 --> 02:11:18,270
SPEAKER_0:  the cryptocurrency professor was like shilling a bunch of coins that did bad and then like deleted the tweets I mean just completely

02:11:18,946 --> 02:11:20,382
SPEAKER_0:  exactly what you'd expect.

02:11:20,770 --> 02:11:24,862
SPEAKER_0:  behind the paywall, it's nothing of substance. you're not going to learn to get rich.

02:11:25,186 --> 02:11:33,022
SPEAKER_0:  by escaping the matrix and going to work for Jeff Bezos. Fulfillment by Amazon is not escaping the matrix, right? Like that's not the way to hustle to the top.

02:11:33,282 --> 02:11:37,950
SPEAKER_0:  It's literally a field of making money that everyone in the world has access to.

02:11:38,626 --> 02:11:41,822
SPEAKER_0:  If you want to differentiate yourself and make money, the first thing you realize is

02:11:42,114 --> 02:11:50,590
SPEAKER_0:  going into skill sets that literally anyone with an internet account can do is a bad way to do that because you have to have some differentiating factor to add value.

02:11:51,042 --> 02:11:51,422
SPEAKER_0:  So.

02:11:52,226 --> 02:11:53,150
SPEAKER_0:  It's just such a...

02:11:54,114 --> 02:11:56,030
SPEAKER_0:  obvious and complete.

02:11:56,386 --> 02:11:58,334
SPEAKER_0:  scam because there is no

02:11:58,754 --> 02:12:01,086
SPEAKER_0:  value to this so-called education.

02:12:01,410 --> 02:12:02,334
SPEAKER_0:  Professors are crap.

02:12:03,362 --> 02:12:09,054
SPEAKER_0:  the advice, they're like hiding some of the bad things they've done and Andretta tastes nowhere to be found. Ultimately, that's why everyone joins.

02:12:09,314 --> 02:12:11,134
SPEAKER_0:  What he's done is very interesting because

02:12:12,162 --> 02:12:13,854
SPEAKER_0:  and I'll give him credit in his marketing.

02:12:14,146 --> 02:12:15,262
SPEAKER_0:  He's been very savvy to like.

02:12:15,490 --> 02:12:17,278
SPEAKER_0:  Make the reasons you admire him.

02:12:17,698 --> 02:12:18,110
SPEAKER_0:  NOT

02:12:18,434 --> 02:12:19,934
SPEAKER_0:  the thing he's sort of selling.

02:12:20,162 --> 02:12:20,766
SPEAKER_0:  Which is weird.

02:12:21,602 --> 02:12:23,198
SPEAKER_0:  He's selling Get Rich Quick.

02:12:23,650 --> 02:12:24,062
SPEAKER_0:  which

02:12:24,514 --> 02:12:25,086
SPEAKER_0:  Teams.

02:12:25,314 --> 02:12:26,974
SPEAKER_0:  like it relates to his persona.

02:12:27,266 --> 02:12:28,926
SPEAKER_0:  but is actually very orthogonal to it.

02:12:29,506 --> 02:12:30,782
SPEAKER_0:  His persona is like...

02:12:31,010 --> 02:12:32,350
SPEAKER_0:  the tell it how it is.

02:12:34,210 --> 02:12:35,614
SPEAKER_0:  Paul Buff, Rich Guy.

02:12:36,098 --> 02:12:37,086
SPEAKER_0:  It's like actually.

02:12:37,538 --> 02:12:41,406
SPEAKER_0:  his persona that you're buying into, and then he's selling you this thing to the side.

02:12:41,730 --> 02:12:44,286
SPEAKER_0:  which when people get in there and they're not delivered on the product.

02:12:44,514 --> 02:12:49,566
SPEAKER_0:  he still is those things that you first thought he was. So it's like, I think it's, to some extent, he's made a lot of

02:12:50,466 --> 02:12:51,070
SPEAKER_0:  Money.

02:12:51,618 --> 02:12:53,406
SPEAKER_0:  by making the thing that he makes money on.

02:12:53,762 --> 02:12:54,942
SPEAKER_0:  not the thing he gets.

02:12:55,234 --> 02:12:58,110
SPEAKER_0:  so much pushback online for and what he's also loved for.

02:12:58,402 --> 02:13:01,982
SPEAKER_0:  So people will push back for his misogyny, but the real way he's making money is just like,

02:13:02,242 --> 02:13:06,942
SPEAKER_0:  basic get rich quick schemes that are super obvious to spot, but everyone's distracted by like

02:13:07,298 --> 02:13:10,142
SPEAKER_0:  Oh, he said some crazy stuff about women or, you know.

02:13:10,370 --> 02:13:12,670
SPEAKER_0:  all these various other scandals he's gotten himself in.

02:13:12,994 --> 02:13:14,622
SPEAKER_1:  to get more and more and more attention.

02:13:14,882 --> 02:13:16,798
SPEAKER_1:  So with the persona.

02:13:17,634 --> 02:13:19,998
SPEAKER_1:  Is the Hustler University still operating?

02:13:20,386 --> 02:13:22,910
SPEAKER_0:  I think they've rebranded it. I'm part of their pitch knob.

02:13:23,394 --> 02:13:24,766
SPEAKER_0:  I'm like, they put me on as like.

02:13:25,058 --> 02:13:25,726
SPEAKER_0:  I mean as like

02:13:25,986 --> 02:13:29,630
SPEAKER_0:  The Matrix is trying to take us out, Lex. And then it's me saying like...

02:13:29,858 --> 02:13:33,374
SPEAKER_0:  You know, they put me in like saying, I'm part of the matrix. They put me in saying. You know, they put me in saying.

02:13:33,762 --> 02:13:39,198
SPEAKER_0:  Oh, this guy sucks, you know, I joined, it sucks. And so they'll play that and they do like a bass drop and it's like...

02:13:39,522 --> 02:13:39,902
SPEAKER_0:  You know.

02:13:40,738 --> 02:13:44,863
SPEAKER_0:  don't listen to people like this, dah, dah, dah, dah. I mean, it's, I'm basically like an in-ear little. in co-op-

02:13:44,863 --> 02:13:46,718
SPEAKER_1:  the matrix to attack.

02:13:46,978 --> 02:13:50,462
SPEAKER_1:  Yes. You're an insider threat that infiltrated. Right?

02:13:50,786 --> 02:13:52,478
SPEAKER_1:  being used by the Matrix to attack him.

02:13:52,706 --> 02:13:55,902
SPEAKER_0:  Well, to- Everyone who criticizes him is part of the Matrix.

02:13:56,322 --> 02:13:58,206
SPEAKER_0:  He won't say who the Matrix is, it's just-

02:13:58,498 --> 02:14:01,790
SPEAKER_0:  It's just the shadowy cabal of rich, powerful people.

02:14:02,306 --> 02:14:05,886
SPEAKER_0:  It's just like the easy narrative for people who are disaffected and...

02:14:06,146 --> 02:14:07,902
SPEAKER_0:  who feel cheated by the system.

02:14:08,194 --> 02:14:11,166
SPEAKER_0:  You just collectivize that system and you make it the bad guy and you go, look, look.

02:14:11,394 --> 02:14:13,214
SPEAKER_0:  those guys, those guys who have been cheating you.

02:14:13,762 --> 02:14:15,326
SPEAKER_0:  They're the bad guys. They want-

02:14:15,618 --> 02:14:16,222
SPEAKER_0:  Me.

02:14:16,962 --> 02:14:17,342
SPEAKER_0:  Shut up.

02:14:18,114 --> 02:14:18,942
SPEAKER_0:  And then now...

02:14:19,170 --> 02:14:19,678
SPEAKER_0:  person that

02:14:20,194 --> 02:14:23,358
SPEAKER_0:  the people who harmed you, they want this guy shut up, you're gonna listen to him. Jan and Bill and I each asked them some questions.

02:14:23,874 --> 02:14:25,182
SPEAKER_0:  It's like the most basic.

02:14:25,890 --> 02:14:29,502
SPEAKER_0:  psychological manipulation that everyone seems to constantly fall for, it's

02:14:30,178 --> 02:14:30,622
SPEAKER_0:  Really, uh-

02:14:31,330 --> 02:14:32,606
SPEAKER_0:  trivial and stupid but-

02:14:32,962 --> 02:14:34,622
SPEAKER_1:  Can you still man?

02:14:35,458 --> 02:14:37,918
SPEAKER_1:  the case for Hustlers University where

02:14:38,178 --> 02:14:39,294
SPEAKER_1:  It's actually.

02:14:40,002 --> 02:14:42,494
SPEAKER_1:  giving young people confidence.

02:14:43,426 --> 02:14:52,222
SPEAKER_1:  teaching invaluable lessons about like actually incentivizing them to do something like fulfillment by Amazon the basic thing to try it sure to learn about it

02:14:52,674 --> 02:14:55,902
SPEAKER_1:  to fail or maybe see like, to try to give a...

02:14:56,322 --> 02:14:58,947
SPEAKER_1:  a catalyst and incentive to try these.

02:14:58,947 --> 02:15:01,470
SPEAKER_0:  As much as it pains me, I will try to give a uh...

02:15:02,146 --> 02:15:03,038
SPEAKER_0:  a succinct.

02:15:04,162 --> 02:15:04,958
SPEAKER_0:  Maybe Steel Man.

02:15:05,250 --> 02:15:05,566
SPEAKER_0:  of it.

02:15:06,178 --> 02:15:08,702
SPEAKER_0:  as best as I can thinking that it's such a greft.

02:15:09,154 --> 02:15:10,974
SPEAKER_0:  But I think what you would say.

02:15:11,522 --> 02:15:11,966
SPEAKER_0:  is that.

02:15:12,994 --> 02:15:14,142
SPEAKER_0:  Some people.

02:15:14,626 --> 02:15:17,214
SPEAKER_0:  in order to make a change in their life.

02:15:17,634 --> 02:15:18,974
SPEAKER_0:  Need A.

02:15:19,458 --> 02:15:20,958
SPEAKER_0:  someone who they can look up to.

02:15:21,666 --> 02:15:25,310
SPEAKER_0:  and men don't have a lot of like strong role models.

02:15:27,138 --> 02:15:28,926
SPEAKER_0:  big male presences in their life.

02:15:29,602 --> 02:15:31,678
SPEAKER_0:  who can serve as a proper example.

02:15:32,034 --> 02:15:34,558
SPEAKER_0:  So the most charitable interpretation would be.

02:15:34,818 --> 02:15:35,710
SPEAKER_0:  Andrew Tate.

02:15:37,058 --> 02:15:40,158
SPEAKER_0:  would encourage you to go reach for the stars, I guess.

02:15:40,770 --> 02:15:43,038
SPEAKER_0:  My problem is I have a deep, like...

02:15:43,650 --> 02:15:45,278
SPEAKER_0:  I have a deep issue with the like.

02:15:45,794 --> 02:15:47,134
SPEAKER_0:  Lust and

02:15:47,522 --> 02:15:51,966
SPEAKER_0:  greed that centers all these things. It's like this glorification of-

02:15:53,858 --> 02:15:59,294
SPEAKER_0:  Wealth equals status, wealth equals good person, wealth and Bugatti equals...

02:15:59,586 --> 02:16:01,982
SPEAKER_0:  You are meaningful, you matter.

02:16:02,306 --> 02:16:02,654
SPEAKER_0:  And like.

02:16:03,202 --> 02:16:03,582
SPEAKER_0:  Dark.

02:16:04,162 --> 02:16:05,534
SPEAKER_0:  underlying thing.

02:16:07,010 --> 02:16:07,518
SPEAKER_0:  is that.

02:16:07,746 --> 02:16:08,350
SPEAKER_0:  None of that.

02:16:08,610 --> 02:16:12,382
SPEAKER_0:  None of that matters. It matters that you make a decent living, but

02:16:12,738 --> 02:16:13,150
SPEAKER_0:  past.

02:16:13,602 --> 02:16:14,398
SPEAKER_0:  Just like that.

02:16:14,722 --> 02:16:20,862
SPEAKER_0:  I think the lust for more stuff and the idolization of these people that is just like opulence.

02:16:21,186 --> 02:16:22,686
SPEAKER_0:  Is Annette bad?

02:16:23,170 --> 02:16:28,414
SPEAKER_0:  So that's like, my steel man has to stop there because I really disagree with like the values that are pushed.

02:16:29,218 --> 02:16:30,343
SPEAKER_0:  people like that.

02:16:30,343 --> 02:16:34,878
SPEAKER_1:  Yeah, no, I agree that that's the thing that should be criticized. I shouldn't say it doesn't matter

02:16:35,202 --> 02:16:37,982
SPEAKER_1:  I think it's just like an amazing meal.

02:16:38,466 --> 02:16:41,342
SPEAKER_1:  at a great restaurant that matters. It's money.

02:16:41,634 --> 02:16:42,718
SPEAKER_1:  and Bugatti's.

02:16:43,170 --> 02:16:45,022
SPEAKER_1:  for many people make life.

02:16:45,282 --> 02:16:48,030
SPEAKER_1:  Beautiful like those are all components, but I think.

02:16:48,354 --> 02:16:53,118
SPEAKER_1:  money isn't the you can also enjoy a beautiful life on a hike in nature you can

02:16:53,538 --> 02:16:55,678
SPEAKER_1:  There's a lot of ways to enjoy life.

02:16:55,970 --> 02:16:56,414
SPEAKER_1:  and

02:16:56,674 --> 02:17:04,414
SPEAKER_1:  One of the deepest has been tested through time is the intimacy, close connection, friendship with other people or with a loved one. They don't talk about like.

02:17:04,866 --> 02:17:05,438
SPEAKER_1:  Love.

02:17:05,922 --> 02:17:08,894
SPEAKER_1:  Yeah, what it means to be deeply connected with another person.

02:17:09,122 --> 02:17:09,694
SPEAKER_1:  It's just like.

02:17:09,986 --> 02:17:10,750
SPEAKER_1:  Get women.

02:17:11,010 --> 02:17:13,086
SPEAKER_1:  get money, all those kinds of things.

02:17:13,346 --> 02:17:18,046
SPEAKER_1:  But that, I think, I don't wanna dismiss that because there's value in that, there's fun in that.

02:17:18,530 --> 02:17:20,190
SPEAKER_1:  I think the positive.

02:17:20,738 --> 02:17:21,534
SPEAKER_1:  I don't, I haven't.

02:17:21,826 --> 02:17:23,966
SPEAKER_1:  investigated at Huston University. But

02:17:24,674 --> 02:17:26,014
SPEAKER_1:  The positive I see.

02:17:26,242 --> 02:17:28,030
SPEAKER_1:  in general as young people.

02:17:29,122 --> 02:17:29,726
SPEAKER_1:  Don't get...

02:17:30,082 --> 02:17:31,550
SPEAKER_1:  Much respect from society.

02:17:32,194 --> 02:17:34,302
SPEAKER_1:  I know it's easy to call it the matrix and so on, but...

02:17:34,882 --> 02:17:36,190
SPEAKER_1:  there's a kind of a

02:17:36,546 --> 02:17:37,342
SPEAKER_1:  Dismissal.

02:17:38,466 --> 02:17:43,742
SPEAKER_1:  of them as human beings, as capable of contributing, of doing anything special.

02:17:44,002 --> 02:17:47,006
SPEAKER_1:  And then here you have young people sitting there broke.

02:17:47,810 --> 02:17:49,726
SPEAKER_1:  Um, with big dreams.

02:17:50,146 --> 02:17:53,054
SPEAKER_1:  They need the mentors. They need somebody to inspire them. So like.

02:17:53,826 --> 02:17:54,302
SPEAKER_1:  Um...

02:17:54,530 --> 02:18:00,830
SPEAKER_1:  I would criticize the flawed nature of the message, but also it's just like, you have to realize like there needs to be.

02:18:01,378 --> 02:18:02,558
SPEAKER_1:  institutions.

02:18:02,786 --> 02:18:05,566
SPEAKER_1:  or people or influencers that help.

02:18:06,306 --> 02:18:07,431
SPEAKER_1:  Inspire, right?

02:18:07,431 --> 02:18:10,718
SPEAKER_0:  The problem is though, is the people who are pitching

02:18:11,106 --> 02:18:12,734
SPEAKER_0:  unrealistic versions of that.

02:18:13,538 --> 02:18:15,294
SPEAKER_0:  are getting a lot of attention.

02:18:15,650 --> 02:18:16,190
SPEAKER_0:  Where it's like...

02:18:16,482 --> 02:18:20,254
SPEAKER_0:  There's so many great free courses where you can learn everything and more.

02:18:20,514 --> 02:18:20,862
SPEAKER_0:  about.

02:18:22,786 --> 02:18:24,478
SPEAKER_0:  Filmin by Amazon or about.

02:18:24,866 --> 02:18:27,166
SPEAKER_0:  copywriting or all these different things.

02:18:27,618 --> 02:18:31,102
SPEAKER_0:  that I think like so often the air is just, the oxygen is sucked up.

02:18:31,522 --> 02:18:34,878
SPEAKER_0:  by all the grifters who promise everything. It's back to what we said about vapor wear.

02:18:35,202 --> 02:18:37,566
SPEAKER_0:  This is one of the reasons that

02:18:38,082 --> 02:18:38,590
SPEAKER_0:  uh...

02:18:38,978 --> 02:18:40,542
SPEAKER_0:  like educational products.

02:18:40,834 --> 02:18:42,846
SPEAKER_0:  can so often be co-opted by grifters.

02:18:43,266 --> 02:18:45,822
SPEAKER_0:  Is vaporware is very hard to distinguish?

02:18:46,306 --> 02:18:46,910
SPEAKER_0:  because...

02:18:48,706 --> 02:18:49,214
SPEAKER_0:  prompt like

02:18:49,442 --> 02:18:51,486
SPEAKER_0:  The feedback loop on education is not clear.

02:18:52,066 --> 02:18:55,230
SPEAKER_0:  It's not obvious immediately. So I can sell you a book.

02:18:55,618 --> 02:18:58,078
SPEAKER_0:  And I can say this is gonna change your life if you apply it.

02:18:58,658 --> 02:19:07,678
SPEAKER_0:  If you don't, if your life doesn't change, I just say, well, you didn't apply it, right? Like it's, it's, there's this weird relationship. It's not clear the value. It's not so easy to like quantify education.

02:19:07,970 --> 02:19:11,454
SPEAKER_0:  So that gets co-opted by people who make all the promises.

02:19:12,290 --> 02:19:15,230
SPEAKER_0:  They get a ton of attention, a ton of money, and then those

02:19:15,490 --> 02:19:16,894
SPEAKER_0:  People are often left.

02:19:17,282 --> 02:19:18,814
SPEAKER_0:  left confused and like.

02:19:19,522 --> 02:19:19,870
SPEAKER_0:  Kind of.

02:19:20,290 --> 02:19:22,558
SPEAKER_0:  disillusioned maybe thinking, well, this didn't work.

02:19:22,914 --> 02:19:24,862
SPEAKER_0:  in one year, so it's not gonna work at all.

02:19:25,218 --> 02:19:27,198
SPEAKER_0:  Um, and so I think, yeah, they're

02:19:27,714 --> 02:19:33,534
SPEAKER_0:  There are problems there. There's certainly a need for like male role models. There's certainly a need for somebody kind of.

02:19:33,858 --> 02:19:35,134
SPEAKER_0:  to speak to.

02:19:35,362 --> 02:19:36,446
SPEAKER_0:  a younger generation.

02:19:36,866 --> 02:19:37,758
SPEAKER_0:  I just think.

02:19:38,114 --> 02:19:39,230
SPEAKER_0:  that person shouldn't.

02:19:40,642 --> 02:19:42,517
SPEAKER_0:  shouldn't be maybe Andrew Tate, like personally.

02:19:42,517 --> 02:19:46,014
SPEAKER_1:  Yeah, so you have to criticize those particular individuals.

02:19:46,594 --> 02:19:50,814
SPEAKER_0:  I also- And yeah, I think the Bugatti aspiration is so stupid.

02:19:51,170 --> 02:19:56,638
SPEAKER_1:  Like it's like, it's so... Let me steal man. So I'm a person who doesn't care about money, don't like money.

02:19:56,898 --> 02:19:57,502
SPEAKER_1:  Um

02:19:57,826 --> 02:19:58,302
SPEAKER_1:  The women.

02:19:58,690 --> 02:20:04,158
SPEAKER_1:  maybe I appreciate the beauty of the other sex, but like.

02:20:05,250 --> 02:20:10,974
SPEAKER_1:  Cars in particular is like, really, is this really the manifestation of all the highest accomplishments?

02:20:11,202 --> 02:20:13,630
SPEAKER_1:  A human being can have a life. Yes, I can criticize all that.

02:20:14,210 --> 02:20:14,654
SPEAKER_1:  But...

02:20:15,170 --> 02:20:17,502
SPEAKER_1:  The to steel man that case is um...

02:20:19,650 --> 02:20:20,766
SPEAKER_1:  A young person.

02:20:21,346 --> 02:20:22,078
SPEAKER_1:  A dreamer.

02:20:22,338 --> 02:20:23,198
SPEAKER_1:  has ambition.

02:20:23,618 --> 02:20:27,134
SPEAKER_1:  And I often find that education throughout my whole life.

02:20:27,522 --> 02:20:28,798
SPEAKER_1:  There's been people who love me.

02:20:29,122 --> 02:20:29,822
SPEAKER_1:  teachers.

02:20:30,370 --> 02:20:32,062
SPEAKER_1:  who saw ambition in me.

02:20:32,674 --> 02:20:34,462
SPEAKER_1:  and try to reason with me.

02:20:34,754 --> 02:20:36,574
SPEAKER_1:  that my ambition is not justified.

02:20:36,994 --> 02:20:38,142
SPEAKER_1:  Looking at the data.

02:20:38,370 --> 02:20:39,230
SPEAKER_1:  Look, kid.

02:20:39,746 --> 02:20:45,598
SPEAKER_1:  You're not that special. Yeah. Look at the data. Right. You're not, and they, they want it. Do they want you to like.

02:20:46,242 --> 02:20:47,838
SPEAKER_1:  Not dream, essentially.

02:20:48,226 --> 02:20:51,230
SPEAKER_1:  And then again, I look at the data, which is.

02:20:52,098 --> 02:20:54,174
SPEAKER_1:  All the people, I just talked to Hajar Gracie.

02:20:54,882 --> 02:20:56,926
SPEAKER_1:  Hodge of Gracie is just a person.

02:20:57,346 --> 02:20:58,302
SPEAKER_1:  widely acknowledges.

02:20:58,594 --> 02:21:00,094
SPEAKER_1:  probably the greatest of all time.

02:21:00,706 --> 02:21:04,158
SPEAKER_1:  dominated everybody, but for the longest time he sucked.

02:21:05,378 --> 02:21:08,638
SPEAKER_1:  And he's so he was surrounded by people that kind of, you know, don't.

02:21:09,026 --> 02:21:12,766
SPEAKER_1:  don't necessarily believe in him, you have to believe in himself.

02:21:13,186 --> 02:21:17,502
SPEAKER_1:  It's nice to have somebody I just as older I get and I've seen it.

02:21:17,858 --> 02:21:20,382
SPEAKER_1:  It's so powerful to have somebody who comes to you.

02:21:20,898 --> 02:21:21,854
SPEAKER_1:  an older person.

02:21:22,626 --> 02:21:26,814
SPEAKER_1:  whether it's real or not, that says you got this kid. I believe in you.

02:21:26,914 --> 02:21:27,486
SPEAKER_0:  Sure.

02:21:28,578 --> 02:21:29,662
SPEAKER_0:  Yeah it does, I mean

02:21:30,978 --> 02:21:31,614
SPEAKER_0:  I think.

02:21:31,874 --> 02:21:32,222
SPEAKER_0:  So.

02:21:33,602 --> 02:21:34,942
SPEAKER_0:  I think dreaming is actually-

02:21:35,362 --> 02:21:36,542
SPEAKER_0:  really important?

02:21:38,018 --> 02:21:40,190
SPEAKER_0:  I'm more protective over...

02:21:40,610 --> 02:21:48,030
SPEAKER_0:  people co-op those dreams for money. Yes, yes, absolutely. And like, I do think it matters so much that we encourage people to take risks.

02:21:48,322 --> 02:21:53,630
SPEAKER_0:  That's one of the great things about America is it lionizes like sort of people who have taken risks in one.

02:21:54,722 --> 02:21:55,262
SPEAKER_0:  But...

02:21:56,098 --> 02:21:58,142
SPEAKER_0:  I think it's just a weird.

02:21:59,330 --> 02:22:02,142
SPEAKER_0:  vapid thing when like the reason you do all of it

02:22:02,434 --> 02:22:08,990
SPEAKER_0:  is for this thing you can get out at the end of the day. When we all know, and you've just heard a million interviews, like nobody ever is.

02:22:09,314 --> 02:22:12,766
SPEAKER_0:  gets the Bugatti and goes, this now completely fulfills me. Everyone knows.

02:22:13,026 --> 02:22:16,958
SPEAKER_0:  the beauty and the fulfillment actually comes from.

02:22:17,250 --> 02:22:22,462
SPEAKER_0:  becoming obsessed about what you're doing for its own sake, sort of the journey, the beauty of that thing.

02:22:23,010 --> 02:22:23,550
SPEAKER_0:  um...

02:22:23,842 --> 02:22:24,478
SPEAKER_0:  And I think.

02:22:25,026 --> 02:22:27,454
SPEAKER_0:  Money's just this thing we have to deal with.

02:22:28,066 --> 02:22:30,366
SPEAKER_0:  to be able to do cool stuff.

02:22:30,722 --> 02:22:32,222
SPEAKER_0:  I acknowledge that, you know.

02:22:32,866 --> 02:22:39,230
SPEAKER_0:  you need money to build the $10 million studio. Like you gotta get the cameras, you gotta get the lights, and I'm very blessed to be able to have gotten that.

02:22:40,802 --> 02:22:44,286
SPEAKER_0:  past a certain point, like I think that is really the function of money is to just

02:22:44,674 --> 02:22:45,662
SPEAKER_0:  Do cool stuff.

02:22:46,050 --> 02:22:47,454
SPEAKER_0:  But ultimately, if you can't...

02:22:48,450 --> 02:22:51,454
SPEAKER_0:  fall in love with the process and like the craft itself.

02:22:51,682 --> 02:22:52,446
SPEAKER_0:  You will be left.

02:22:52,738 --> 02:22:54,238
SPEAKER_0:  very unhappy at the end of it.

02:22:55,298 --> 02:22:57,758
SPEAKER_0:  And so to start people off on that journey.

02:22:58,466 --> 02:23:01,886
SPEAKER_0:  by pointing to the shiny object and going like, that's what you should care about.

02:23:02,402 --> 02:23:06,526
SPEAKER_0:  seems to me so backwards, we should learn from the actual people who have done it and said

02:23:06,786 --> 02:23:08,382
SPEAKER_0:  That shiny thing did nothing for me.

02:23:09,314 --> 02:23:12,222
SPEAKER_0:  Learn to love the journey and like, that's the thing we pitch people.

02:23:12,674 --> 02:23:14,430
SPEAKER_0:  as unsexy as that might be.

02:23:14,850 --> 02:23:19,966
SPEAKER_1:  Yeah, absolutely. That that's what's in the same applies to like the Red Pill community that talks about dating and so on.

02:23:20,418 --> 02:23:21,694
SPEAKER_1:  that there is a...

02:23:22,530 --> 02:23:24,990
SPEAKER_1:  It's not just about the number of hot women.

02:23:25,954 --> 02:23:26,846
SPEAKER_1:  you go to bed with.

02:23:27,202 --> 02:23:30,590
SPEAKER_1:  It's also about intimacy and love and all those kinds of things. And so like distinct and it's like we forcibly

02:23:31,010 --> 02:23:32,414
SPEAKER_1:  There is...

02:23:32,930 --> 02:23:35,070
SPEAKER_1:  components to a fulfilling life.

02:23:36,066 --> 02:23:36,894
SPEAKER_1:  that uh...

02:23:37,538 --> 02:23:38,398
SPEAKER_1:  is important to.

02:23:38,786 --> 02:23:39,198
SPEAKER_1:  to the

02:23:39,490 --> 02:23:44,990
SPEAKER_1:  educate young people about. Totally. But at the same time, feeding the dream the same take big risks.

02:23:45,474 --> 02:23:46,238
SPEAKER_1:  and you.

02:23:46,626 --> 02:23:47,646
SPEAKER_1:  The little you.

02:23:48,034 --> 02:23:50,270
SPEAKER_1:  that has no evidence of ever being great.

02:23:50,850 --> 02:23:53,886
SPEAKER_1:  can be great because there's evidence time and time again.

02:23:54,210 --> 02:23:57,982
SPEAKER_1:  of people that come from very humble beginnings and doing incredible things that change the world.

02:23:58,274 --> 02:23:59,998
SPEAKER_0:  Yeah, and there's just a tremendous like...

02:24:00,546 --> 02:24:02,846
SPEAKER_0:  funny thing where you can't become great.

02:24:03,234 --> 02:24:06,174
SPEAKER_0:  without having a willful denial of the statistics.

02:24:06,498 --> 02:24:10,494
SPEAKER_0:  Like in some ways you have to take the chance, even if that chance is so improbable.

02:24:10,946 --> 02:24:13,758
SPEAKER_0:  And it's always those people who did take that chance to end up winning some.

02:24:15,330 --> 02:24:17,950
SPEAKER_1:  Probably SBF and FTX is.

02:24:18,626 --> 02:24:21,886
SPEAKER_1:  the biggest thing you've ever covered. But previously-

02:24:22,178 --> 02:24:24,606
SPEAKER_1:  You've called the Save the Kids scam the world's.

02:24:24,898 --> 02:24:29,630
SPEAKER_1:  Influencers scam that like the the the the biggest in the world and forces scam you've ever seen

02:24:29,986 --> 02:24:31,038
SPEAKER_1:  Can you describe it?

02:24:31,810 --> 02:24:34,398
SPEAKER_0:  Sure, so Save the Kids was a charity coin.

02:24:34,722 --> 02:24:36,286
SPEAKER_0:  that was launched by...

02:24:36,898 --> 02:24:42,494
SPEAKER_0:  a number of extremely popular influencers. I think they had over 50 million followers together.

02:24:43,362 --> 02:24:47,614
SPEAKER_0:  huge names and they basically said, hey guys, invest in this coin. We're going to save the kids.

02:24:48,674 --> 02:24:50,238
SPEAKER_0:  A portion of the proceeds go to charity.

02:24:51,234 --> 02:24:55,838
SPEAKER_0:  And this coin, it's unruggable. So, rugging is the term.

02:24:56,258 --> 02:25:00,030
SPEAKER_0:  Remember earlier we talked about Safemoon, you just grab the pool of funds in the middle, you take them out.

02:25:01,218 --> 02:25:04,062
SPEAKER_0:  It's unrockable because we have this smart code.

02:25:04,610 --> 02:25:05,886
SPEAKER_0:  that is gonna prevent.

02:25:06,754 --> 02:25:09,790
SPEAKER_0:  people who are quote whales, which is a crypto term.

02:25:10,242 --> 02:25:12,702
SPEAKER_0:  for saying you have a large portion of the tokens.

02:25:13,410 --> 02:25:15,710
SPEAKER_0:  It'll prevent those people from selling a large amount of that.

02:25:16,034 --> 02:25:16,734
SPEAKER_0:  at one time.

02:25:18,082 --> 02:25:20,926
SPEAKER_0:  And so basically you don't have to worry about trusting us.

02:25:21,154 --> 02:25:22,430
SPEAKER_0:  It just is what it is.

02:25:23,106 --> 02:25:24,158
SPEAKER_0:  Join and we will.

02:25:24,450 --> 02:25:24,862
SPEAKER_0:  You know?

02:25:25,442 --> 02:25:26,718
SPEAKER_0:  change the world, save the kids, whatever.

02:25:27,298 --> 02:25:30,622
SPEAKER_0:  It was really skeezy from the beginning and sketchy because

02:25:31,234 --> 02:25:35,806
SPEAKER_0:  Their logo matched the Save the Children logo, which is like an actual charity that, you know.

02:25:36,226 --> 02:25:38,430
SPEAKER_0:  So they basically copied it and said, We're saving the kids.

02:25:38,882 --> 02:25:40,510
SPEAKER_0:  Um, like a knockoff brand.

02:25:40,770 --> 02:25:42,718
SPEAKER_0:  and almost immediately the project rugs.

02:25:42,978 --> 02:25:44,062
SPEAKER_0:  They stole the money.

02:25:44,642 --> 02:25:46,526
SPEAKER_0:  and tracing back through.

02:25:47,330 --> 02:25:51,262
SPEAKER_0:  The code was changed at the last second before launch.

02:25:51,522 --> 02:25:54,078
SPEAKER_0:  Like if you looked at their code that they launched as a test.

02:25:54,466 --> 02:25:59,998
SPEAKER_0:  versus the code they launched in actuality, they changed only like two lines and it was the whale code.

02:26:00,418 --> 02:26:04,670
SPEAKER_0:  basically make the whale code non-existent. Like you can sell as much as you want, as fast as you want.

02:26:05,250 --> 02:26:05,758
SPEAKER_0:  Um

02:26:05,986 --> 02:26:09,150
SPEAKER_0:  And it turned out that some of the influencers had not only...

02:26:09,794 --> 02:26:10,334
SPEAKER_0:  Sold.

02:26:10,594 --> 02:26:12,606
SPEAKER_0:  that and made money, but also...

02:26:12,834 --> 02:26:15,486
SPEAKER_0:  had a pattern of pump and dumping tokens.

02:26:15,714 --> 02:26:17,886
SPEAKER_0:  So we can talk about what that is. Yeah, what's pumping up?

02:26:18,434 --> 02:26:21,950
SPEAKER_0:  A pump and dump is just where you have a huge following.

02:26:22,370 --> 02:26:25,054
SPEAKER_0:  you promote your little Lex coin to everybody.

02:26:25,314 --> 02:26:29,598
SPEAKER_0:  while holding a big portion of it. And as everyone rushes in to buy it, the price is going to pump.

02:26:30,402 --> 02:26:32,190
SPEAKER_0:  and you dump at the same time.

02:26:32,482 --> 02:26:34,366
SPEAKER_0:  So that's where the name comes from, Pump and Dump.

02:26:34,754 --> 02:26:37,822
SPEAKER_0:  You pump the price, sell all your tokens, make a lot of money.

02:26:38,146 --> 02:26:38,654
SPEAKER_0:  So.

02:26:39,010 --> 02:26:42,014
SPEAKER_0:  I traced basically their wallets on the blockchain and found that

02:26:42,690 --> 02:26:46,270
SPEAKER_0:  Two of the actors specifically had had a long history of doing this.

02:26:46,722 --> 02:26:47,294
SPEAKER_0:  Um...

02:26:48,098 --> 02:26:51,294
SPEAKER_0:  which really proved malicious intent, and why I called it the worst is not-

02:26:51,554 --> 02:26:54,622
SPEAKER_0:  It certainly wasn't the worst in terms of like the amount of people affected.

02:26:54,946 --> 02:26:58,174
SPEAKER_0:  it relatively was like a small pump and dump.

02:26:58,786 --> 02:26:59,838
SPEAKER_0:  rugged almost immediately.

02:27:00,962 --> 02:27:02,462
SPEAKER_0:  but in terms of the amount of...

02:27:02,786 --> 02:27:04,254
SPEAKER_0:  people that were involved in it.

02:27:04,578 --> 02:27:10,590
SPEAKER_0:  in terms of the amount of malicious behavior before it that like sort of proved that this wasn't an accident.

02:27:10,882 --> 02:27:15,486
SPEAKER_0:  The fact that there was like this whale code, it was one of the most cynical attempts to just take.

02:27:16,194 --> 02:27:18,110
SPEAKER_0:  the money of the followers you had and just like.

02:27:18,946 --> 02:27:19,518
SPEAKER_0:  That's mine now.

02:27:19,938 --> 02:27:21,374
SPEAKER_0:  So that's why I.

02:27:21,698 --> 02:27:22,942
SPEAKER_0:  But that's to save the kids.

02:27:23,202 --> 02:27:24,478
SPEAKER_1:  So that was...

02:27:24,962 --> 02:27:28,286
SPEAKER_0:  That was a lot of the phase members and it was.

02:27:28,738 --> 02:27:33,182
SPEAKER_0:  think Addison Rae. There were a lot of people who seemed like they were kind of taking shrapnel on it.

02:27:33,570 --> 02:27:38,334
SPEAKER_0:  There was like this guy, Tico, who he didn't even sell the tokens. He just like held onto it the entire time and lost.

02:27:39,298 --> 02:27:42,686
SPEAKER_0:  a few thousand dollars or maybe even, I forget the exact amount, he lost a lot of money.

02:27:42,946 --> 02:27:43,486
SPEAKER_0:  Our decent mount.

02:27:43,970 --> 02:27:46,590
SPEAKER_0:  And so like, he took a lot of shrapnel with that.

02:27:47,138 --> 02:27:50,174
SPEAKER_0:  but there are also people who are maliciously doing this. So...

02:27:50,818 --> 02:27:52,190
SPEAKER_0:  in that investigation like.

02:27:52,738 --> 02:27:54,814
SPEAKER_0:  Several of the members of Faze got kicked out.

02:27:55,554 --> 02:27:58,046
SPEAKER_0:  one of them got like permanently banned and then.

02:27:58,498 --> 02:28:03,134
SPEAKER_0:  This other guy that I talked about fled the country. He sold all his belongings and fled the country.

02:28:03,714 --> 02:28:07,070
SPEAKER_0:  and hit out in London or wherever he is now.

02:28:07,298 --> 02:28:09,694
SPEAKER_0:  I don't really know where he is. Somewhere in the UK area.

02:28:10,274 --> 02:28:14,302
SPEAKER_1:  So the basic idea there is to try to convert your influence into money.

02:28:17,090 --> 02:28:19,715
SPEAKER_0:  That's the basic idea behind a lot of influencer crypto.

02:28:19,715 --> 02:28:20,190
SPEAKER_1:  motions.

02:28:21,154 --> 02:28:21,726
SPEAKER_1:  Well, but...

02:28:22,786 --> 02:28:26,430
SPEAKER_1:  Right, but that little word influencer means something because they're

02:28:26,946 --> 02:28:30,974
SPEAKER_1:  Are most crypto scams, influencer scams, they're not, right? Most.

02:28:31,714 --> 02:28:32,839
SPEAKER_1:  most current

02:28:32,839 --> 02:28:34,366
SPEAKER_0:  Check out most high profile ones.

02:28:34,626 --> 02:28:34,942
SPEAKER_0:  Like.

02:28:35,394 --> 02:28:39,006
SPEAKER_0:  just by nature, they tend to be made high profile by the influencer.

02:28:39,234 --> 02:28:40,478
SPEAKER_0:  So sometimes they are.

02:28:41,218 --> 02:28:47,678
SPEAKER_0:  You're right, a lot of money has been lost and like nobody finds out because there's no one big sort of attached to it. They just steal a lot of money.

02:28:48,002 --> 02:28:48,894
SPEAKER_0:  But...

02:28:49,474 --> 02:28:52,062
SPEAKER_0:  Influencers are great salespeople because like

02:28:52,738 --> 02:28:55,006
SPEAKER_0:  in order to overcome the resistance.

02:28:55,298 --> 02:28:55,838
SPEAKER_0:  of

02:28:56,386 --> 02:28:59,358
SPEAKER_0:  getting you to buy some random coin. There's to be a reason.

02:28:59,810 --> 02:29:04,030
SPEAKER_0:  And so much of the 21st century content creator generation is defined as-

02:29:04,290 --> 02:29:08,606
SPEAKER_0:  by these strange parasocial relationships where people feel like they know you.

02:29:09,058 --> 02:29:11,262
SPEAKER_0:  Not the character you play, but you.

02:29:11,586 --> 02:29:13,406
SPEAKER_0:  and you have some friendship with them.

02:29:13,890 --> 02:29:15,070
SPEAKER_0:  When in actuality you don't know.

02:29:15,330 --> 02:29:15,838
SPEAKER_0:  the viewers.

02:29:16,290 --> 02:29:18,782
SPEAKER_0:  You know, you have a sense, but you don't actually know.

02:29:19,138 --> 02:29:20,158
SPEAKER_0:  all of these people.

02:29:20,482 --> 02:29:21,278
SPEAKER_0:  And so.

02:29:21,602 --> 02:29:22,782
SPEAKER_0:  that relationship.

02:29:23,202 --> 02:29:23,678
SPEAKER_0:  is ex-

02:29:23,938 --> 02:29:26,206
SPEAKER_0:  extremely powerful in terms of persuasion.

02:29:26,754 --> 02:29:30,334
SPEAKER_0:  so you can say, I believe in this, and I've watched you.

02:29:30,786 --> 02:29:35,582
SPEAKER_0:  year for years and all of a sudden I say like if Lex believes in it I believe in it I trust him as a human

02:29:35,970 --> 02:29:36,574
SPEAKER_0:  And so.

02:29:36,930 --> 02:29:39,294
SPEAKER_0:  that differentiates these coins and all of a sudden the coin

02:29:39,682 --> 02:29:40,350
SPEAKER_0:  blows up.

02:29:40,674 --> 02:29:43,838
SPEAKER_0:  gets really popular, you made this side deal, you make a ton of money.

02:29:44,290 --> 02:29:50,910
SPEAKER_1:  I have to say podcasting in particular is an intimacy. Like I'm a huge fan of podcasts and I feel like I'm friends with the people I listen to.

02:29:52,002 --> 02:29:52,414
SPEAKER_1:  and

02:29:52,738 --> 02:29:54,686
SPEAKER_1:  Boys that are responsibility.

02:29:57,154 --> 02:30:00,062
SPEAKER_1:  And that's why it...

02:30:00,386 --> 02:30:03,966
SPEAKER_1:  really hurts me to announce that I am launching Lexcoin.

02:30:05,666 --> 02:30:06,398
SPEAKER_1:  Oh!

02:30:07,970 --> 02:30:14,878
SPEAKER_1:  No, man, I hate money. I hate this kind of the scheming of all of this.

02:30:15,202 --> 02:30:15,934
SPEAKER_1:  The use.

02:30:16,258 --> 02:30:20,383
SPEAKER_1:  the use of any kind of degree of fame that you have for that kind of stuff. There's something just-

02:30:20,383 --> 02:30:21,886
SPEAKER_0:  It's so frustrating as.

02:30:22,242 --> 02:30:25,982
SPEAKER_0:  These people, I have a general sense of what they were like.

02:30:26,498 --> 02:30:27,486
SPEAKER_0:  Sort of what I'm...

02:30:27,938 --> 02:30:28,606
SPEAKER_0:  I'm in the-

02:30:29,186 --> 02:30:32,286
SPEAKER_0:  Even though I wouldn't describe myself as an influencer, I make content on YouTube.

02:30:33,474 --> 02:30:39,710
SPEAKER_0:  I know that especially since they were taking these huge corporate sponsorships, they were making tons of money. They didn't have need for...

02:30:40,098 --> 02:30:43,742
SPEAKER_0:  these scams. I mean, I think it's one thing to scam if you're like...

02:30:44,130 --> 02:30:45,438
SPEAKER_0:  broke on the street.

02:30:45,698 --> 02:30:48,062
SPEAKER_0:  You know, and you're playing three card Monte to like, live.

02:30:48,514 --> 02:30:51,710
SPEAKER_0:  And I think it's a whole other ethically cruel thing to do.

02:30:51,938 --> 02:30:54,814
SPEAKER_0:  if you're basically trying to upgrade your penthouse.

02:30:55,042 --> 02:30:58,366
SPEAKER_0:  to the building next door. And like you're already well off and you just kind of.

02:30:58,818 --> 02:31:00,670
SPEAKER_0:  want to get even further ahead. I think that's where it.

02:31:01,058 --> 02:31:05,342
SPEAKER_1:  Well, this is the fascinating thing. I've been very fortunate recently to sort of.

02:31:05,666 --> 02:31:06,366
SPEAKER_1:  Um...

02:31:07,170 --> 02:31:08,222
SPEAKER_1:  Uh...

02:31:08,578 --> 02:31:08,958
SPEAKER_1:  You know.

02:31:09,282 --> 02:31:10,910
SPEAKER_1:  whatever, a larger platform.

02:31:11,298 --> 02:31:20,798
SPEAKER_1:  And when you find out is like life is amazing. I always thought life is amazing, but it becomes more amazing like, you meet so many cool people and so on. But what you start getting is.

02:31:21,122 --> 02:31:23,422
SPEAKER_1:  You have more opportunities to like.

02:31:24,226 --> 02:31:24,606
SPEAKER_1:  Yeah, like.

02:31:25,058 --> 02:31:34,078
SPEAKER_1:  like scammers will come to you and try to use you, right? And I could see for somebody it could be tempting to be like, ooh, it would be nice to make some money.

02:31:34,242 --> 02:31:39,646
SPEAKER_0:  I wanted to say, like, on this, kind of we're on this topic of opportunities you get, you know, kind of when you get a platform.

02:31:40,578 --> 02:31:43,966
SPEAKER_0:  So one of the reasons kind of I railed a little bit earlier against them.

02:31:44,994 --> 02:31:49,438
SPEAKER_0:  materialism or whatever, I think to the extent to which you can moderate your own greed.

02:31:50,498 --> 02:31:52,478
SPEAKER_0:  you can play longer term games.

02:31:52,866 --> 02:31:54,494
SPEAKER_0:  And I think so many people.

02:31:55,042 --> 02:31:57,822
SPEAKER_0:  end up cutting an otherwise promising career short.

02:31:58,498 --> 02:32:00,894
SPEAKER_0:  by just wanting it too fast?

02:32:01,282 --> 02:32:04,062
SPEAKER_0:  So I think it's like a huge edge, just like discipline.

02:32:04,546 --> 02:32:06,238
SPEAKER_0:  is in terms of like achieving what you want.

02:32:06,594 --> 02:32:11,454
SPEAKER_0:  I think I'm like a very moderate, like being comfortable with a moderate existence and finding happiness in that.

02:32:12,034 --> 02:32:13,374
SPEAKER_0:  is a huge edge.

02:32:13,826 --> 02:32:18,142
SPEAKER_0:  because really your overhead is so much cheaper than the people who need a Ferrari or...

02:32:18,370 --> 02:32:27,358
SPEAKER_0:  a super nice house to feel fulfilled. And when your overhead is less, you have the luxury to say no to like sketchy offers. You have freedom that other people don't have. music

02:32:28,066 --> 02:32:39,198
SPEAKER_0:  A lot of times people don't pitch it this way. They pitch a Ferrari as freedom or like big houses like you've made it. In a lot of ways, those shackle you back to like, you gotta find the cashflow for those things. It's never a free ride.

02:32:39,778 --> 02:32:44,606
SPEAKER_1:  Yeah, that's really beautifully put. I've always said that I had fuck you money at the very beginning.

02:32:44,898 --> 02:32:46,302
SPEAKER_1:  I was broke for most of my life.

02:32:47,042 --> 02:32:48,414
SPEAKER_1:  the way you have fuck you money.

02:32:48,994 --> 02:32:54,558
SPEAKER_1:  is by not needing much to say fuck you. That's right. I mean, that's the overhead that you're talking about if you're gonna live.

02:32:54,786 --> 02:32:56,798
SPEAKER_1:  if you can live simply and be truly happy.

02:32:57,122 --> 02:32:58,558
SPEAKER_1:  and be truly free.

02:32:58,882 --> 02:32:59,422
SPEAKER_1:  I think.

02:33:00,034 --> 02:33:07,678
SPEAKER_1:  That means you could be free in any kind of situation. You could make the wise kind of decisions. In that case, money...

02:33:08,546 --> 02:33:13,694
SPEAKER_1:  uh... enables you in certain ways to do more cool stuff but doesn't shackle you like you said

02:33:14,018 --> 02:33:16,606
SPEAKER_1:  too many people in the society would shackle.

02:33:17,122 --> 02:33:18,558
SPEAKER_1:  because material possession is kind of like...

02:33:18,818 --> 02:33:20,798
SPEAKER_1:  draw you into this race.

02:33:21,218 --> 02:33:21,694
SPEAKER_1:  uh...

02:33:22,018 --> 02:33:24,094
SPEAKER_1:  of uh, more more more more.

02:33:24,546 --> 02:33:31,646
SPEAKER_1:  and then you feel the burden of that, bigger houses and all that kind of stuff, and now you have to keep working, you have to keep doing this thing.

02:33:31,874 --> 02:33:35,198
SPEAKER_1:  that you have to make more money and if it's a YouTube channel and so on.

02:33:35,554 --> 02:33:38,750
SPEAKER_1:  You have to get more and the same, it's not even just about money.

02:33:39,170 --> 02:33:39,646
SPEAKER_1:  Um.

02:33:39,970 --> 02:33:40,894
SPEAKER_1:  That's why I-

02:33:41,858 --> 02:33:44,990
SPEAKER_1:  Deliberately don't check views and likes and all that kind of stuff

02:33:45,282 --> 02:33:47,422
SPEAKER_1:  is you don't want that dopamine of like...

02:33:48,066 --> 02:33:48,670
SPEAKER_1:  Um...

02:33:48,898 --> 02:33:52,478
SPEAKER_1:  of pulling you in, I have to do the thing that gets more and more attention or.

02:33:52,802 --> 02:33:53,214
SPEAKER_1:  Um.

02:33:53,634 --> 02:33:54,558
SPEAKER_1:  More more.

02:33:55,618 --> 02:33:56,734
SPEAKER_1:  Yeah, like money and.

02:33:57,250 --> 02:34:01,630
SPEAKER_1:  Yeah, it's so wise. Yeah, great. It's a huge negative hit on your arm.

02:34:03,042 --> 02:34:03,390
SPEAKER_1:  and you're a

02:34:04,354 --> 02:34:05,479
SPEAKER_1:  ability to do creative.

02:34:05,479 --> 02:34:08,830
SPEAKER_0:  Can I ask you about that? I'm always interested in this.

02:34:09,858 --> 02:34:10,334
SPEAKER_0:  Um...

02:34:10,818 --> 02:34:12,030
SPEAKER_0:  I completely agree.

02:34:12,386 --> 02:34:16,862
SPEAKER_0:  I think it's funny because when you abstract yourself out to the people you admire and respect

02:34:17,090 --> 02:34:19,166
SPEAKER_0:  who inspired you to do the creative work you do.

02:34:20,066 --> 02:34:21,630
SPEAKER_0:  you never think about.

02:34:21,986 --> 02:34:28,382
SPEAKER_0:  like the views they were getting, or the money they were making, or the influence they had, all you ever think about is the work itself.

02:34:29,218 --> 02:34:30,046
SPEAKER_0:  And it's funny.

02:34:30,498 --> 02:34:32,222
SPEAKER_0:  when a lot of people get in this position.

02:34:33,218 --> 02:34:37,406
SPEAKER_0:  Your temptation is to focus on that which you can measure, which is like all the

02:34:38,114 --> 02:34:40,094
SPEAKER_0:  stuff you said, like the likes the views.

02:34:40,450 --> 02:34:41,886
SPEAKER_0:  That's not actually.

02:34:42,434 --> 02:34:44,862
SPEAKER_0:  the target or what you got into it for.

02:34:45,314 --> 02:34:49,182
SPEAKER_0:  If you get into it for like, because you're inspired or whatever, your goal is inspiration, impact plaguing the water, you could be inspired or this Close to World to inscrute your expansion

02:34:49,762 --> 02:34:52,126
SPEAKER_0:  And like that can't be quantified that same way.

02:34:53,602 --> 02:34:55,934
SPEAKER_0:  So it's interesting, you have to find a way.

02:34:56,162 --> 02:34:56,510
SPEAKER_0:  as a

02:34:56,834 --> 02:34:58,590
SPEAKER_0:  creator of any of this stuff.

02:34:59,106 --> 02:35:01,566
SPEAKER_0:  to like deliberately detach yourself.

02:35:01,986 --> 02:35:03,006
SPEAKER_0:  from the measurable.

02:35:03,554 --> 02:35:07,870
SPEAKER_0:  and focus on this thing, which is kind of abstract. And I was wondering if you have any ideas for that.

02:35:08,322 --> 02:35:08,734
SPEAKER_1:  So one.

02:35:08,962 --> 02:35:11,070
SPEAKER_1:  Yeah, there's a bunch of ideas. So one is

02:35:11,810 --> 02:35:12,446
SPEAKER_1:  uh

02:35:13,410 --> 02:35:15,390
SPEAKER_1:  Figure out ways where you don't see.

02:35:17,122 --> 02:35:18,302
SPEAKER_1:  the number of views.

02:35:18,914 --> 02:35:19,774
SPEAKER_1:  on things.

02:35:20,258 --> 02:35:20,926
SPEAKER_1:  So I have a-

02:35:21,634 --> 02:35:24,542
SPEAKER_1:  I wrote a Chrome extension for myself that hides the number of views.

02:35:25,122 --> 02:35:26,247
SPEAKER_1:  Um, that's really.

02:35:26,247 --> 02:35:28,350
SPEAKER_0:  That's funny. No, what's funny is I have-...

02:35:28,898 --> 02:35:35,326
SPEAKER_0:  Because it's useful for other people's content. Oh my gosh, that's freaky. I'm going to need to borrow this. That was my problem. I actually have.

02:35:35,618 --> 02:35:37,054
SPEAKER_0:  some Chrome extensions for.

02:35:37,378 --> 02:35:38,334
SPEAKER_0:  Like I don't like.

02:35:38,562 --> 02:35:46,334
SPEAKER_0:  going down like recommendation rabbit holes when I'm at work. I just wanna like search for a video, find it. I don't wanna see like all the up next cause I'll waste time.

02:35:46,658 --> 02:35:52,839
SPEAKER_0:  So I use Chrome extensions for that. But the views is a problem because it's relevant to me as a creator, like, is this a big video? So just check the video playlist for the results.

02:35:52,839 --> 02:35:58,622
SPEAKER_1:  Yeah, which is why I really hurt when they remove like likes and dislikes because I want to know for tutorials and so on

02:35:59,202 --> 02:36:03,327
SPEAKER_1:  What's I mean, that's probably really useful for you the dislikes. Yeah

02:36:03,327 --> 02:36:04,638
SPEAKER_0:  Do you have that? Do you ever?

02:36:04,962 --> 02:36:08,679
SPEAKER_0:  ever considered making that Chrome extension public? Sure!

02:36:08,679 --> 02:36:11,679
SPEAKER_1:  Yeah, and there will be a good philosophy behind it, right? Like don't if you're

02:36:11,679 --> 02:36:16,179
SPEAKER_0:  I really like it. I love the idea. I've wanted this thing before. I don't know if it necessarily exists.

02:36:16,179 --> 02:36:18,270
SPEAKER_1:  I don't think I've made up.

02:36:18,690 --> 02:36:21,374
SPEAKER_1:  a Chrome extension public. That'd be cool. I'd love to see.

02:36:21,762 --> 02:36:24,478
SPEAKER_1:  Yeah, I would go to that process of adding it to the...

02:36:25,090 --> 02:36:31,079
SPEAKER_1:  Cause I love like open sourcing stuff. So yeah, I'll go add it to the Chrome extension, like the store.

02:36:31,079 --> 02:36:32,062
SPEAKER_0:  I totally have.

02:36:32,322 --> 02:36:34,526
SPEAKER_0:  I've hated this for like a long time.

02:36:34,946 --> 02:36:42,334
SPEAKER_0:  YouTube made a change and they just continue to make the analytics front and center, which makes sense from their perspective. They're trying to give people better data.

02:36:42,594 --> 02:36:46,718
SPEAKER_0:  on what is successful and what makes something successful. They're trying to train their creators.

02:36:47,010 --> 02:36:48,222
SPEAKER_0:  But in the process...

02:36:48,770 --> 02:36:53,598
SPEAKER_0:  it can lead to some unhealthy habits of thinking views define a video

02:36:53,826 --> 02:37:00,606
SPEAKER_0:  And so I've long thought, okay, I've learned analytics, I understand retention, now I sort of wanna do like the zen, like forget it all.

02:37:01,026 --> 02:37:02,910
SPEAKER_0:  And you can only do that if it's out of your site.

02:37:03,138 --> 02:37:06,846
SPEAKER_1:  It depends how many friends you have who are creators. The other really important thing...

02:37:07,586 --> 02:37:09,854
SPEAKER_1:  And I found this has nothing to do with creatives.

02:37:10,466 --> 02:37:11,134
SPEAKER_1:  people

02:37:11,650 --> 02:37:13,086
SPEAKER_1:  respect very much in my life.

02:37:14,242 --> 02:37:15,614
SPEAKER_1:  Some of them people would know.

02:37:16,482 --> 02:37:17,150
SPEAKER_1:  could be famous.

02:37:17,954 --> 02:37:19,806
SPEAKER_1:  They will come to me and say.

02:37:20,130 --> 02:37:22,942
SPEAKER_1:  they will comment on how popular a video was on YouTube.

02:37:23,938 --> 02:37:25,150
SPEAKER_1:  that will sort of complement.

02:37:25,922 --> 02:37:36,062
SPEAKER_1:  The success. The success defined by the popularity. Even for a podcast where most of the listenership is not on YouTube or in Spotify now is getting crazy.

02:37:36,482 --> 02:37:39,582
SPEAKER_1:  they will still compliment the YouTube number.

02:37:39,810 --> 02:37:45,950
SPEAKER_1:  So one of the deliberate things I do is I either, depending if it's a close friend, I'll get offended and made fun of them for that.

02:37:46,466 --> 02:37:50,910
SPEAKER_1:  in terms of signal to them. This is not the right thing. Yeah, I don't want that.

02:37:51,362 --> 02:37:55,294
SPEAKER_1:  And for people more like strangers that complement that kind of stuff.

02:37:55,554 --> 02:37:55,998
SPEAKER_1:  I-

02:37:56,226 --> 02:37:57,598
SPEAKER_1:  shown zero interest.

02:37:57,954 --> 02:37:59,582
SPEAKER_1:  I don't receive the compliment well.

02:37:59,970 --> 02:38:03,326
SPEAKER_1:  and I'll focus on the aspects of the compliment that have to do with like...

02:38:03,874 --> 02:38:05,246
SPEAKER_1:  What do they find interesting?

02:38:05,730 --> 02:38:07,486
SPEAKER_1:  like, you know, I kind of make them.

02:38:07,842 --> 02:38:08,222
SPEAKER_1:  Uh.

02:38:08,450 --> 02:38:12,245
SPEAKER_1:  Reveal to them that you shouldn't care about the number of views.

02:38:12,245 --> 02:38:16,510
SPEAKER_0:  strange. There's like this weird hypnotism that happens when you get past a certain number.

02:38:17,378 --> 02:38:20,766
SPEAKER_0:  and that number is some approximation. It's like, it's always like hard numbers. It's like.

02:38:20,994 --> 02:38:23,070
SPEAKER_0:  100,000, a million, 10 million.

02:38:23,362 --> 02:38:27,710
SPEAKER_0:  People just see a number and they just go like, wow, that is, and they assign a quality to it that-

02:38:28,066 --> 02:38:30,558
SPEAKER_0:  may not, like it usually means nothing at all.

02:38:31,298 --> 02:38:32,510
SPEAKER_0:  I agree, I've never...

02:38:32,770 --> 02:38:35,038
SPEAKER_0:  I've never been good at like handling that because you're like

02:38:35,426 --> 02:38:36,094
SPEAKER_0:  Thank you.

02:38:36,354 --> 02:38:37,479
SPEAKER_0:  You know, it's like, okay.

02:38:37,479 --> 02:38:41,470
SPEAKER_1:  That said, I do admire, very different from me, but I admire Mr. Beast.

02:38:42,082 --> 02:38:43,262
SPEAKER_1:  unapologetically.

02:38:44,290 --> 02:38:49,118
SPEAKER_1:  says like the numbers all that matters like basically the number

02:38:49,602 --> 02:38:51,838
SPEAKER_1:  shows like the number of views you get.

02:38:52,706 --> 02:38:54,046
SPEAKER_1:  Shows like how much.

02:38:54,850 --> 02:38:58,974
SPEAKER_1:  I don't know joy you brought to people's lives because if they watch the thing

02:38:59,426 --> 02:38:59,902
SPEAKER_1:  day.

02:39:00,194 --> 02:39:07,998
SPEAKER_1:  kept watching the thing, they didn't turn to now, that means they loved it. You brought value to their life, you brought enjoyment, and I'm going to bring the-

02:39:08,322 --> 02:39:11,582
SPEAKER_1:  the maximum amount of enjoyment to the maximum number of people.

02:39:12,034 --> 02:39:16,222
SPEAKER_1:  and I'm gonna do the most epic videos and all that kind of stuff. I admire that.

02:39:16,770 --> 02:39:19,422
SPEAKER_1:  when you're so unapologetically into the numbers.

02:39:20,034 --> 02:39:22,366
SPEAKER_0:  Yeah, he's sort of, it's interesting, he's like...

02:39:23,138 --> 02:39:24,670
SPEAKER_0:  Gosh, we're getting way too in the way tonight.

02:39:24,930 --> 02:39:30,046
SPEAKER_0:  Is this a, I don't know, I'm like constantly self-monitoring about like what topics we're on, but if we can.

02:39:30,498 --> 02:39:33,886
SPEAKER_0:  MrBeast is so interesting because he's almost done what? Have you ever seen Moneyball?

02:39:34,978 --> 02:39:39,838
SPEAKER_0:  Yes. This is a story of how someone brought statistics to baseball and it revolutionized everything.

02:39:40,130 --> 02:39:41,470
SPEAKER_0:  He's Moneyballed YouTube.

02:39:42,466 --> 02:39:44,702
SPEAKER_0:  He took statistics to YouTube and it changed everything.

02:39:45,474 --> 02:39:46,686
SPEAKER_0:  Everybody now.

02:39:47,362 --> 02:39:48,702
SPEAKER_0:  So many people are playing catch up.

02:39:49,410 --> 02:39:50,942
SPEAKER_0:  I think it would be interesting.

02:39:51,618 --> 02:39:54,110
SPEAKER_0:  in a few years to see how he develops.

02:39:54,722 --> 02:39:58,782
SPEAKER_0:  And now that he's kind of revolutionized the data side of things.

02:39:59,586 --> 02:40:00,574
SPEAKER_0:  how he

02:40:01,218 --> 02:40:02,878
SPEAKER_0:  then approaches future videos.

02:40:03,202 --> 02:40:04,926
SPEAKER_0:  because there's a point at which.

02:40:05,570 --> 02:40:07,710
SPEAKER_0:  You've optimized, you've optimized, you've optimized.

02:40:08,130 --> 02:40:13,246
SPEAKER_0:  But optimizing for short-term video performance is not the same as optimizing for long-term viewer happiness.

02:40:13,826 --> 02:40:15,070
SPEAKER_0:  And how do you do that?

02:40:15,810 --> 02:40:20,414
SPEAKER_0:  assuming the YouTube algorithm does not perfectly already do it for you, which it doesn't.

02:40:20,802 --> 02:40:22,110
SPEAKER_0:  but they're trying to obviously do that.

02:40:22,466 --> 02:40:23,902
SPEAKER_0:  optimized for long-term happiness, but.

02:40:24,002 --> 02:40:26,622
SPEAKER_1:  and also growing Optimizer for long term.

02:40:26,914 --> 02:40:27,614
SPEAKER_1:  creative growth.

02:40:28,834 --> 02:40:30,622
SPEAKER_1:  I think the thing that people don't.

02:40:30,882 --> 02:40:34,622
SPEAKER_1:  I mean, maybe I don't know. I don't actually don't know enough about Jimmy, but like.

02:40:35,362 --> 02:40:35,902
SPEAKER_1:  To me.

02:40:36,226 --> 02:40:36,862
SPEAKER_1:  The thing that

02:40:37,602 --> 02:40:39,070
SPEAKER_1:  seems to be special about him.

02:40:39,618 --> 02:40:40,126
SPEAKER_1:  isn't.

02:40:40,418 --> 02:40:41,534
SPEAKER_1:  the moneyball aspect.

02:40:42,050 --> 02:40:43,358
SPEAKER_1:  That's really important.

02:40:43,650 --> 02:40:44,222
SPEAKER_1:  It's like.

02:40:44,610 --> 02:40:45,854
SPEAKER_1:  taking the data seriously.

02:40:46,210 --> 02:40:48,734
SPEAKER_1:  But to me, it's the part of the idea generation.

02:40:49,410 --> 02:40:51,646
SPEAKER_1:  the constant brainstorming coming up with videos.

02:40:52,194 --> 02:40:55,582
SPEAKER_1:  So it's nice to connect the idea generation with the data.

02:40:55,970 --> 02:40:56,478
SPEAKER_1:  but like.

02:40:56,770 --> 02:40:57,182
SPEAKER_1:  How?

02:40:57,442 --> 02:40:58,462
SPEAKER_1:  many people.

02:40:58,818 --> 02:41:01,246
SPEAKER_1:  when they create on YouTube and other platforms.

02:41:01,954 --> 02:41:04,510
SPEAKER_1:  really generate a huge amount of ideas.

02:41:04,898 --> 02:41:06,206
SPEAKER_1:  I constantly brainstorm.

02:41:06,754 --> 02:41:08,190
SPEAKER_1:  Constantly, constantly brainstorm.

02:41:08,546 --> 02:41:09,982
SPEAKER_1:  At least for me, I don't.

02:41:11,426 --> 02:41:13,278
SPEAKER_1:  I don't think I go.

02:41:13,986 --> 02:41:15,358
SPEAKER_1:  uh... so many

02:41:15,842 --> 02:41:17,310
SPEAKER_1:  Steps ahead in my thinking.

02:41:17,698 --> 02:41:22,910
SPEAKER_1:  I don't like try to come up with all possible conversations. I don't come up with all possible videos I can make.

02:41:23,042 --> 02:41:26,494
SPEAKER_0:  But you can't, so the one mistake to make is to map.

02:41:26,946 --> 02:41:31,262
SPEAKER_0:  Jimmy's philosophy onto every genre, because not every genre fits that model.

02:41:31,618 --> 02:41:33,022
SPEAKER_0:  Your model is not.

02:41:33,410 --> 02:41:35,934
SPEAKER_0:  an idea-centric model. It's a people-centric model.

02:41:36,450 --> 02:41:37,822
SPEAKER_0:  And so you like.

02:41:39,106 --> 02:41:44,030
SPEAKER_0:  If you were in the business of creating just mass entertainment for the sake of mass entertainment,

02:41:44,578 --> 02:41:46,910
SPEAKER_0:  you might focus on, okay.

02:41:47,234 --> 02:41:53,566
SPEAKER_0:  The reason going idea-focused instead of person-focused is such a revolutionary idea in some senses

02:41:53,794 --> 02:41:55,646
SPEAKER_0:  is because ideas can be broader.

02:41:55,874 --> 02:41:58,334
SPEAKER_0:  more broadly appealing than any single human can be.

02:42:00,194 --> 02:42:04,830
SPEAKER_0:  But you're not going for that. You're going for a podcast interview. And I think for you,

02:42:05,698 --> 02:42:11,038
SPEAKER_0:  The goal should always be how deep can you get with interesting guests and like finding the most interesting guest.

02:42:11,266 --> 02:42:13,891
SPEAKER_0:  which is a different probably set of skills.

02:42:13,891 --> 02:42:18,750
SPEAKER_1:  Well put, really well put, but I think the right mapping there is finding the most interesting guess.

02:42:19,042 --> 02:42:20,734
SPEAKER_1:  Yeah, and I think.

02:42:21,154 --> 02:42:21,758
SPEAKER_1:  Uhhh

02:42:22,050 --> 02:42:24,862
SPEAKER_1:  I don't do enough work on that. So for example, I...

02:42:25,218 --> 02:42:31,102
SPEAKER_1:  I try to be, something I do prioritize is talking to people that nobody's talked to before.

02:42:32,450 --> 02:42:33,886
SPEAKER_1:  because it's like I kind of assume

02:42:34,178 --> 02:42:38,174
SPEAKER_1:  Myself is not a good. I know a lot of people that much better than me. I really admire

02:42:38,530 --> 02:42:43,230
SPEAKER_1:  I think Joe Rogan is still the GOAT. He's just an incredible conversationalist.

02:42:43,490 --> 02:42:44,414
SPEAKER_1:  So it's like, all right.

02:42:45,474 --> 02:42:46,558
SPEAKER_1:  Who is somebody?

02:42:46,914 --> 02:42:48,286
SPEAKER_1:  Joe's not gonna talk to.

02:42:49,122 --> 02:42:49,662
SPEAKER_1:  Uh...

02:42:51,138 --> 02:42:57,214
SPEAKER_1:  Either he's not interested or it's not gonna happen. Like I wanna talk to that person. I wanna reveal the interesting aspect of that person.

02:42:57,602 --> 02:42:59,038
SPEAKER_1:  And I think...

02:43:00,642 --> 02:43:04,254
SPEAKER_1:  I should do a Mr. Beast style rigger.

02:43:05,026 --> 02:43:06,878
SPEAKER_1:  in searching for interesting people.

02:43:07,234 --> 02:43:09,278
SPEAKER_0:  and you should probably find people.

02:43:09,858 --> 02:43:11,134
SPEAKER_0:  to help you search.

02:43:12,066 --> 02:43:13,950
SPEAKER_1:  So he does that, but if we're being honest.

02:43:14,338 --> 02:43:16,702
SPEAKER_1:  He does that of course with other folks.

02:43:17,026 --> 02:43:18,302
SPEAKER_1:  But he's the main engine.

02:43:18,786 --> 02:43:20,766
SPEAKER_0:  Yeah, you need like sort of like a...

02:43:21,410 --> 02:43:22,686
SPEAKER_0:  a pre-filter.

02:43:22,914 --> 02:43:23,998
SPEAKER_0:  You're the final filter.

02:43:24,354 --> 02:43:25,566
SPEAKER_0:  Cause your problem is...

02:43:26,306 --> 02:43:27,294
SPEAKER_0:  Your only.

02:43:27,842 --> 02:43:30,878
SPEAKER_0:  able to think of humans that you've thought of before?

02:43:31,234 --> 02:43:32,286
SPEAKER_0:  or been exposed to.

02:43:32,674 --> 02:43:34,974
SPEAKER_0:  and most of the world you've never been exposed to.

02:43:35,266 --> 02:43:37,598
SPEAKER_0:  So you need people to like pre-filter and go.

02:43:37,922 --> 02:43:38,366
SPEAKER_0:  Okay.

02:43:38,594 --> 02:43:41,502
SPEAKER_0:  These guys are just interesting humans. Lex has never heard of them.

02:43:41,794 --> 02:43:43,998
SPEAKER_0:  and then you sort of take a batch of like.

02:43:44,322 --> 02:43:47,326
SPEAKER_0:  a hundred people and you go, who seems the most interesting for me?

02:43:48,034 --> 02:43:53,342
SPEAKER_1:  But by the way, on that topic, we're we's into we's, I have almost done a building up.

02:43:53,634 --> 02:43:55,454
SPEAKER_1:  I programmed.

02:43:56,034 --> 02:43:57,470
SPEAKER_1:  this guest recommendation.

02:43:58,434 --> 02:44:01,918
SPEAKER_1:  where I wanna get suggestions from other people cause I really wanna find

02:44:02,370 --> 02:44:05,086
SPEAKER_1:  people that nobody knows. This is the tricky thing.

02:44:05,378 --> 02:44:13,118
SPEAKER_1:  Not you're not famous, but I the idea is there's probably fascinating humans out there that nobody knows. Correct!

02:44:13,762 --> 02:44:17,150
SPEAKER_1:  That I want to find those and I believe in the crowdsourcing aspect will.

02:44:17,378 --> 02:44:21,182
SPEAKER_1:  raise them. And now of course the top 100 will be crypto scams. No.

02:44:21,474 --> 02:44:22,238
SPEAKER_1:  But yes.

02:44:22,498 --> 02:44:27,134
SPEAKER_1:  So like, I have to make sure that these kinds of swarms of humans that recommend

02:44:27,682 --> 02:44:31,838
SPEAKER_1:  I can filter through and there's this whole kinds of systems for that, but I want to find the walkthrough.

02:44:32,450 --> 02:44:35,870
SPEAKER_1:  the fascinating people out there nobody's ever heard from and

02:44:36,802 --> 02:44:40,510
SPEAKER_1:  From a programmer perspective, I thought surely I could do that by just building the system.

02:44:41,186 --> 02:44:42,311
SPEAKER_1:  uh... that's how program

02:44:42,311 --> 02:44:44,286
SPEAKER_0:  always think they'll just automate a system to do it.

02:44:44,578 --> 02:44:47,710
SPEAKER_1:  That's the Jamie money ball, right? Like looking at the data.

02:44:48,066 --> 02:44:48,670
SPEAKER_1:  Uh...

02:44:49,442 --> 02:44:49,950
SPEAKER_1:  uh...

02:44:50,338 --> 02:44:54,398
SPEAKER_1:  Weeds on weeds. How do we get to Mr. Beast exactly? I'm not sure. Okay,

02:44:54,626 --> 02:44:55,550
SPEAKER_1:  Save kids.

02:44:56,258 --> 02:44:57,950
SPEAKER_1:  Influencer. Yeah.

02:44:58,434 --> 02:45:00,318
SPEAKER_1:  Let me ask you more on the guru front.

02:45:00,642 --> 02:45:03,966
SPEAKER_1:  You've, uh, okay. Let's start with somebody that you've covered that.

02:45:04,546 --> 02:45:08,222
SPEAKER_1:  I think you've covered a lot and I'm really embarrassed to not know much about them.

02:45:08,706 --> 02:45:12,081
SPEAKER_1:  I think this is like old school coffee cell. You've been through stages. You've been through stages.

02:45:12,081 --> 02:45:12,831
SPEAKER_0:  stages and phase.

02:45:12,831 --> 02:45:13,502
SPEAKER_1:  this ah

02:45:13,730 --> 02:45:15,966
SPEAKER_1:  A character named Dan Lok.

02:45:16,514 --> 02:45:17,150
SPEAKER_1:  Uh...

02:45:17,826 --> 02:45:21,374
SPEAKER_1:  Who is he? You've exposed him for cult-like-

02:45:22,082 --> 02:45:25,982
SPEAKER_1:  uh... human and his cult-like practices who is he what is he done

02:45:26,626 --> 02:45:29,150
SPEAKER_0:  So Dan Lok is sort of.

02:45:29,442 --> 02:45:31,966
SPEAKER_0:  He's gone through a number of iterations, but he was.

02:45:32,290 --> 02:45:34,430
SPEAKER_0:  Kind of this like sales trainer guy.

02:45:34,722 --> 02:45:36,446
SPEAKER_0:  who really made a hard push.

02:45:36,802 --> 02:45:38,814
SPEAKER_0:  into what he called high ticket sales.

02:45:39,202 --> 02:45:44,990
SPEAKER_0:  and he was telling people that they could kind of escape the nine to five rat race if they just learn high ticket sales.

02:45:45,346 --> 02:45:47,102
SPEAKER_0:  and they can have the life of their dreams.

02:45:47,746 --> 02:45:51,454
SPEAKER_0:  Basically, it's like, I'll teach you to sell, but I'll teach you to ask.

02:45:51,938 --> 02:45:58,110
SPEAKER_0:  Like, not only will I teach you to sell you that pen, but I'll teach you to sell it for $50,000 instead of a dollar.

02:45:58,338 --> 02:45:58,718
SPEAKER_0:  Right.

02:45:59,074 --> 02:45:59,710
SPEAKER_0:  Um...

02:46:00,514 --> 02:46:04,894
SPEAKER_0:  So I talked to a lot of the people who had taken this course, because it was pretty expensive. I think it was like...

02:46:06,146 --> 02:46:09,982
SPEAKER_0:  $2500 or $1000 and mind you the people who are taking it are like

02:46:10,370 --> 02:46:13,598
SPEAKER_0:  teachers and like people who don't have a lot of money.

02:46:14,146 --> 02:46:16,958
SPEAKER_0:  and then you take the course and immediately find out.

02:46:17,378 --> 02:46:18,270
SPEAKER_0:  Okay, well there's an upsell.

02:46:18,626 --> 02:46:19,550
SPEAKER_0:  At the end of the course.

02:46:20,098 --> 02:46:20,702
SPEAKER_0:  You're not ready.

02:46:21,026 --> 02:46:22,078
SPEAKER_0:  You need to go from like.

02:46:22,402 --> 02:46:24,286
SPEAKER_0:  High Ticket Closer, which is one of the products.

02:46:24,578 --> 02:46:24,990
SPEAKER_0:  too.

02:46:25,378 --> 02:46:26,014
SPEAKER_0:  inner circle.

02:46:26,434 --> 02:46:30,910
SPEAKER_0:  or like the level up, right? And all of these courses are structured like this.

02:46:31,394 --> 02:46:34,430
SPEAKER_0:  So they spend a tremendous amount on Google ads.

02:46:34,658 --> 02:46:35,838
SPEAKER_0:  to get people in the door.

02:46:36,066 --> 02:46:36,990
SPEAKER_0:  promising the dream.

02:46:37,282 --> 02:46:40,894
SPEAKER_0:  And then once you're in, you're actually not done being like the product.

02:46:41,602 --> 02:46:42,558
SPEAKER_0:  You're actually

02:46:43,074 --> 02:46:52,734
SPEAKER_0:  in this system that tries to upsell you again and again and again and again. And eventually you're paying monthly and you're getting more and more. You're constantly paying for access to Dan Lok's wisdom and like...

02:46:53,026 --> 02:46:53,694
SPEAKER_0:  Ideas.

02:46:54,018 --> 02:46:54,334
SPEAKER_0:  and f-

02:46:54,594 --> 02:46:55,646
SPEAKER_0:  Fundamentally.

02:46:57,698 --> 02:47:01,182
SPEAKER_0:  this sales system wasn't working for people. I mean I talked to like for example a teacher.

02:47:01,442 --> 02:47:03,582
SPEAKER_0:  who put in like $25,000.

02:47:04,386 --> 02:47:06,846
SPEAKER_0:  was in debt at one point and has nothing to show for it.

02:47:07,074 --> 02:47:07,774
SPEAKER_0:  I know.

02:47:08,098 --> 02:47:09,662
SPEAKER_0:  and it was sort of these tactics.

02:47:09,954 --> 02:47:10,558
SPEAKER_0:  of

02:47:10,818 --> 02:47:16,318
SPEAKER_0:  Pressuring, pressuring, pressuring. And then anytime anyone would complain, he would try to silence them. So I heard from like...

02:47:16,546 --> 02:47:17,054
SPEAKER_0:  Um...

02:47:17,666 --> 02:47:18,110
SPEAKER_0:  Funny enough.

02:47:18,498 --> 02:47:19,870
SPEAKER_0:  This lady was a teacher as well.

02:47:20,130 --> 02:47:21,598
SPEAKER_0:  she put together a...

02:47:22,242 --> 02:47:27,102
SPEAKER_0:  Facebook group basically saying, I think this guy's a scam, his course didn't work, it's not working for a lot of people.

02:47:28,162 --> 02:47:32,446
SPEAKER_0:  because fundamentally the promise of turning someone from a non-salesman into a-

02:47:33,346 --> 02:47:35,262
SPEAKER_0:  person who's making six figures selling.

02:47:35,650 --> 02:47:39,710
SPEAKER_0:  is not an easy thing to do. It's not just a matter of just like take my course. But anyways.

02:47:40,066 --> 02:47:42,110
SPEAKER_0:  It wasn't working. She created a Facebook group about it.

02:47:42,498 --> 02:47:43,582
SPEAKER_0:  and he likes Suser.

02:47:43,810 --> 02:47:45,854
SPEAKER_0:  or and was like legally pressuring her.

02:47:46,306 --> 02:47:47,230
SPEAKER_0:  to stop doing that.

02:47:47,746 --> 02:47:48,350
SPEAKER_0:  Um

02:47:48,834 --> 02:47:52,030
SPEAKER_0:  and I realized like somebody has to speak out about this than everyone who is.

02:47:52,322 --> 02:47:53,438
SPEAKER_0:  is getting silenced.

02:47:53,730 --> 02:48:01,054
SPEAKER_0:  I was like, I'm gonna use my platform to raise awareness to this. And people came out of the woodwork. I mean saying that this guy defrauded me or he scammed me.

02:48:01,538 --> 02:48:01,854
SPEAKER_0:  and

02:48:02,338 --> 02:48:03,646
SPEAKER_0:  I want to just really quickly.

02:48:03,874 --> 02:48:05,790
SPEAKER_0:  Take a second, take a beat.

02:48:06,146 --> 02:48:08,126
SPEAKER_0:  to explain why.

02:48:08,642 --> 02:48:09,918
SPEAKER_0:  Get rich quick schemes.

02:48:10,370 --> 02:48:10,878
SPEAKER_0:  different.

02:48:11,586 --> 02:48:15,326
SPEAKER_0:  than let's say selling a water bottle and saying it's the greatest water bottle.

02:48:16,354 --> 02:48:18,750
SPEAKER_0:  Right? Because sometimes people wonder, they go like, well, doesn't like

02:48:19,682 --> 02:48:23,742
SPEAKER_0:  Nissan say their car is gonna make you happy and then it doesn't make you happy. Like why is that different?

02:48:24,226 --> 02:48:25,886
SPEAKER_0:  from the kind of advertising of.

02:48:26,882 --> 02:48:29,822
SPEAKER_0:  Get Rich Quick Course. I mean, both of them are sort of promising things that aren't true.

02:48:30,498 --> 02:48:34,110
SPEAKER_0:  But you get something, you take some kind of a training, you know, isn't it the same thing?

02:48:34,786 --> 02:48:35,102
SPEAKER_0:  No.

02:48:35,554 --> 02:48:35,966
SPEAKER_0:  Here's why.

02:48:37,090 --> 02:48:41,694
SPEAKER_0:  There's this concept in economics called elastic demand and inelastic demand.

02:48:43,170 --> 02:48:46,750
SPEAKER_0:  What it essentially means is that if I raise the value of this water bottle

02:48:47,074 --> 02:48:48,798
SPEAKER_0:  There's a point at which you're just gonna be like, no.

02:48:49,058 --> 02:48:50,110
SPEAKER_0:  It doesn't make any sense, right?

02:48:51,042 --> 02:48:52,766
SPEAKER_0:  but there are areas in our lives.

02:48:52,994 --> 02:48:55,230
SPEAKER_0:  where we have desperation.

02:48:55,554 --> 02:48:56,158
SPEAKER_0:  around them.

02:48:57,026 --> 02:48:57,374
SPEAKER_0:  that.

02:48:57,666 --> 02:49:01,854
SPEAKER_0:  can get deeply predatory very quickly because they have no

02:49:02,818 --> 02:49:03,486
SPEAKER_0:  There's no.

02:49:03,746 --> 02:49:05,918
SPEAKER_0:  elasticity around their demand. For example,

02:49:06,242 --> 02:49:06,878
SPEAKER_0:  your health.

02:49:07,490 --> 02:49:09,790
SPEAKER_0:  If you get cancer and I have the pill.

02:49:10,786 --> 02:49:16,350
SPEAKER_0:  that will solve it, or at least, let's say I don't, I have a sugar pill here, but if I can convince you that this pill will-

02:49:16,898 --> 02:49:17,790
SPEAKER_0:  Solve your cancer.

02:49:18,210 --> 02:49:21,822
SPEAKER_0:  or treat your cancer. You will pay any amount of money you have on this earth.

02:49:22,562 --> 02:49:23,742
SPEAKER_0:  to get this pill.

02:49:24,866 --> 02:49:27,230
SPEAKER_0:  But obviously that gets really predatory really quick because

02:49:27,938 --> 02:49:28,574
SPEAKER_0:  selling.

02:49:28,962 --> 02:49:32,286
SPEAKER_0:  something that isn't real is almost as compelling as selling something that is real.

02:49:32,514 --> 02:49:32,862
SPEAKER_0:  Right?

02:49:33,186 --> 02:49:33,630
SPEAKER_0:  So.

02:49:34,050 --> 02:49:38,110
SPEAKER_0:  This happens in the get rich quick space too. There's any amount of money you would pay to make.

02:49:38,498 --> 02:49:39,166
SPEAKER_0:  a lot more money.

02:49:39,394 --> 02:49:39,806
SPEAKER_0:  Right?

02:49:40,706 --> 02:49:44,286
SPEAKER_0:  So these products have inelastic demand. That's why you see what is essentially...

02:49:44,802 --> 02:49:45,918
SPEAKER_0:  a few webinars.

02:49:46,274 --> 02:49:47,934
SPEAKER_0:  getting sold for $2,500.

02:49:48,802 --> 02:49:50,462
SPEAKER_0:  courses that literally have.

02:49:51,010 --> 02:49:56,766
SPEAKER_0:  identical videos on YouTube, like very similar course curriculums, that are selling for such extravagant amounts of money.

02:49:57,442 --> 02:49:58,110
SPEAKER_0:  and

02:49:59,490 --> 02:50:02,686
SPEAKER_0:  I think there can be comparisons made to college, because obviously there's

02:50:02,914 --> 02:50:03,838
SPEAKER_0:  similar like

02:50:04,482 --> 02:50:05,182
SPEAKER_0:  questions about.

02:50:05,890 --> 02:50:06,526
SPEAKER_0:  Benefits?

02:50:06,786 --> 02:50:11,230
SPEAKER_0:  But in this case, there's not even statistics available that even shows the average person gets something out of it.

02:50:11,746 --> 02:50:15,454
SPEAKER_0:  That's true of like, if you go to college, your average income will improve, right?

02:50:15,778 --> 02:50:26,750
SPEAKER_0:  That's the justification there. There's none of that. There's no case studies. There's nothing backing their extravagant claims of you're gonna make all this money, you're gonna make all this wealth. Instead, they're just, as we said before, they're selling you a dream.

02:50:27,234 --> 02:50:29,150
SPEAKER_0:  So that's why I find all those.

02:50:29,410 --> 02:50:32,510
SPEAKER_0:  like types of Git Ridge quick schemes so problematic and uh...

02:50:32,770 --> 02:50:34,238
SPEAKER_0:  That's why I've railed against them for-

02:50:34,466 --> 02:50:35,591
SPEAKER_0:  significant amount of time.

02:50:35,591 --> 02:50:40,222
SPEAKER_1:  What have you learned from attacking, exposing some of the things that deadlockers.

02:50:40,674 --> 02:50:43,166
SPEAKER_1:  What have you learned about human nature?

02:50:43,714 --> 02:50:45,406
SPEAKER_1:  and fraudsters and gurus and so on.

02:50:45,794 --> 02:50:46,846
SPEAKER_1:  Good question.

02:50:47,810 --> 02:50:48,638
SPEAKER_0:  I think one of them.

02:50:48,866 --> 02:50:49,534
SPEAKER_0:  is that

02:50:50,914 --> 02:50:52,862
SPEAKER_0:  There's this systemic problem that

02:50:53,826 --> 02:50:56,510
SPEAKER_0:  The phrase, there's a sucker born every minute.

02:50:57,026 --> 02:50:57,598
SPEAKER_0:  It's very true.

02:50:57,986 --> 02:51:00,158
SPEAKER_0:  There is no end to the people.

02:51:00,546 --> 02:51:01,086
SPEAKER_0:  too.

02:51:01,602 --> 02:51:03,230
SPEAKER_0:  will fall for something like this.

02:51:03,618 --> 02:51:06,974
SPEAKER_0:  And the problem is, is because there's just no end to need and want.

02:51:07,362 --> 02:51:07,774
SPEAKER_0:  and like.

02:51:08,098 --> 02:51:09,054
SPEAKER_0:  and just lack.

02:51:09,506 --> 02:51:10,494
SPEAKER_0:  I mean, it's easy to...

02:51:11,106 --> 02:51:14,974
SPEAKER_0:  on the one hand, criticize people's greed, but a lot of times you have to put yourself in their shoes.

02:51:15,490 --> 02:51:16,830
SPEAKER_0:  If you're at a dead-end job.

02:51:17,698 --> 02:51:18,846
SPEAKER_0:  You have nothing going for you.

02:51:19,362 --> 02:51:21,886
SPEAKER_0:  If you don't have the money to go to college, you don't want to get in debt, fair play.

02:51:22,786 --> 02:51:23,486
SPEAKER_0:  Where do you go?

02:51:23,714 --> 02:51:24,094
SPEAKER_0:  Right?

02:51:24,770 --> 02:51:29,118
SPEAKER_0:  As you said, there's somebody who's there saying they believe in you, they believe you can make six figures.

02:51:29,826 --> 02:51:30,302
SPEAKER_0:  You know, you're.

02:51:30,818 --> 02:51:32,862
SPEAKER_0:  you're gonna believe in that. And so-

02:51:33,858 --> 02:51:35,070
SPEAKER_0:  I really felt like...

02:51:35,810 --> 02:51:38,526
SPEAKER_0:  It made a lot more sense to tackle it from the...

02:51:38,818 --> 02:51:39,614
SPEAKER_0:  other side.

02:51:39,970 --> 02:51:41,694
SPEAKER_0:  from the side of people that can stop.

02:51:42,274 --> 02:51:43,486
SPEAKER_0:  that can basically...

02:51:44,002 --> 02:51:46,398
SPEAKER_0:  be exposed and basically be.

02:51:46,690 --> 02:51:47,006
SPEAKER_0:  Um.

02:51:47,490 --> 02:51:48,286
SPEAKER_0:  Have sort of like.

02:51:48,642 --> 02:51:50,462
SPEAKER_0:  a negative put on their work. I mean-

02:51:50,690 --> 02:51:52,702
SPEAKER_0:  they're largely going under the radar so.

02:51:53,026 --> 02:51:53,790
SPEAKER_0:  I kind of felt like.

02:51:54,690 --> 02:51:55,998
SPEAKER_0:  You know, do you want to educate?

02:51:56,738 --> 02:52:01,086
SPEAKER_0:  Do you want to like blame it on the victims and say you should have known better? You should have done this. Stop.

02:52:01,858 --> 02:52:02,270
SPEAKER_0:  But they're-

02:52:02,562 --> 02:52:04,702
SPEAKER_0:  There's no end to that. or

02:52:04,962 --> 02:52:08,446
SPEAKER_0:  you go after the grifters themselves. And so that's what I realized. I realize like-

02:52:08,738 --> 02:52:09,758
SPEAKER_0:  That's the tactic.

02:52:10,530 --> 02:52:12,030
SPEAKER_0:  that I went with.

02:52:12,386 --> 02:52:14,910
SPEAKER_0:  And it's tough because it's a little like, it's completely risky to do that, but.

02:52:15,394 --> 02:52:15,870
SPEAKER_0:  Um...

02:52:17,314 --> 02:52:18,439
SPEAKER_0:  Yeah, you just gotta be smart about it.

02:52:18,439 --> 02:52:20,350
SPEAKER_1:  So your platform has gotten...

02:52:20,610 --> 02:52:24,414
SPEAKER_1:  really big, so there's some responsibility to that. Weirdly big, yeah. Yeah.

02:52:24,962 --> 02:52:25,630
SPEAKER_1:

02:52:26,690 --> 02:52:27,815
SPEAKER_1:  Let's say, thx for watching

02:52:27,815 --> 02:52:29,886
SPEAKER_0:  only a year ago it was like a lot.

02:52:30,434 --> 02:52:32,126
SPEAKER_0:  smaller and then it's hard to.

02:52:32,674 --> 02:52:35,710
SPEAKER_0:  make that adjustment, you know? Cause like to me it's just the same.

02:52:36,354 --> 02:52:36,958
SPEAKER_0:  It's the same show.

02:52:37,250 --> 02:52:37,726
SPEAKER_1:  been doing.

02:52:38,338 --> 02:52:42,142
SPEAKER_1:  So how do you avoid becoming a guru yourself or?

02:52:42,818 --> 02:52:44,254
SPEAKER_1:  Ah, your ego growing.

02:52:44,866 --> 02:52:49,534
SPEAKER_1:  And there's different trajectories it could take, one of which is

02:52:49,890 --> 02:52:51,070
SPEAKER_1:  you can start seeing.

02:52:51,330 --> 02:52:52,862
SPEAKER_1:  Everybody is a scammer.

02:52:53,154 --> 02:52:54,654
SPEAKER_1:  and only you can reveal it.

02:52:55,138 --> 02:52:56,030
SPEAKER_1:  and like every.

02:52:56,258 --> 02:52:59,166
SPEAKER_1:  And like you have a audience of people who love.

02:52:59,554 --> 02:53:06,430
SPEAKER_1:  seeing the epic coffeezilla grilling. Sure. And you can destroy everyone and that power now is getting to your head.

02:53:06,754 --> 02:53:07,358
SPEAKER_1:  How do you avoid that?

02:53:08,066 --> 02:53:08,446
SPEAKER_0:  Well.

02:53:08,898 --> 02:53:12,766
SPEAKER_0:  I mean, this is like less optically obvious. I think the main way is like.

02:53:13,314 --> 02:53:15,998
SPEAKER_0:  My circle of friends doesn't care about any of that.

02:53:16,226 --> 02:53:16,606
SPEAKER_0:  Bye again.

02:53:16,962 --> 02:53:19,710
SPEAKER_0:  My wife doesn't care. The people whose opinion I value.

02:53:20,130 --> 02:53:21,694
SPEAKER_0:  has no relation to like...

02:53:21,922 --> 02:53:24,222
SPEAKER_0:  a subscriber metric or anything like that.

02:53:24,546 --> 02:53:25,150
SPEAKER_0:  I think that's like.

02:53:25,730 --> 02:53:31,582
SPEAKER_0:  Tangibly the most important thing to just staying grounded. As far as like becoming a guru, I just don't have anything to like-

02:53:32,002 --> 02:53:33,822
SPEAKER_0:  I mean, I'm not interested in.

02:53:34,242 --> 02:53:38,558
SPEAKER_0:  teaching people finance. I'm not interested in teaching people, not interested in selling a course.

02:53:39,266 --> 02:53:39,966
SPEAKER_0:  And I've kind of-

02:53:40,258 --> 02:53:43,518
SPEAKER_0:  given myself a hard line on that, which I think has helped me a bit.

02:53:43,970 --> 02:53:44,446
SPEAKER_0:  is

02:53:44,770 --> 02:53:46,334
SPEAKER_0:  There's a temptation to go.

02:53:46,594 --> 02:53:47,998
SPEAKER_0:  Well, I can tell what's a scam.

02:53:48,354 --> 02:53:49,854
SPEAKER_0:  So let me tell you what's not a scam.

02:53:50,434 --> 02:53:53,758
SPEAKER_0:  And a lot of people have offered a lot of money to do that and basically be like-

02:53:53,986 --> 02:53:54,366
SPEAKER_0:  Hey.

02:53:54,946 --> 02:53:58,558
SPEAKER_0:  I have such and such legitimate product, come be like an endorser.

02:53:59,106 --> 02:53:59,806
SPEAKER_0:  and

02:54:00,354 --> 02:54:03,518
SPEAKER_0:  I just don't do that because I think it undermines a lot of what I do.

02:54:04,130 --> 02:54:05,438
SPEAKER_0:  is if you get like...

02:54:06,498 --> 02:54:09,182
SPEAKER_0:  if you're taking money in on the side to say this is legit.

02:54:09,474 --> 02:54:11,870
SPEAKER_0:  and you're saying this isn't legit, it's a huge conflict of interest.

02:54:12,194 --> 02:54:12,702
SPEAKER_0:  So I think it's about.

02:54:12,962 --> 02:54:16,382
SPEAKER_0:  managing conflicts of interest and keeping people around me that

02:54:17,026 --> 02:54:19,358
SPEAKER_0:  are grounded and also I think...

02:54:20,770 --> 02:54:22,750
SPEAKER_0:  Yeah, my only interest really is just like...

02:54:23,170 --> 02:54:27,070
SPEAKER_0:  make cool stuff and I guess I'll do that until people stop watching.

02:54:28,866 --> 02:54:32,638
SPEAKER_1:  Question from on that topic from the coffee's little subreddit shout out.

02:54:33,090 --> 02:54:33,502
SPEAKER_1:  Shout out.

02:54:34,882 --> 02:54:43,134
SPEAKER_1:  How does Koffe find the strength to maintain his integrity and resist temptation of being paid a great amount of money to advertise or promote a potential scam?

02:54:44,834 --> 02:54:45,982
SPEAKER_1:  Uh, I think that's like-

02:54:46,210 --> 02:54:54,398
SPEAKER_0:  goes back to what we've been talking about a lot, which is just on what you prioritize, what you value. I've just never, I guess I grew up kind of lower middle class.

02:54:55,458 --> 02:54:56,126
SPEAKER_0:  and

02:54:56,642 --> 02:54:59,966
SPEAKER_0:  I had a great time. I had a great childhood. I had very loving parents.

02:55:00,642 --> 02:55:01,822
SPEAKER_0:  And because of that.

02:55:03,170 --> 02:55:05,630
SPEAKER_0:  I guess intuited at an early age that

02:55:06,722 --> 02:55:10,302
SPEAKER_0:  Money doesn't do a whole lot. And I knew a lot of people who were way better off.

02:55:10,658 --> 02:55:12,286
SPEAKER_0:  who had miserable childhoods.

02:55:13,058 --> 02:55:15,998
SPEAKER_0:  because whether their dad was always gone at work or like.

02:55:16,418 --> 02:55:16,862
SPEAKER_0:  They just.

02:55:17,154 --> 02:55:19,646
SPEAKER_0:  had other family issues that just money can't buy.

02:55:20,322 --> 02:55:20,958
SPEAKER_0:  and

02:55:21,186 --> 02:55:21,790
SPEAKER_0:  I realized.

02:55:22,594 --> 02:55:23,902
SPEAKER_0:  I guess quickly.

02:55:24,514 --> 02:55:25,054
SPEAKER_0:  um...

02:55:26,562 --> 02:55:27,774
SPEAKER_0:  Money's a very like...

02:55:28,514 --> 02:55:31,422
SPEAKER_0:  It's a glittery object that isn't what it appears to be.

02:55:31,906 --> 02:55:32,798
SPEAKER_0:  And so...

02:55:33,346 --> 02:55:36,542
SPEAKER_0:  To me, I'm like, I'm having the time of my life making my show.

02:55:37,346 --> 02:55:41,726
SPEAKER_0:  I'm not gonna have the time, like, I could, you could ruin all that just trying to go for this quick check.

02:55:42,082 --> 02:55:43,806
SPEAKER_0:  when it's like, no, I'm having a great time.

02:55:44,258 --> 02:55:45,086
SPEAKER_1:  Yeah, it's actually

02:55:45,346 --> 02:55:45,918
SPEAKER_1:  uh

02:55:46,306 --> 02:55:51,422
SPEAKER_1:  maybe you're probably the same way, but for me, there's a lot of happiness and having integrity.

02:55:52,130 --> 02:55:55,614
SPEAKER_1:  in looking in the mirror and knowing that you're the kind of person that has that.

02:55:56,098 --> 02:55:56,510
SPEAKER_1:  In fact...

02:55:56,738 --> 02:55:58,878
SPEAKER_1:  walking away from money is also fun.

02:55:59,682 --> 02:56:01,470
SPEAKER_1:  because it's like promising your.

02:56:01,698 --> 02:56:05,534
SPEAKER_1:  Like it's showing, it's easy to like just say you have integrity. It's nice to like.

02:56:06,050 --> 02:56:10,014
SPEAKER_1:  Ha, I actually, I've discovered several times in my life that I have integrity.

02:56:11,298 --> 02:56:14,238
SPEAKER_0:  You can put like basically to the test.

02:56:15,362 --> 02:56:21,022
SPEAKER_1:  I've said, I don't know if I publicly said, but to myself, I say like, you can't buy.

02:56:21,506 --> 02:56:24,382
SPEAKER_1:  There's a lot of things you can't buy with me, like $4 billion.

02:56:24,738 --> 02:56:25,950
SPEAKER_1:  like a trillion dollars.

02:56:26,370 --> 02:56:28,446
SPEAKER_1:  But it'd be nice to get tested that way.

02:56:28,770 --> 02:56:31,902
SPEAKER_1:  It'd be cool to see, cause you never know until you're in that room.

02:56:32,578 --> 02:56:36,510
SPEAKER_1:  I'm the same with power given power. I'd like to believe on the kind of person

02:56:36,962 --> 02:56:38,846
SPEAKER_1:  That wouldn't abuse power, but you don't know.

02:56:39,106 --> 02:56:40,222
SPEAKER_1:  until you're tested.

02:56:40,642 --> 02:56:41,022
SPEAKER_1:  Anyway.

02:56:41,538 --> 02:56:43,870
SPEAKER_1:  You're in a really tricky position because you're doing...

02:56:44,290 --> 02:56:47,326
SPEAKER_1:  Incredibly you are a world-class journalist straight up

02:56:47,746 --> 02:56:50,590
SPEAKER_1:  And so there is pressure on that of like.

02:56:51,138 --> 02:56:52,414
SPEAKER_1:  not having.

02:56:54,306 --> 02:56:59,454
SPEAKER_1:  Earing on the side of caution with like having conflicts, adventures and stuff like that. It's a really tough seat.

02:57:00,034 --> 02:57:00,638
SPEAKER_1:  to sit in.

02:57:01,538 --> 02:57:02,110
SPEAKER_1:  Um...

02:57:02,754 --> 02:57:06,078
SPEAKER_1:  It's really tough, it's really tough, but it's unfairly tough, I feel like.

02:57:06,498 --> 02:57:06,910
SPEAKER_1:  Um...

02:57:07,138 --> 02:57:08,702
SPEAKER_1:  But it's good that you're sort of...

02:57:09,218 --> 02:57:11,102
SPEAKER_1:  weighing all of those. That said.

02:57:11,522 --> 02:57:13,598
SPEAKER_1:  Go donate to Coffeezilla.

02:57:14,274 --> 02:57:15,038
SPEAKER_1:  Donate all.

02:57:15,330 --> 02:57:15,902
SPEAKER_1:  Everything.

02:57:16,386 --> 02:57:16,990
SPEAKER_1:  Support him.

02:57:17,314 --> 02:57:19,742
SPEAKER_1:  is a really, really important human being.

02:57:20,610 --> 02:57:21,118
SPEAKER_1:  uh

02:57:22,050 --> 02:57:25,150
SPEAKER_1:  The other guy I did, I think is the first person I discovered that you

02:57:26,146 --> 02:57:28,670
SPEAKER_1:  investigated as Brian Rose of London Real.

02:57:30,018 --> 02:57:31,102
SPEAKER_1:  Can you talk about his story?

02:57:31,554 --> 02:57:32,094
SPEAKER_0:  Um...

02:57:33,186 --> 02:57:37,310
SPEAKER_0:  Brian Rose, he was sort of this interesting figure cause he was like

02:57:38,050 --> 02:57:39,166
SPEAKER_0:  trying to be...

02:57:39,554 --> 02:57:48,734
SPEAKER_0:  to one level or another, the Joe Rogan of London, which I don't think he did a terribly bad job of, especially initially, he had some really interesting podcasts.

02:57:48,962 --> 02:57:50,558
SPEAKER_0:  with some really interesting people.

02:57:50,978 --> 02:58:00,254
SPEAKER_0:  And it's funny enough, I started out as I would watch him. I mean, I don't know if I was a huge fan, but I was like, I like some of his interviews. He had some really good, like big gets in terms of...

02:58:00,610 --> 02:58:00,958
SPEAKER_0:  You know.

02:58:01,218 --> 02:58:02,334
SPEAKER_0:  Great guests.

02:58:02,978 --> 02:58:03,486
SPEAKER_0:  I'm

02:58:03,906 --> 02:58:04,894
SPEAKER_0:  However, when...

02:58:05,250 --> 02:58:05,598
SPEAKER_0:  kind of

02:58:06,050 --> 02:58:08,734
SPEAKER_0:  COVID started, he went down this really weird.

02:58:09,986 --> 02:58:11,838
SPEAKER_0:  grifting rabbit hole where

02:58:12,290 --> 02:58:14,334
SPEAKER_0:  He did like this interview with...

02:58:14,882 --> 02:58:19,166
SPEAKER_0:  David Icke, who's, as you know, like a pretty big COVID conspiracy theorist.

02:58:19,874 --> 02:58:20,382
SPEAKER_0:  um...

02:58:20,898 --> 02:58:26,366
SPEAKER_0:  And I mean like actual, like he believes some of the Royals are literally lizards.

02:58:27,170 --> 02:58:28,702
SPEAKER_0:  So he got shut down for that.

02:58:29,442 --> 02:58:34,174
SPEAKER_0:  and he kind of made a big stink, which I think it's fine. Nobody likes to be censored.

02:58:34,530 --> 02:58:36,734
SPEAKER_0:  And I'm not even saying that he should have been.

02:58:36,994 --> 02:58:37,502
SPEAKER_0:  Censored.

02:58:37,890 --> 02:58:39,646
SPEAKER_0:  but his reaction to that was to like...

02:58:39,874 --> 02:58:42,302
SPEAKER_0:  raise a ton of money from his audience, promising this-

02:58:42,850 --> 02:58:44,446
SPEAKER_0:  digital freedom platform.

02:58:44,962 --> 02:58:49,278
SPEAKER_0:  And at first it was like, oh, we want to raise $100,000. And then they raised it like within a day.

02:58:49,538 --> 02:58:51,102
SPEAKER_0:  So he's like, well, we gotta raise.

02:58:51,458 --> 02:58:56,446
SPEAKER_0:  a lot more money, and so eventually, they raised a million dollars, and he's trying to raise $250,000 a month.

02:58:57,058 --> 02:58:58,590
SPEAKER_0:  to kind of keep putting.

02:58:59,330 --> 02:59:00,638
SPEAKER_0:  his viewers money into this stuff.

02:59:00,866 --> 02:59:03,774
SPEAKER_0:  So I started digging into the platform they were building and there was nothing free about it.

02:59:04,514 --> 02:59:05,950
SPEAKER_0:  They had censorship guidelines.

02:59:06,274 --> 02:59:08,574
SPEAKER_0:  And there was nothing about a platform at all. There was no.

02:59:08,834 --> 02:59:10,334
SPEAKER_0:  underlying infrastructure he just

02:59:10,978 --> 02:59:12,318
SPEAKER_0:  got some white label.

02:59:12,642 --> 02:59:13,918
SPEAKER_0:  uh, live streaming thing.

02:59:15,106 --> 02:59:26,462
SPEAKER_0:  I criticized him for that. It was just this ridiculous thing. All the donators expected one thing. They thought Brian Rose was gonna take on Google and Facebook and like bring free speech back for everybody. And of course he didn't.

02:59:26,914 --> 02:59:27,358
SPEAKER_0:  Um...

02:59:27,906 --> 02:59:30,334
SPEAKER_0:  And then it kind of got worse because...

02:59:30,722 --> 02:59:32,254
SPEAKER_0:  He started taking a lot of heat for that.

02:59:32,962 --> 02:59:35,070
SPEAKER_0:  and he really pivoted hard until...

02:59:36,194 --> 02:59:38,622
SPEAKER_0:  the DeFi grift, so he started selling this course about

02:59:39,010 --> 02:59:42,686
SPEAKER_0:  DeFi Mastery and this is a guy who knows nothing about crypto.

02:59:43,010 --> 02:59:44,734
SPEAKER_0:  or very little at the least.

02:59:45,218 --> 02:59:45,822
SPEAKER_0:  So.

02:59:46,306 --> 02:59:50,142
SPEAKER_0:  It just got really kind of, he just kind of doubled down on this.

02:59:50,466 --> 02:59:53,182
SPEAKER_0:  course model of you're gonna be rich if you just follow me. It was.

02:59:53,986 --> 02:59:59,902
SPEAKER_0:  Ultimately, you just type in Brian Rose on YouTube, you can see what his audience thought of that, and you just wait.

03:00:00,258 --> 03:00:03,678
SPEAKER_0:  All of them have left him at this point. He's getting like a thousand views a video.

03:00:04,386 --> 03:00:06,622
SPEAKER_0:  And it wasn't because of me. I mean, it was like.

03:00:07,106 --> 03:00:07,710
SPEAKER_0:  People.

03:00:07,970 --> 03:00:09,470
SPEAKER_0:  lost taste in...

03:00:09,986 --> 03:00:15,966
SPEAKER_0:  just the constant ask for more money, more money, more money. At some point, people get sick of it, and it's like...

03:00:16,226 --> 03:00:16,798
SPEAKER_0:  Everyoneâ€”

03:00:17,186 --> 03:00:19,678
SPEAKER_0:  has an understanding that like no one works for free, but.

03:00:20,034 --> 03:00:21,182
SPEAKER_0:  when it starts to be.

03:00:21,602 --> 03:00:25,182
SPEAKER_0:  ego driven and driven around money. Everything's about money.

03:00:25,538 --> 03:00:26,663
SPEAKER_0:  it uh...

03:00:26,663 --> 03:00:27,454
SPEAKER_1:  drives people away.

03:00:28,130 --> 03:00:31,838
SPEAKER_1:  Well, you're a part of that sort of helping. It's nice to have a voice.

03:00:32,642 --> 03:00:36,766
SPEAKER_0:  I certainly spoke out. I mean, it wasn't like I was quiet. I was very loud about it at the time.

03:00:37,282 --> 03:00:37,790
SPEAKER_0:  Um...

03:00:38,178 --> 03:00:39,742
SPEAKER_0:  But I mean in the sense that.

03:00:41,858 --> 03:00:42,270
SPEAKER_0:  There are.

03:00:44,290 --> 03:00:46,974
SPEAKER_0:  If you look at someone like Andrew Tate, I made a video about him.

03:00:47,426 --> 03:00:50,462
SPEAKER_0:  Even though he's been banned off all the platforms, he gets more views than Brian Rose.

03:00:51,394 --> 03:00:51,870
SPEAKER_0:  and

03:00:52,898 --> 03:00:56,734
SPEAKER_0:  I think it's just like it was a testament to how much Brian Rose was like doing like the grift.

03:00:57,122 --> 03:00:57,822
SPEAKER_0:  that people could.

03:00:58,114 --> 03:01:00,862
SPEAKER_0:  even people who were fans and didn't care about what I said.

03:01:01,314 --> 03:01:04,926
SPEAKER_0:  like couldn't look past, you know, just the constant ask for more and more.

03:01:05,474 --> 03:01:06,558
SPEAKER_0:  Money, people just get burned out.

03:01:07,938 --> 03:01:10,526
SPEAKER_1:  Is there some aspect that you worry about where

03:01:10,914 --> 03:01:12,702
SPEAKER_1:  with a large audience.

03:01:14,402 --> 03:01:17,534
SPEAKER_1:  There seems to be a certain aspect of human nature where people like

03:01:17,954 --> 03:01:20,094
SPEAKER_1:  like the sea others destroyed. Sure.

03:01:20,674 --> 03:01:23,134
SPEAKER_1:  Uh, do you worry about hurting people?

03:01:23,778 --> 03:01:24,670
SPEAKER_1:  They don't deserve it.

03:01:25,314 --> 03:01:26,110
SPEAKER_1:  or rather

03:01:27,906 --> 03:01:28,638
SPEAKER_1:  sort of a...

03:01:28,898 --> 03:01:31,134
SPEAKER_1:  Attacking people with their grifter light.

03:01:32,034 --> 03:01:32,510
SPEAKER_1:  but.

03:01:32,770 --> 03:01:35,166
SPEAKER_1:  They get like a giant storm.

03:01:35,810 --> 03:01:37,406
SPEAKER_1:  of negativity towards them.

03:01:37,666 --> 03:01:38,558
SPEAKER_1:  and therefore sort of.

03:01:39,138 --> 03:01:42,718
SPEAKER_1:  uh... overpoweringly cancel them really hurt them

03:01:42,978 --> 03:01:43,966
SPEAKER_1:  disproportionately.

03:01:44,322 --> 03:01:44,734
SPEAKER_1:  Sure.

03:01:45,378 --> 03:01:45,726
SPEAKER_0:  I mean...

03:01:46,082 --> 03:01:47,838
SPEAKER_0:  I try to be sensitive to...

03:01:48,642 --> 03:01:50,014
SPEAKER_0:  my platform.

03:01:50,370 --> 03:01:51,678
SPEAKER_0:  And as I've grown...

03:01:52,258 --> 03:01:55,742
SPEAKER_0:  I've tried to make sure my video topics have grown with me.

03:01:56,194 --> 03:01:56,702
SPEAKER_0:  and like

03:01:58,786 --> 03:02:05,342
SPEAKER_0:  It does reach this tricky point where if you're exposing a grifter with like 50,000 subs who's doing

03:02:05,570 --> 03:02:06,366
SPEAKER_0:  Some harm.

03:02:06,946 --> 03:02:08,030
SPEAKER_0:  Are you punching down?

03:02:09,282 --> 03:02:10,142
SPEAKER_0:  and

03:02:11,842 --> 03:02:13,214
SPEAKER_0:  So far, there's been enough.

03:02:13,634 --> 03:02:16,254
SPEAKER_0:  high profile things that I can distract myself with.

03:02:16,578 --> 03:02:17,822
SPEAKER_0:  where this has never been a problem.

03:02:18,242 --> 03:02:20,222
SPEAKER_0:  You don't ever want to be...

03:02:22,498 --> 03:02:23,166
SPEAKER_0:  Sort of like.

03:02:23,746 --> 03:02:25,502
SPEAKER_0:  Sir Lancelot in retirement.

03:02:25,762 --> 03:02:26,270
SPEAKER_0:  Um.

03:02:26,754 --> 03:02:28,094
SPEAKER_0:  Where have you heard this analogy?

03:02:28,514 --> 03:02:30,718
SPEAKER_0:  Okay, so there's this great analogy where it's like...

03:02:31,106 --> 03:02:32,702
SPEAKER_0:  Sir Lancelot's the guy who's...

03:02:32,930 --> 03:02:34,398
SPEAKER_0:  Slays the dragon, right?

03:02:34,690 --> 03:02:39,518
SPEAKER_0:  He gets a lot of fame and he gets a lot of fortune for saving the dragon or at least a lot of people love him.

03:02:41,282 --> 03:02:43,038
SPEAKER_0:  But what happens after he slays the first dragon?

03:02:43,970 --> 03:02:46,494
SPEAKER_0:  He's gotta go find a bigger dragon. So he goes find a bigger dragon.

03:02:46,914 --> 03:02:47,230
SPEAKER_0:  and

03:02:47,650 --> 03:02:52,254
SPEAKER_0:  Eventually, depending on how many dragons you think there are in the world, maybe he kills all the dragons.

03:02:53,282 --> 03:03:02,974
SPEAKER_0:  And one day people go see Sir Lancelot and he's in a field with cows and he's chopping their heads. And he's sort of put himself in retirement.

03:03:03,394 --> 03:03:07,742
SPEAKER_0:  but he can't even enjoy the fruits because his whole thing is like, I'm killing the dragon.

03:03:08,386 --> 03:03:12,382
SPEAKER_0:  So I try to be cognizant and I try to always make myself willing to.

03:03:12,962 --> 03:03:14,334
SPEAKER_0:  Hang up my...

03:03:15,106 --> 03:03:17,118
SPEAKER_0:  my suspenders, I guess. I got my hat.

03:03:18,018 --> 03:03:18,974
SPEAKER_0:  I try to be aware of like-

03:03:19,426 --> 03:03:23,518
SPEAKER_0:  If I significantly improve the problem, I put myself out of business.

03:03:24,834 --> 03:03:25,918
SPEAKER_0:  I want to be okay with that.

03:03:26,402 --> 03:03:26,878
SPEAKER_0:  Basically.

03:03:27,650 --> 03:03:28,254
SPEAKER_0:  um...

03:03:28,482 --> 03:03:29,886
SPEAKER_0:  and just be fun with it. I don't-

03:03:30,178 --> 03:03:33,182
SPEAKER_0:  The funny thing is I was more worried about this as like an issue.

03:03:33,954 --> 03:03:34,494
SPEAKER_0:  Earlier?

03:03:35,042 --> 03:03:36,926
SPEAKER_0:  because I thought there was a finite like.

03:03:37,410 --> 03:03:39,710
SPEAKER_0:  I was like, man, I'm gonna solve this faster.

03:03:39,970 --> 03:03:43,454
SPEAKER_0:  especially as it started gaining traction, like I'm going to solve this fast, I got this, you know.

03:03:43,714 --> 03:03:45,118
SPEAKER_0:  Classic Naive.

03:03:45,538 --> 03:03:48,085
SPEAKER_0:  Um, you know, we all think we're so influential.

03:03:48,085 --> 03:03:48,990
SPEAKER_1:  X comes along.

03:03:49,442 --> 03:03:57,598
SPEAKER_0:  Well, yeah, you just get like, with time you get humbled because you talk to people. I've talked to like versions of Coffeezilla.

03:03:57,954 --> 03:03:58,974
SPEAKER_0:  that are older.

03:03:59,682 --> 03:04:00,350
SPEAKER_0:  and

03:04:00,642 --> 03:04:03,806
SPEAKER_0:  It's like, it's like, oh, yeah, they didn't solve it. They probably were better.

03:04:03,906 --> 03:04:08,126
SPEAKER_1:  I just imagine a smoke filled room of just...

03:04:08,354 --> 03:04:09,406
SPEAKER_1:  like retired.

03:04:09,730 --> 03:04:10,558
SPEAKER_1:  Batman.

03:04:11,458 --> 03:04:12,510
SPEAKER_1:  and you're at this young...

03:04:12,802 --> 03:04:13,470
SPEAKER_1:  bright eyed.

03:04:14,242 --> 03:04:16,158
SPEAKER_1:  Oh yeah, yeah.

03:04:16,386 --> 03:04:19,870
SPEAKER_1:  And you don't- Binary-spirited investigator. Yeah, exactly.

03:04:20,546 --> 03:04:25,854
SPEAKER_1:  What's the process of investigation that you can speak to? What is some interesting...

03:04:26,754 --> 03:04:30,142
SPEAKER_1:  things you've learned about what it takes to do great investigations.

03:04:30,786 --> 03:04:34,014
SPEAKER_0:  Sure. Investigations reveal something new.

03:04:34,594 --> 03:04:35,870
SPEAKER_0:  or bring something to light?

03:04:36,482 --> 03:04:37,918
SPEAKER_0:  So I think...

03:04:38,178 --> 03:04:41,246
SPEAKER_0:  What everyone thinks in terms of investigations is like a lot of like...

03:04:41,602 --> 03:04:42,686
SPEAKER_0:  you know, Googling or like...

03:04:42,978 --> 03:04:44,062
SPEAKER_0:  searching through articles.

03:04:44,418 --> 03:04:46,814
SPEAKER_0:  I think that's the first thing you want to get away from.

03:04:47,330 --> 03:04:48,766
SPEAKER_0:  and you wanna try to...

03:04:49,346 --> 03:04:50,206
SPEAKER_0:  Talk to people.

03:04:51,138 --> 03:04:54,526
SPEAKER_0:  doing like the non-obvious things and just trying to get perspectives.

03:04:55,074 --> 03:04:57,566
SPEAKER_0:  that are beyond just what is available.

03:04:57,922 --> 03:04:58,654
SPEAKER_0:  A lot of it's just.

03:04:58,914 --> 03:05:00,926
SPEAKER_0:  having conversations is so enlightening.

03:05:01,410 --> 03:05:01,918
SPEAKER_0:  Um.

03:05:02,242 --> 03:05:05,470
SPEAKER_0:  both to victims and also obviously trying to get, to the people themselves.

03:05:05,954 --> 03:05:06,814
SPEAKER_0:  Secondly...

03:05:07,362 --> 03:05:08,254
SPEAKER_0:  There's sometimes some-

03:05:08,514 --> 03:05:11,646
SPEAKER_0:  analysis you can generate that's meaningful like blockchain evidence.

03:05:12,002 --> 03:05:13,406
SPEAKER_0:  So in the case of SafeMoon...

03:05:13,634 --> 03:05:14,270
SPEAKER_0:  For example.

03:05:14,754 --> 03:05:15,678
SPEAKER_0:  going back to that.

03:05:16,738 --> 03:05:20,990
SPEAKER_0:  I found someone's secret account where they were pumping, dumping coins. They were saying things like...

03:05:21,250 --> 03:05:22,558
SPEAKER_0:  Who saw it? I'll- I'll-

03:05:22,818 --> 03:05:27,934
SPEAKER_0:  you know, I'm so mad at the guy who sold, F the guy who sold, and you look at his account and he was the guy selling.

03:05:28,354 --> 03:05:29,758
SPEAKER_0:  And it's like that is just

03:05:29,986 --> 03:05:30,686
SPEAKER_0:  That's great stuff.

03:05:30,946 --> 03:05:31,390
SPEAKER_0:  So.

03:05:32,194 --> 03:05:35,486
SPEAKER_0:  Digging through the blockchain, I've gained some skills there.

03:05:35,874 --> 03:05:36,446
SPEAKER_0:  Um...

03:05:36,674 --> 03:05:37,950
SPEAKER_0:  And that's kind of this fun.

03:05:38,402 --> 03:05:40,702
SPEAKER_0:  I guess I would say it's this weird edge I have right now.

03:05:41,090 --> 03:05:41,886
SPEAKER_0:  because a lot of people.

03:05:42,370 --> 03:05:43,550
SPEAKER_0:  Don't know too much about that.

03:05:43,842 --> 03:05:46,206
SPEAKER_0:  And so I have this weird expertise that works now

03:05:46,562 --> 03:05:48,158
SPEAKER_0:  I don't think that'll work forever, because I think people will.

03:05:48,418 --> 03:05:50,366
SPEAKER_0:  kind of figure out how to do very similar analyses.

03:05:50,690 --> 03:05:51,038
SPEAKER_0:  But.

03:05:51,682 --> 03:05:55,057
SPEAKER_0:  So it's like kind of an interesting edge right now that I have.

03:05:55,057 --> 03:05:58,057
SPEAKER_1:  So that's like a data driven investigation, but you also do interviews, right?

03:05:58,057 --> 03:06:05,534
SPEAKER_0:  Yeah, definitely. And then also recently I've tried to get more response, speaking to your point about like as your platform gets bigger, you need more responsibility.

03:06:05,826 --> 03:06:07,486
SPEAKER_0:  I've tried to get much more.

03:06:08,738 --> 03:06:12,414
SPEAKER_0:  responsible about like reaching out or somehow giving the

03:06:12,706 --> 03:06:14,430
SPEAKER_0:  subject some way to talk.

03:06:15,042 --> 03:06:18,942
SPEAKER_0:  because I think in early on, I was such a small channel that A, I-

03:06:19,202 --> 03:06:20,926
SPEAKER_0:  If I asked them, they wouldn't answer.

03:06:21,890 --> 03:06:25,214
SPEAKER_0:  B, I kind of felt like I was launching these videos into the abyss.

03:06:26,050 --> 03:06:29,310
SPEAKER_0:  And when some of my videos had real traction, I was like, okay.

03:06:29,858 --> 03:06:30,718
SPEAKER_0:  Hang on a second.

03:06:31,874 --> 03:06:34,558
SPEAKER_0:  Double check this, let's triple check it. Let's try to make sure.

03:06:35,074 --> 03:06:35,454
SPEAKER_0:  Um.

03:06:35,842 --> 03:06:38,302
SPEAKER_0:  All this stuff is correct and there's no other side of the story.

03:06:38,914 --> 03:06:42,206
SPEAKER_0:  I'll say this has interesting implications because, for example,

03:06:42,466 --> 03:06:45,662
SPEAKER_0:  I investigated this thing called Genesis, their billion-dollar crypto lender.

03:06:46,146 --> 03:06:47,998
SPEAKER_0:  And my conclusion was that they were insolvent.

03:06:49,186 --> 03:06:54,942
SPEAKER_0:  That's a huge accusation. So what do you do? Well, I emailed their press team, everybody. I said, hey, I think you're insolvent.

03:06:55,266 --> 03:06:57,566
SPEAKER_0:  I think you're this, I think I laid out all my accusations.

03:06:57,922 --> 03:06:59,326
SPEAKER_0:  And I said, you have till.

03:06:59,618 --> 03:07:00,510
SPEAKER_0:  I think 2 p.m.

03:07:00,930 --> 03:07:01,982
SPEAKER_0:  the next day to respond.

03:07:03,650 --> 03:07:04,286
SPEAKER_0:  at 8 a.m.

03:07:04,578 --> 03:07:05,182
SPEAKER_0:  before.

03:07:05,474 --> 03:07:06,206
SPEAKER_0:  I made my video.

03:07:06,498 --> 03:07:09,598
SPEAKER_0:  They announced to all their investors that they're freezing withdrawals. They don't have the money.

03:07:10,402 --> 03:07:10,910
SPEAKER_0:  So they front.

03:07:11,778 --> 03:07:17,662
SPEAKER_0:  I don't know if they saw the inter, like I don't know if they actually saw that email. I don't want to take credit for collapsing them or whatever, but...

03:07:18,274 --> 03:07:22,142
SPEAKER_0:  My point is, had I not taken that level of kind of care and just said,

03:07:22,562 --> 03:07:24,638
SPEAKER_0:  Hey, you're a scammer, you're frauds.

03:07:24,994 --> 03:07:25,982
SPEAKER_0:  Ironically...

03:07:26,242 --> 03:07:29,854
SPEAKER_0:  Could I have done more good by allowing people to withdraw their money early?

03:07:30,562 --> 03:07:34,398
SPEAKER_0:  I made some tweets that people did see that like some people got their money out.

03:07:34,786 --> 03:07:38,622
SPEAKER_0:  but my YouTube audience is much larger and could I have helped more people had I?

03:07:38,850 --> 03:07:39,294
SPEAKER_0:  NOT

03:07:39,682 --> 03:07:43,807
SPEAKER_0:  given them basically the ability to know what I was gonna produce when I produced it. TEXT BOARD

03:07:43,807 --> 03:07:44,990
SPEAKER_1:  your life is difficult.

03:07:45,442 --> 03:07:50,558
SPEAKER_1:  because you can potentially hurt the company that doesn't deserve it if you're wrong

03:07:51,170 --> 03:07:51,998
SPEAKER_1:  or you.

03:07:52,578 --> 03:07:55,550
SPEAKER_1:  If you're right and you warn the company, you might hurt the...

03:07:56,290 --> 03:07:56,830
SPEAKER_1:  Oof.

03:07:58,850 --> 03:08:04,478
SPEAKER_1:  Um, well, I'm glad your wife is a supporter and keeps you strong. That's a tough, tough decision.

03:08:05,346 --> 03:08:05,854
SPEAKER_1:  Um...

03:08:06,210 --> 03:08:11,166
SPEAKER_1:  Ultimately, I guess you want to err on the side of the individual people.

03:08:12,322 --> 03:08:14,334
SPEAKER_1:  of the investors and so on.

03:08:14,850 --> 03:08:17,502
SPEAKER_1:  but it's tough, it's always a really, really tricky decision.

03:08:18,402 --> 03:08:18,974
SPEAKER_1:  Very tricky.

03:08:22,178 --> 03:08:23,326
SPEAKER_1:  That's so interesting.

03:08:23,778 --> 03:08:24,766
SPEAKER_1:  And then...

03:08:26,466 --> 03:08:28,478
SPEAKER_1:  The thing I've seen in your interviews, I-

03:08:29,218 --> 03:08:30,974
SPEAKER_1:  that I don't remember, because I think...

03:08:31,202 --> 03:08:34,654
SPEAKER_1:  When you I watched you earlier in your career

03:08:34,978 --> 03:08:38,462
SPEAKER_1:  You were a little bit harsher, you were like trollier.

03:08:39,490 --> 03:08:42,942
SPEAKER_1:  You're having a little more fun. Sure. I've seen you recently.

03:08:43,202 --> 03:08:44,414
SPEAKER_1:  You do have the fun.

03:08:44,962 --> 03:08:46,398
SPEAKER_1:  But whenever you interview...

03:08:46,658 --> 03:08:48,318
SPEAKER_1:  You seem respectful, like-

03:08:48,706 --> 03:08:50,398
SPEAKER_1:  Like you attack in good faith.

03:08:50,882 --> 03:08:53,886
SPEAKER_1:  which is really important for an interviewer. So then people...

03:08:54,146 --> 03:08:56,382
SPEAKER_1:  can go on and actually try to defend themselves.

03:08:56,802 --> 03:09:02,366
SPEAKER_1:  That's really important signal to send to people because then you're not just about tearing down, you're after like the-

03:09:03,266 --> 03:09:08,510
SPEAKER_1:  It's cliche to say, but the truth, you're really trying to actually investigate in good faith.

03:09:08,738 --> 03:09:12,638
SPEAKER_1:  which is great, so that signal is out there. So people like SBF could.

03:09:13,186 --> 03:09:16,190
SPEAKER_1:  Like he should go on your platform, I think.

03:09:16,450 --> 03:09:17,342
SPEAKER_1:  I mean, now it's like.

03:09:18,306 --> 03:09:19,166
SPEAKER_1:  in full.

03:09:19,938 --> 03:09:27,358
SPEAKER_1:  not just like a half-assed conversation on Twitter space, but in full. So that's great that that signal's out there. But of course the downside of sort of.

03:09:27,682 --> 03:09:28,702
SPEAKER_1:  as you become.

03:09:28,962 --> 03:09:31,774
SPEAKER_1:  more famous people might be scared to sort of go on.

03:09:32,226 --> 03:09:36,350
SPEAKER_1:  But you do put that signal being respectful out there, which is really, really important.

03:09:36,578 --> 03:09:37,438
SPEAKER_1:  You know, it's interesting.

03:09:38,146 --> 03:09:42,206
SPEAKER_0:  It surprises me. I know it surprises other people because other people have commented.

03:09:42,562 --> 03:09:45,630
SPEAKER_0:  but it consistently surprises me how many people still talk to me.

03:09:46,434 --> 03:09:46,910
SPEAKER_0:  Uh...

03:09:47,522 --> 03:09:53,470
SPEAKER_0:  And maybe it's because they, and I really do give a good attempt to try to argue in good faith. I try not to just like-

03:09:53,698 --> 03:09:58,654
SPEAKER_0:  load up ad homonyms or anything like that. I just try to present the evidence and let the audience make up their mind.

03:09:59,138 --> 03:09:59,678
SPEAKER_0:  um...

03:10:00,642 --> 03:10:05,918
SPEAKER_0:  But it surprises me sometimes that people will just be like, yeah, they want to talk, they want to talk, they want to talk.

03:10:06,306 --> 03:10:06,910
SPEAKER_0:  I think.

03:10:08,450 --> 03:10:09,310
SPEAKER_0:  It's very.

03:10:09,794 --> 03:10:10,590
SPEAKER_0:  Human in a way.

03:10:11,106 --> 03:10:12,574
SPEAKER_0:  And I think it's like almost.

03:10:13,986 --> 03:10:19,966
SPEAKER_0:  It's almost like good. Like one of the things that is always told to everyone who's gonna talk to the cops like you should never talk to the cops, whatever.

03:10:20,386 --> 03:10:20,862
SPEAKER_0:  Tom.

03:10:21,378 --> 03:10:23,166
SPEAKER_0:  Which is true, you shouldn't talk to the cops.

03:10:23,426 --> 03:10:26,846
SPEAKER_0:  Because even if you're innocent, they can use your words, they can twist your words with that.

03:10:27,426 --> 03:10:27,742
SPEAKER_0:  But.

03:10:28,066 --> 03:10:30,302
SPEAKER_0:  There's something that gets lost in that.

03:10:30,722 --> 03:10:32,414
SPEAKER_0:  like almost robotic like

03:10:32,642 --> 03:10:33,694
SPEAKER_0:  you know, self-interest.

03:10:34,370 --> 03:10:37,278
SPEAKER_0:  that I think having open conversations.

03:10:38,018 --> 03:10:41,822
SPEAKER_0:  Even if you've done something wrong, I think there's something really compelling about that.

03:10:42,050 --> 03:10:45,630
SPEAKER_0:  that continues to make people talk in interrogation rooms.

03:10:45,922 --> 03:10:47,934
SPEAKER_0:  in Twitter spaces, wherever you are.

03:10:48,226 --> 03:10:49,086
SPEAKER_0:  Regardless of.

03:10:49,314 --> 03:10:51,326
SPEAKER_0:  whether you totally shouldn't be talking.

03:10:51,842 --> 03:10:52,286
SPEAKER_0:  and

03:10:52,514 --> 03:10:56,830
SPEAKER_0:  I don't want to downplay that. That's actually really important. I mean, it's like a lot of-

03:10:57,058 --> 03:11:00,414
SPEAKER_0:  Cases get solved, a lot of investigations go farther.

03:11:00,642 --> 03:11:02,430
SPEAKER_0:  because people sort of make the...

03:11:02,786 --> 03:11:04,222
SPEAKER_0:  miscalculation to talk.

03:11:04,482 --> 03:11:08,446
SPEAKER_0:  but I think it's like almost important in a way that we have that human bias to like.

03:11:09,250 --> 03:11:11,102
SPEAKER_0:  Connect in spite of self-interest.

03:11:11,362 --> 03:11:14,430
SPEAKER_1:  Yeah, but also they're judging the integrity.

03:11:14,786 --> 03:11:16,350
SPEAKER_1:  and the good faith of the other person.

03:11:16,738 --> 03:11:20,094
SPEAKER_1:  So I think when people consume your content, especially your latest content,

03:11:20,802 --> 03:11:21,982
SPEAKER_1:  They know that you're...

03:11:22,754 --> 03:11:23,550
SPEAKER_1:  a good person.

03:11:24,802 --> 03:11:26,238
SPEAKER_1:  I found myself.

03:11:27,458 --> 03:11:29,406
SPEAKER_1:  Like there's a lot of journalists that reach out to me.

03:11:30,434 --> 03:11:33,022
SPEAKER_1:  and I find myself like not wanting to talk to them.

03:11:33,474 --> 03:11:36,606
SPEAKER_1:  because I don't know if the other person on the side is coming in good faith.

03:11:37,314 --> 03:11:39,550
SPEAKER_1:  Even on silly stuff, I'm not a- Same way.

03:11:39,874 --> 03:11:41,022
SPEAKER_1:  Like I'm not a...

03:11:41,538 --> 03:11:45,630
SPEAKER_1:  I don't have anything to hide. You don't really have anything to hide, but you don't know.

03:11:46,978 --> 03:11:48,853
SPEAKER_1:  what their spin is.

03:11:48,853 --> 03:11:50,206
SPEAKER_0:  Can I tell you an example?

03:11:50,786 --> 03:11:55,422
SPEAKER_0:  I'm dying because I believe so strongly that journalists have done themselves such a disservice.

03:11:55,938 --> 03:11:57,566
SPEAKER_0:  Okay, one of the truest things is that like

03:11:57,826 --> 03:12:01,694
SPEAKER_0:  Everyone loves journalism in theory and almost everyone

03:12:02,114 --> 03:12:04,030
SPEAKER_0:  dislikes journalists as a whole.

03:12:04,354 --> 03:12:09,310
SPEAKER_0:  Like there's a deep distrust of journalists and there's a deep love for journalism. This is Weird Disconnect.

03:12:09,794 --> 03:12:13,502
SPEAKER_0:  I think a lot of it can be summarized in, there's this book called The Journey to the West.

03:12:13,986 --> 03:12:14,430
SPEAKER_0:  Ah.

03:12:15,842 --> 03:12:17,374
SPEAKER_0:  Is that thing called the journalist and the murderer?

03:12:17,890 --> 03:12:19,774
SPEAKER_0:  It's written by Janet Malcolm.

03:12:20,418 --> 03:12:22,046
SPEAKER_0:  the first line of this book.

03:12:22,434 --> 03:12:26,302
SPEAKER_0:  is that every journalist who knows what they're doing...

03:12:26,978 --> 03:12:27,678
SPEAKER_0:  Who isn't too s-

03:12:28,482 --> 03:12:32,318
SPEAKER_0:  is smart enough to know what they're doing, knows what they're doing is deeply unethical.

03:12:32,770 --> 03:12:34,782
SPEAKER_0:  or something like that, and what they're talking about.

03:12:35,138 --> 03:12:38,334
SPEAKER_0:  is that there's a tradition in journalism to betray the subject.

03:12:38,914 --> 03:12:39,422
SPEAKER_0:  to.

03:12:40,002 --> 03:12:41,022
SPEAKER_0:  Lie to them.

03:12:41,410 --> 03:12:42,974
SPEAKER_0:  in the hopes of getting a story.

03:12:43,234 --> 03:12:45,662
SPEAKER_0:  and play to their ego and to their...

03:12:45,890 --> 03:12:47,006
SPEAKER_0:  sense of self.

03:12:47,362 --> 03:12:53,694
SPEAKER_0:  to make it seem like you're gonna write one article and you stab them in the back at the end when you press publish and you write the totally different article.

03:12:53,954 --> 03:12:56,574
SPEAKER_0:  This is what actually everyone hates about journalists.

03:12:56,834 --> 03:13:03,518
SPEAKER_0:  And it's happened to me before. So I did a story like way back in the day, I got interviewed about something that was like data with YouTube.

03:13:04,578 --> 03:13:09,886
SPEAKER_0:  I made a few comments about data on YouTube, and somehow by the time the article got published, I had had a lot of comments aboutá¹

03:13:10,242 --> 03:13:13,118
SPEAKER_0:  me endorsing their opinion that PewDiePie is an anti-Semite.

03:13:13,890 --> 03:13:19,454
SPEAKER_0:  And I'm like, I reach out to this person and I say, I never said that. Like, what are you, how did you even twist my words to say that?

03:13:19,682 --> 03:13:22,334
SPEAKER_0:  And I felt so disgusted and betrayed to have like...

03:13:23,234 --> 03:13:28,158
SPEAKER_0:  I'm like this mouthpiece for an ideology or like a thought that I do not actually agree with.

03:13:29,058 --> 03:13:29,502
SPEAKER_0:  So.

03:13:30,210 --> 03:13:34,750
SPEAKER_0:  And when journalists do this, they think, well, I'm never gonna interview this person again, so it's okay.

03:13:34,978 --> 03:13:35,326
SPEAKER_0:  So it's like.

03:13:35,970 --> 03:13:38,974
SPEAKER_0:  almost like the ends justify the means, I get the story.

03:13:39,586 --> 03:13:45,470
SPEAKER_0:  But the ends don't justify the means because you've now undermined the entire field's credibility.

03:13:45,794 --> 03:13:46,590
SPEAKER_0:  with that person.

03:13:46,914 --> 03:13:48,798
SPEAKER_0:  And when that happens, enough time.

03:13:49,346 --> 03:13:50,622
SPEAKER_0:  times you end up.

03:13:50,850 --> 03:13:55,294
SPEAKER_0:  sitting across from Lex Friedman and it's like, well, I don't know if they're gonna represent me fairly. Because the.

03:13:55,810 --> 03:13:56,990
SPEAKER_0:  Base Assumption.

03:13:57,314 --> 03:14:06,430
SPEAKER_0:  is that regardless of what the journalist says, they could betray you and they might betray you at the end of the day and be saying you're great while they're secretly writing like a hit piece about like

03:14:06,754 --> 03:14:07,582
SPEAKER_0:  you know how much.

03:14:07,874 --> 03:14:08,766
SPEAKER_0:  You know, you're a bad.

03:14:09,122 --> 03:14:10,206
SPEAKER_0:  force for the world.

03:14:10,882 --> 03:14:11,582
SPEAKER_0:  Where?

03:14:11,842 --> 03:14:13,982
SPEAKER_0:  Whereas there's an alternate universe.

03:14:14,370 --> 03:14:18,078
SPEAKER_0:  where if the journalist was somewhat upfront about their approach...

03:14:18,722 --> 03:14:22,398
SPEAKER_0:  Or at least didn't mislead and didn't say like, I love you. I think you're great.

03:14:22,882 --> 03:14:23,422
SPEAKER_0:  Um...

03:14:24,738 --> 03:14:25,630
SPEAKER_0:  you would end up with.

03:14:26,082 --> 03:14:27,358
SPEAKER_0:  less access.

03:14:27,906 --> 03:14:32,126
SPEAKER_0:  but you would end up with more trusted journalism, which I think in the long run would be.

03:14:34,050 --> 03:14:35,198
SPEAKER_0:  We get more access.

03:14:35,650 --> 03:14:40,254
SPEAKER_0:  I think in the long term, yeah, but all of these, like everything we're talking about is long-term games versus short-term games.

03:14:40,546 --> 03:14:52,045
SPEAKER_0:  In the short term, you get more access if you suck up to the person, if you say this, say this, say this, and you stab them in the back later. Long-term, you build a long-term reputation, and people trust you, it actually matters more.

03:14:52,045 --> 03:14:57,854
SPEAKER_1:  It's nice when that reputation is your own individual. It's like you have a YouTube channel, you're one individual.

03:14:58,530 --> 03:15:00,638
SPEAKER_1:  So people trust that because

03:15:00,930 --> 03:15:03,934
SPEAKER_1:  You have a huge disincentive to scoop people over.

03:15:05,218 --> 03:15:07,294
SPEAKER_1:  I feel like if you're in New York Times.

03:15:07,874 --> 03:15:11,390
SPEAKER_1:  If you screw somebody over, the New York Times gets the hit, not you individually.

03:15:11,810 --> 03:15:12,766
SPEAKER_1:  so you can like...

03:15:13,154 --> 03:15:13,854
SPEAKER_1:  Uh...

03:15:14,658 --> 03:15:16,382
SPEAKER_1:  you're safer, but like.

03:15:16,834 --> 03:15:25,726
SPEAKER_1:  The reason I don't screw people over is I know that, well, there's my own ethics and integrity. Also, there's a strong incentive to like.

03:15:25,986 --> 03:15:28,574
SPEAKER_1:  because you're now, I'm going, that person is gonna go.

03:15:29,058 --> 03:15:32,478
SPEAKER_1:  public with me screwing them over completely lying about everything.

03:15:32,802 --> 03:15:34,686
SPEAKER_1:  how I presented the person, for example.

03:15:35,042 --> 03:15:38,526
SPEAKER_1:  And that's just gonna, you know, that's gonna percolate throughout.

03:15:38,946 --> 03:15:41,790
SPEAKER_1:  the populace and they're gonna be like, Alex is the person that's at the line.

03:15:42,114 --> 03:15:43,454
SPEAKER_1:  uh... line second shit

03:15:43,874 --> 03:15:45,630
SPEAKER_1:  And so there's a huge disincentive to do that.

03:15:46,018 --> 03:15:47,614
SPEAKER_1:  Yeah, yeah, I still have that.

03:15:47,746 --> 03:15:52,574
SPEAKER_0:  That is what's interesting about the move towards independent journalism.

03:15:53,058 --> 03:15:53,598
SPEAKER_0:  Um...

03:15:53,858 --> 03:15:56,318
SPEAKER_0:  I think we'll probably end up at a space where...

03:15:57,986 --> 03:16:02,590
SPEAKER_0:  It's so interesting. Mainstream journalism has so much work to do to repair the trust.

03:16:03,074 --> 03:16:04,638
SPEAKER_0:  with the average individual.

03:16:05,218 --> 03:16:05,758
SPEAKER_0:  Um...

03:16:06,658 --> 03:16:12,126
SPEAKER_0:  and it's going to take a lot of self-reflection. I've talked to a few mainstream journalists about this.

03:16:12,610 --> 03:16:13,278
SPEAKER_0:  and

03:16:13,762 --> 03:16:16,478
SPEAKER_0:  A lot of them will admit it behind closed doors, but like...

03:16:16,866 --> 03:16:21,470
SPEAKER_0:  There's this general sense that, oh, the public's not being fair to us. They're very self-

03:16:22,626 --> 03:16:23,774
SPEAKER_0:  Defensive, I guess, in a way.

03:16:24,162 --> 03:16:25,950
SPEAKER_0:  And I understand why, because...

03:16:27,042 --> 03:16:30,206
SPEAKER_0:  Sometimes it's just a few bad apples that ruin it for everybody.

03:16:31,362 --> 03:16:34,174
SPEAKER_0:  without the acknowledgement of the deep distrust.

03:16:35,394 --> 03:16:36,958
SPEAKER_0:  that they have with...

03:16:37,506 --> 03:16:41,118
SPEAKER_0:  good portion of our society, there's no way to rebuild that.

03:16:41,506 --> 03:16:43,710
SPEAKER_0:  just like when there's no acknowledgement of the

03:16:43,938 --> 03:16:46,302
SPEAKER_0:  corruption of the 2008 financial crash.

03:16:46,626 --> 03:16:54,014
SPEAKER_0:  There's no way to rebuild that, even if most bankers, most traders are not unethical or duplicitous or-

03:16:54,882 --> 03:17:01,374
SPEAKER_0:  totally normal people who maybe aren't deserving of the bad reputation, but you have to acknowledge the damage that's been done.

03:17:01,730 --> 03:17:02,142
SPEAKER_0:  Bye.

03:17:02,402 --> 03:17:05,150
SPEAKER_0:  bad actors before you can like heal that system.

03:17:05,634 --> 03:17:11,070
SPEAKER_1:  Well, what do you think about Elon just opening the door to a journalist to see all the emails that were sent?

03:17:11,554 --> 03:17:11,934
SPEAKER_1:  uh, the

03:17:12,322 --> 03:17:13,822
SPEAKER_1:  quote unquote, Twitter files.

03:17:14,658 --> 03:17:17,822
SPEAKER_0:  Yeah, that's really interesting. I mean, I saw a lot of-

03:17:18,562 --> 03:17:21,566
SPEAKER_0:  I'm like in this weird thing where I see, I'm so.

03:17:22,146 --> 03:17:26,046
SPEAKER_0:  I follow a lot of independent people and I follow a lot of mainstream journalists and the-

03:17:26,978 --> 03:17:28,958
SPEAKER_0:  that are very polar opposite takes on that.

03:17:29,346 --> 03:17:33,982
SPEAKER_1:  People really quickly politicize it, but to me, the thing that was fascinating is just the transparency.

03:17:34,242 --> 03:17:37,598
SPEAKER_1:  that I've never seen from one of the really frustrating things to me.

03:17:37,986 --> 03:17:41,566
SPEAKER_1:  A lot of this podcast has been about interviewing tech people, CEOs, and so on.

03:17:41,986 --> 03:17:44,158
SPEAKER_1:  and they're just so guarded with everything.

03:17:44,642 --> 03:17:47,070
SPEAKER_1:  It's hard to get to and so it's nice to get.

03:17:48,290 --> 03:17:48,766
SPEAKER_1:  Um.

03:17:49,218 --> 03:17:51,646
SPEAKER_1:  Hopefully this is a signal look you can be transparent

03:17:52,162 --> 03:17:53,342
SPEAKER_1:  Like this is signaled to...

03:17:53,570 --> 03:17:54,878
SPEAKER_1:  Increase transparency.

03:17:55,906 --> 03:17:56,798
SPEAKER_1:  Hopefully so.

03:17:56,898 --> 03:17:57,246
SPEAKER_0:  I don't.

03:17:58,082 --> 03:18:01,502
SPEAKER_0:  Yeah, it's been tribalized so quickly, it's like I've lost a lot of faith in that. You

03:18:01,826 --> 03:18:04,798
SPEAKER_0:  And unfortunately, it's been this like bludgeon match of like

03:18:05,890 --> 03:18:06,462
SPEAKER_0:  You know?

03:18:07,458 --> 03:18:08,766
SPEAKER_0:  If you're on the right, you think.

03:18:09,378 --> 03:18:12,574
SPEAKER_0:  It's uncovering the greatest story ever about Hunter Biden. If you're on the left, you think.

03:18:13,090 --> 03:18:19,166
SPEAKER_0:  They were just silencing revenge porn pics of Hunter Biden. So therefore it was justified. And by the way, Trump also.

03:18:19,490 --> 03:18:23,998
SPEAKER_0:  sent messages to Twitter, so doesn't that mean that we should be criticizing Twitter? I mean, this is animals.

03:18:24,226 --> 03:18:27,454
SPEAKER_0:  goes back to why I don't touch politics is because I think.

03:18:28,130 --> 03:18:32,254
SPEAKER_0:  As many problems as I have, I think when you become a journalist that-

03:18:32,546 --> 03:18:36,254
SPEAKER_0:  not even a political journalist, when you become a journalist in politics.

03:18:36,482 --> 03:18:37,182
SPEAKER_0:  You have like

03:18:37,410 --> 03:18:39,838
SPEAKER_0:  twice the problem, so I'm happy to be.

03:18:40,226 --> 03:18:41,886
SPEAKER_0:  Well outside of that.

03:18:42,146 --> 03:18:42,974
SPEAKER_0:  kind of sphere.

03:18:43,298 --> 03:18:49,214
SPEAKER_1:  But it's an interesting, forget Twitter files, but Twitter itself is really, really...

03:18:49,442 --> 03:18:50,046
SPEAKER_1:  Interesting.

03:18:50,594 --> 03:18:51,230
SPEAKER_1:  forearm.

03:18:51,746 --> 03:18:54,590
SPEAKER_1:  the virality of information transfer.

03:18:55,298 --> 03:18:57,822
SPEAKER_1:  And from a journalistic perspective, it's like...

03:18:58,274 --> 03:19:00,862
SPEAKER_1:  how information travels, how it becomes distributed.

03:19:01,666 --> 03:19:02,430
SPEAKER_1:  What do you think?

03:19:03,010 --> 03:19:03,806
SPEAKER_0:  What do you think about?

03:19:04,162 --> 03:19:04,766
SPEAKER_0:  Twitter.

03:19:05,762 --> 03:19:07,358
SPEAKER_0:  I'm always conflicted on Twitter because

03:19:07,938 --> 03:19:08,542
SPEAKER_0:  I almost

03:19:09,090 --> 03:19:09,502
SPEAKER_0:  hate

03:19:09,954 --> 03:19:10,814
SPEAKER_0:  how much I...

03:19:11,458 --> 03:19:12,862
SPEAKER_0:  Enjoy using it.

03:19:13,442 --> 03:19:15,326
SPEAKER_0:  I'm like, this is like this mindless bird app.

03:19:15,714 --> 03:19:16,670
SPEAKER_0:  consuming my time.

03:19:17,346 --> 03:19:17,854
SPEAKER_0:  Um.

03:19:18,082 --> 03:19:19,678
SPEAKER_0:  It's this incredible networking tool.

03:19:20,450 --> 03:19:23,550
SPEAKER_0:  But what's weird is, when I think about my own presence on Twitter...

03:19:24,098 --> 03:19:27,294
SPEAKER_0:  They've almost made it too easy to like say something that.

03:19:27,522 --> 03:19:28,574
SPEAKER_0:  you've half thought.

03:19:29,026 --> 03:19:31,582
SPEAKER_0:  Like the friction to send a tweet is so much less than like

03:19:31,842 --> 03:19:34,974
SPEAKER_0:  if I'm gonna make a YouTube video, there's several points at which I'm like, well...

03:19:35,298 --> 03:19:36,542
SPEAKER_0:  What's the other side? What's this? What's that?

03:19:37,186 --> 03:19:38,046
SPEAKER_0:  There's no friction there.

03:19:38,466 --> 03:19:40,638
SPEAKER_0:  And so one thing I've noticed is everyone I follow on Twitter.

03:19:42,146 --> 03:19:45,406
SPEAKER_0:  A lot of them, after reading all their tweets, I think nothing-

03:19:45,954 --> 03:19:47,134
SPEAKER_0:  More of them, nothing less of them.

03:19:47,458 --> 03:19:52,926
SPEAKER_0:  but there's a lot of them that I think less of. And I don't think I've ever had an experience where I've read someone's tweets.

03:19:53,474 --> 03:19:54,494
SPEAKER_0:  And I think more of them?

03:19:54,722 --> 03:19:57,310
SPEAKER_0:  in a way. And I'm like, what does that say that

03:19:58,722 --> 03:20:00,990
SPEAKER_1:  Yeah, what is that? Like there's so many people I-

03:20:01,794 --> 03:20:02,846
SPEAKER_1:  Admire.

03:20:03,650 --> 03:20:07,358
SPEAKER_1:  that the worst of them is represented on Twitter.

03:20:07,586 --> 03:20:08,574
SPEAKER_1:  Like, uh...

03:20:09,058 --> 03:20:10,183
SPEAKER_1:  There's a lot of-

03:20:10,183 --> 03:20:11,683
SPEAKER_0:  There's a million examples.

03:20:11,683 --> 03:20:13,182
SPEAKER_1:  like snarky and

03:20:13,858 --> 03:20:16,702
SPEAKER_1:  sometimes mocking and derisive and...

03:20:16,962 --> 03:20:19,230
SPEAKER_1:  Negative and like emotional messes

03:20:19,842 --> 03:20:20,414
SPEAKER_1:  uh...

03:20:21,250 --> 03:20:22,686
SPEAKER_1:  I don't know, yeah, what is that?

03:20:23,010 --> 03:20:24,638
SPEAKER_1:  Um, maybe...

03:20:24,962 --> 03:20:31,678
SPEAKER_1:  Maybe we shouldn't criticize it and accept that as like a beautiful, raw aspect of that human being, but not encompassing.

03:20:32,034 --> 03:20:33,909
SPEAKER_1:  not representing the full entire idea.

03:20:33,909 --> 03:20:34,974
SPEAKER_0:  Let's reflect like

03:20:35,234 --> 03:20:36,702
SPEAKER_0:  It's impossible to not.

03:20:37,314 --> 03:20:45,406
SPEAKER_0:  reflected to some extent, or you'd have to counter that bias really carefully because that is them, it is a thought they had, it's just probably something that should have been an unexpressed.

03:20:46,018 --> 03:20:46,782
SPEAKER_0:  thought perhaps.

03:20:47,138 --> 03:20:47,742
SPEAKER_0:  Um...

03:20:48,386 --> 03:20:50,942
SPEAKER_0:  So yeah, I kind of wonder like my.

03:20:51,234 --> 03:20:54,334
SPEAKER_0:  I'm like, should I be on Twitter? But the problem is, it's such a-

03:20:54,818 --> 03:20:57,182
SPEAKER_0:  a great place where so many

03:20:58,018 --> 03:21:00,542
SPEAKER_0:  Like, so much of the news happens on Twitter, so much of-

03:21:01,346 --> 03:21:05,470
SPEAKER_0:  the journalism breaks on Twitter. Even people in the New York Times, will tweet their scoop.

03:21:05,826 --> 03:21:07,646
SPEAKER_0:  And they'll put that out on Twitter first.

03:21:08,002 --> 03:21:10,046
SPEAKER_0:  So it's this really weird thing where...

03:21:10,306 --> 03:21:11,742
SPEAKER_0:  I'd love to be off it.

03:21:11,970 --> 03:21:14,174
SPEAKER_0:  and it's like too useful for my job, but I kind of.

03:21:14,754 --> 03:21:15,358
SPEAKER_0:  Kinda hate it.

03:21:15,554 --> 03:21:18,110
SPEAKER_1:  No, no, you need to... well, it depends, but...

03:21:18,466 --> 03:21:19,998
SPEAKER_1:  From my perspective, you should be on it.

03:21:20,578 --> 03:21:25,726
SPEAKER_1:  Oh, I definitely am. Yeah. So like a coffee zone should definitely be on Twitter.

03:21:26,082 --> 03:21:26,526
SPEAKER_1:  But...

03:21:27,618 --> 03:21:31,038
SPEAKER_1:  have developed the calluses in the

03:21:31,842 --> 03:21:33,470
SPEAKER_1:  the strength to...

03:21:33,698 --> 03:21:36,286
SPEAKER_1:  not give into the sort of the lesser aspects like.

03:21:36,578 --> 03:21:42,046
SPEAKER_1:  Because you're silly, you're funny, you can be cutting with your humor.

03:21:42,434 --> 03:21:44,766
SPEAKER_1:  I wouldn't give into the...

03:21:46,242 --> 03:21:49,598
SPEAKER_1:  like the darker aspects of that, like low effort negativity.

03:21:50,178 --> 03:21:53,918
SPEAKER_1:  If you're the way you are in your videos, I would say if you're ever negative.

03:21:54,210 --> 03:21:56,510
SPEAKER_1:  or making fun of stuff, I think that's high effort.

03:21:57,154 --> 03:21:57,470
SPEAKER_1:  So.

03:21:57,730 --> 03:22:00,702
SPEAKER_1:  I would still put a lot of effort into it, calmly thinking through.

03:22:01,090 --> 03:22:01,406
SPEAKER_1:  that.

03:22:02,178 --> 03:22:05,086
SPEAKER_1:  because, and also not giving into the dopamine.

03:22:05,506 --> 03:22:08,766
SPEAKER_1:  Desire to do to say something that's gonna get a lot of likes

03:22:09,346 --> 03:22:13,310
SPEAKER_1:  uh... you know i have that all the time you use twitter enough you realize

03:22:13,922 --> 03:22:16,606
SPEAKER_1:  certain messages that are going to get more likes than others.

03:22:16,994 --> 03:22:18,119
SPEAKER_1:  And, uh...

03:22:18,119 --> 03:22:22,302
SPEAKER_0:  the ones that are extreme more extreme yeah and like emotional like

03:22:23,010 --> 03:22:29,854
SPEAKER_0:  Lex is an idiot or like Lex is the greatest human being ever. It's much better than, oh wow, what a polite nuanced conversation.

03:22:30,114 --> 03:22:32,862
SPEAKER_0:  I can tell you right now which of those three tweets it isn't going to perform with.

03:22:33,794 --> 03:22:34,270
SPEAKER_0:  Yeah.

03:22:34,370 --> 03:22:35,838
SPEAKER_1:  Yeah, so I.

03:22:36,290 --> 03:22:40,190
SPEAKER_1:  I think extremes are okay if you believe it. Okay. So I will sometimes say.

03:22:40,834 --> 03:22:41,502
SPEAKER_1:  Um...

03:22:41,826 --> 03:22:46,302
SPEAKER_1:  positive things. I said that the Twitter files release was historic.

03:22:46,818 --> 03:22:48,478
SPEAKER_1:  Of course, this before...

03:22:48,898 --> 03:22:51,774
SPEAKER_1:  I realize, I mean, the reason I said it.

03:22:52,290 --> 03:22:52,862
SPEAKER_1:  is not.

03:22:53,474 --> 03:22:57,182
SPEAKER_1:  is because the transparency. It's so refreshing.

03:22:57,410 --> 03:23:00,350
SPEAKER_1:  to see some annual of transparency.

03:23:01,026 --> 03:23:01,982
SPEAKER_1:  And then of course...

03:23:02,754 --> 03:23:16,446
SPEAKER_1:  those kinds of comments, the way Twitter does, is every side will interpret it in the worst possible way for them and they will run with it. Or some side, when it's political, yeah, one side will interpret, yes.

03:23:17,090 --> 03:23:18,965
SPEAKER_1:  uh... i agree with the latest

03:23:18,965 --> 03:23:23,774
SPEAKER_0:  Historic they might not have even read the article. They just like they literally or the tweet thread

03:23:24,002 --> 03:23:25,470
SPEAKER_0:  And they're just like, it is historic.

03:23:25,666 --> 03:23:33,502
SPEAKER_1:  His story is because Hunter Biden was finally the collusion or whatever it is. And then the other side is like, no, it's a nothing burger.

03:23:33,762 --> 03:23:34,270
SPEAKER_1:  Um...

03:23:34,562 --> 03:23:42,974
SPEAKER_1:  Yeah, that that aspect of nuance and that's frozen in time even with editing there's a so tough it's it's tricky But if you maintain a

03:23:43,362 --> 03:23:45,022
SPEAKER_1:  a cool head through all of that.

03:23:45,538 --> 03:23:46,910
SPEAKER_1:  and uh...

03:23:47,330 --> 03:23:49,918
SPEAKER_1:  call to your ethics and your ideas and use it.

03:23:50,242 --> 03:23:51,870
SPEAKER_1:  to spread the ideas.

03:23:52,226 --> 03:23:54,462
SPEAKER_1:  which you do extremely well on YouTube.

03:23:54,882 --> 03:23:56,958
SPEAKER_1:  I think it could be a really powerful platform.

03:23:57,218 --> 03:23:58,878
SPEAKER_1:  There's no other platform.

03:23:59,554 --> 03:24:03,326
SPEAKER_1:  that allows for the viral spread of ideas, good ideas.

03:24:03,586 --> 03:24:05,150
SPEAKER_1:  then

03:24:05,794 --> 03:24:06,334
SPEAKER_1:  uh...

03:24:06,690 --> 03:24:08,222
SPEAKER_1:  than this, and this is where...

03:24:08,802 --> 03:24:10,366
SPEAKER_1:  Like especially with Twitter spaces.

03:24:11,842 --> 03:24:13,278
SPEAKER_1:  I mean, where else?

03:24:13,826 --> 03:24:14,910
SPEAKER_1:  What I see.

03:24:15,202 --> 03:24:17,726
SPEAKER_1:  I think twice impromptu conversations.

03:24:18,274 --> 03:24:20,149
SPEAKER_1:  we will...

03:24:20,149 --> 03:24:20,542
SPEAKER_0:  Never.

03:24:20,770 --> 03:24:25,534
SPEAKER_0:  Yeah, nowhere else. Because he wasn't gonna come on my show. He wasn't gonna come on some big prepared thing. It's like, hey.

03:24:26,466 --> 03:24:29,022
SPEAKER_0:  YOLO, let's go into Twitter space and I like pop up.

03:24:29,698 --> 03:24:30,334
SPEAKER_0:  You know what's funny?

03:24:31,106 --> 03:24:35,294
SPEAKER_0:  And this, I hope this release is late enough or well, SPF probably won't see this. Thank you.

03:24:35,458 --> 03:24:37,502
SPEAKER_1:  Although I'm sure he's a- and unfortunately.

03:24:37,794 --> 03:24:40,254
SPEAKER_1:  Unfortunately, he will. Oh, yes.

03:24:41,346 --> 03:24:43,902
SPEAKER_0:  Hopefully I'll have time to enact my little plan.

03:24:44,162 --> 03:24:48,222
SPEAKER_0:  But I'm hoping if he goes on any future spaces I can like haunt him from-

03:24:48,450 --> 03:24:51,966
SPEAKER_0:  interview to interview, which is like I keep showing up and he's like

03:24:52,226 --> 03:24:52,894
SPEAKER_0:  I hate this guy.

03:24:52,994 --> 03:24:55,486
SPEAKER_1:  But I think he's already kind of probably.

03:24:56,290 --> 03:24:56,830
SPEAKER_1:  Um...

03:24:58,146 --> 03:25:02,014
SPEAKER_1:  has like PTSD of like, in the shadows lurks a coffeezilla.

03:25:02,498 --> 03:25:03,870
SPEAKER_1:  That just would be, that would just...

03:25:04,546 --> 03:25:06,750
SPEAKER_0:  It's just like, that really amuses me.

03:25:07,234 --> 03:25:08,446
SPEAKER_1:  I mean there is a...

03:25:09,218 --> 03:25:13,630
SPEAKER_1:  I think he honestly would enjoy talking to you. There's an aspect of Twitter spaces that's a little...

03:25:14,018 --> 03:25:16,510
SPEAKER_1:  uncertain of like, what are we doing here?

03:25:16,738 --> 03:25:21,758
SPEAKER_1:  There's an urgency because other voices might want to butt in. Exactly. Exactly. If it's an intimate one-on-one.

03:25:21,986 --> 03:25:24,350
SPEAKER_1:  where you can like breathe, like hold on a second.

03:25:25,154 --> 03:25:26,238
SPEAKER_1:  I think it's much easier.

03:25:26,594 --> 03:25:27,358
SPEAKER_1:  So that's since.

03:25:27,618 --> 03:25:29,150
SPEAKER_1:  This piece is a little bit negative.

03:25:29,410 --> 03:25:30,366
SPEAKER_1:  Um, that.

03:25:31,042 --> 03:25:37,694
SPEAKER_1:  there's too many voices, especially if it's a very controversial kind of thing. So it's tricky. But at the same time,

03:25:37,954 --> 03:25:40,542
SPEAKER_1:  the friction, it's so easy to just jump in.

03:25:41,602 --> 03:25:42,078
SPEAKER_1:  Uh...

03:25:42,594 --> 03:25:43,774
SPEAKER_1:  So I can just...

03:25:44,642 --> 03:25:48,798
SPEAKER_1:  I mean, just imagine like a Twitter space with like Zelensky and Putin.

03:25:49,122 --> 03:25:49,470
SPEAKER_1:  Thank you.

03:25:50,114 --> 03:25:53,150
SPEAKER_1:  how else are these two going to talk, right?

03:25:53,506 --> 03:25:58,366
SPEAKER_0:  Can't you imagine? If you try to set it up on Zoom, like it's never happening. It's never happening. David Ð±Ð¾Ð³ol

03:25:58,594 --> 03:26:00,469
SPEAKER_0:  Just imagine a poon like-

03:26:00,469 --> 03:26:01,219
SPEAKER_1:  sitting there like.

03:26:01,219 --> 03:26:02,719
SPEAKER_0:  Zalensky's live.

03:26:02,719 --> 03:26:04,862
SPEAKER_1:  Just live, right? Just jumping in.

03:26:05,442 --> 03:26:06,846
SPEAKER_1:  hilarious

03:26:07,298 --> 03:26:09,086
SPEAKER_1:  Let's speak Russian.

03:26:09,378 --> 03:26:09,758
SPEAKER_1:  Okay.

03:26:10,050 --> 03:26:15,390
SPEAKER_1:  uh... the actions of small changes so how how you have a productive day to have any insights in

03:26:15,714 --> 03:26:17,342
SPEAKER_1:  how to manage your time optimally.

03:26:17,858 --> 03:26:20,414
SPEAKER_0:  Yeah, I mean, I've gone the gamut of.

03:26:20,674 --> 03:26:23,518
SPEAKER_0:  from obsessive time tracking in 15 minute buckets.

03:26:23,874 --> 03:26:24,478
SPEAKER_0:  to.

03:26:24,898 --> 03:26:29,310
SPEAKER_0:  kind of like the other extreme where it's more...

03:26:30,242 --> 03:26:31,614
SPEAKER_0:  kind of like large scale.

03:26:32,546 --> 03:26:35,038
SPEAKER_0:  some deep work here, two hour bucket, you know.

03:26:35,330 --> 03:26:36,926
SPEAKER_0:  Count for an hour of lunch and...

03:26:37,250 --> 03:26:38,814
SPEAKER_0:  some other thing, but now.

03:26:39,266 --> 03:26:42,654
SPEAKER_0:  Now I just roughly, because I manage a team there's some things that

03:26:42,946 --> 03:26:43,326
SPEAKER_0:  Kind of.

03:26:43,906 --> 03:26:44,286
SPEAKER_0:  Come up.

03:26:44,546 --> 03:26:53,150
SPEAKER_0:  It's only a team of two, it's not like big, but I just have things that are not necessarily controllable by me, I like have to take some meetings or whatever. It's not as easy to plan out my day ahead of time.

03:26:53,442 --> 03:26:54,526
SPEAKER_0:  So I do a lot of.

03:26:54,882 --> 03:26:58,814
SPEAKER_0:  retrospective time management, where I look at my day, and that's what I mostly do now.

03:26:59,202 --> 03:26:59,806
SPEAKER_0:  Um...

03:27:00,322 --> 03:27:05,310
SPEAKER_0:  and I account, did I spend this day productively? What could I do better? And then try to implement it in the future.

03:27:05,826 --> 03:27:09,278
SPEAKER_0:  So a lot of this, I realized, is very personal for me.

03:27:09,986 --> 03:27:10,526
SPEAKER_0:  I-

03:27:10,786 --> 03:27:13,694
SPEAKER_0:  do very well in long streaks of working.

03:27:14,146 --> 03:27:18,782
SPEAKER_0:  And if I, I can't do a lot of work in 15 minutes, I can't do a lot of work in even an hour.

03:27:19,106 --> 03:27:23,198
SPEAKER_0:  But if you give me like three hours or five hours or six hours of uninterrupted work.

03:27:23,714 --> 03:27:24,126
SPEAKER_0:  That's like.

03:27:24,418 --> 03:27:25,543
SPEAKER_0:  That's where I get most of my stuff done.

03:27:25,543 --> 03:27:30,174
SPEAKER_1:  So from the, it just, it'd be fun to explore those. The one you did 15 minute buckets.

03:27:30,562 --> 03:27:31,166
SPEAKER_1:  So...

03:27:31,714 --> 03:27:32,510
SPEAKER_1:  You have a day.

03:27:32,930 --> 03:27:37,662
SPEAKER_1:  in front of you and you have like a Google sheet or a spreadsheet or something. Yeah, I did an Excel. So.

03:27:38,242 --> 03:27:38,846
SPEAKER_1:  Uhhh

03:27:39,426 --> 03:27:40,254
SPEAKER_1:  and you're her.

03:27:41,218 --> 03:27:44,126
SPEAKER_1:  Do you have a plan for the day or do you go like when you did it?

03:27:44,578 --> 03:27:44,894
SPEAKER_1:  Bye.

03:27:45,378 --> 03:27:46,718
SPEAKER_1:  Or you just literally...

03:27:47,522 --> 03:27:48,094
SPEAKER_1:  sort of.

03:27:48,450 --> 03:27:49,790
SPEAKER_1:  focus on a particular task.

03:27:50,306 --> 03:27:53,681
SPEAKER_1:  And then you're tracking as you're doing that task every 15 minutes.

03:27:53,681 --> 03:27:54,974
SPEAKER_0:  Yeah, I would kind of do it live.

03:27:55,554 --> 03:27:56,094
SPEAKER_0:  Um

03:27:56,322 --> 03:28:00,286
SPEAKER_0:  I'm not, so one of the reasons I'm so obsessive about it is because I'm not organized by nature.

03:28:00,834 --> 03:28:03,838
SPEAKER_0:  And I lost, like in college I learned how.

03:28:04,130 --> 03:28:04,702
SPEAKER_0:  much.

03:28:05,346 --> 03:28:09,022
SPEAKER_0:  lack of organization can just hurt you in terms of output.

03:28:09,826 --> 03:28:14,942
SPEAKER_0:  And so I realized like I just had to build systems that would enable me to become more.

03:28:15,330 --> 03:28:16,126
SPEAKER_0:  organized so.

03:28:16,450 --> 03:28:17,054
SPEAKER_0:  Uhhh...

03:28:17,794 --> 03:28:19,166
SPEAKER_0:  Really, I think...

03:28:20,066 --> 03:28:20,606
SPEAKER_0:  Doing that?

03:28:20,834 --> 03:28:22,814
SPEAKER_0:  really taught me a lot about time.

03:28:23,170 --> 03:28:28,606
SPEAKER_0:  in the same way that tracking calories can teach you about food. Yes. Learning, accounting for these things.

03:28:28,994 --> 03:28:33,630
SPEAKER_0:  will give you skills that eventually you might not need to track on such a granular level because

03:28:33,858 --> 03:28:38,078
SPEAKER_0:  you've kind of like figured out. So that's kind of how I feel about it. I think everyone should-

03:28:38,530 --> 03:28:40,094
SPEAKER_0:  if you care about productivity and stuff.

03:28:40,418 --> 03:28:45,630
SPEAKER_0:  should do a little bit of it. I don't think it's sustainable in the long-term. It just takes so much effort and time to like...

03:28:46,050 --> 03:28:47,198
SPEAKER_0:  And I think the marginal.

03:28:48,002 --> 03:28:52,350
SPEAKER_0:  Effect of it in the long term is kind of minimal. Once you learn these basic skills, you're going to be able to do it.

03:28:52,706 --> 03:28:53,534
SPEAKER_0:  But, um...

03:28:54,274 --> 03:28:56,318
SPEAKER_0:  Yeah, I was basically tracking like live what I did.

03:28:56,578 --> 03:28:57,150
SPEAKER_0:  and

03:28:57,794 --> 03:28:59,230
SPEAKER_0:  What I saw is that.

03:28:59,810 --> 03:29:03,902
SPEAKER_0:  A lot of my real work would be done in small sections of the day.

03:29:04,194 --> 03:29:05,790
SPEAKER_0:  and then it'd be like a lot of just nothing.

03:29:06,146 --> 03:29:08,478
SPEAKER_0:  like a lot of small things where I'm busy.

03:29:08,994 --> 03:29:10,846
SPEAKER_0:  but little is being achieved.

03:29:11,522 --> 03:29:12,446
SPEAKER_0:  And so I think that's.

03:29:12,834 --> 03:29:14,270
SPEAKER_0:  a really interesting insight.

03:29:14,722 --> 03:29:17,982
SPEAKER_0:  I've never figured out how to un-busy myself and focus on the

03:29:18,594 --> 03:29:19,742
SPEAKER_0:  core essentials, I'm still.

03:29:20,002 --> 03:29:20,638
SPEAKER_0:  Getting to that.

03:29:21,154 --> 03:29:22,046
SPEAKER_0:  But...

03:29:22,338 --> 03:29:29,470
SPEAKER_0:  It is interesting realizing most of your day is like a lot of nothing and then like some real deep work where most of your value comes from is like 20% of your day.

03:29:29,730 --> 03:29:37,182
SPEAKER_1:  Yeah, I tried to start every day with that. So the hardest task of the day and you focus for long periods of time. And I also have the segment of two hours.

03:29:37,634 --> 03:29:39,710
SPEAKER_1:  where it's a set of tasks that I do every single day.

03:29:40,098 --> 03:29:41,278
SPEAKER_1:  What are the ideas you do that?

03:29:41,922 --> 03:29:42,910
SPEAKER_1:  for like your whole life.

03:29:43,202 --> 03:29:44,478
SPEAKER_1:  It's like long-term investment.

03:29:44,706 --> 03:29:46,046
SPEAKER_1:  of Anki and-

03:29:46,562 --> 03:29:47,198
SPEAKER_1:  It's just like.

03:29:47,874 --> 03:29:48,574
SPEAKER_1:  learning and

03:29:49,282 --> 03:29:49,854
SPEAKER_1:  Um...

03:29:50,850 --> 03:29:54,494
SPEAKER_1:  reminding yourself of facts that are useful in your everyday life.

03:29:54,786 --> 03:29:58,014
SPEAKER_1:  And then for me, I'll also music. I'll play a little bit of music. Play the piano.

03:29:58,498 --> 03:29:58,814
SPEAKER_1:  piano.

03:29:59,138 --> 03:29:59,774
SPEAKER_1:  So like

03:30:00,098 --> 03:30:01,822
SPEAKER_1:  keeping that regular thing as part of your life.

03:30:01,954 --> 03:30:05,502
SPEAKER_0:  And one thing that I've really taken from this because I've read all the like

03:30:06,050 --> 03:30:08,670
SPEAKER_0:  I had a self-improvement phase in my early 20s.

03:30:09,090 --> 03:30:09,598
SPEAKER_0:  Um

03:30:10,402 --> 03:30:14,622
SPEAKER_0:  And one thing you learn is that everyone wants to give you a broad general solution.

03:30:15,138 --> 03:30:15,582
SPEAKER_0:  But...

03:30:16,258 --> 03:30:16,958
SPEAKER_0:  really

03:30:17,506 --> 03:30:20,446
SPEAKER_0:  The real trick of figuring out like optimizing.

03:30:20,674 --> 03:30:26,462
SPEAKER_0:  is figuring out the things that work for you specifically. So like one interesting thing you said is like, oh, I like to do.

03:30:26,722 --> 03:30:28,062
SPEAKER_0:  my hard work at the beginning of the day.

03:30:28,578 --> 03:30:29,022
SPEAKER_0:  Um.

03:30:29,922 --> 03:30:30,590
SPEAKER_0:  I know.

03:30:30,818 --> 03:30:32,062
SPEAKER_0:  A lot of people recommend this.

03:30:32,290 --> 03:30:33,918
SPEAKER_0:  I've tried so many times.

03:30:34,370 --> 03:30:36,158
SPEAKER_0:  and I just do better work.

03:30:36,418 --> 03:30:36,894
SPEAKER_0:  late at night.

03:30:37,346 --> 03:30:39,518
SPEAKER_0:  And so usually my streak of work is from like...

03:30:40,066 --> 03:30:40,798
SPEAKER_0:  After dinner?

03:30:41,218 --> 03:30:42,398
SPEAKER_0:  730 to like.

03:30:42,658 --> 03:30:43,934
SPEAKER_0:  2 a.m. that's my.

03:30:44,226 --> 03:30:45,054
SPEAKER_0:  prime time.

03:30:45,410 --> 03:30:45,950
SPEAKER_0:  Um...

03:30:46,178 --> 03:30:52,030
SPEAKER_0:  And so like a lot of my videos, which you'll see, which is like lit from this studio, which appears to be daytime, it's like shot at 3 a.m.

03:30:52,322 --> 03:30:54,782
SPEAKER_0:  you know, just like in a caffeine fueled rush.

03:30:55,138 --> 03:30:55,646
SPEAKER_0:  Um...

03:30:55,938 --> 03:31:01,918
SPEAKER_0:  but that's kind of how it works for me. And then also like with the social outlets and stuff like that which-

03:31:02,530 --> 03:31:08,318
SPEAKER_0:  It's easy and I feel like we think similarly on this. So it's easy to discount these things as.

03:31:08,706 --> 03:31:10,462
SPEAKER_0:  less relevant because they don't have

03:31:11,010 --> 03:31:11,998
SPEAKER_0:  quantitative.

03:31:12,482 --> 03:31:13,918
SPEAKER_0:  metrics associated with them.

03:31:14,914 --> 03:31:16,862
SPEAKER_0:  But in terms of longevity and

03:31:17,090 --> 03:31:17,470
SPEAKER_0:  like.

03:31:17,794 --> 03:31:19,134
SPEAKER_0:  I think to be able to.

03:31:19,522 --> 03:31:20,894
SPEAKER_0:  do creative work.

03:31:21,506 --> 03:31:24,606
SPEAKER_0:  there's an amount of recharge and like re-inputting stuff.

03:31:25,186 --> 03:31:28,030
SPEAKER_0:  that is frequently discounted by people like us who are like.

03:31:28,290 --> 03:31:30,526
SPEAKER_0:  obsessed with quantitative metrics.

03:31:30,914 --> 03:31:32,190
SPEAKER_0:  And so I really found that.

03:31:32,482 --> 03:31:38,878
SPEAKER_0:  Some of my best work gets done after I take a break or I'll go play live sets of music.

03:31:39,394 --> 03:31:46,206
SPEAKER_0:  And I mean, like that's like for me really recharging, but nowhere on a spreadsheet is that gonna show up as productive or like meaningful.

03:31:46,658 --> 03:31:47,518
SPEAKER_0:  But for me...

03:31:48,642 --> 03:31:50,782
SPEAKER_0:  For whatever reason, it recharges me in a way that like...

03:31:51,106 --> 03:31:52,231
SPEAKER_0:  I need to pay attention to.

03:31:52,231 --> 03:32:01,470
SPEAKER_1:  I usually have a spreadsheet of 15 minute increments when I'm socially interacting with people and I evaluate how I'm getting roasted right now. No, I'm not. It's actually

03:32:01,762 --> 03:32:03,902
SPEAKER_1:  I probably roasting myself.

03:32:04,546 --> 03:32:05,662
SPEAKER_1:  I do find that...

03:32:06,018 --> 03:32:07,806
SPEAKER_1:  when I do have social interactions.

03:32:08,194 --> 03:32:11,998
SPEAKER_1:  I like to deal with people that are outside of that exceptionally busy.

03:32:12,642 --> 03:32:13,342
SPEAKER_1:  themselves.

03:32:13,922 --> 03:32:15,454
SPEAKER_1:  because then you understand the value of time.

03:32:16,642 --> 03:32:19,678
SPEAKER_1:  And when you understand the value of time, your interaction.

03:32:20,098 --> 03:32:21,950
SPEAKER_1:  becomes more intimate and intense.

03:32:22,722 --> 03:32:23,070
SPEAKER_1:  like.

03:32:23,554 --> 03:32:25,630
SPEAKER_1:  The cliche of work hard.

03:32:25,954 --> 03:32:27,006
SPEAKER_1:  party hard or whatever.

03:32:27,266 --> 03:32:29,118
SPEAKER_1:  the shade. Play hard. Play hard dammit.

03:32:29,442 --> 03:32:31,317
SPEAKER_1:  Whatever the English.

03:32:31,317 --> 03:32:32,067
SPEAKER_0:  interaction

03:32:32,067 --> 03:32:33,086
SPEAKER_1:  No, I'm just kidding.

03:32:33,314 --> 03:32:34,078
SPEAKER_1:  Um

03:32:34,850 --> 03:32:35,198
SPEAKER_1:  uh

03:32:35,874 --> 03:32:36,574
SPEAKER_1:  The...

03:32:36,898 --> 03:32:40,766
SPEAKER_1:  That, I mean that cliche, there's a truth to that, but the intensity.

03:32:40,994 --> 03:32:42,174
SPEAKER_1:  of the social interaction.

03:32:43,106 --> 03:32:43,646
SPEAKER_1:  Even like-

03:32:43,938 --> 03:32:47,358
SPEAKER_1:  You know, it's not even the intensity, it's not even the party heart, it's like, um...

03:32:48,098 --> 03:32:51,742
SPEAKER_1:  even if you're going hiking and relaxing taking in nature says very relaxed

03:32:52,098 --> 03:32:54,174
SPEAKER_1:  but you understand the value of that. There's Maria Wong in our programs and the touchscreen,

03:32:54,434 --> 03:32:57,214
SPEAKER_1:  when you put a huge amount of value on those moments.

03:32:57,634 --> 03:32:58,558
SPEAKER_1:  in nature.

03:32:58,946 --> 03:33:01,086
SPEAKER_1:  That recharges me much more.

03:33:01,314 --> 03:33:04,030
SPEAKER_1:  So you have to surround yourself with people that think of life that way.

03:33:04,258 --> 03:33:06,462
SPEAKER_1:  that think about the value of every single moment.

03:33:06,690 --> 03:33:11,550
SPEAKER_1:  That's one of the things you do when you break it up in 15 minute increments is you realize how much

03:33:11,938 --> 03:33:13,022
SPEAKER_1:  Time there's in the day.

03:33:13,474 --> 03:33:17,022
SPEAKER_1:  how much awesomeness there's in a day to experience, to get done and so on.

03:33:17,378 --> 03:33:20,350
SPEAKER_1:  And then so you can feel that when you're with somebody.

03:33:20,738 --> 03:33:21,118
SPEAKER_1:  Um.

03:33:21,506 --> 03:33:24,286
SPEAKER_1:  And then for me personally, like when I interact with people.

03:33:24,706 --> 03:33:25,790
SPEAKER_1:  I really like to be.

03:33:26,146 --> 03:33:27,262
SPEAKER_1:  fully present.

03:33:27,522 --> 03:33:28,702
SPEAKER_1:  for the interaction like.

03:33:29,090 --> 03:33:29,886
SPEAKER_0:  I can tell this is.

03:33:30,274 --> 03:33:31,838
SPEAKER_0:  For anyone who has, you know.

03:33:32,386 --> 03:33:34,110
SPEAKER_0:  I've been the audience forever, so I-

03:33:34,402 --> 03:33:37,214
SPEAKER_0:  I haven't been on this side of the table before. You're very intense. OH MY GOD STFU

03:33:37,570 --> 03:33:39,783
SPEAKER_0:  right in the eye. You're like. Right in the eye.

03:33:39,783 --> 03:33:42,033
SPEAKER_1:  eye contact is an issue but yes.

03:33:42,033 --> 03:33:49,543
SPEAKER_0:  There's a soulful gaze guys just in case you're wondering. Yeah, it's very soulful. All right, very all right reading It's like a bug back to serious

03:33:49,543 --> 03:33:50,430
SPEAKER_1:  is talk. Okay.

03:33:51,138 --> 03:33:54,846
SPEAKER_1:  You've studied a lot of people who lie, who defraud.

03:33:56,674 --> 03:33:58,814
SPEAKER_1:  Uh, cheat and scam.

03:33:59,810 --> 03:34:01,758
SPEAKER_1:  on a basic human level.

03:34:02,018 --> 03:34:02,494
SPEAKER_1:  Um...

03:34:02,850 --> 03:34:03,230
SPEAKER_1:  How?

03:34:03,490 --> 03:34:05,822
SPEAKER_1:  Do you have trouble trusting human beings in your life?

03:34:06,626 --> 03:34:07,102
SPEAKER_1:  Uh...

03:34:07,970 --> 03:34:09,502
SPEAKER_1:  What's your relationship with trust?

03:34:09,922 --> 03:34:11,326
SPEAKER_1:  other humans? Great question.

03:34:11,778 --> 03:34:12,190
SPEAKER_0:  So.

03:34:12,834 --> 03:34:16,414
SPEAKER_0:  Funny enough, before I did this, I was like an incorrigible optimist.

03:34:17,122 --> 03:34:17,566
SPEAKER_0:  I-

03:34:18,402 --> 03:34:20,478
SPEAKER_0:  everything, the sun shined.

03:34:20,898 --> 03:34:22,174
SPEAKER_0:  every which place.

03:34:22,786 --> 03:34:24,574
SPEAKER_0:  Um, I always saw like.

03:34:24,834 --> 03:34:26,654
SPEAKER_0:  Everybody is fundamentally.

03:34:26,914 --> 03:34:30,974
SPEAKER_0:  good, nobody was bad, it just was like sort of wrong place, wrong time, bad incentives.

03:34:33,506 --> 03:34:35,262
SPEAKER_0:  That view has darkened significantly.

03:34:35,490 --> 03:34:36,542
SPEAKER_0:  Uh, but.

03:34:37,410 --> 03:34:40,158
SPEAKER_0:  I just try to remember my sample set.

03:34:40,450 --> 03:34:42,718
SPEAKER_0:  and just like I'm just sampling sort of the worst.

03:34:43,298 --> 03:34:46,494
SPEAKER_0:  And I try not to let it bleed into my...

03:34:47,298 --> 03:34:49,022
SPEAKER_0:  day to day life and I think I've.

03:34:49,570 --> 03:34:52,318
SPEAKER_0:  I think it's probably because I was such an optimist early on.

03:34:52,578 --> 03:34:53,118
SPEAKER_0:  that I've.

03:34:53,570 --> 03:34:55,710
SPEAKER_0:  I've been able to kind of retain some of it.

03:34:55,938 --> 03:34:57,438
SPEAKER_0:  I call it enlightened optimism.

03:34:57,666 --> 03:35:00,190
SPEAKER_0:  like choosing to be optimistic in the face of.

03:35:01,218 --> 03:35:07,998
SPEAKER_0:  a realistic sense of the problems in the world, and with a realistic sense of like the scale and the challenge ahead.

03:35:08,578 --> 03:35:09,182
SPEAKER_0:  Um...

03:35:10,242 --> 03:35:13,214
SPEAKER_0:  I actually think it's much braver to be an optimist.

03:35:14,114 --> 03:35:17,470
SPEAKER_0:  when you're aware of what's going on in the world then you're more than to be a cynic, I think.

03:35:17,954 --> 03:35:20,542
SPEAKER_0:  Being a complete cynic is maybe...

03:35:21,090 --> 03:35:22,046
SPEAKER_0:  I'm not saying it's wrong.

03:35:22,274 --> 03:35:24,542
SPEAKER_0:  but I'm saying it's maybe the easier way.

03:35:24,994 --> 03:35:25,918
SPEAKER_0:  Just mentally.

03:35:26,242 --> 03:35:26,878
SPEAKER_0:  said cope.

03:35:27,266 --> 03:35:28,926
SPEAKER_0:  with so much negativity.

03:35:29,314 --> 03:35:29,918
SPEAKER_0:  It's like.

03:35:30,178 --> 03:35:33,342
SPEAKER_0:  just saying, well, it's all bad, it's all doomed to fail, it's all gonna go bust.

03:35:34,434 --> 03:35:34,974
SPEAKER_0:  is

03:35:36,290 --> 03:35:36,702
SPEAKER_0:  easier.

03:35:38,658 --> 03:35:42,910
SPEAKER_1:  Yeah, that leap into believing that's a good world is...

03:35:43,842 --> 03:35:46,334
SPEAKER_1:  It's a little baby act of courage.

03:35:47,522 --> 03:35:48,478
SPEAKER_1:  Or at least I think so.

03:35:49,826 --> 03:35:50,846
SPEAKER_1:  I don't think it's naive.

03:35:52,162 --> 03:35:56,574
SPEAKER_0:  No, it can be. Some people are naive that are optimistic, but oftentimes...

03:35:57,122 --> 03:35:57,630
SPEAKER_0:  Um...

03:35:57,890 --> 03:36:01,822
SPEAKER_0:  Just because someone's optimistic does not mean they're naive. They could be full well aware of how-

03:36:02,338 --> 03:36:03,422
SPEAKER_0:  troubling the world is.

03:36:04,450 --> 03:36:06,366
SPEAKER_1:  And I also believe some of the people you study.

03:36:07,266 --> 03:36:10,718
SPEAKER_1:  I'm a big believer that all of us are capable of good and evil.

03:36:13,090 --> 03:36:16,990
SPEAKER_1:  So in some sense, the people you study are just the successful ones.

03:36:17,858 --> 03:36:19,230
SPEAKER_1:  the ones who are

03:36:20,770 --> 03:36:21,278
SPEAKER_1:  chose.

03:36:21,698 --> 03:36:26,270
SPEAKER_1:  sort of the dark path and we're successful at it. I think all of us can choose the dark path in life.

03:36:29,058 --> 03:36:30,942
SPEAKER_1:  It's a, that's like the.

03:36:32,738 --> 03:36:35,454
SPEAKER_1:  That's the responsibility we all carry, is we get to choose that.

03:36:35,682 --> 03:36:36,926
SPEAKER_1:  at every moment.

03:36:37,314 --> 03:36:39,294
SPEAKER_1:  And it's like a big responsibility.

03:36:40,226 --> 03:36:44,606
SPEAKER_1:  And it's a chance to really have integrity. It's a chance to stand for something good in this world.

03:36:45,090 --> 03:36:47,038
SPEAKER_1:  All of us have that because I think

03:36:47,330 --> 03:36:49,054
SPEAKER_1:  All of us are capable of you.

03:36:49,378 --> 03:36:52,350
SPEAKER_1:  All of us could be good Germans, all of us could in atrocities.

03:36:52,866 --> 03:36:54,718
SPEAKER_1:  be part of the atrocities.

03:36:55,938 --> 03:36:57,278
SPEAKER_0:  Yeah, I think it's...

03:36:58,242 --> 03:37:00,734
SPEAKER_0:  I really have, especially in recent years.

03:37:01,218 --> 03:37:02,334
SPEAKER_0:  try to.

03:37:03,042 --> 03:37:04,894
SPEAKER_0:  somewhat depersonalize my work.

03:37:05,410 --> 03:37:06,526
SPEAKER_0:  And, um.

03:37:09,058 --> 03:37:10,718
SPEAKER_0:  it almost like as like a...

03:37:11,138 --> 03:37:11,614
SPEAKER_0:  I don't know.

03:37:11,970 --> 03:37:14,334
SPEAKER_0:  like a force of nature that I'm fighting more than like

03:37:14,658 --> 03:37:15,358
SPEAKER_0:  individuals.

03:37:15,938 --> 03:37:17,790
SPEAKER_0:  Because of this exact thing, I think like.

03:37:18,306 --> 03:37:21,406
SPEAKER_0:  sort of, therefore but the grace of God, their go I is kind of a

03:37:21,762 --> 03:37:24,190
SPEAKER_0:  really profound way to understand yourself.

03:37:24,962 --> 03:37:27,006
SPEAKER_0:  rather than it's just like fundamentally.

03:37:27,522 --> 03:37:28,254
SPEAKER_0:  good and like

03:37:29,058 --> 03:37:30,046
SPEAKER_0:  full of integrity.

03:37:30,498 --> 03:37:35,326
SPEAKER_0:  acknowledging that so much of that is a product of your environment and your family and your upbringing.

03:37:36,130 --> 03:37:39,454
SPEAKER_0:  and so much of the people who don't have that is a product of

03:37:40,098 --> 03:37:42,078
SPEAKER_0:  their environment, it doesn't absolve them.

03:37:42,754 --> 03:37:44,702
SPEAKER_0:  but it gives you more perspective.

03:37:46,338 --> 03:37:46,974
SPEAKER_0:  Too tr-

03:37:47,362 --> 03:37:49,054
SPEAKER_0:  like to sort of deal fairly.

03:37:49,282 --> 03:37:49,886
SPEAKER_0:  Does that make sense?

03:37:50,114 --> 03:37:52,062
SPEAKER_0:  and not approach it from a place of anger?

03:37:52,322 --> 03:37:53,054
SPEAKER_0:  or a place of

03:37:53,474 --> 03:37:54,270
SPEAKER_0:  outrage

03:37:54,562 --> 03:37:58,782
SPEAKER_0:  There is a sense of sadness for the victims. There's a sense of outrage for the victims.

03:37:59,650 --> 03:38:02,398
SPEAKER_0:  approach the individual who's done the thing.

03:38:03,810 --> 03:38:04,318
SPEAKER_0:  From that.

03:38:05,506 --> 03:38:06,750
SPEAKER_0:  place of understanding of.

03:38:07,074 --> 03:38:10,526
SPEAKER_0:  This isn't just this person. There's like a whole broader thing going on here.

03:38:11,362 --> 03:38:12,958
SPEAKER_1:  idea of advice for young people

03:38:13,538 --> 03:38:15,582
SPEAKER_1:  of how to live this life.

03:38:16,546 --> 03:38:22,014
SPEAKER_1:  how to have a career they can be proud of. So high school students, college students, or maybe a life they can be proud of.

03:38:23,874 --> 03:38:24,999
SPEAKER_1:  Let me think about this.

03:38:24,999 --> 03:38:25,502
SPEAKER_0:  for a second.

03:38:31,298 --> 03:38:31,998
SPEAKER_0:  I think.

03:38:33,666 --> 03:38:35,678
SPEAKER_0:  Don't be afraid to go against the grain.

03:38:36,578 --> 03:38:38,142
SPEAKER_0:  and sort of challenge.

03:38:39,778 --> 03:38:41,406
SPEAKER_0:  the expectations on you.

03:38:42,114 --> 03:38:42,750
SPEAKER_0:  um...

03:38:44,738 --> 03:38:47,230
SPEAKER_0:  Like you sort of have to do this weird thing where you acknowledge

03:38:47,778 --> 03:38:50,750
SPEAKER_0:  how difficult it will be to achieve something great, while also

03:38:51,234 --> 03:38:52,958
SPEAKER_0:  having the courage to go for it anyways.

03:38:53,602 --> 03:38:54,942
SPEAKER_0:  and understanding that.

03:38:55,298 --> 03:38:58,686
SPEAKER_0:  other people don't have it figured out, I think, is a big theme of my work.

03:38:59,298 --> 03:39:01,086
SPEAKER_0:  which is that everyone wants like

03:39:01,762 --> 03:39:03,614
SPEAKER_0:  the guru to show them the way.

03:39:04,002 --> 03:39:07,262
SPEAKER_0:  to show them the secrets, so much of life and achieving anything.

03:39:07,586 --> 03:39:10,270
SPEAKER_0:  is learning to figure it out yourself and like.

03:39:10,626 --> 03:39:11,710
SPEAKER_0:  The Meta Skill.

03:39:12,098 --> 03:39:14,718
SPEAKER_0:  of being an autodidactic where you can.

03:39:14,978 --> 03:39:17,054
SPEAKER_0:  I don't know if I said that word right. You basically use self teach.

03:39:17,314 --> 03:39:19,902
SPEAKER_0:  you learn the meta skill of like learning to learn.

03:39:20,642 --> 03:39:25,950
SPEAKER_0:  I think that's such an underrated aspect of education. People leave education, they go, when am I going to use two plus two?

03:39:26,242 --> 03:39:28,222
SPEAKER_0:  We're not gonna learn, you know, use calculus.

03:39:28,642 --> 03:39:31,742
SPEAKER_0:  but so much of it is learning this higher level abstract thinking.

03:39:32,162 --> 03:39:33,438
SPEAKER_0:  that can apply to anything.

03:39:33,986 --> 03:39:34,782
SPEAKER_0:  and

03:39:35,874 --> 03:39:38,174
SPEAKER_0:  Getting that early on is, um...

03:39:39,554 --> 03:39:40,990
SPEAKER_0:  incredibly powerful.

03:39:41,442 --> 03:39:43,390
SPEAKER_0:  So yeah, I would say like a lot of it.

03:39:43,938 --> 03:39:44,574
SPEAKER_0:  is

03:39:45,698 --> 03:39:49,886
SPEAKER_0:  is I guess to some extent, like you kind of have to do that Steve jobs thing where you realize that

03:39:50,338 --> 03:39:52,158
SPEAKER_0:  Nobody else in the world is smarter than you.

03:39:52,994 --> 03:39:53,662
SPEAKER_0:  and that.

03:39:53,986 --> 03:39:54,910
SPEAKER_0:  Both means that like

03:39:55,138 --> 03:39:57,918
SPEAKER_0:  They can't show you the perfect way, but it also means you could do great things.

03:39:58,306 --> 03:39:59,902
SPEAKER_0:  and kind of chart your own path, I don't know.

03:40:00,258 --> 03:40:01,118
SPEAKER_0:  That's so cheesy.

03:40:01,346 --> 03:40:09,278
SPEAKER_0:  This is why I hate giving advice. I feel like it's cheesy. And I don't think it is. I think my journey is so full of luck and like-

03:40:09,666 --> 03:40:12,894
SPEAKER_0:  specific experience. I wonder how generalizable it is, but

03:40:13,762 --> 03:40:18,343
SPEAKER_0:  if I've learned anything, and if I could talk specifically to myself, I guess that's what I would say.

03:40:18,343 --> 03:40:20,734
SPEAKER_1:  I mean, you've taken a very difficult path.

03:40:21,602 --> 03:40:26,462
SPEAKER_1:  And I think part of taking that path, like of a great journalist, frankly, is like.

03:40:27,682 --> 03:40:29,918
SPEAKER_1:  I can be that person.

03:40:31,362 --> 03:40:33,406
SPEAKER_1:  I just believing in yourself that you could take that.

03:40:33,698 --> 03:40:35,550
SPEAKER_1:  Because if you see...

03:40:36,002 --> 03:40:37,214
SPEAKER_1:  A problem in the world.

03:40:38,754 --> 03:40:40,286
SPEAKER_1:  You could be the solution to that problem.

03:40:40,994 --> 03:40:42,142
SPEAKER_1:  Like you can solve that problem. Yeah.

03:40:42,594 --> 03:40:44,798
SPEAKER_1:  I think that's like, uh, it's really important to believe that.

03:40:45,218 --> 03:40:45,758
SPEAKER_1:  Is the...

03:40:46,050 --> 03:40:46,782
SPEAKER_1:  It depends.

03:40:47,394 --> 03:40:50,718
SPEAKER_1:  Maybe you're lucky to have the belief inside yourself.

03:40:51,362 --> 03:40:51,742
SPEAKER_1:  Uh...

03:40:52,578 --> 03:40:55,806
SPEAKER_1:  Maybe the thing that you're saying is like, don't look to others for that strength.

03:40:56,738 --> 03:41:00,382
SPEAKER_0:  And also, and also like be really comfortable failing, I think.

03:41:01,090 --> 03:41:01,598
SPEAKER_0:  One of the-

03:41:01,858 --> 03:41:04,414
SPEAKER_0:  Best things that like you would never know about me?

03:41:05,122 --> 03:41:07,614
SPEAKER_0:  just looking at my background that helped me.

03:41:08,194 --> 03:41:08,926
SPEAKER_0:  was

03:41:09,602 --> 03:41:11,166
SPEAKER_0:  playing music live.

03:41:12,322 --> 03:41:14,814
SPEAKER_0:  I had incredible amounts of stage fright.

03:41:15,842 --> 03:41:16,446
SPEAKER_0:  Growing up.

03:41:17,506 --> 03:41:19,998
SPEAKER_0:  mostly because I was terrible at piano. I was like shocked.

03:41:20,642 --> 03:41:22,782
SPEAKER_0:  And I specifically, I taught myself how to play.

03:41:23,170 --> 03:41:25,758
SPEAKER_0:  and I joined jazz band in like high school.

03:41:26,018 --> 03:41:26,750
SPEAKER_0:  Did it through college.

03:41:27,266 --> 03:41:27,806
SPEAKER_0:  I remember-

03:41:28,386 --> 03:41:31,710
SPEAKER_0:  all my recitals, I messed up every single solo I ever did.

03:41:32,354 --> 03:41:33,790
SPEAKER_0:  I never like actually nailed it.

03:41:34,626 --> 03:41:38,238
SPEAKER_0:  And every time I'd go up there, I'd have so much dread around this.

03:41:39,426 --> 03:41:42,750
SPEAKER_0:  And it was easier to get up there because there were sort of some people up there.

03:41:43,138 --> 03:41:43,966
SPEAKER_0:  But eventually...

03:41:44,386 --> 03:41:46,814
SPEAKER_0:  I started like playing live too and I sucked at that.

03:41:47,362 --> 03:41:49,470
SPEAKER_0:  And I've just gone through the trenches of like, just like...

03:41:49,730 --> 03:41:50,174
SPEAKER_0:  being.

03:41:50,658 --> 03:41:51,710
SPEAKER_0:  publicly sort of

03:41:52,130 --> 03:41:54,014
SPEAKER_0:  in my mind humiliated.

03:41:55,842 --> 03:42:00,318
SPEAKER_0:  prepared me so much for what I do now of trying to basically being fearless.

03:42:00,770 --> 03:42:01,534
SPEAKER_0:  of failure.

03:42:02,466 --> 03:42:04,446
SPEAKER_0:  in the face of like a wide audience.

03:42:05,122 --> 03:42:08,766
SPEAKER_0:  I don't have that anymore, because I've experienced so many...

03:42:09,026 --> 03:42:11,166
SPEAKER_0:  iterations of it at a smaller scale of just like.

03:42:11,490 --> 03:42:15,774
SPEAKER_0:  Abject public humiliation to where it's like not something that bothers me. I have no stage fright

03:42:16,098 --> 03:42:17,406
SPEAKER_0:  that doesn't bother me anymore.

03:42:18,690 --> 03:42:23,038
SPEAKER_0:  You'd think like, oh, maybe he just was always good at this. I was terrible at it. I had a complete phobia.

03:42:23,458 --> 03:42:23,870
SPEAKER_0:  about.

03:42:24,098 --> 03:42:24,862
SPEAKER_0:  public anything.

03:42:25,474 --> 03:42:26,590
SPEAKER_0:  So, um...

03:42:27,778 --> 03:42:32,798
SPEAKER_0:  It was that rapid iteration of just failure. And eventually I just came to the conclusion that I want to love it.

03:42:33,090 --> 03:42:34,014
SPEAKER_0:  I wanna like, love like-

03:42:34,242 --> 03:42:35,902
SPEAKER_0:  getting up on a stage and bombing?

03:42:36,482 --> 03:42:37,694
SPEAKER_0:  If you can learn to bite.

03:42:37,954 --> 03:42:38,558
SPEAKER_0:  Love that?

03:42:38,882 --> 03:42:39,934
SPEAKER_0:  and be fearless there.

03:42:40,738 --> 03:42:42,078
SPEAKER_0:  Almost nothing you can't do.

03:42:42,882 --> 03:42:47,518
SPEAKER_1:  Yeah, that's brilliant advice. I'm with you still terrifying to me like live performance.

03:42:48,130 --> 03:42:50,174
SPEAKER_1:  But yeah, that's exactly the feeling is.

03:42:50,434 --> 03:42:51,230
SPEAKER_1:  loving.

03:42:52,354 --> 03:42:53,726
SPEAKER_1:  the fact that you tried.

03:42:54,178 --> 03:42:54,846
SPEAKER_1:  And somehow...

03:42:55,202 --> 03:42:55,870
SPEAKER_1:  Failure.

03:42:56,290 --> 03:42:56,862
SPEAKER_1:  is like.

03:42:57,538 --> 03:42:59,838
SPEAKER_1:  a deeper celebration of the fact that you tried.

03:43:00,642 --> 03:43:06,526
SPEAKER_1:  Because success is easy. But failure is like bombing. I mean, music, yeah.

03:43:06,786 --> 03:43:10,462
SPEAKER_1:  on the smallest and the largest of stages.

03:43:10,754 --> 03:43:12,030
SPEAKER_1:  I'm not gonna say who.

03:43:12,386 --> 03:43:13,886
SPEAKER_1:  But there's a huge band.

03:43:14,850 --> 03:43:17,118
SPEAKER_1:  Huge band that wanted to be on stage.

03:43:18,050 --> 03:43:18,558
SPEAKER_1:  and

03:43:19,906 --> 03:43:21,054
SPEAKER_1:  Probably will happen.

03:43:21,570 --> 03:43:22,270
SPEAKER_1:  but like...

03:43:22,786 --> 03:43:24,798
SPEAKER_1:  but I turned it down because I was like...

03:43:25,826 --> 03:43:26,558
SPEAKER_1:  No.

03:43:26,946 --> 03:43:28,821
SPEAKER_1:  Cause I'm gonna suck for sure.

03:43:28,821 --> 03:43:29,694
SPEAKER_0:  The question is.

03:43:29,890 --> 03:43:31,806
SPEAKER_1:  Do you do it? Wanna suck?

03:43:32,226 --> 03:43:32,574
SPEAKER_1:  in a

03:43:32,866 --> 03:43:36,094
SPEAKER_1:  in front of a very large live audience. Yep.

03:43:36,386 --> 03:43:37,054
SPEAKER_1:  And uh...

03:43:37,346 --> 03:43:39,326
SPEAKER_1:  And then I turned it down, I was like, no.

03:43:40,962 --> 03:43:42,142
SPEAKER_1:  But now I realize...

03:43:42,434 --> 03:43:43,102
SPEAKER_1:  Yes.

03:43:43,874 --> 03:43:55,646
SPEAKER_1:  Embrace it. It's gonna be good. It's gonna be good for you. It's gonna crush your ego to the degrees remaining. And it's just good for you. It's good not to take yourself seriously and do those kinds of things. But honestly, I feel that way.

03:43:56,290 --> 03:43:57,342
SPEAKER_1:  in an audience.

03:43:58,082 --> 03:43:59,134
SPEAKER_1:  I can't open mic.

03:44:00,546 --> 03:44:01,310
SPEAKER_1:  It hurts.

03:44:01,570 --> 03:44:03,550
SPEAKER_1:  That's why I really admire comedians.

03:44:04,354 --> 03:44:08,958
SPEAKER_1:  I go to open mics all the time with comedians and musicians.

03:44:09,346 --> 03:44:11,262
SPEAKER_1:  I just see them bomb and you'll play-

03:44:11,490 --> 03:44:12,606
SPEAKER_1:  play in front of like just a.

03:44:12,834 --> 03:44:13,758
SPEAKER_1:  a few folks and

03:44:14,242 --> 03:44:19,230
SPEAKER_1:  They're putting their heart out and especially the ones that kind of suck, but are going all out anyway.

03:44:19,778 --> 03:44:24,574
SPEAKER_0:  I think open mics are the best place to learn though, because it's the lowest stakes you can get.

03:44:24,802 --> 03:44:26,142
SPEAKER_0:  Well, while still being public.

03:44:26,818 --> 03:44:32,382
SPEAKER_0:  If you're gonna face fears around this, because we're talking very specifically public speaking or any kind of like...

03:44:32,738 --> 03:44:34,078
SPEAKER_0:  you know, being in front of a camera.

03:44:34,338 --> 03:44:35,454
SPEAKER_0:  If you're gonna face your fear.

03:44:35,874 --> 03:44:36,798
SPEAKER_0:  You have to do it.

03:44:37,154 --> 03:44:39,070
SPEAKER_0:  And the easiest way to do it is to lower the stakes.

03:44:39,330 --> 03:44:42,878
SPEAKER_0:  You're not gonna start being Lex Friedman on stage with a huge band. You don't wanna be.

03:44:43,106 --> 03:44:45,854
SPEAKER_0:  Like it's like in that way, it is so impossible.

03:44:46,306 --> 03:44:46,814
SPEAKER_0:  Um.

03:44:47,618 --> 03:44:52,062
SPEAKER_0:  But the more you lower the stakes and just like open it up to like two strangers, five strangers.

03:44:52,738 --> 03:44:54,974
SPEAKER_0:  the most dive bar open mic you can go to.

03:44:55,426 --> 03:44:56,990
SPEAKER_0:  and like start performing.

03:44:57,826 --> 03:45:01,182
SPEAKER_0:  That's really what I did is like, like I love open mics now because it's like.

03:45:02,050 --> 03:45:05,182
SPEAKER_0:  Low stakes on the one hand, but you really get the feeling of like.

03:45:05,506 --> 03:45:05,822
SPEAKER_1:  Mm-hmm.

03:45:06,786 --> 03:45:08,990
SPEAKER_1:  And get better and better and better at that. Yeah, for sure.

03:45:10,690 --> 03:45:11,358
SPEAKER_1:  and then

03:45:11,618 --> 03:45:14,494
SPEAKER_1:  you'll get the strength to take bigger and bigger and bigger risks.

03:45:14,818 --> 03:45:16,766
SPEAKER_1:  Listen, Koff, I'm a huge fan of yours.

03:45:17,218 --> 03:45:19,102
SPEAKER_1:  not just for who you are and

03:45:19,618 --> 03:45:21,150
SPEAKER_1:  but for what you stand for.

03:45:21,538 --> 03:45:22,526
SPEAKER_1:  People like you.

03:45:23,426 --> 03:45:25,534
SPEAKER_1:  are rare and they're a huge inspiration.

03:45:25,922 --> 03:45:27,838
SPEAKER_1:  I just, I'm inspired by your.

03:45:28,162 --> 03:45:29,502
SPEAKER_1:  Fearlessness, the year.

03:45:29,826 --> 03:45:31,966
SPEAKER_1:  that you're taking on some of the.

03:45:32,226 --> 03:45:35,038
SPEAKER_1:  most powerful and richest people in this world in doing so.

03:45:35,362 --> 03:45:43,166
SPEAKER_1:  with respect, I think, with good faith, but also with the boldness and fearlessness. Listen, man, I'm a huge fan. Keep doing what you're doing.

03:45:43,490 --> 03:45:47,614
SPEAKER_1:  As long as you got the strength for it, because I think you inspire all of us. You're doing important work, brother.

03:45:48,034 --> 03:45:48,638
SPEAKER_1:  Thanks for having me.

03:45:49,762 --> 03:45:52,062
SPEAKER_1:  Thanks for listening to this conversation with Coffeezilla.

03:45:52,450 --> 03:45:55,582
SPEAKER_1:  To support this podcast, please check out our sponsors in the description.

03:45:56,002 --> 03:45:56,478
SPEAKER_1:  And now...

03:45:56,738 --> 03:45:59,038
SPEAKER_1:  Let me leave you with some words from Walter Lippmann.

03:45:59,938 --> 03:46:02,142
SPEAKER_1:  There can be no higher law in journalism.

03:46:02,626 --> 03:46:03,678
SPEAKER_1:  than to tell the truth.

03:46:04,034 --> 03:46:05,534
SPEAKER_1:  and to shame the devil.

03:46:06,722 --> 03:46:08,478
SPEAKER_1:  Thank you for listening and hope to see you.

03:46:08,898 --> 03:46:09,406
SPEAKER_1:  next time.
