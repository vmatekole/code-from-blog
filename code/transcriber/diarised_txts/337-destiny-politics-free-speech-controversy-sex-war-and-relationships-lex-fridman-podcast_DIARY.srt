00:00:00,066 --> 00:00:02,910
SPEAKER_0:  if you have a democratic style of governance.

00:00:03,138 --> 00:00:04,798
SPEAKER_0:  You are interesting people.

00:00:05,090 --> 00:00:14,622
SPEAKER_0:  with one of the most awesome and radical of responsibilities. And that's saying that you're going to pick the people that are gonna make some of the hardest decisions in all of human history. If you're gonna trust people.

00:00:14,850 --> 00:00:30,654
SPEAKER_0:  to vote correctly, you have to be able to trust them to have open and honest dialogue with each other. Whether that's Nazis or KKK people or whoever talking, you have to believe that your people are going to be able to rise above and make the correct determinations when they hear these types of speeches. And if you're so worried...

00:00:30,882 --> 00:00:45,342
SPEAKER_0:  that somebody is gonna hear a certain political figure and they're gonna be completely radicalized instantly, then what that tells me is that you don't have enough faith in humans for democracy to be a viable institution, which is fine. You can be anti-democratic, but I don't think you can be pro-democracy and anti-free speech.

00:00:48,194 --> 00:00:50,622
SPEAKER_1:  Following is a conversation with Stephen Bonnell.

00:00:51,394 --> 00:00:53,310
SPEAKER_1:  also known online as Destiny.

00:00:53,730 --> 00:00:56,382
SPEAKER_1:  He's a video game streamer and political commentator.

00:00:56,738 --> 00:00:59,486
SPEAKER_1:  One of the early pioneers of both livestreaming in general.

00:00:59,714 --> 00:01:02,142
SPEAKER_1:  and live streamed political debate and discourse.

00:01:02,754 --> 00:01:04,894
SPEAKER_1:  Politically, he is a progressive.

00:01:05,218 --> 00:01:09,310
SPEAKER_1:  Identifying is either left or far left, depending on your perspective.

00:01:10,018 --> 00:01:12,478
SPEAKER_1:  There are many reasons I wanted to talk to Stephen.

00:01:12,898 --> 00:01:14,558
SPEAKER_1:  First, I just talked to Ben Shapiro.

00:01:14,914 --> 00:01:17,278
SPEAKER_1:  and many people have told me that Stephen.

00:01:17,602 --> 00:01:19,902
SPEAKER_1:  is the bench up here of the left.

00:01:20,354 --> 00:01:24,254
SPEAKER_1:  in terms of political perspective and exceptional debate skills.

00:01:24,930 --> 00:01:25,726
SPEAKER_1:  Second reason.

00:01:26,050 --> 00:01:27,838
SPEAKER_1:  is he skillfully defends

00:01:28,066 --> 00:01:30,334
SPEAKER_1:  some nuanced non-standard views.

00:01:31,106 --> 00:01:35,262
SPEAKER_1:  at the same time being pro-establishment, pro-institutions and pro-Biden.

00:01:35,682 --> 00:01:38,622
SPEAKER_1:  while also being pro-capitalism and pro-free speech.

00:01:39,522 --> 00:01:40,222
SPEAKER_1:  Third reason.

00:01:40,578 --> 00:01:43,198
SPEAKER_1:  is he has been there at the beginning.

00:01:43,426 --> 00:01:47,550
SPEAKER_1:  and throughout the meteoric rise of the video game live streaming community.

00:01:48,098 --> 00:01:49,694
SPEAKER_1:  in some mainstream circles.

00:01:50,082 --> 00:01:52,286
SPEAKER_1:  This community is not taken seriously.

00:01:52,738 --> 00:01:53,310
SPEAKER_1:  Perhaps.

00:01:53,602 --> 00:01:56,574
SPEAKER_1:  because of its demographic distribution skewing young.

00:01:56,994 --> 00:01:57,374
SPEAKER_1:  or

00:01:57,634 --> 00:02:00,702
SPEAKER_1:  perhaps because of the sometimes hard style of communication.

00:02:01,698 --> 00:02:04,926
SPEAKER_1:  But I think this community should be taken seriously.

00:02:05,314 --> 00:02:06,302
SPEAKER_1:  and show them respect.

00:02:07,266 --> 00:02:10,334
SPEAKER_1:  Millions of young minds tune in to live streams like Destiny's.

00:02:10,626 --> 00:02:11,358
SPEAKER_1:  to question.

00:02:11,618 --> 00:02:13,918
SPEAKER_1:  and to try to understand what is going on with the world.

00:02:14,370 --> 00:02:17,534
SPEAKER_1:  often exploring challenging, even controversial ideas.

00:02:18,210 --> 00:02:22,366
SPEAKER_1:  The language is sometimes harsher and the humor sometimes meter than I would prefer.

00:02:22,978 --> 00:02:23,390
SPEAKER_1:  What?

00:02:23,778 --> 00:02:24,254
SPEAKER_1:  I.

00:02:24,770 --> 00:02:25,694
SPEAKER_1:  Grandpa Lex.

00:02:26,146 --> 00:02:30,814
SPEAKER_1:  put on my rain boots, and went into the beautiful chaotic muck of online discourse.

00:02:31,202 --> 00:02:33,534
SPEAKER_1:  and have so far survived to tell the tale.

00:02:34,146 --> 00:02:34,942
SPEAKER_1:  with a smile.

00:02:35,362 --> 00:02:37,790
SPEAKER_1:  and even more love in my heart than before.

00:02:39,266 --> 00:02:40,318
SPEAKER_1:  On top of all this.

00:02:40,674 --> 00:02:43,230
SPEAKER_1:  We were lucky to have Melina Goranson.

00:02:43,522 --> 00:02:45,694
SPEAKER_1:  a popular streamer and world traveler.

00:02:45,954 --> 00:02:47,774
SPEAKER_1:  Join us at the end of the conversation.

00:02:48,098 --> 00:02:51,614
SPEAKER_1:  you can check out her channel on twitch.tv slash Molina.

00:02:52,098 --> 00:02:56,382
SPEAKER_1:  and you can check out Steven's channel on youtube.com slash destiny.

00:02:57,186 --> 00:02:58,910
SPEAKER_1:  This is the Lex Friedman podcast.

00:02:59,202 --> 00:03:02,142
SPEAKER_1:  To support it, please check out our sponsors in the description.

00:03:02,530 --> 00:03:03,742
SPEAKER_1:  And now, dear friends.

00:03:04,226 --> 00:03:05,086
SPEAKER_1:  Here's Destiny.

00:03:06,210 --> 00:03:07,902
SPEAKER_0:  I don't know if you watched me watching your...

00:03:08,130 --> 00:03:09,022
SPEAKER_0:  Yay interview.

00:03:09,634 --> 00:03:10,270
SPEAKER_0:  Thank you so much.

00:03:10,818 --> 00:03:13,694
SPEAKER_0:  I'm so curious when you're navigating a conversation like that.

00:03:14,530 --> 00:03:20,062
SPEAKER_0:  Are you, how intentional is the thought process between like building rapport and pushing and.

00:03:20,194 --> 00:03:28,382
SPEAKER_1:  giving a little and letting like zero, zero intention. I was watching and thank you so much. It was very kind for you to review that conversation. It meant a lot that you.

00:03:28,866 --> 00:03:35,166
SPEAKER_1:  or complimentary parts on the technical aspects of the conversation, but no, zero. And I'm actually deliberately.

00:03:36,226 --> 00:03:39,806
SPEAKER_1:  trying to avoid, I think you've called it debate brain.

00:03:40,162 --> 00:03:43,230
SPEAKER_1:  which is just another flavor of

00:03:43,906 --> 00:03:44,862
SPEAKER_1:  thinking about.

00:03:45,858 --> 00:03:48,350
SPEAKER_1:  like the meta conversation, trying to optimize.

00:03:48,738 --> 00:03:50,078
SPEAKER_1:  How should this conversation go?

00:03:50,498 --> 00:03:52,702
SPEAKER_1:  because I feel like the more...

00:03:52,962 --> 00:03:54,910
SPEAKER_1:  you do that, the better you get at that.

00:03:55,714 --> 00:03:57,534
SPEAKER_1:  the less human connection you have.

00:03:57,858 --> 00:04:05,758
SPEAKER_1:  Like the less genuinely you're actually sitting there in the moment and listening to the person, you're more like calculating what's the right thing to say versus like feeling what is.

00:04:06,242 --> 00:04:10,494
SPEAKER_1:  What is that person feeling right now? What are they thinking? That's what I'm trying to do is like

00:04:10,818 --> 00:04:11,518
SPEAKER_1:  putting myself

00:04:12,226 --> 00:04:13,566
SPEAKER_1:  in their mind and thinking.

00:04:13,826 --> 00:04:15,358
SPEAKER_1:  What does the world look like to them?

00:04:15,650 --> 00:04:17,342
SPEAKER_1:  What does the world feel like to them?

00:04:17,954 --> 00:04:18,750
SPEAKER_1:  And so from that.

00:04:19,202 --> 00:04:21,598
SPEAKER_1:  I truly try to listen. Now I'm also learning.

00:04:22,402 --> 00:04:23,038
SPEAKER_1:  thisgrasshoppers.com

00:04:23,394 --> 00:04:26,174
SPEAKER_1:  Rogan and others have been giving me shit for not pushing back.

00:04:27,010 --> 00:04:28,414
SPEAKER_1:  It's good sometimes to say.

00:04:29,602 --> 00:04:30,334
SPEAKER_1:  from a place of

00:04:30,978 --> 00:04:33,630
SPEAKER_1:  care for the other human being to say stop.

00:04:34,786 --> 00:04:38,942
SPEAKER_1:  What did you just say? I don't think that's represents who you are.

00:04:39,458 --> 00:04:40,574
SPEAKER_1:  and what you really mean.

00:04:40,834 --> 00:04:41,502
SPEAKER_1:  or maybe

00:04:42,370 --> 00:04:44,574
SPEAKER_1:  if it does at that time represents who they are.

00:04:45,474 --> 00:04:46,718
SPEAKER_1:  I can see a better.

00:04:47,714 --> 00:04:51,806
SPEAKER_1:  a better world if they grow into a different direction and try to point that direction out to them.

00:04:52,194 --> 00:04:56,286
SPEAKER_0:  It was a really complicated dance between letting somebody share their full story.

00:04:56,674 --> 00:04:57,790
SPEAKER_0:  versus letting somebody like.

00:04:58,082 --> 00:05:01,694
SPEAKER_0:  essentially, I guess like proselytize your audience and it's like, okay, hold on. Let's-

00:05:02,082 --> 00:05:02,974
SPEAKER_0:  take a minute here but

00:05:03,298 --> 00:05:04,382
SPEAKER_0:  Yeah, I used to be.

00:05:04,898 --> 00:05:13,662
SPEAKER_0:  Four or five years ago, it was attack, attack, attack, attack, attack, whatever you said. And now I'm leaning way more towards the like, okay, well, tell me how you feel about everything and then we'll go from there. Why would you feel the same?

00:05:14,050 --> 00:05:21,886
SPEAKER_0:  A lot of people like my new approach. Some older fans will watch and they're like, why are you letting this guy just ramble on? You know, he said like five or six wrong things and you're only gonna call him out on two of them. And it's like.

00:05:22,274 --> 00:05:24,149
SPEAKER_0:  It's different styles of conversation, but yeah.

00:05:24,149 --> 00:05:24,899
SPEAKER_1:  due to a lot of reason.

00:05:24,899 --> 00:05:25,854
SPEAKER_0:  search beforehand too.

00:05:26,434 --> 00:05:31,934
SPEAKER_0:  depending on the conversation, yeah. So if we're gonna talk like vaccines and stuff, yeah, that's a ton of reading and stuff that I never thought I'd know.

00:05:32,514 --> 00:05:39,639
SPEAKER_0:  going into it. If it's a more personal, like political philosophy conversation, there's not as much you can prepare for just it truly depends on the conversation

00:05:39,639 --> 00:05:41,694
SPEAKER_1:  Are you actually listening to the other person?

00:05:42,082 --> 00:05:48,734
SPEAKER_0:  I'm always listening, you have to listen, because as soon as you stop listening, the quality of everything falls apart, the connection disappears, the quality of the conversation disappears.

00:05:49,122 --> 00:05:51,998
SPEAKER_0:  but my natural inclination is to just be way more aggressive.

00:05:52,418 --> 00:05:56,510
SPEAKER_0:  than normal so I have to constantly remind myself. I guess you would call it a meta conversation when I'm like, okay.

00:05:56,930 --> 00:06:06,846
SPEAKER_0:  He's probably saying this because of that, or we'll let him go here and then we'll stop later. But yeah, because my preferred style of conversation is like, I'm gonna talk, and the second I say something you disagree with, then let's.

00:06:07,458 --> 00:06:11,934
SPEAKER_0:  iron it out, right? I got like, I think I like syllogisms like, okay, here's premise today!

00:06:12,738 --> 00:06:14,270
SPEAKER_0:  Good, okay, premise B, okay.

00:06:14,626 --> 00:06:19,838
SPEAKER_0:  And then conclusion, and then as long as we're both deductively sound, we're not crazy, no psychosis, then we're gonna agree on everything.

00:06:20,098 --> 00:06:28,830
SPEAKER_0:  Whereas other people like to, most people think in stories, like narratives, like a whole, there's a whole like narrative and the individual facts don't matter as much because they'll pick and choose what they want and

00:06:29,506 --> 00:06:32,478
SPEAKER_0:  It's really hard because everybody thinks narrative is so I have to function in that world.

00:06:32,738 --> 00:06:34,622
SPEAKER_0:  but it's frustrating for me sometimes.

00:06:34,818 --> 00:06:35,806
SPEAKER_1:  Why, I seen.

00:06:36,226 --> 00:06:38,558
SPEAKER_1:  You've had a lot of excellent debates, one of them I just-

00:06:38,818 --> 00:06:40,414
SPEAKER_1:  recently last night watch is a

00:06:41,058 --> 00:06:42,270
SPEAKER_1:  on systemic racism.

00:06:42,658 --> 00:06:46,783
SPEAKER_1:  And it's the first time I've seen you completely lose your shit. Oh, shoot.

00:06:46,783 --> 00:06:47,710
SPEAKER_0:  Who was that against?

00:06:47,842 --> 00:06:53,406
SPEAKER_1:  I'm not sure exactly, but you were just very frustrated and sorry, not lose your ship, but you're frustrated constantly because

00:06:53,634 --> 00:06:55,518
SPEAKER_1:  Let's lay out 123.

00:06:55,842 --> 00:06:57,662
SPEAKER_1:  and every time you try to lay it out.

00:06:57,922 --> 00:06:58,942
SPEAKER_1:  it would falter.

00:06:59,362 --> 00:07:00,766
SPEAKER_1:  I think it had to do with sort of.

00:07:01,218 --> 00:07:03,358
SPEAKER_1:  Can you use data to make an argument?

00:07:03,618 --> 00:07:06,878
SPEAKER_1:  or do you need to use a study that does an interpretation of that data?

00:07:07,362 --> 00:07:12,030
SPEAKER_1:  And then there's like this tension between, I think this is a behavioral economist that you were talking to in there.

00:07:12,514 --> 00:07:16,926
SPEAKER_1:  point is you do this kind of nice layout that the whole point of behavioral economics that says

00:07:17,538 --> 00:07:20,670
SPEAKER_1:  there's more to it than just the data. you have to give it context and

00:07:21,314 --> 00:07:25,886
SPEAKER_1:  do the rich, rigorous interpretation in the context of the full human story.

00:07:26,146 --> 00:07:32,158
SPEAKER_1:  And then there was the dance back and forth. Sometimes you use data, sometimes not, and you're getting really frustrated and shutting down.

00:07:32,546 --> 00:07:34,430
SPEAKER_1:  And so that felt like a failure mode.

00:07:34,658 --> 00:07:37,278
SPEAKER_1:  I've seen Sam Harris have similar sticking points.

00:07:37,602 --> 00:07:40,414
SPEAKER_1:  Like if we can't agree on the terminology, we can't go on.

00:07:40,930 --> 00:07:41,470
SPEAKER_1:  to me.

00:07:42,178 --> 00:07:45,054
SPEAKER_1:  I feel like I'm sort of.

00:07:45,634 --> 00:07:47,614
SPEAKER_1:  the Wittgenstein perspective is like.

00:07:49,154 --> 00:07:53,214
SPEAKER_1:  I think if you get stuck on any one thing, you're just not gonna make progress. You have to...

00:07:53,922 --> 00:07:55,774
SPEAKER_1:  Part of the conversation has to be.

00:07:56,802 --> 00:07:57,374
SPEAKER_1:  about.

00:07:58,242 --> 00:08:00,862
SPEAKER_1:  doing a good dance together.

00:08:01,538 --> 00:08:03,486
SPEAKER_1:  versus being dogmatically stuck.

00:08:04,226 --> 00:08:05,534
SPEAKER_1:  on the path to truth.

00:08:05,890 --> 00:08:08,350
SPEAKER_0:  I think the true challenge is identifying.

00:08:08,578 --> 00:08:10,558
SPEAKER_0:  what of those sticking points are important.

00:08:10,914 --> 00:08:12,542
SPEAKER_0:  versus what is.

00:08:13,122 --> 00:08:13,630
SPEAKER_0:  NOT

00:08:14,082 --> 00:08:16,702
SPEAKER_0:  Important. It's like if I'm having an argument with somebody about like

00:08:16,962 --> 00:08:18,686
SPEAKER_0:  Jewish representation in media.

00:08:19,170 --> 00:08:22,750
SPEAKER_0:  they might, it might be like a big conversation they might say a couple things

00:08:23,042 --> 00:08:38,526
SPEAKER_0:  Like I think Jewish people, you know, they tend to help their own or whatever. And it's like, okay. But like for the purpose of the conversation, we can keep moving. But if they casually drop like, you know, yeah. I think that's why the Holocaust numbers were blown up from like 100,000 to 6 million. And that's why I was like, okay, well, hold on. Wait, wait, if you think this, we have to stop here because.

00:08:39,042 --> 00:08:45,950
SPEAKER_0:  This is gonna be, it's not just a language game in this part, if you really believe this fact, then the whole rest of the conversation is gonna be informed by that.

00:08:46,082 --> 00:08:47,998
SPEAKER_1:  believe you know and it has to be something that

00:08:48,706 --> 00:08:50,174
SPEAKER_1:  doesn't bother you personally.

00:08:50,658 --> 00:08:52,318
SPEAKER_1:  You have to step outside your own ego.

00:08:53,058 --> 00:08:57,790
SPEAKER_1:  So Holocaust denial is somebody that would bother a lot of people. And there's some things.

00:08:58,050 --> 00:08:58,494
SPEAKER_1:  I

00:08:58,978 --> 00:09:03,806
SPEAKER_1:  Just observing you, I feel like when you get really good at a conversation, you can become a stickler.

00:09:04,482 --> 00:09:05,278
SPEAKER_1:  to, uh...

00:09:05,730 --> 00:09:07,358
SPEAKER_1:  you might have your favorite terms.

00:09:07,586 --> 00:09:10,211
SPEAKER_1:  that really bothers you people don't agree on a star

00:09:10,211 --> 00:09:17,022
SPEAKER_0:  Begs the question you mean raising the question. Yeah, I usually just want it people say stuff. I just let it slide Yeah, yeah, because if you fight you

00:09:17,506 --> 00:09:24,542
SPEAKER_0:  When you're having a conversation with somebody and you're talking to their audience at the same time, because that's really what's happening, you never want to come off as over combative or over aggressive.

00:09:24,802 --> 00:09:27,774
SPEAKER_0:  because it puts people in like, there's like a trigger in your brain.

00:09:28,002 --> 00:09:37,086
SPEAKER_0:  And this is true of relationships, of friendships, of persuasive rhetoric or whatever. There's a trigger in the brain and as soon as that defensive trigger gets like flipped on, everything is over. You've lost the ability to persuade.

00:09:37,314 --> 00:09:39,166
SPEAKER_0:  because everything becomes a fight at that point.

00:09:39,618 --> 00:09:41,406
SPEAKER_1:  Well, I wanted to talk to you because

00:09:41,698 --> 00:09:47,230
SPEAKER_1:  I heard somewhere that you were referred to as the Ben Shapiro of the left. And since I'm talking with Ben.

00:09:47,618 --> 00:09:50,558
SPEAKER_1:  as well I want it to sort of complete spiritually.

00:09:51,458 --> 00:09:52,638
SPEAKER_1:  this platonic.

00:09:53,026 --> 00:09:54,910
SPEAKER_1:  political philosophy puzzle in my head.

00:09:55,138 --> 00:09:56,862
SPEAKER_1:  You are a progressive.

00:09:57,090 --> 00:09:59,998
SPEAKER_1:  but a progressive with many non-standard progressive views.

00:10:00,322 --> 00:10:05,214
SPEAKER_1:  And you had a heck of a fascinating journey through all of that. Like I said, I think you argue.

00:10:05,826 --> 00:10:10,526
SPEAKER_1:  with passions sometimes with excessive amounts of passion, but almost- way of saying that.

00:10:11,234 --> 00:10:12,126
SPEAKER_1:  Almost always.

00:10:12,578 --> 00:10:15,710
SPEAKER_1:  with good faith and with rigor, with seriousness.

00:10:16,258 --> 00:10:19,710
SPEAKER_1:  I asked on your subreddit, which is an excellent subreddit. Shout out to...

00:10:20,098 --> 00:10:21,502
SPEAKER_1:  the Destiny subreddit.

00:10:22,178 --> 00:10:33,790
SPEAKER_1:  so much at least for that particular post. What I really loved is when I asked for questions for you, they were like, holy shit, there's adults in there, let's all behave. Nobody say incest. I was like, what?

00:10:34,050 --> 00:10:38,814
SPEAKER_1:  What was going on here, but actually the the the questions that rose to the top were really good. So

00:10:39,042 --> 00:10:40,734
SPEAKER_1:  Somebody said that destiny was

00:10:41,666 --> 00:10:47,934
SPEAKER_1:  Speaking of your journey was a conservative in his early teens. Then he became a libertarian

00:10:48,162 --> 00:10:52,702
SPEAKER_1:  Then he became a left-wing social justice warrior. Then he flirted with socialism.

00:10:53,026 --> 00:10:53,662
SPEAKER_1:  And now...

00:10:53,890 --> 00:10:57,342
SPEAKER_1:  He is a social democrat liberal. I've also heard you refer to yourself.

00:10:57,922 --> 00:10:59,454
SPEAKER_1:  as a far left person.

00:11:00,674 --> 00:11:03,870
SPEAKER_1:  to the degree there's truth to that journey. Can you take me through your evolution?

00:11:04,642 --> 00:11:07,070
SPEAKER_1:  through the landscape of political ideologies.

00:11:07,778 --> 00:11:11,102
SPEAKER_0:  that you went through. So my dad comes from Kentucky.

00:11:11,458 --> 00:11:13,886
SPEAKER_0:  and my mom is a Cuban immigrant.

00:11:14,466 --> 00:11:21,790
SPEAKER_0:  Cubans are notorious for being very conservative in the United States for historical reasons and for other reasons, but um.

00:11:22,306 --> 00:11:24,414
SPEAKER_0:  My upbringing was a very Republican one.

00:11:24,770 --> 00:11:27,006
SPEAKER_0:  I grew up listening to Rush Limbaugh.

00:11:27,234 --> 00:11:27,966
SPEAKER_0:  Glenn Beck

00:11:28,194 --> 00:11:29,342
SPEAKER_0:  Michael Savage.

00:11:29,570 --> 00:11:31,486
SPEAKER_0:  on the radio, Billy Cunningham.

00:11:32,418 --> 00:11:37,374
SPEAKER_0:  Sean Hannity a little bit later on, like, that was like my whole upbringing politically. I remember I was writing

00:11:38,434 --> 00:11:40,958
SPEAKER_0:  I'd written articles for the school journal in favor of.

00:11:41,250 --> 00:11:45,278
SPEAKER_0:  uh... defending the war in iraq and you know defending bush from all the criticism

00:11:45,570 --> 00:11:46,110
SPEAKER_0:  I was like...

00:11:46,402 --> 00:11:47,006
SPEAKER_0:  upbringing.

00:11:47,586 --> 00:11:51,358
SPEAKER_0:  I think once I hit high school college, I had my edgy like.

00:11:51,682 --> 00:11:54,654
SPEAKER_0:  libertarian-esque high school phase of like reading Ayn Rand.

00:11:55,010 --> 00:12:01,278
SPEAKER_0:  of figuring out that like, oh my God, nothing in life matters except for class and money. That's actually the answer to everything.

00:12:01,666 --> 00:12:05,694
SPEAKER_0:  I got to college, I became a Ron Paul fan, very big Ron Paul fan.

00:12:06,178 --> 00:12:06,846
SPEAKER_0:  and then

00:12:07,938 --> 00:12:11,454
SPEAKER_0:  From there, I kind of work, do life, life happens.

00:12:11,938 --> 00:12:19,550
SPEAKER_0:  at the kind of the lowest point of my life in terms of where I'm working financially everything is like kind of in ruin in my life. There's a whole bunch of dumb stuff that's happened. Probably my most conservative point.

00:12:19,810 --> 00:12:20,958
SPEAKER_0:  I don't know what it is about like...

00:12:21,218 --> 00:12:26,046
SPEAKER_0:  being poor and thinking like you can work your way out of it, you can do whatever. My upbringing is always just like, if you're not-

00:12:26,370 --> 00:12:26,718
SPEAKER_0:  If you're not.

00:12:27,042 --> 00:12:29,246
SPEAKER_0:  If you're not having financial success, work, work, work, work, work, work.

00:12:29,634 --> 00:12:30,046
SPEAKER_0:  Um.

00:12:30,402 --> 00:12:38,558
SPEAKER_0:  And then I got into streaming, very, very lucky break. Everything just lined up at the right time. And then as I've progressed through streaming, I would say through the years, I've gradually fallen more and more to the left.

00:12:38,882 --> 00:12:42,046
SPEAKER_0:  especially once my kid turned four, five, six years old.

00:12:42,274 --> 00:12:44,478
SPEAKER_0:  and I started to see how much different his life.

00:12:44,706 --> 00:12:45,214
SPEAKER_0:  was.

00:12:45,442 --> 00:12:52,355
SPEAKER_0:  just because of the financial opportunities that I was able to provide for him through no merit of his own. And that started to radically change how I viewed the world in a lot of ways.

00:12:52,355 --> 00:12:54,366
SPEAKER_1:  So actually let's like linger on that

00:12:55,010 --> 00:12:55,678
SPEAKER_1:  Low point.

00:12:56,770 --> 00:12:59,230
SPEAKER_1:  You worked at McDonald's, you worked at a casino.

00:12:59,906 --> 00:13:03,326
SPEAKER_1:  You did carpet cleaning. What was the lowest point?

00:13:04,002 --> 00:13:05,246
SPEAKER_1:  Definitely the carpet cleaning.

00:13:05,570 --> 00:13:11,774
SPEAKER_1:  Really? Absolutely. Why? Why was it the lowest point? That's when you were just flirting with starting streaming?

00:13:12,002 --> 00:13:15,006
SPEAKER_0:  My whole life has been a series of lucky breaks, really, truly.

00:13:15,298 --> 00:13:17,310
SPEAKER_0:  I grew up playing a lot of video games.

00:13:17,570 --> 00:13:18,558
SPEAKER_0:  But back in...

00:13:18,914 --> 00:13:22,407
SPEAKER_0:  my day, our day, you had to read. There's a lot of text on the screen.

00:13:22,407 --> 00:13:23,907
SPEAKER_1:  Back in my day we used to play

00:13:23,907 --> 00:13:28,382
SPEAKER_0:  They didn't all talk to you. Yeah, because nowadays everything's voice acted, back then you to read a lot.

00:13:28,738 --> 00:13:31,363
SPEAKER_0:  I was a really good reader and a really good vocabular.

00:13:31,363 --> 00:13:35,863
SPEAKER_1:  actually say that what games are we talking about what do you mean just reading you're talking about like our p.

00:13:35,863 --> 00:13:44,318
SPEAKER_0:  Yeah, JRPG. So like Final Fantasy games, fantasy stars, like all of these, like any RPG that would have been on the SNES, Sega, PlayStation, these are the things that I'm... Pause it.

00:13:44,834 --> 00:13:45,182
SPEAKER_1:  Okay.

00:13:45,474 --> 00:13:48,190
SPEAKER_1:  I just talked to Todd Howard, who's...

00:13:48,994 --> 00:13:51,486
SPEAKER_1:  of the Elder Scrolls fame and the

00:13:51,810 --> 00:13:53,630
SPEAKER_1:  Fallout fame and beyond.

00:13:54,370 --> 00:13:56,030
SPEAKER_1:  What's your thoughts on Elder Scrolls?

00:13:56,546 --> 00:13:59,102
SPEAKER_1:  Why is Skyrim the greatest RPG of all time?

00:13:59,490 --> 00:13:59,998
SPEAKER_1:  Man.

00:14:00,258 --> 00:14:04,190
SPEAKER_0:  I really don't like Skyrim or Fallout. You don't love it? Oh really?

00:14:04,482 --> 00:14:18,686
SPEAKER_0:  Why do you hate Scarra? Yeah, so I really like characters and like compelling stories and narratives around those characters. And I like to see them kind of like grow and change, kind of like a movie or a story. So in your like Final Fantasy games, you've got characters. There are a lot of like, um...

00:14:19,170 --> 00:14:32,318
SPEAKER_0:  ain't like classical tropes of like a character starts off kind of like edgy angsty all on their own they develop relationships friendships they realize that the life is more about themselves and they do that and i like that that growth that's kind of what you see in all of those old role-playing games

00:14:32,546 --> 00:14:41,921
SPEAKER_0:  I didn't like the open world ones as much because your main character is just like a blank slate, never talks, it's for you to like project onto, but there's not the same like linear narrative of like growth for the character.

00:14:41,921 --> 00:14:48,671
SPEAKER_1:  That's fascinating. There's an actual story arc to the character that's more crafted in a beautiful way by the designers of the game.

00:14:48,671 --> 00:14:55,421
SPEAKER_0:  Yeah, that's better or worse. I tend towards like I want to hear a compelling story around like a set of characters that like grow and change Just again. Oh, that's beautiful.

00:14:55,421 --> 00:14:59,454
SPEAKER_1:  put them. Yeah, I just really loved being able to leave the town.

00:15:00,130 --> 00:15:06,846
SPEAKER_1:  You go outside the town and you look outside its nature and the world of possibilities is before you you do whatever the fuck you want.

00:15:07,074 --> 00:15:08,478
SPEAKER_1:  I mean that immensity.

00:15:08,994 --> 00:15:14,110
SPEAKER_1:  or just being lost in the world. It was really immersive for me. But yeah, you're right. Whatever attracts you about a world.

00:15:14,690 --> 00:15:15,070
SPEAKER_1:  So.

00:15:15,426 --> 00:15:16,542
SPEAKER_1:  You were just starting to.

00:15:17,442 --> 00:15:18,782
SPEAKER_1:  play video games.

00:15:19,138 --> 00:15:21,598
SPEAKER_1:  You go out play video games, that's one of your lucky breaks.

00:15:22,210 --> 00:15:30,878
SPEAKER_0:  There's just like a lot of random skills you pick up depending on the type of game you play. I played a lot of text-based games on the computer, so I was a very fast typer. I'm still a very fast typer.

00:15:31,138 --> 00:15:31,742
SPEAKER_0:  Um...

00:15:32,002 --> 00:15:36,414
SPEAKER_0:  read a lot, learned weird kind of math stuff for some of the calculations, some of the games.

00:15:36,738 --> 00:15:38,270
SPEAKER_0:  I think I'm pretty good at...

00:15:38,562 --> 00:15:40,414
SPEAKER_0:  getting information, figuring stuff out.

00:15:40,738 --> 00:15:41,886
SPEAKER_0:  learning patterns, all of that.

00:15:42,274 --> 00:15:45,598
SPEAKER_0:  And then that plus the reading and everything the games meant that I.

00:15:46,018 --> 00:15:51,358
SPEAKER_0:  I don't want to say I excelled in school because my grades were pretty bad, but I was in all honors, all AP classes or whatever.

00:15:51,586 --> 00:16:00,158
SPEAKER_0:  A lot of dual enrollment, a lot of AP credit going into college. So I did pretty well in school, probably better than I should have, but it was because I had the game stuff that was like really powering a lot of my brain there.

00:16:00,450 --> 00:16:02,174
SPEAKER_0:  I was trying to sleep through class.

00:16:02,434 --> 00:16:04,926
SPEAKER_1:  So you're able to soak in information, integrate it.

00:16:05,602 --> 00:16:08,158
SPEAKER_0:  quickly take notes. generally I think I'm pretty good at that yeah.

00:16:08,514 --> 00:16:12,926
SPEAKER_1:  What you do this a lot when you stream your typing stuff. Is there a system in that note taking?

00:16:13,474 --> 00:16:15,006
SPEAKER_1:  and what note, what do you use?

00:16:15,234 --> 00:16:16,926
SPEAKER_1:  for note taking. doesn't matter.

00:16:17,314 --> 00:16:23,326
SPEAKER_0:  I use a notepad. The original. The original. The notepad.

00:16:23,458 --> 00:16:25,470
SPEAKER_1:  Is there genius in the madness?

00:16:25,730 --> 00:16:27,390
SPEAKER_1:  behind that or you just don't give a shit.

00:16:27,650 --> 00:16:28,382
SPEAKER_0:  No, I mean like...

00:16:28,738 --> 00:16:34,782
SPEAKER_0:  It's going to depend on the style of conversation. If I'm with somebody that is very meticulously organized with their thoughts and they're a...

00:16:35,234 --> 00:16:40,606
SPEAKER_0:  Find a better word here for Rambler. You can edit that in. Better word for Rambler. Some of the talks a lot and a lot. I'll start like.

00:16:41,090 --> 00:17:01,621
SPEAKER_0:  taking notes, bullet points like this, this, this, this, this, this, this, because there's a style of conversation where I say seven or eight different things. And then when you go to respond to everything I said, I cut you off immediately. And we argue that point. But if somebody is going to do that, he's just like, hold on, you just said these eight things, I'm going to respond to every single one. I've written them all down and then you can go if you want to go point by point, we can. But you just said all this and I wrote it down somewhere to go.

00:17:01,621 --> 00:17:04,766
SPEAKER_1:  So what are you actually writing down? Like a couple of words per point they left.

00:17:05,442 --> 00:17:23,486
SPEAKER_0:  Honestly, there are very few unique conversations in politics. A lot of them are retreading old ground. So if we're having a debate on abortion, somebody might say, well, I believe this thing about viability and I believe this thing about when they're a fetus versus a human, and I'll just write down those points so that when I go to respond, I have note cards, a guiding thing there. Except minister,

00:17:23,778 --> 00:17:25,118
SPEAKER_0:  keep me centered on my response.

00:17:25,474 --> 00:17:28,766
SPEAKER_1:  political discourse is a kind of tree you're walking down. I got it. taken

00:17:29,218 --> 00:17:30,078
SPEAKER_0:  Just to keep my...

00:17:30,530 --> 00:17:34,499
SPEAKER_0:  focus guided so I'm not like running off on a weird tangent responding something I didn't say or something

00:17:34,499 --> 00:17:39,326
SPEAKER_1:  What about like doing research? It's just, is there a system to your note taking? Because

00:17:39,714 --> 00:17:43,326
SPEAKER_1:  Mentally, you seem to be one of the most organized people I've listened to, so...

00:17:43,586 --> 00:17:44,158
SPEAKER_1:  Is there...

00:17:44,482 --> 00:17:47,070
SPEAKER_1:  Is it in your mind or is there a system that's on paper?

00:17:47,650 --> 00:17:48,606
SPEAKER_1:  A little of both.

00:17:48,866 --> 00:17:49,918
SPEAKER_0:  I feel like the human mind.

00:17:50,338 --> 00:17:51,294
SPEAKER_0:  is a beautiful thing.

00:17:51,618 --> 00:17:53,086
SPEAKER_0:  If you have interest in an area.

00:17:53,506 --> 00:18:01,566
SPEAKER_0:  So like what I'll tell people is, let's say there's like a totally new topic that I'm researching, I don't know anything. And I'll do a couple of these on stream. I think they're boring, people watch it.

00:18:01,826 --> 00:18:10,238
SPEAKER_0:  I might open a Wikipedia article and I'll read and I hit something I don't know and then I open the next Wikipedia article and I'll read it and then I might have like seven tabs open and I'll read and I'll read and I'll read.

00:18:10,466 --> 00:18:10,910
SPEAKER_0:  Um...

00:18:11,170 --> 00:18:18,110
SPEAKER_0:  and I'll read a ton of stuff, maybe for hour, two, three, four hours of stuff. And then by the end, you know, someone in chat will ask me like, do you even remember like this particular thing?

00:18:18,370 --> 00:18:20,734
SPEAKER_0:  And I'll say, not really, no, not too much.

00:18:21,122 --> 00:18:26,942
SPEAKER_0:  But what happens is, as long as you've seen it once, what'll happen is like the next day of the day after, we'll read something else and be like, oh.

00:18:27,170 --> 00:18:41,694
SPEAKER_0:  I remember that thing from this thing. I remember like vaguely that. And then if you see it like a third time, you're like, oh, this makes sense because especially when it comes to, oh, here's like a little trick on stuff. If you're ever reading any news and there's a place that pops up, always look at it on a map.

00:18:42,050 --> 00:18:47,646
SPEAKER_0:  because so much of history is like on a map. It's so important to like know the geography. It makes things make so much more sense.

00:18:47,874 --> 00:19:00,318
SPEAKER_0:  Um, but yeah, once I, once I start to see stuff over and over again, just because I've like read it a few times, stuff will start to kind of connect to my mind and like, oh yeah, well, this makes sense. Of course these people believe this because of this, or of course, like this happened here, it's because you know, that happened there.

00:19:00,834 --> 00:19:18,654
SPEAKER_0:  So yeah, it's a lot of that. If there's a topic that I'm doing specific research for, so like vaccine related stuff is a big one, the Ukrainian-Russian conflict is a big one, that I'll break out a note, I'll probably get a Google doc, and I'll just start writing an outline of kind of the rough points of everything just to organize my thoughts around different topics.

00:19:18,978 --> 00:19:27,678
SPEAKER_1:  We're just gonna go attention upon attention upon attention. We'll return to the low point of your life at some point. Always returning from the philosophy to the psychology. So you did, uh...

00:19:28,162 --> 00:19:29,118
SPEAKER_1:  the Ukraine topic.

00:19:30,466 --> 00:19:31,710
SPEAKER_1:  One question is...

00:19:32,738 --> 00:19:35,102
SPEAKER_1:  What role does US play?

00:19:36,258 --> 00:19:37,022
SPEAKER_1:  in this war.

00:19:37,570 --> 00:19:39,998
SPEAKER_1:  Could they have done something to avoid the war?

00:19:40,738 --> 00:19:44,990
SPEAKER_1:  Did they have a role to play in forcing Vladimir Putin's hand?

00:19:45,666 --> 00:19:48,158
SPEAKER_1:  Do they have a role to play in?

00:19:48,546 --> 00:19:51,262
SPEAKER_1:  deescalating the war towards a peace agreement.

00:19:51,842 --> 00:19:54,398
SPEAKER_1:  and the opposite if it does escalate.

00:19:55,074 --> 00:19:58,142
SPEAKER_1:  towards something like the use of a tactical nuclear weapon.

00:19:58,562 --> 00:20:00,510
SPEAKER_1:  Are they to blame? Are we to blame?

00:20:01,282 --> 00:20:04,734
SPEAKER_0:  Oh man, somebody sent me an email a while ago with great words.

00:20:05,346 --> 00:20:10,590
SPEAKER_0:  there's a specific way to navigate a conversation where you can kind of like contribute to a negative event

00:20:10,882 --> 00:20:13,054
SPEAKER_0:  but you're not really the one responsible for it.

00:20:13,378 --> 00:20:32,030
SPEAKER_0:  Like the classic example is a woman goes out late at night, gets a little bit too drunk and then something happens. And it's like, while there might have been steps she could have taken to mitigate the risk, it's not her fault of what happened because the responsibility rests on the agent making the choice, right? There's a chooser at some point that is choosing to do wrong or evil.

00:20:32,802 --> 00:20:40,958
SPEAKER_0:  I don't believe in any of the arguments that say the United States has contributed to Russia's position on Ukraine or the actions they've taken on Ukraine.

00:20:41,218 --> 00:20:42,878
SPEAKER_0:  There are several arguments that

00:20:43,106 --> 00:20:44,030
SPEAKER_0:  some people.

00:20:44,322 --> 00:20:50,206
SPEAKER_0:  uh... some even political scholars are are are putting out there to say that the united states to blame but i find them completely unconvincing

00:20:50,882 --> 00:20:55,262
SPEAKER_0:  I think that when you ask the question of like, what is the United States role or what has our role been?

00:20:55,682 --> 00:21:07,742
SPEAKER_0:  I think it's really important for us. I don't think we even agree as a country on what our role should be, which I think is a hard one because you've got this kind of, there's this growing populist movement in the United States. It might be the far left and the far right. I think populists tend to have this kind of.

00:21:08,322 --> 00:21:22,654
SPEAKER_0:  isolationist view of the world, where the United States should just be our own thing, we shouldn't be telling anybody what to do, we shouldn't be the world police, and then kind of more in these like center left, center right positions, and then across a lot of Europe you've got, well okay, the United States is kind of like the big kid on the block.

00:21:22,882 --> 00:21:27,326
SPEAKER_0:  like we're looking to them for guidance and leadership on situations like what's going on in Ukraine.

00:21:27,778 --> 00:21:28,158
SPEAKER_0:  So.

00:21:28,866 --> 00:21:36,574
SPEAKER_0:  Insofar as the original question is like, what is the United States responsibility? I think we have a responsibility to ensure the relative freedom.

00:21:37,026 --> 00:21:38,814
SPEAKER_0:  prosperity and stability across Europe.

00:21:39,202 --> 00:21:43,326
SPEAKER_0:  I think that defending Ukraine's sovereignty and right to their borders is a part of that.

00:21:43,586 --> 00:21:51,422
SPEAKER_0:  And I don't believe that prior to the invasion in 20, 22, I don't think the United States was contributing to Russia invading that country.

00:21:52,418 --> 00:22:09,022
SPEAKER_0:  I know there are arguments given that like the expansion of NATO, you know, has something that's been threatening to Russia, but the Baltics joined and Russia didn't do anything about it. The invasion to Crimea was very clearly a response to the revolution in 2014. The invasion on the borders is clearly a response to Ukraine winning that.

00:22:09,346 --> 00:22:18,302
SPEAKER_0:  Civil War in the southeast and the Donbass and Russia becoming more aggressive. I don't think that you can blame any of that on NATO expansion There's no NATO countries that are threatening Russia or debating Russia.

00:22:18,786 --> 00:22:19,326
SPEAKER_1:  Do you think?

00:22:19,554 --> 00:22:21,022
SPEAKER_1:  There is a nuclear threat.

00:22:22,274 --> 00:22:27,038
SPEAKER_1:  Do you think about this? Do you worry about this? Do you think about this?

00:22:27,650 --> 00:22:31,102
SPEAKER_0:  I think that possibility exists either way, and I think the responsibility for that is on Russia.

00:22:31,650 --> 00:22:36,350
SPEAKER_0:  because it just can't be the case that if you have nukes, you're allowed to invade countries and take their land.

00:22:36,610 --> 00:22:56,702
SPEAKER_0:  Because of anything, I think that that down the road also increases the potential for nuclear problems in the future, right? Because at that point, either every single country has to acquire their own nuclear weapons, because if you don't, Russia's gonna mess with you, or every single country has to join NATO, and now what, we're back at square zero, ground zero, square one, where people are like, oh, well look, all these countries joining NATO is aggressive towards Russia, what are you gonna do?

00:22:57,730 --> 00:23:00,350
SPEAKER_1:  Yeah, you've mentioned that there's a...

00:23:01,122 --> 00:23:04,222
SPEAKER_1:  complicated calculus going on with the countries that have

00:23:04,642 --> 00:23:07,710
SPEAKER_1:  They have nuclear weapons. And what's our responsibility?

00:23:08,578 --> 00:23:12,030
SPEAKER_1:  Are you allowed to do anything you want to countries that don't have nuclear weapons?

00:23:13,186 --> 00:23:19,422
SPEAKER_1:  That's a really tricky discussion. For sure. Because what is US supposed to do if Russia drops the tactical nuclear weapon?

00:23:20,450 --> 00:23:22,078
SPEAKER_1:  There's a set of options.

00:23:23,362 --> 00:23:24,958
SPEAKER_1:  None of which are good.

00:23:25,346 --> 00:23:25,726
SPEAKER_1:  and

00:23:26,914 --> 00:23:28,894
SPEAKER_1:  It's such a tricky moment right now.

00:23:29,378 --> 00:23:30,462
SPEAKER_1:  Because, uh...

00:23:30,914 --> 00:23:32,446
SPEAKER_1:  things that Biden and

00:23:33,218 --> 00:23:34,878
SPEAKER_1:  other public figures say.

00:23:35,202 --> 00:23:41,310
SPEAKER_1:  I feel like has a significant impact on the way this game turns out because I think mutually sure destruction is partially a game of-

00:23:42,882 --> 00:23:43,518
SPEAKER_1:  words.

00:23:43,746 --> 00:23:44,094
SPEAKER_1:  No.

00:23:44,546 --> 00:23:44,862
SPEAKER_1:  That's it.

00:23:45,090 --> 00:23:47,358
SPEAKER_1:  I mean, I believe in the power of conversation.

00:23:48,514 --> 00:23:50,014
SPEAKER_1:  of leaders talking to each other.

00:23:50,626 --> 00:23:51,166
SPEAKER_1:  I feel like.

00:23:52,034 --> 00:23:54,718
SPEAKER_1:  You have to have a balance between threat.

00:23:55,330 --> 00:23:56,638
SPEAKER_1:  and compromise.

00:23:57,314 --> 00:23:57,854
SPEAKER_1:  and like...

00:23:58,850 --> 00:23:59,518
SPEAKER_1:  empathy.

00:23:59,938 --> 00:24:00,830
SPEAKER_1:  for the needs.

00:24:01,218 --> 00:24:02,974
SPEAKER_1:  geopolitical, the economic.

00:24:03,266 --> 00:24:04,254
SPEAKER_1:  needs venation.

00:24:04,930 --> 00:24:07,486
SPEAKER_1:  but also sort of respect.

00:24:08,386 --> 00:24:10,462
SPEAKER_1:  and represent your own interest.

00:24:10,818 --> 00:24:12,990
SPEAKER_1:  It's a tricky one, like how do you play the...

00:24:13,634 --> 00:24:14,654
SPEAKER_1:  How do you play the hand?

00:24:14,978 --> 00:24:15,998
SPEAKER_0:  It reminds me of...

00:24:16,386 --> 00:24:20,958
SPEAKER_0:  I don't know if you've ever heard of evolutionary psychology or evolutionary biology, there are things called tit for tat strategies.

00:24:21,442 --> 00:24:23,070
SPEAKER_0:  It kind of reminds me of that where it's like if...

00:24:23,298 --> 00:24:33,566
SPEAKER_0:  Like there are a whole bunch of these little biological mechanisms where creatures will develop like socializing like tit for tat. If you do something bad to me, I'm going to do something bad for you. And then more complicated schemes will come out where it'll be like.

00:24:33,794 --> 00:24:45,118
SPEAKER_0:  tit tit for tat, or it's like you can make one mistake and then I'm gonna get you if you do a second one or it could be tit tit tit for tat or there could be tit for tat tat for tat. There's like all these like back and forths where creatures kind of optimize themselves and.

00:24:45,506 --> 00:24:45,982
SPEAKER_0:  Um.

00:24:46,466 --> 00:24:50,910
SPEAKER_0:  Yeah, I think something the United States did really well in terms of that kind of conversational strategy and I

00:24:51,426 --> 00:25:10,846
SPEAKER_0:  of this in the beginning was Biden was very clear about setting out like the exact level of US involvement for the war. We're not going to do a no-fly zone. There's not going to be US troops on the ground in Ukraine, but we are going to send a whole bunch of money and a whole bunch of arms and a whole bunch of Intel to them. And I thought he did a good job at laying out like the limitation of the US involvement while opening as much as we could in the ways that we could help.

00:25:11,202 --> 00:25:14,910
SPEAKER_0:  but the, yeah, that looming threat of some sort of tactical nuclear weapon

00:25:15,202 --> 00:25:19,838
SPEAKER_0:  I think on the table right now is like, it's going to be the annihilation of like Russian sea forces and everything, but.

00:25:20,354 --> 00:25:22,174
SPEAKER_0:  you know, what happens if it continues to escalate?

00:25:22,530 --> 00:25:24,510
SPEAKER_0:  That's like a world that nobody wants to.

00:25:24,738 --> 00:25:25,950
SPEAKER_0:  Nobody wants to be in, yeah.

00:25:26,850 --> 00:25:27,975
SPEAKER_0:  So we talked about difficult.

00:25:27,975 --> 00:25:31,870
SPEAKER_1:  and again thank you so much for reviewing the yay conversation

00:25:33,058 --> 00:25:34,206
SPEAKER_1:  Let me ask you about Putin.

00:25:36,578 --> 00:25:38,846
SPEAKER_1:  Speaking of difficult conversations, so if you sit down.

00:25:39,074 --> 00:25:40,958
SPEAKER_1:  if I sit down with somebody like Vladimir Putin.

00:25:41,666 --> 00:25:43,102
SPEAKER_1:  or Volodymyr Zelensky.

00:25:43,842 --> 00:25:47,966
SPEAKER_1:  What's the right way to have that conversation? Oh man. How about that one where we could talk about...

00:25:49,218 --> 00:25:50,494
SPEAKER_1:  somebody more.

00:25:51,234 --> 00:25:52,350
SPEAKER_1:  well understood.

00:25:54,306 --> 00:25:59,230
SPEAKER_1:  through history like something like Stalin or Hitler, something like that. Maybe that's an easier example.

00:25:59,522 --> 00:26:00,478
SPEAKER_1:  to illustrate.

00:26:01,442 --> 00:26:03,998
SPEAKER_1:  how to handle extremely difficult conversations.

00:26:04,258 --> 00:26:07,102
SPEAKER_0:  Yeah, I mean, I can handle really difficult conversations between like two people.

00:26:07,458 --> 00:26:12,734
SPEAKER_0:  uh... use of countries though your there's so much that you are representing in that conversation

00:26:13,410 --> 00:26:15,326
SPEAKER_0:  I guess the thing that would be interesting to me...

00:26:16,226 --> 00:26:17,310
SPEAKER_0:  would be like what his.

00:26:17,634 --> 00:26:19,262
SPEAKER_0:  Vladimir Putin's interest.

00:26:19,554 --> 00:26:20,926
SPEAKER_0:  Like what is the genuine?

00:26:21,218 --> 00:26:22,366
SPEAKER_0:  interest that he has.

00:26:22,594 --> 00:26:29,310
SPEAKER_0:  in the conflict. Because I think finding out like what is your buy-in or what is your like what is the driving force keeping here is probably the most important thing.

00:26:29,570 --> 00:26:32,670
SPEAKER_0:  I think for Zelensky, I think it's quite a bit more simpler because he's-

00:26:33,282 --> 00:26:35,934
SPEAKER_0:  he's on the defense, so it's defending his country and his people.

00:26:36,258 --> 00:26:57,054
SPEAKER_0:  For Putin, I've heard all sorts of things. Dugan has his writings on the East versus the West, the collapse of the West in the face of all of the liberalism and the weird LGBT stuff that they criticize. You've got the desire to return to this former Soviet Union-esque thing. You've got Putin's quotes that the collapse of the Soviet Union was the biggest geopolitical disaster. You've got Putin's quotes that the collapse of the Soviet Union

00:26:57,378 --> 00:26:58,398
SPEAKER_0:  20th century and...

00:26:58,914 --> 00:27:03,070
SPEAKER_0:  I guess figuring out like what is Putin after? I'm not actually sure. I don't know the answer to that question. People write about it, but yeah.

00:27:03,170 --> 00:27:09,758
SPEAKER_1:  Well, there's a lot of answers to that question. There's a lot of answers that he can give you that question. So say sit down with them for three hours and talk about it.

00:27:10,978 --> 00:27:11,934
SPEAKER_1:  I think.

00:27:12,642 --> 00:27:16,894
SPEAKER_1:  This is a really interesting distinction because you do do difficult conversations.

00:27:17,186 --> 00:27:18,654
SPEAKER_1:  in the space of ideas.

00:27:19,138 --> 00:27:24,766
SPEAKER_1:  But also in your stream you have, I mean there's a bunch of drama going on, there's human psychologies laid out.

00:27:25,218 --> 00:27:27,262
SPEAKER_1:  in its full richness before you.

00:27:27,682 --> 00:27:30,206
SPEAKER_1:  So to me with leaders, I think.

00:27:31,042 --> 00:27:34,078
SPEAKER_1:  Part of the conversation has to be about the human psychology.

00:27:35,298 --> 00:27:37,182
SPEAKER_1:  not like a meta conversation, but like.

00:27:38,402 --> 00:27:39,582
SPEAKER_1:  really understand.

00:27:39,938 --> 00:27:43,006
SPEAKER_1:  what they feel, what they fear, who they are as a human being.

00:27:43,586 --> 00:27:43,934
SPEAKER_1:  make.

00:27:44,162 --> 00:27:45,374
SPEAKER_1:  as a family man.

00:27:46,018 --> 00:27:46,686
SPEAKER_1:  as a

00:27:47,234 --> 00:27:49,374
SPEAKER_1:  as a person proud of their country.

00:27:49,666 --> 00:27:52,062
SPEAKER_1:  as a person with an ego, as a person who's been...

00:27:52,514 --> 00:27:55,646
SPEAKER_1:  affected, if not corrupted by powers, all of us.

00:27:55,970 --> 00:27:57,918
SPEAKER_1:  can be and likely are.

00:27:58,498 --> 00:27:59,262
SPEAKER_1:  So all of that.

00:27:59,522 --> 00:28:01,534
SPEAKER_1:  That gives context to then

00:28:02,018 --> 00:28:04,254
SPEAKER_1:  the answers about what do you want in this war.

00:28:04,514 --> 00:28:05,662
SPEAKER_1:  is that the answers.

00:28:06,018 --> 00:28:07,262
SPEAKER_1:  what you want in this

00:28:07,490 --> 00:28:09,246
SPEAKER_1:  war will be political answers.

00:28:10,082 --> 00:28:15,518
SPEAKER_1:  It's like a game that's being played again with words and politicians are incredibly good at playing that game.

00:28:16,162 --> 00:28:17,534
SPEAKER_1:  I think the deeper truth.

00:28:18,530 --> 00:28:21,790
SPEAKER_1:  comes from understanding the human being from which those words.

00:28:23,234 --> 00:28:26,609
SPEAKER_1:  And I think that's what you do. I don't know if you do those kinds of conversations where.

00:28:26,609 --> 00:28:27,262
SPEAKER_0:  never talked to any.

00:28:27,554 --> 00:28:28,679
SPEAKER_0:  country leader so

00:28:28,679 --> 00:28:34,910
SPEAKER_1:  Not a country leader, but say a controversial figure or somebody that represents a certain idea. Don't just...

00:28:35,330 --> 00:28:37,502
SPEAKER_1:  talk in the space of ideas or challenge the ideas.

00:28:37,922 --> 00:28:41,342
SPEAKER_1:  but understand who is this person, how did you come to those ideas?

00:28:41,826 --> 00:28:45,278
SPEAKER_0:  Oh yeah, when I've had... there have been a couple of very controversial...

00:28:45,570 --> 00:28:46,782
SPEAKER_0:  Riot Leaning Figures.

00:28:47,010 --> 00:28:50,878
SPEAKER_0:  uh... so the two obviously the my streams are lauren southern and nick juntas

00:28:51,170 --> 00:28:53,854
SPEAKER_0:  and those types of conversations initially.

00:28:54,274 --> 00:28:56,702
SPEAKER_0:  aren't very political at all. Yeah, it's more like like

00:28:57,186 --> 00:28:59,390
SPEAKER_0:  Obviously we believe in very, very, very different things.

00:28:59,618 --> 00:29:04,958
SPEAKER_0:  Beliefs don't happen accidentally, so how did you get to where you are? Those are way more personal conversations, that's true.

00:29:05,218 --> 00:29:11,710
SPEAKER_1:  Is there things you regret about those conversations where you failed? Is there things you're proud of where you succeeded?

00:29:12,322 --> 00:29:16,798
SPEAKER_0:  for things that I'm proud of. I feel like I'm really good at attempting...

00:29:17,154 --> 00:29:18,590
SPEAKER_0:  to understand people without judgment.

00:29:19,010 --> 00:29:24,670
SPEAKER_0:  that I think a lot of people feel like they can have conversations with me where they can share a lot and I'm not going to jump down their throat for

00:29:24,930 --> 00:29:28,062
SPEAKER_0:  them having a politically incorrect observation, or for them.

00:29:28,322 --> 00:29:41,502
SPEAKER_0:  being judgmental to somebody else or having like a feeling that's maybe not something they should have, something they're embarrassed about. So I think I do a really good job at that. And then by extension of that, I've gotten the ability to hear perspectives from so many different people that I think I can understand a lot of different perspectives.

00:29:42,114 --> 00:29:44,190
SPEAKER_0:  Um, for failures of mine...

00:29:44,610 --> 00:29:45,790
SPEAKER_0:  I mean, it's always going to be...

00:29:46,690 --> 00:29:51,262
SPEAKER_0:  On stream, it'll be like I didn't push back hard enough or I didn't know a certain fact for a conversation.

00:29:51,746 --> 00:30:00,894
SPEAKER_0:  These are usually the they're going to be on these like very technical grounds generally. I'm pretty happy with like the direction my conversations have gone recently especially over like the past six months.

00:30:01,026 --> 00:30:02,078
SPEAKER_1:  So your goal is to...

00:30:02,914 --> 00:30:05,022
SPEAKER_1:  and de-radicalize the audience.

00:30:05,346 --> 00:30:06,046
SPEAKER_1:  those folks.

00:30:06,690 --> 00:30:08,126
SPEAKER_0:  So that used to be my goal.

00:30:08,514 --> 00:30:12,894
SPEAKER_0:  My goal was de-radicalization. Now I'm kind of hoping that that's just the byproduct.

00:30:13,282 --> 00:30:15,998
SPEAKER_0:  So the goal I think is to talk to somebody and to show.

00:30:16,226 --> 00:30:23,294
SPEAKER_0:  They believe this because of these reasons. And if you wanna change people's beliefs, we have to talk about the underlying reasons for why they think the things they think.

00:30:23,618 --> 00:30:29,566
SPEAKER_0:  It's not enough to just say like that belief is bad. Cause it's like, well, they believe it for a whole bunch of things that are true and real to them at least.

00:30:29,826 --> 00:30:31,902
SPEAKER_0:  So you have to address all of the underlying.

00:30:32,354 --> 00:30:34,814
SPEAKER_0:  things that they believe before you can change the overlying belief.

00:30:35,426 --> 00:30:39,902
SPEAKER_0:  So if I'm having a conversation with somebody, it'll be like, okay, why do you feel this about that, that, and that?

00:30:40,162 --> 00:30:41,342
SPEAKER_0:  Okay, I understand that.

00:30:41,634 --> 00:30:43,486
SPEAKER_0:  Maybe like a better way to solve that would be like...

00:30:43,906 --> 00:30:44,926
SPEAKER_0:  this or that instead of

00:30:45,282 --> 00:30:46,366
SPEAKER_0:  this thing. This change will decide how many times a run a month.

00:30:46,722 --> 00:30:49,534
SPEAKER_1:  To what degree do you have to empathize with the person's worldview?

00:30:50,306 --> 00:30:51,262
SPEAKER_1:  versus pushback.

00:30:51,522 --> 00:30:53,566
SPEAKER_0:  That's always the hard one.

00:30:53,922 --> 00:31:07,358
SPEAKER_0:  When I'm talking to other people, it's almost always me stepping as much inside their bubble as I can. I have to like live and breathe their worldview and be able to speak their worldview in order to like navigate their thoughts. Because my worldview is um...

00:31:07,778 --> 00:31:22,846
SPEAKER_0:  I'm not even using this as an insult. I don't know if I am a little bit autistic or something, but when I break apart things, I just want to see like study, study, study, fact, fact, fact. That's how my mind works for everything. That's just how, that's what I like to see. Like personal stories don't do much for me. Narratives don't do much for me. Show me like the data and the studies or whatever.

00:31:23,074 --> 00:31:28,094
SPEAKER_0:  But for other people, I think most brains are more human than that, and they tend to see things more kind of like

00:31:28,322 --> 00:31:34,494
SPEAKER_0:  uh... surreal pictures that kind of painted in the brush strokes are way broader and you know they don't care about the itty bitty tiny fact

00:31:35,234 --> 00:31:42,046
SPEAKER_0:  So if I'm talking to somebody else and I'm trying to get into their head and I'm trying to change their mind on things, I'm going to be stepping into their world.

00:31:42,690 --> 00:31:44,766
SPEAKER_0:  and I'm going to try to be working through that framework.

00:31:44,994 --> 00:31:46,462
SPEAKER_0:  Really good example might be...

00:31:47,074 --> 00:32:03,134
SPEAKER_0:  We'll say like when it comes to trans issues for minors, okay? 16 or 17 year old needs to get on puberty blockers. The way that I want that debate to play out is let's look at all the data, let's see what are the outcomes, let's see what are the processes for getting a medication, and then we'll evaluate all of that and then we'll go in whatever.

00:32:03,746 --> 00:32:12,030
SPEAKER_0:  points more favorably, but that's wholly unconvincing to most people, right? So as a parent, if I'm having that conversation with another parent, the easiest way for me to have that conversation is like, hey.

00:32:12,258 --> 00:32:17,822
SPEAKER_0:  We both have kids. Imagine how horrible it would be if we felt like our kids needed help and the government was trying to get between.

00:32:18,082 --> 00:32:20,286
SPEAKER_0:  us and their doctor in that conversation.

00:32:20,578 --> 00:32:36,830
SPEAKER_0:  That might be how that talk plays out, which I think that's a really good argument because I think there probably are times when the government should get in between it, but I'll have that conversation because now I'm in a world where they understand what I'm saying. I'm resonating with the way that they feel about things and then I can make progress with the way that they're kind of viewing the world because I'm talking in a language they understand.

00:32:37,282 --> 00:32:42,494
SPEAKER_1:  So on this particular topic of trans issues, is that the reason you were banned from Twitch?

00:32:42,722 --> 00:32:44,286
SPEAKER_0:  I'm not sure, I don't know.

00:32:44,578 --> 00:32:49,246
SPEAKER_0:  They just said hate speech, but I don't use like slurs or anything. So it's hard to know exactly so

00:32:49,346 --> 00:32:55,006
SPEAKER_1:  I think you made the claim that trans women shouldn't compete with cis women in women's athletics. I think you made the claim that trans women shouldn't compete with cis women in women's athletics.

00:32:55,746 --> 00:32:56,510
SPEAKER_1:  Can you...

00:32:57,410 --> 00:33:00,062
SPEAKER_1:  Make this case and can you still man the case against it?

00:33:00,546 --> 00:33:02,718
SPEAKER_1:  I think in your community there's a lot of

00:33:03,042 --> 00:33:04,382
SPEAKER_1:  Trans folks who love you

00:33:04,738 --> 00:33:06,846
SPEAKER_1:  and there's a lot who hate you. yeah.

00:33:07,074 --> 00:33:09,758
SPEAKER_1:  And so if you can walk the tightrope.

00:33:09,986 --> 00:33:11,006
SPEAKER_1:  of this conversation.

00:33:11,394 --> 00:33:12,766
SPEAKER_1:  try to steel man both sides.

00:33:13,218 --> 00:33:20,158
SPEAKER_0:  One of the argumentative strategies I say is that like any time you have a conversation, you should be able to argue both sides better than anybody else.

00:33:20,482 --> 00:33:22,846
SPEAKER_0:  for the my side, the genuine belief side.

00:33:23,074 --> 00:33:23,550
SPEAKER_0:  uh...

00:33:24,002 --> 00:33:25,822
SPEAKER_0:  It feels like overwhelmingly.

00:33:26,242 --> 00:33:27,998
SPEAKER_0:  All of the data is showing that.

00:33:28,386 --> 00:33:30,206
SPEAKER_0:  trans, mostly trans women.

00:33:30,594 --> 00:33:35,838
SPEAKER_0:  Even after I think three years on some sort of like HRT or you know estrogen

00:33:36,130 --> 00:33:36,542
SPEAKER_0:  uh

00:33:36,930 --> 00:33:42,046
SPEAKER_0:  stuff, they're still maintaining these advantages from their male puberty over cisgender women.

00:33:42,754 --> 00:33:48,190
SPEAKER_0:  And if that is the case, if we are gonna draw these distinctions around our sports between women and men,

00:33:48,418 --> 00:33:55,294
SPEAKER_0:  It feels unfair to have a category inside the women's sports that are maintaining advantages that are coming from a male puberty.

00:33:55,650 --> 00:33:57,982
SPEAKER_0:  regardless of the amount of time they've spent on

00:33:58,306 --> 00:33:59,774
SPEAKER_0:  hormone replacement therapy.

00:34:00,354 --> 00:34:02,046
SPEAKER_0:  So that would be my argument on that side.

00:34:02,370 --> 00:34:05,598
SPEAKER_1:  So it's unfair from a performance enhancement.

00:34:06,018 --> 00:34:07,614
SPEAKER_1:  So the same way we ban

00:34:08,322 --> 00:34:09,150
SPEAKER_1:  performance.

00:34:09,474 --> 00:34:13,854
SPEAKER_1:  performance enhancing drugs that involve increasing of testosterone.

00:34:14,210 --> 00:34:18,270
SPEAKER_1:  in that same way would be unfair. Essentially, yeah. What's the case?

00:34:18,914 --> 00:34:19,422
SPEAKER_1:  against.

00:34:19,874 --> 00:34:23,262
SPEAKER_0:  Yeah, so the case in favor of them competing together is that

00:34:23,490 --> 00:34:27,326
SPEAKER_0:  realistically, there's not going to be a transports category.

00:34:27,714 --> 00:34:32,542
SPEAKER_0:  realistically trans women aren't going to be competitive with cis men because they've gone through these huge

00:34:32,834 --> 00:34:35,838
SPEAKER_0:  uh... you know like hormone changes by the medication they're taking

00:34:36,642 --> 00:34:47,774
SPEAKER_0:  And that when we look at how sports are kind of done anyway, there's a whole bunch of biological differences between people within sports categories that are determining their placement in the professional world.

00:34:48,130 --> 00:34:49,630
SPEAKER_0:  So for instance,

00:34:49,890 --> 00:34:52,926
SPEAKER_0:  Somebody like me is probably never gonna go far in the NBA because I'm not tall enough.

00:34:53,218 --> 00:34:58,334
SPEAKER_0:  I think the average height in the NBA. Don't doubt yourself. Don't doubt myself, yeah. I want to say like six, six or something there.

00:34:58,786 --> 00:35:00,542
SPEAKER_0:  huge people.

00:35:00,866 --> 00:35:07,006
SPEAKER_0:  Or you know, you look at like Michael Phelps as a classic example of a guy whose torso is like so long, his body is built for swimming.

00:35:07,458 --> 00:35:20,350
SPEAKER_0:  And I think there are some trans people that will look at that or somebody advocating for this position. They'll look at that and they'll go, okay, realistically, the way that Michael Phelps body processes lactic acid, the shape physiologically of his body, it's gonna put him in a level of competition.

00:35:20,802 --> 00:35:23,326
SPEAKER_0:  so many men are never going to reach just because of biology.

00:35:23,746 --> 00:35:43,742
SPEAKER_0:  How is it fair that you can have these biological outliers competing in these categories, but then when we come to like sports categories with trans and cis women, you're going to take trans women and say that they can't compete against cis women. Can't you also just say that they have some level of biological difference there? Like is it really going to be that great of a difference than what Michael Phelps has versus the average swimmer or an NBA player has versus like the average height male?

00:35:45,154 --> 00:35:45,726
SPEAKER_1:  Yeah.

00:35:46,370 --> 00:35:53,854
SPEAKER_1:  Do you think we're gonna get into some tricky ethical territory as we start to be able to, through biology and genetics, modify the human body?

00:35:54,978 --> 00:35:55,806
SPEAKER_0:  Absolutely.

00:35:56,162 --> 00:36:04,734
SPEAKER_0:  I feel like those things are coming sooner than we wanted them to. The, oh man, do the AI, have you seen the AI art? Yes, that's so.

00:36:04,898 --> 00:36:06,023
SPEAKER_1:  Of course, I'm an AI person.

00:36:06,023 --> 00:36:13,694
SPEAKER_0:  Oh, okay, then yeah, yeah. That's always been like, what's gonna happen when robots can do art better than humans lol.

00:36:13,922 --> 00:36:19,038
SPEAKER_0:  Like, well, we'll see in 20 years, in 20 years, in 20 years. And now you have AI art winning competitions.

00:36:19,394 --> 00:36:19,934
SPEAKER_0:  and

00:36:20,162 --> 00:36:21,214
SPEAKER_0:  It's funny because...

00:36:21,858 --> 00:36:23,774
SPEAKER_0:  robots are essentially

00:36:24,098 --> 00:36:27,390
SPEAKER_0:  What's the robot behind you by the way? The robot behind me? Bro, oh nice.

00:36:27,650 --> 00:36:31,806
SPEAKER_0:  Robots are really good. Careful what you say. Yeah, I'll be careful.

00:36:32,066 --> 00:36:37,141
SPEAKER_0:  That's not like one of the Chinese ones with a gun on it, right? Oh, okay. Hopefully not.

00:36:37,141 --> 00:36:38,641
SPEAKER_1:  What we'll see depending on

00:36:38,641 --> 00:36:39,710
SPEAKER_0:  what you say.

00:36:40,034 --> 00:36:44,350
SPEAKER_0:  Robots are really good at showing the limitations of the human mind.

00:36:44,770 --> 00:36:45,406
SPEAKER_0:  and

00:36:45,634 --> 00:36:48,126
SPEAKER_0:  Categories that we didn't believe we were limited before

00:36:48,610 --> 00:36:51,678
SPEAKER_0:  I think that humans have this idea intrinsically.

00:36:52,354 --> 00:36:54,302
SPEAKER_0:  we have like some type of...

00:36:54,562 --> 00:36:54,910
SPEAKER_0:  Like.

00:36:55,138 --> 00:36:57,086
SPEAKER_0:  innovative creative drive.

00:36:57,346 --> 00:37:03,326
SPEAKER_0:  that is just outside of the bounds of physical understanding. And with a sophisticated enough program,

00:37:03,554 --> 00:37:07,230
SPEAKER_0:  we see that maybe that's not actually true that's a really scary thing

00:37:07,522 --> 00:37:21,310
SPEAKER_0:  philosophically to deal with because we feel like we're very special, right? We own the planet, we make computers, and the idea that you can start to get these robots that can do things that's like, okay, you can do math. Fine. Okay. You can do calculations, but it's fine, but you can't do art. That's the human stuff.

00:37:21,634 --> 00:37:23,550
SPEAKER_0:  And then when I start to do that, it's like, oh shoot.

00:37:23,970 --> 00:37:26,558
SPEAKER_1:  And that terrifies you a little bit, like a losing.

00:37:27,202 --> 00:37:29,726
SPEAKER_1:  the human species losing control of our dominance.

00:37:30,050 --> 00:37:30,750
SPEAKER_0:  Um...

00:37:31,042 --> 00:37:37,214
SPEAKER_0:  I don't think it's necessarily losing control of our dominance. I mean, I guess like a Skynet thing could come in at some point. But I think it more...

00:37:38,306 --> 00:37:40,062
SPEAKER_0:  brings us to this really fundamental level of like

00:37:40,450 --> 00:37:42,590
SPEAKER_0:  What does it mean to be human? What is it that we're good at?

00:37:42,914 --> 00:37:47,550
SPEAKER_0:  What should we be doing with technology? We never really ask that question in the Western world. It's always...

00:37:48,130 --> 00:37:50,398
SPEAKER_0:  Technology is normative in that.

00:37:50,626 --> 00:38:13,854
SPEAKER_0:  Technology equals good and more technology equals better. That's been like the default assumption. In fact, if you ask a lot of people, how do you know if civilization has progressed over the past 100 or 200 years? They don't say we have better relationships, we have longer marriages, we blah, blah, blah. They'll say technology has improved. We've got crazy phones, we've got crazy computers. And the idea that more technology might be bad has never even crossed somebody's mind, unless it's used for a really bad thing.

00:38:13,986 --> 00:38:17,822
SPEAKER_1:  Well, it's interesting. We kind of think as more and more automation is happening.

00:38:18,114 --> 00:38:18,654
SPEAKER_1:  We're going to.

00:38:19,202 --> 00:38:25,182
SPEAKER_1:  more and more meaning from things like being artists and doing creative pursuits. And here's like, oh shit.

00:38:26,146 --> 00:38:38,974
SPEAKER_1:  If the art, if the creative pursuits are also being automated, then what are we going to gain meaning from? What are the activities from which you'll gain meaning? You know, my whole life had been working on artificial intelligence systems. There's been different revolutions. One of them is that.

00:38:39,234 --> 00:38:41,214
SPEAKER_1:  is the machine learning revolution and.

00:38:42,338 --> 00:38:44,510
SPEAKER_1:  It's interesting to build up intuition and.

00:38:45,282 --> 00:38:50,366
SPEAKER_1:  destroy that intuition about what is and isn't solvable by machines.

00:38:50,594 --> 00:38:51,998
SPEAKER_1:  I think, um...

00:38:52,386 --> 00:38:53,566
SPEAKER_1:  for the longest time I grew up.

00:38:53,794 --> 00:38:56,894
SPEAKER_1:  thinking the game of Go is not solvable.

00:38:57,570 --> 00:38:58,014
SPEAKER_1:  uh

00:38:58,626 --> 00:39:00,830
SPEAKER_1:  because my understanding of AI systems.

00:39:01,250 --> 00:39:02,462
SPEAKER_1:  is ultimately this.

00:39:03,554 --> 00:39:06,142
SPEAKER_1:  is fundamentally a search mechanism.

00:39:06,466 --> 00:39:08,798
SPEAKER_1:  that is fundamentally going to be brute force.

00:39:09,250 --> 00:39:10,375
SPEAKER_1:  There's no shortcuts.

00:39:10,375 --> 00:39:15,390
SPEAKER_0:  Sure. Like if it can't solve the traveling salesman problem, it's not even going to be able to give you an approximation.

00:39:15,810 --> 00:39:22,046
SPEAKER_1:  So most interesting problems are giant travel salesman problem. And then so of course it's not going to be able to solve that.

00:39:22,562 --> 00:39:24,926
SPEAKER_1:  then the deep learning revolution.

00:39:25,218 --> 00:39:29,022
SPEAKER_1:  made you realize holy shit these large neural networks with a giant number of knobs

00:39:29,378 --> 00:39:30,814
SPEAKER_1:  is able to actually

00:39:31,042 --> 00:39:31,998
SPEAKER_1:  somehow.

00:39:32,514 --> 00:39:33,054
SPEAKER_1:  uh...

00:39:33,730 --> 00:39:34,814
SPEAKER_1:  estimate.

00:39:35,202 --> 00:39:35,966
SPEAKER_1:  functions.

00:39:36,322 --> 00:39:36,830
SPEAKER_1:  They can.

00:39:37,346 --> 00:39:42,622
SPEAKER_1:  do a pretty good job of understanding deep representation of a thing, whether that's a game of Go.

00:39:42,978 --> 00:39:44,574
SPEAKER_1:  or whether it's the human.

00:39:44,802 --> 00:39:45,886
SPEAKER_1:  Natural Language.

00:39:46,178 --> 00:39:49,086
SPEAKER_1:  or if it's images and video or.

00:39:49,474 --> 00:39:53,918
SPEAKER_1:  audio and even actions in different video games and actions of robotics and so on.

00:39:54,370 --> 00:39:57,726
SPEAKER_1:  And then you realize with diffusion models and different

00:39:58,114 --> 00:40:01,918
SPEAKER_1:  different generative models you start to realize holy shit it can actually

00:40:02,146 --> 00:40:02,942
SPEAKER_1:  generate.

00:40:03,202 --> 00:40:04,126
SPEAKER_1:  Not just.

00:40:04,898 --> 00:40:05,822
SPEAKER_1:  Interesting.

00:40:06,466 --> 00:40:06,782
SPEAKER_1:  Uh.

00:40:07,490 --> 00:40:08,542
SPEAKER_1:  representations.

00:40:08,802 --> 00:40:15,870
SPEAKER_1:  or interesting manifestations of the representations of forms, but it's able to do something that impresses humans in its creativity.

00:40:16,674 --> 00:40:22,206
SPEAKER_1:  It's beautiful in the way we think of art is beautiful. Like it surprises us and makes us chuckle and makes us.

00:40:22,722 --> 00:40:24,958
SPEAKER_1:  a sit back and all and all those kinds of things.

00:40:25,378 --> 00:40:29,630
SPEAKER_1:  And yet the thing that it seems to struggle with the most is the physical world currently.

00:40:30,434 --> 00:40:33,630
SPEAKER_1:  So that's counterintuitive. We humans think that it's, um...

00:40:33,890 --> 00:40:34,878
SPEAKER_1:  It's pretty trivial.

00:40:35,330 --> 00:40:37,150
SPEAKER_1:  the being able to pick up a cup.

00:40:38,146 --> 00:40:42,366
SPEAKER_1:  Being able to like write with a pen, like in the physical space, we think that's trivial.

00:40:42,978 --> 00:40:45,662
SPEAKER_1:  We give ourselves respect for being great artists and great.

00:40:46,082 --> 00:40:50,846
SPEAKER_1:  mathematicians and all that kind of stuff and that seems to be much easier than the physical space.

00:40:51,074 --> 00:40:54,078
SPEAKER_0:  Her bodies are really cool. There is a, um, I don't know-

00:40:54,530 --> 00:41:02,302
SPEAKER_0:  probably Azimov or somebody there was some science fiction writer that had a short story and it was like an alien that had landed on earth and it was describing our bodies from a totally alien perspective.

00:41:02,530 --> 00:41:13,310
SPEAKER_0:  And when you think about all the things we can do, it's pretty cool. We can climb through a whole multitude of environments. We can exist in a multitude of temperatures. We can manipulate things.

00:41:13,602 --> 00:41:25,694
SPEAKER_0:  just with our hands and how you know the way that we can interact with things around us and yeah We're very capable on like a physical level even though like you said we think about ourselves like oh well human beings have really big brains and we do we're really intelligent as well but our bodies are pretty cool too.

00:41:26,402 --> 00:41:27,198
SPEAKER_0:  And it's out.

00:41:27,714 --> 00:41:30,110
SPEAKER_1:  Fascinating hierarchical biological system.

00:41:30,658 --> 00:41:31,550
SPEAKER_1:  Like, um...

00:41:32,258 --> 00:41:33,982
SPEAKER_1:  that were made up of a bunch of different

00:41:35,554 --> 00:41:36,606
SPEAKER_1:  living organisms.

00:41:37,314 --> 00:41:39,198
SPEAKER_1:  that all don't know about the big picture.

00:41:39,522 --> 00:41:43,934
SPEAKER_1:  of our body and it's all functioning its own little local world is doing this thing.

00:41:44,194 --> 00:41:45,982
SPEAKER_1:  but together as of.

00:41:46,498 --> 00:41:49,950
SPEAKER_1:  it forms a super resilient system. All of that.

00:41:50,338 --> 00:41:50,974
SPEAKER_1:  comes from.

00:41:51,778 --> 00:41:53,310
SPEAKER_1:  a very, uh...

00:41:53,986 --> 00:41:54,814
SPEAKER_1:  compressed

00:41:55,522 --> 00:42:01,534
SPEAKER_1:  encoding of what makes a human you start with the DNA and it builds up from a single cell to giant organism.

00:42:02,690 --> 00:42:03,838
SPEAKER_1:  I mean, and...

00:42:04,226 --> 00:42:05,470
SPEAKER_1:  Because of the DNA.

00:42:05,730 --> 00:42:07,230
SPEAKER_1:  through the evolution process you can.

00:42:07,618 --> 00:42:14,302
SPEAKER_1:  constantly create new humans and new living organisms that adapt to the environment like that resilience to the physical world

00:42:15,170 --> 00:42:18,174
SPEAKER_1:  It seems like running the whole earth over again.

00:42:19,202 --> 00:42:21,150
SPEAKER_1:  the whole evolutionary process over again.

00:42:21,634 --> 00:42:24,766
SPEAKER_1:  is might be the only way to do it.

00:42:25,282 --> 00:42:27,774
SPEAKER_1:  So to create a robot that actually adapts.

00:42:28,898 --> 00:42:31,614
SPEAKER_1:  is as resilient to the dynamic world.

00:42:32,098 --> 00:42:33,662
SPEAKER_1:  might be a really difficult problem.

00:42:34,402 --> 00:42:34,974
SPEAKER_0:  Possibly.

00:42:35,394 --> 00:42:43,742
SPEAKER_0:  Well, I was going to say like in a programming environment, you can do things on time scales that are impossible in the real world, right? Like the benefit to AI and computers is a computational they can.

00:42:44,002 --> 00:42:50,558
SPEAKER_0:  so much data so quickly. Whereas on human timetables, we have to wait. When you talk about evolution, you know, it's...

00:42:50,786 --> 00:42:55,518
SPEAKER_0:  Generation after generation after generation, you know, maybe in a virtual environment that could be simulated

00:42:55,778 --> 00:42:57,653
SPEAKER_0:  and then those changes could happen a lot quicker.

00:42:57,653 --> 00:43:00,382
SPEAKER_1:  on the human time scale, but you have to look at Earth.

00:43:00,962 --> 00:43:04,990
SPEAKER_1:  quantum mechanical system the computation is happening super fast.

00:43:05,282 --> 00:43:07,742
SPEAKER_1:  This is a giant computer doing a giant simulation.

00:43:08,194 --> 00:43:10,206
SPEAKER_1:  So just because for us humans it's slow.

00:43:10,786 --> 00:43:15,006
SPEAKER_1:  There's like trillions of organisms involved in you, your destiny being you.

00:43:15,522 --> 00:43:17,598
SPEAKER_0:  sure, but the next iteration of like.

00:43:17,858 --> 00:43:19,070
SPEAKER_0:  from human to human.

00:43:19,490 --> 00:43:24,574
SPEAKER_0:  Even if on the quantum level there's a lot of stuff going on, you talk about like changes in DNA, for instance, right?

00:43:25,186 --> 00:43:29,982
SPEAKER_0:  that's happening from a generation to generation timescale. Like in a virtual environment, that could theoretically happen.

00:43:30,306 --> 00:43:40,766
SPEAKER_0:  Well, it already is. There's like protein folding, like huge cloud computing, probably ML stuff that's like working on doing all of that stuff. And it'll run like trillions and trillions of simulations, you know, every second and stuff. Maybe not every second, but.

00:43:41,090 --> 00:43:44,062
SPEAKER_1:  still slower than the actual protein folding, much slower.

00:43:44,546 --> 00:43:45,086
SPEAKER_1:  The...

00:43:45,602 --> 00:43:48,990
SPEAKER_1:  That's for the problem of solving protein folding.

00:43:49,282 --> 00:43:54,654
SPEAKER_1:  uh... to estimate the three d structure but the actual body does that the actual portion folding way faster

00:43:55,010 --> 00:43:55,646
SPEAKER_1:  So like, we're-

00:43:56,194 --> 00:43:59,134
SPEAKER_1:  The question is, can we shortcut the simulation of?

00:43:59,682 --> 00:44:00,574
SPEAKER_1:  human evolution.

00:44:00,898 --> 00:44:02,814
SPEAKER_1:  try to figure out how to build up an organism.

00:44:03,074 --> 00:44:03,550
SPEAKER_1:  without

00:44:04,002 --> 00:44:08,830
SPEAKER_1:  simulating all the details because we have to simulate all the details of biology were screwed.

00:44:08,930 --> 00:44:13,415
SPEAKER_0:  We don't have. Oh true, we'd have to put something in a pond and then watch it for a billion years.

00:44:13,415 --> 00:44:16,734
SPEAKER_1:  way to do it. That's what the universe most likely is.

00:44:17,122 --> 00:44:20,446
SPEAKER_1:  It's a kind of simulation created by a teenager in their basement.

00:44:20,962 --> 00:44:23,870
SPEAKER_1:  to try to see what happens. It's a computer game.

00:44:24,194 --> 00:44:27,678
SPEAKER_1:  That might be the most efficient way to create interesting organisms.

00:44:28,258 --> 00:44:28,606
SPEAKER_1:  but.

00:44:29,058 --> 00:44:30,142
SPEAKER_1:  within the system.

00:44:30,530 --> 00:44:32,094
SPEAKER_1:  perhaps possible to create.

00:44:34,050 --> 00:44:35,678
SPEAKER_1:  other robots that will.

00:44:35,906 --> 00:44:40,318
SPEAKER_1:  be of use and will entertain us in the way that other humans entertain us.

00:44:40,706 --> 00:44:41,726
SPEAKER_1:  That's a really interesting.

00:44:42,242 --> 00:44:44,318
SPEAKER_1:  course problem but it's surprising

00:44:44,770 --> 00:44:46,046
SPEAKER_1:  how difficult it has been.

00:44:47,170 --> 00:44:49,406
SPEAKER_1:  to create systems that operate in the physical world.

00:44:49,890 --> 00:44:52,798
SPEAKER_1:  and operating that physical world in a way that's safe to humans.

00:44:53,186 --> 00:44:53,694
SPEAKER_1:  and

00:44:53,922 --> 00:44:55,262
SPEAKER_1:  interesting to humans.

00:44:55,650 --> 00:44:59,102
SPEAKER_1:  because there's also the human factor, the human-robot interaction. To me, that's...

00:44:59,490 --> 00:45:02,174
SPEAKER_1:  like the most interesting problem to figure out how to do that well.

00:45:02,690 --> 00:45:03,838
SPEAKER_1:  And so.

00:45:04,706 --> 00:45:05,982
SPEAKER_1:  Yamask and others.

00:45:06,274 --> 00:45:10,366
SPEAKER_1:  Boston Dynamics have worked on legged robots, so I really care about legged robots.

00:45:11,138 --> 00:45:12,606
SPEAKER_1:  Those are super interesting.

00:45:12,834 --> 00:45:14,974
SPEAKER_1:  how to make them such that they're.

00:45:16,002 --> 00:45:19,614
SPEAKER_1:  able to operate successfully in a dynamic environment. Super Tricky.

00:45:20,098 --> 00:45:20,510
SPEAKER_1:  They're like.

00:45:21,026 --> 00:45:22,558
SPEAKER_1:  They're like the dumbest of dogs.

00:45:23,138 --> 00:45:25,534
SPEAKER_1:  Speaking of which, there's a dog barking outside.

00:45:26,018 --> 00:45:31,262
SPEAKER_1:  I mean, it's really tricky to create those kinds of organisms that live in the human world.

00:45:31,682 --> 00:45:32,350
SPEAKER_1:  Then again...

00:45:33,122 --> 00:45:34,302
SPEAKER_1:  if more and more...

00:45:34,914 --> 00:45:37,118
SPEAKER_1:  of us moving to the digital world.

00:45:38,114 --> 00:45:39,518
SPEAKER_1:  So you stream a lot.

00:45:39,906 --> 00:45:41,502
SPEAKER_1:  Like part of who you are.

00:45:42,562 --> 00:45:44,670
SPEAKER_1:  exist in the digital space.

00:45:45,122 --> 00:45:47,518
SPEAKER_1:  The fact that you have a physical representation also.

00:45:48,578 --> 00:45:50,302
SPEAKER_1:  maybe more and more will become

00:45:50,690 --> 00:45:51,390
SPEAKER_1:  Not important.

00:45:52,514 --> 00:45:55,934
SPEAKER_0:  I hope that's the case because I bought a lot of stock in Metta and man, it's down.

00:45:56,354 --> 00:45:57,479
SPEAKER_0:  A lot.

00:45:57,479 --> 00:46:02,110
SPEAKER_1:  of the company. Is there some degree, like can you look at yourself?

00:46:02,402 --> 00:46:07,454
SPEAKER_1:  Like Stephen, the physical meat vehicle and then the destiny, this digital space.

00:46:07,874 --> 00:46:08,606
SPEAKER_1:  like digital.

00:46:09,250 --> 00:46:09,918
SPEAKER_1:  Avatar

00:46:10,914 --> 00:46:14,110
SPEAKER_1:  Do you sense that in a certain way you're the digital avatar?

00:46:14,754 --> 00:46:23,358
SPEAKER_0:  I've always tried to keep my on-stream personality as genuine as possible, so they're one and the same to me. I don't really view them as two separate entities, so... But I mean, I always view myself as Steven.

00:46:24,226 --> 00:46:26,526
SPEAKER_0:  real life person. My destiny is my online name but...

00:46:26,946 --> 00:46:32,894
SPEAKER_1:  No, but because so many of your social network is established in the digital space, like so many people know you through the digital space.

00:46:33,474 --> 00:46:36,414
SPEAKER_1:  Can there be, can we swap out another person that looks like you?

00:46:37,186 --> 00:46:39,294
SPEAKER_1:  and like an AI system and then that.

00:46:39,682 --> 00:46:41,854
SPEAKER_1:  entity known as Destiny will continue existing.

00:46:42,178 --> 00:46:46,430
SPEAKER_0:  I mean, it must be like, there must be some level of sophistication that could emulate.

00:46:46,690 --> 00:46:48,030
SPEAKER_0:  A human brain, I would imagine, right?

00:46:49,346 --> 00:46:51,221
SPEAKER_0:  probably text not there yet but well the question

00:46:51,221 --> 00:46:51,838
SPEAKER_1:  question is.

00:46:52,258 --> 00:46:56,670
SPEAKER_1:  What's the level of sophistication of the audience that would recognize that something has changed?

00:46:57,890 --> 00:46:58,206
SPEAKER_1:  like

00:46:58,626 --> 00:46:59,646
SPEAKER_1:  It's the Turing test.

00:47:00,034 --> 00:47:01,118
SPEAKER_1:  Yeah. How hard is it?

00:47:01,602 --> 00:47:04,286
SPEAKER_1:  to trick your audience, your large.

00:47:04,642 --> 00:47:07,006
SPEAKER_1:  audience of fans that watch your streams.

00:47:07,522 --> 00:47:10,654
SPEAKER_1:  that when you swap out an AI that emulates you.

00:47:11,266 --> 00:47:12,446
SPEAKER_1:  that nothing has changed.

00:47:13,218 --> 00:47:13,726
SPEAKER_1:  and

00:47:14,306 --> 00:47:17,726
SPEAKER_1:  The question is, do you have to really simulate so much of the human brain for that?

00:47:18,050 --> 00:47:18,750
SPEAKER_1:  I don't think so.

00:47:19,330 --> 00:47:20,350
SPEAKER_1:  Probably not.

00:47:20,930 --> 00:47:21,438
SPEAKER_1:  So...

00:47:21,794 --> 00:47:24,446
SPEAKER_1:  I mean, like you said, a lot of.

00:47:24,674 --> 00:47:30,110
SPEAKER_1:  political discourse is it just walking down the tree together so you can probably emulate a lot of that discussion

00:47:30,402 --> 00:47:37,790
SPEAKER_0:  Yeah, it would depend on if you're doing old data sets and you're training on that and I'm having conversations about abortion and your crane and vaccines, I imagine it could do it for quite a while.

00:47:38,114 --> 00:47:40,254
SPEAKER_0:  The only thing that would be weird is when novel issues pop up.

00:47:40,514 --> 00:47:42,334
SPEAKER_0:  then you probably need a more sophisticated.

00:47:42,594 --> 00:47:44,469
SPEAKER_0:  resemblance of the inner brain right now.

00:47:44,469 --> 00:47:44,958
SPEAKER_1:  They have to keep.

00:47:45,218 --> 00:47:51,998
SPEAKER_1:  keep training on the internet so how the language models and that's the most incredible breakthroughs is the language models you just have to keep retraining the system

00:47:52,546 --> 00:47:53,758
SPEAKER_1:  on Reddit.

00:47:54,082 --> 00:47:57,182
SPEAKER_1:  which is actually what a lot of it is trained on, which is hilarious.

00:47:57,410 --> 00:47:58,942
SPEAKER_0:  I do think it's really interesting that like...

00:47:59,170 --> 00:48:11,550
SPEAKER_0:  kind of like funny problems like the trolley problem that we can kind of work through our normative ethical systems on are now like real questions. Like if you're driving a Tesla and it's on autopilot and you're going to hit somebody but it can swerve and hit somebody else like what ought the system do?

00:48:11,778 --> 00:48:16,510
SPEAKER_0:  We went very quickly from fun kind of like project in philosophy class to

00:48:16,738 --> 00:48:20,830
SPEAKER_0:  We need to solve this for insurance purposes, like as quickly as possible. It's kind of interesting to think about.

00:48:21,122 --> 00:48:24,990
SPEAKER_1:  But I actually have a, I'll bring up the trolley problem with you later.

00:48:25,218 --> 00:48:30,093
SPEAKER_1:  There's a fascinating version of it that I find hilarious. Okay, let's return.

00:48:30,093 --> 00:48:30,843
SPEAKER_0:  to your low point.

00:48:30,843 --> 00:48:31,486
SPEAKER_1:  Oh yeah.

00:48:31,810 --> 00:48:32,478
SPEAKER_1:  Uhhh...

00:48:32,866 --> 00:48:40,030
SPEAKER_1:  You started playing video games. That was a lucky break. You, uh, you did text-based ones. That was a lucky break because you got to be pretty good at learning.

00:48:40,418 --> 00:48:40,862
SPEAKER_1:  and then.

00:48:41,218 --> 00:48:44,254
SPEAKER_1:  you started thinking about going to college and so on what happened next

00:48:44,866 --> 00:48:52,318
SPEAKER_0:  I mean, I went to like a prep school. So you kind of have to go to college after that's like the point, right? I was also millennial. All of us had to go to college. That's always what they told us.

00:48:52,898 --> 00:48:54,686
SPEAKER_0:  Um, my life was kind of-

00:48:55,106 --> 00:48:57,022
SPEAKER_0:  It's hard to describe.

00:48:57,314 --> 00:49:01,854
SPEAKER_0:  I didn't really think much of the future. I was just kind of enjoying the day-to-day because everything in my life was pretty weird.

00:49:02,146 --> 00:49:07,518
SPEAKER_0:  Both my parents had moved to Florida by the time I was 16, 17. I was living with my grandma, I was working.

00:49:07,842 --> 00:49:09,534
SPEAKER_0:  I had a girlfriend, moved out.

00:49:09,794 --> 00:49:11,422
SPEAKER_0:  We got a place to college.

00:49:12,386 --> 00:49:18,718
SPEAKER_0:  By the time I got into college, I had transitioned from working at McDonald's to, I was working at a casino restaurant basically.

00:49:19,266 --> 00:49:21,566
SPEAKER_0:  and I was really good at that job. So hi.

00:49:21,922 --> 00:49:24,382
SPEAKER_0:  level of patience for drunk people and sane people.

00:49:24,706 --> 00:49:31,998
SPEAKER_0:  and I was doing music in school because I've really grown to love music. And my thought process was I can do music.

00:49:32,290 --> 00:49:42,334
SPEAKER_0:  as a hobby, I guess, unless I get really good and maybe I can make money with that. But otherwise I love music. I'm okay going to school for music, getting good at it. And then just doing that on the side. And then my main job would kind of be this career was building at the casino.

00:49:43,426 --> 00:49:43,998
SPEAKER_0:  and

00:49:44,770 --> 00:49:47,966
SPEAKER_0:  basically the trying to balance personal life plus graveyard shift.

00:49:48,226 --> 00:49:55,294
SPEAKER_0:  six day or weeks at a casino and then a full-time music degree was not possible for me and eventually I had to drop school after I think it was like three years

00:49:55,842 --> 00:49:58,590
SPEAKER_0:  And after I dropped school to maintain my casino job.

00:49:58,850 --> 00:50:01,982
SPEAKER_0:  After a few months, I got fired from my casino job.

00:50:02,242 --> 00:50:05,534
SPEAKER_0:  So I'd essentially just thrown away like the past like three or four years of my life.

00:50:05,858 --> 00:50:07,486
SPEAKER_1:  Why'd you get fired from the casino job?

00:50:07,746 --> 00:50:08,958
SPEAKER_1:  I heard there's a story behind that.

00:50:09,186 --> 00:50:16,862
SPEAKER_0:  Yeah, there's a story. Basically, I was just really dumb when it came to understanding corporate politics. And this is funny because the same attitude kind of followed me into the streaming world.

00:50:17,186 --> 00:50:19,038
SPEAKER_0:  My thought process has kind of always been...

00:50:19,586 --> 00:50:25,822
SPEAKER_0:  Um, that like, as long as I'm really good at what I do, I should be untouchable. If I'm really good, you can't do anything to me. I don't have to play any dumb games or whatever.

00:50:26,626 --> 00:50:27,166
SPEAKER_0:  and

00:50:27,394 --> 00:50:32,830
SPEAKER_0:  At the casino, I think I was the youngest, it was originally shifly than supervisor position at the casino.

00:50:33,346 --> 00:50:35,678
SPEAKER_0:  And when I started to get my own shifts.

00:50:35,970 --> 00:50:38,590
SPEAKER_0:  there were problems that i would run into on graveyard shift because of

00:50:38,946 --> 00:50:40,190
SPEAKER_0:  carry over from the swing shift.

00:50:40,514 --> 00:50:44,958
SPEAKER_0:  Remember, one of these problems was underneath the soda machine, they weren't cleaning it properly, and fruit flies were showing up.

00:50:45,570 --> 00:50:48,286
SPEAKER_0:  And I, my manager came in one morning and she was like.

00:50:48,546 --> 00:50:49,118
SPEAKER_0:  Uh, hey.

00:50:49,538 --> 00:50:59,262
SPEAKER_0:  what's going on with the machine. And I told them, I was like, listen, I can't do, I can't take everything from Swing Shift and do everything in Grape Shift. I can't do this. They need to figure out their stuff better or I need more employees. It's not possible for me.

00:50:59,490 --> 00:51:04,158
SPEAKER_0:  And she's like, what did you tell anybody else? Like, yeah, I complained to the supervisor on the swing shift all the time.

00:51:04,610 --> 00:51:05,214
SPEAKER_0:  I should tell me.

00:51:05,538 --> 00:51:09,310
SPEAKER_0:  If you're not getting the answer that you like, then it's your responsibility to...

00:51:09,570 --> 00:51:10,782
SPEAKER_0:  Email the next person up.

00:51:11,106 --> 00:51:12,446
SPEAKER_0:  I was like, oh, okay, that's interesting.

00:51:13,218 --> 00:51:17,054
SPEAKER_0:  And some months went on and I ran into more problems because on Graveyard

00:51:17,314 --> 00:51:40,063
SPEAKER_0:  Here's how I don't know if it's everywhere, but morning shift is the easiest. And that's when you're the most overstaffed because that's when all the VPs are in and that's when all the managers are there and everybody blah, blah, blah. Swing shift is the most challenging. That's what your highest flow of customers is. You're also decently staffed there, but there's a lot of stuff going on and graveyard, nobody cares at all about you. They don't give you any employees. You might get swamped. You might not who cares. Make sure it's clean for day shift. That's the only thing that matters.

00:51:40,063 --> 00:51:41,726
SPEAKER_1:  question for sort of clarification.

00:51:41,954 --> 00:51:43,294
SPEAKER_1:  This is 24 hour.

00:51:43,778 --> 00:51:45,246
SPEAKER_1:  24 hour dinner, yeah.

00:51:45,474 --> 00:51:50,302
SPEAKER_1:  This was the dining in a casino. Oh, by the way, I had an amazing moment at a casino recently.

00:51:50,626 --> 00:51:51,646
SPEAKER_1:  It's a special place.

00:51:51,874 --> 00:51:53,598
SPEAKER_1:  A dining room casino is a place of magic.

00:51:53,986 --> 00:51:58,449
SPEAKER_0:  There's a lot of, I don't know if I'd say magic, but there's a lot of otherworldly stuff going on.

00:51:58,449 --> 00:51:59,262
SPEAKER_1:  There's

00:51:59,554 --> 00:52:03,614
SPEAKER_1:  And I had an interaction with a waitress that was the sweetest waitress in the world.

00:52:04,002 --> 00:52:04,894
SPEAKER_1:  I was just like...

00:52:05,250 --> 00:52:07,038
SPEAKER_1:  I don't know, made me feel less alone on this.

00:52:07,650 --> 00:52:11,102
SPEAKER_1:  world of ours. So graveyard begins when?

00:52:11,650 --> 00:52:13,694
SPEAKER_0:  For me, my shift was 10pm to 6am.

00:52:13,954 --> 00:52:16,579
SPEAKER_0:  or sometimes I get called in early, so it'd be 8 p.m. to 6 a.m.

00:52:16,579 --> 00:52:19,102
SPEAKER_1:  So that's no love for that shift.

00:52:19,650 --> 00:52:22,110
SPEAKER_0:  No, especially not trying to do school at the same time. Absolutely not.

00:52:22,754 --> 00:52:37,630
SPEAKER_0:  But yeah, basically long story short, I ran into a problem with my super where I didn't have enough employees on my shift VPs were coming in in the morning. There's something like hey the diners kind of dirty and I'm like you've cut all my employees past 4am Like on some nights, I'm literally cooking and doing front of house like all on my own. Like I can't do this

00:52:37,858 --> 00:52:38,302
SPEAKER_0:  and

00:52:38,626 --> 00:52:43,102
SPEAKER_0:  My manager Pam told me, well, you've got to figure it out. And so I remembered her advice.

00:52:43,330 --> 00:52:47,774
SPEAKER_0:  So I emailed the VP of Food and Beverage and I cc'd her, and I said, I'm not getting the help I need for my restaurant.

00:52:48,034 --> 00:52:50,974
SPEAKER_0:  Now I didn't know at the time that I was basically completely throwing her under the bus.

00:52:51,490 --> 00:52:55,582
SPEAKER_0:  because of that email, but retroactively, when I look back on things.

00:52:55,938 --> 00:52:59,742
SPEAKER_0:  retrospectively I see that was the moment that I got like marked for deletion.

00:53:00,162 --> 00:53:14,750
SPEAKER_0:  And I didn't really understand it, even though I'd heard terminology for papering somebody out the door. But after that point, I started to get written up for like a lot of little random things. Like I'll come, like I'd missed one day of work in my three years at the casino. And I started to get written up for like showing up like one or two minutes late.

00:53:15,010 --> 00:53:15,678
SPEAKER_0:  That's kind of weird.

00:53:15,906 --> 00:53:23,070
SPEAKER_0:  whatever, or written up for random ways about filing paperwork. And then eventually there came a situation with another employee where they were

00:53:23,298 --> 00:53:29,886
SPEAKER_0:  It's complicated, it has to be like call out stuff. But basically they wanted to come or they wanted to call out and I told them if they called out, they were going to get fired because.

00:53:30,370 --> 00:53:41,822
SPEAKER_0:  They were at like 10 points. They were at nine points and 10 points is firing, blah, blah, blah. Pam told me, you can tell her that she's gonna get a point, but you can't tell her she's gonna get fired. I don't know what that meant. And then I told her that if you call out, you're gonna get, you know, you're fucked. You're gonna get fired.

00:53:42,050 --> 00:54:04,062
SPEAKER_0:  or you're gonna be at 10 points. And then I got called in early like three days later and Pam was like, you inappropriately communicated with an employee because you said the F word in a text message. And I'm like, really? There's no shot. And she's like, well, you also tried to fire the employee. And I was like, no, I told her she was gonna get 10 points. She's like, well, you used the F word. I'm like, this is insane. And I didn't, just cause I was such a, such a high performing employee. It's like, there's no way I'm getting fired. And then I did. I was like, yeah.

00:54:04,514 --> 00:54:06,718
SPEAKER_0:  cashed out my 401k and moped for like three months.

00:54:07,042 --> 00:54:08,606
SPEAKER_0:  because I had thrown away school.

00:54:08,834 --> 00:54:14,459
SPEAKER_0:  for this casino job and then I got fired from this job that like, yeah, nobody believed I got fired it was just insane.

00:54:14,459 --> 00:54:16,702
SPEAKER_1:  So if you look back, if you were allowed to not just to...

00:54:17,058 --> 00:54:18,398
SPEAKER_1:  look back to your own memory.

00:54:18,658 --> 00:54:21,918
SPEAKER_1:  But actually watch yourself. Like some of you recorded video that whole time.

00:54:22,594 --> 00:54:26,302
SPEAKER_1:  Do you think you would be surprised? You would notice some things that potentially.

00:54:26,818 --> 00:54:29,886
SPEAKER_1:  of not having a self-awareness, not having like social...

00:54:30,594 --> 00:54:35,678
SPEAKER_1:  like a civility and social etiquette that's played in the human relations. Yeah, absolutely.

00:54:36,706 --> 00:54:39,038
SPEAKER_1:  So is that is that at the core of it essentially?

00:54:39,298 --> 00:54:42,718
SPEAKER_0:  Yeah, I think so. I mean, that follows me even to this day. There's a lot of, um...

00:54:43,426 --> 00:54:55,262
SPEAKER_0:  I don't know if you're recording or not, but when we spoke early about like meta-conversations, I have to think a lot sometimes about meta-conversations because the way that I want to drive a conversation will sometimes be way different than what is like the best way to have a conversation, whereas I just want to like-

00:54:55,618 --> 00:54:56,830
SPEAKER_0:  go really hard on like some.

00:54:57,218 --> 00:55:02,814
SPEAKER_0:  itty bitty like some idiosyncrasy, some factor figure, whatever, but that's not like the human conversation I need to have, you know?

00:55:03,266 --> 00:55:06,590
SPEAKER_1:  So you got fired slash left that job.

00:55:06,946 --> 00:55:10,910
SPEAKER_1:  And that took you to the job that would be the lowest point.

00:55:11,266 --> 00:55:11,582
SPEAKER_0:  Yeah.

00:55:12,482 --> 00:55:14,974
SPEAKER_0:  There was a huge downgrade in pay.

00:55:15,362 --> 00:55:16,350
SPEAKER_0:  I went from getting like...

00:55:16,642 --> 00:55:24,222
SPEAKER_0:  I think of the casino, because I worked so much overtime, I was doing like 22.50 an hour on all my overtime. And this was back in 2008, 2009, it's like a college.

00:55:24,642 --> 00:55:26,334
SPEAKER_0:  Student, like, amazing pay.

00:55:26,850 --> 00:55:27,262
SPEAKER_0:  Um...

00:55:27,618 --> 00:55:30,654
SPEAKER_0:  I had benefits, like everything was good, and then the cocarbit cleaning was like...

00:55:30,946 --> 00:55:33,310
SPEAKER_0:  I was probably getting my paycheck like every other week.

00:55:33,698 --> 00:55:36,350
SPEAKER_0:  was maybe $1,500 or $1,000.

00:55:36,770 --> 00:55:37,854
SPEAKER_0:  and I'm working like.

00:55:38,146 --> 00:55:40,670
SPEAKER_0:  13 day stretches, like I have every other Sunday off.

00:55:41,122 --> 00:55:47,925
SPEAKER_0:  and it's so many hours. Like I have to show up at the shop at like seven or six and then I go home at like eight or nine depending on when my jobs are throughout.

00:55:47,925 --> 00:55:51,902
SPEAKER_1:  the day. You doing all businesses or residential or what are you doing? Everything.

00:55:52,226 --> 00:55:55,710
SPEAKER_1:  Everything. Are you working for a company that's cooperating or are you?

00:55:56,098 --> 00:55:59,473
SPEAKER_1:  Okay, so like there's a scheduled thing, you have to go to it and so on. If you don't this

00:55:59,473 --> 00:56:02,782
SPEAKER_0:  but still like this is why the schedule would suck is sometimes I'd show up at

00:56:03,170 --> 00:56:05,694
SPEAKER_0:  I think we had to be in the shop at, I think it was 7am.

00:56:06,018 --> 00:56:07,326
SPEAKER_0:  We shop at the shop at 7am.

00:56:07,586 --> 00:56:10,590
SPEAKER_0:  First job might be at eight or nine, but that job might be like a one hour job.

00:56:10,818 --> 00:56:14,654
SPEAKER_0:  So I might show up at 7am and have a job from 8.30 to 9.30. Then my next job might not be from...

00:56:15,074 --> 00:56:15,966
SPEAKER_0:  until like say 11.

00:56:16,290 --> 00:56:17,982
SPEAKER_0:  So from A39 thread I'll do one job.

00:56:18,434 --> 00:56:21,470
SPEAKER_0:  And then I've got a drop from like 11 to 12 or something.

00:56:21,730 --> 00:56:23,934
SPEAKER_0:  then I might have like a decent job from like five to eight.

00:56:24,994 --> 00:56:26,494
SPEAKER_0:  But like my whole day is destroyed.

00:56:27,746 --> 00:56:29,118
SPEAKER_0:  And I'm doing like three.

00:56:29,378 --> 00:56:36,414
SPEAKER_0:  smallest jobs, so I'm getting like 30 bucks maybe for being in the shop or, you know, my job for like 10 or 11 hours and it's just like horrible.

00:56:37,026 --> 00:56:41,246
SPEAKER_1:  So here's somebody that seems to be extremely good at thinking and conversation.

00:56:41,506 --> 00:56:42,238
SPEAKER_1:  And so...

00:56:42,466 --> 00:56:44,062
SPEAKER_1:  have a bit of an ego perhaps.

00:56:44,578 --> 00:56:47,742
SPEAKER_1:  in both the negative and the positive sense of that word.

00:56:48,386 --> 00:56:51,326
SPEAKER_1:  Was there some aspect of working at McDonald's?

00:56:52,258 --> 00:56:56,990
SPEAKER_1:  and then working at the casino and then working for the, as a carpet cleaner that was humbling.

00:56:57,698 --> 00:56:58,654
SPEAKER_0:  No, never.

00:56:58,914 --> 00:56:59,518
SPEAKER_0:  Um...

00:56:59,682 --> 00:57:02,206
SPEAKER_1:  I had a... The ego burned bright through it all.

00:57:02,658 --> 00:57:03,742
SPEAKER_1:  See, well...

00:57:04,194 --> 00:57:05,319
SPEAKER_1:  or not, you can push.

00:57:05,319 --> 00:57:10,814
SPEAKER_0:  back in the ego. Yeah, no, I understand. I totally get what you mean. I had a really close friend growing up whose name was Chris.

00:57:11,042 --> 00:57:12,766
SPEAKER_0:  and i think we probably don't use we're

00:57:12,994 --> 00:57:14,718
SPEAKER_0:  Like four or five, I think, he lived behind me.

00:57:15,074 --> 00:57:22,110
SPEAKER_0:  And I grew up with him and I'd always been kind of an outsider to the world that I was in once I got to high school for sure.

00:57:22,402 --> 00:57:54,270
SPEAKER_0:  because all of those kids were incredibly wealthy. You know, Corvettes and Mustangs when they turned 16, it was a prep school. And I was doing the, they had like a work study program there where you could stay after school from 2.30 to five every day to kind of like work to pay for your tuition. So I've been working like throughout all of high school. I got another job at McDonald's when I was 18, worked at the casino. Like I had always been doing that kind of work. I never really viewed it as like beneath me or anything. It's not like I don't have like a family of doctors or lawyers or anything. And then me and my other friend, Chris guy, we'd always make fun of everybody else for being kind of like, you know, like preppy kids and everything, so.

00:57:54,850 --> 00:57:55,934
SPEAKER_1:  So there is a...

00:57:56,386 --> 00:57:58,078
SPEAKER_1:  There's some pride to that sort of.

00:57:58,498 --> 00:57:59,134
SPEAKER_1:  hard work.

00:57:59,426 --> 00:58:06,270
SPEAKER_0:  Yeah, I guess a little bit, yeah. Because, yeah, looking especially at my dad, like the solution to every problem was to just throw more hours of work at it, basically. So that was always my...

00:58:06,658 --> 00:58:08,062
SPEAKER_0:  Yeah, I go too. And I never am.

00:58:08,162 --> 00:58:09,918
SPEAKER_1:  What was psychologically the low point?

00:58:10,946 --> 00:58:15,166
SPEAKER_0:  I think psychologically the low point was that, as I'm doing this carpet cleaning job,

00:58:15,842 --> 00:58:17,918
SPEAKER_0:  uh, driving around my city.

00:58:18,242 --> 00:58:19,966
SPEAKER_0:  There's like this feeling of...

00:58:22,018 --> 00:58:25,406
SPEAKER_0:  I guess for a lot of people it's probably college, but there's a feeling when you're in high school.

00:58:25,826 --> 00:58:26,142
SPEAKER_0:  that.

00:58:26,466 --> 00:58:31,614
SPEAKER_0:  Everything is like so exciting and the whole world is kind of in front of you and there are

00:58:32,066 --> 00:58:35,006
SPEAKER_0:  trillion different branching paths of possibilities.

00:58:35,298 --> 00:58:43,070
SPEAKER_0:  And you know, even through high school, you're thinking like, am I going to be a doctor or a lawyer or can I join the MBA or can I do this or that? There's all these things in front of you.

00:58:43,650 --> 00:58:44,190
SPEAKER_0:  and

00:58:44,450 --> 00:58:48,030
SPEAKER_0:  when I especially felt it when I was doing these carpet cleaning jobs and

00:58:48,994 --> 00:58:59,518
SPEAKER_0:  I think it was in the fall, I'd be outside some of these houses and I'd just kind of look around and I'd recognize a lot of these neighborhoods that I'd drive around with friends in or I'd be walking through, I ran cross-country, some of them I'd be running through these neighborhoods.

00:58:59,874 --> 00:59:02,238
SPEAKER_0:  And it was just kind of like this feeling of looking around and it was like...

00:59:03,138 --> 00:59:04,254
SPEAKER_0:  when I was here in the past.

00:59:04,674 --> 00:59:06,814
SPEAKER_0:  This is like kind of like a transitionary phase of my life.

00:59:07,138 --> 00:59:12,318
SPEAKER_0:  where I'm doing this and it's so fun and exciting, and then I'm gonna move on to something else and it's gonna be fun and exciting and awesome.

00:59:12,610 --> 00:59:14,686
SPEAKER_0:  And then like, you know, two years later.

00:59:15,010 --> 00:59:16,702
SPEAKER_0:  My whole life has collapsed.

00:59:17,026 --> 00:59:19,326
SPEAKER_0:  Like I'm in a house that I can't afford anymore. ey reasons go trash

00:59:19,618 --> 00:59:21,886
SPEAKER_0:  X that I hate is pregnant with my kid.

00:59:22,114 --> 00:59:26,750
SPEAKER_0:  and I have no money, I've got no upward mobility, I failed college.

00:59:27,170 --> 00:59:31,294
SPEAKER_0:  I, my job is horrible. Like just every single, like this is like.

00:59:31,586 --> 00:59:42,015
SPEAKER_0:  All of those, the wave function had collapsed into one thing and that one thing was the worst thing that could have possibly been at the time for me. Yeah, like everything was gone and horrible. So yeah, that was the feeling I had at the time.

00:59:42,015 --> 00:59:43,166
SPEAKER_1:  ever contemplate suicide.

00:59:44,194 --> 00:59:45,886
SPEAKER_0:  thought about thinking about it.

00:59:46,114 --> 00:59:47,646
SPEAKER_0:  But I've just never been that kind of person, so...

00:59:48,322 --> 00:59:50,814
SPEAKER_1:  I mean, basically as a way to escape from the hardship.

00:59:50,946 --> 00:59:59,166
SPEAKER_0:  Something that I'm so incredibly lucky, I don't know why or how, I'm just gonna chalk it up to biology. I've always had really high mental baseline.

00:59:59,522 --> 01:00:04,766
SPEAKER_0:  I've like depression and all of that. There've been a few short stints I've dealt with it, past 30 because I did a lot of drugs.

01:00:04,994 --> 01:00:09,790
SPEAKER_0:  But other than that, my mental baseline is just so high. And even in the carpet cleaning days...

01:00:10,050 --> 01:00:28,995
SPEAKER_0:  Like if you man the videos might still be there I think on my old YouTube channel channel where I'll be like playing Starcraft when I first started getting a streaming and I'll be calling Up customers like this Steve from guaranteed clean. We had to move your job back one hour Is it okay if I show up instead of 230 and then I hang up? It's like alright guys. We got three more games and it's like let's go like stuff like that So my baseline has always been like really high for mental function

01:00:28,995 --> 01:00:35,422
SPEAKER_1:  even in the low point, you had strength. Is there anything you can give by way of advice from people that-

01:00:35,842 --> 01:00:39,518
SPEAKER_1:  for whom the wave function collapses, as it does for many of us.

01:00:39,874 --> 01:00:40,862
SPEAKER_1:  Like holy fuck.

01:00:41,122 --> 01:00:44,798
SPEAKER_1:  The world is not full of opportunity and you're kind of a failure.

01:00:45,250 --> 01:00:47,166
SPEAKER_1:  Like I've been there.

01:00:47,266 --> 01:00:49,470
SPEAKER_0:  Yeah, I don't know. It's rough because like...

01:00:49,986 --> 01:00:53,374
SPEAKER_0:  I usually ask for compassion from people that I have it better off.

01:00:53,730 --> 01:00:54,942
SPEAKER_0:  Because once you're down there...

01:00:55,234 --> 01:00:59,454
SPEAKER_0:  Like the only reason I say I got lucky, but it wasn't even really lucky.

01:00:59,682 --> 01:01:21,918
SPEAKER_0:  or it was lucky, but it was more lucky. It wasn't just lucky that I got into streaming. It was lucky that I was into computers at an early age. It was lucky that I played video games at an early age. It was lucky that all the tech came up at exactly that right point in time. I was a pretty smart guy, but it was definitely preparation meets opportunity. And that opportunity was like at the exact precise moment of my life. If anything had gone differently, then I would just be cleaning carpets today.

01:01:22,178 --> 01:01:24,894
SPEAKER_1:  So in the many worlds interpretation of quantum mechanics...

01:01:25,986 --> 01:01:27,861
SPEAKER_0:  This is like one out of like, there's

01:01:27,861 --> 01:01:31,902
SPEAKER_1:  Many, many Stevens, they're just still carpet cleaning.

01:01:32,226 --> 01:01:34,174
SPEAKER_1:  and they're full of pain and resentment.

01:01:34,562 --> 01:01:34,910
SPEAKER_0:  Yeah.

01:01:35,394 --> 01:01:40,030
SPEAKER_0:  The one piece of advice that I give, I hate that I have to push back against all these crypto bros and everybody online.

01:01:40,802 --> 01:01:43,422
SPEAKER_0:  Decently intelligent people that are successful. I've never hurt anybody.

01:01:43,906 --> 01:01:46,654
SPEAKER_0:  a contradiction to this. Maybe you will. You can tell me if you disagree.

01:01:47,554 --> 01:01:55,038
SPEAKER_0:  I always look at kids in high school and I'm like, just try a little bit harder, like 30 minutes a night. If you don't study, just do 30 minutes, just do a little bit more.

01:01:55,266 --> 01:01:55,646
SPEAKER_0:  Um.

01:01:56,002 --> 01:02:00,990
SPEAKER_0:  It is, you are laying the foundation for the rest of your life and you can't appreciate it in high school and college.

01:02:01,410 --> 01:02:02,974
SPEAKER_0:  Oh my god, when you get out.

01:02:03,234 --> 01:02:05,630
SPEAKER_0:  everything in your life is so much easier. you have

01:02:06,018 --> 01:02:16,143
SPEAKER_0:  Probably more responsibility over the direction of your life when you're like 13, 14 years old than you ever will once you're like 25 and older because this is like when you're determining the foundations that everything's going to build on.

01:02:16,143 --> 01:02:18,110
SPEAKER_1:  100%

01:02:18,498 --> 01:02:20,318
SPEAKER_1:  First of all, it does seem that

01:02:21,442 --> 01:02:23,326
SPEAKER_1:  the liberating aspect of being young.

01:02:23,554 --> 01:02:24,126
SPEAKER_1:  It's like

01:02:24,738 --> 01:02:25,886
SPEAKER_1:  Anything you learn.

01:02:26,978 --> 01:02:29,918
SPEAKER_1:  So working hard at learning something will pay off.

01:02:30,626 --> 01:02:33,598
SPEAKER_1:  in like nonlinear ways, like you said with video games. I feel like.

01:02:33,986 --> 01:02:38,846
SPEAKER_1:  So like people who like I hate school. Alright, well fine, but find something.

01:02:39,618 --> 01:02:44,606
SPEAKER_1:  where you're challenging yourself, you're growing, you're learning, you're learning a skill, you're learning about a thing.

01:02:45,954 --> 01:02:46,398
SPEAKER_1:  course.

01:02:46,690 --> 01:02:52,734
SPEAKER_1:  You know, you could push back and say, well, there's some trajectories that might not be productive. Like if you spend the entirety of your teen years.

01:02:53,026 --> 01:02:56,510
SPEAKER_1:  playing, I don't know, League of Legends, or a game you have.

01:02:56,834 --> 01:02:57,959
SPEAKER_1:  love and hate relationship with

01:02:57,959 --> 01:02:58,709
SPEAKER_0:  No, just a hate and hate.

01:02:58,709 --> 01:03:00,702
SPEAKER_1:  relationship. Okay, well, we'll talk about

01:03:00,994 --> 01:03:05,214
SPEAKER_1:  I think you have a love-hate relationship with hate in general. We'll just talk about it in love.

01:03:05,570 --> 01:03:09,278
SPEAKER_1:  We'll try to decomplexify that one.

01:03:09,858 --> 01:03:13,598
SPEAKER_1:  I think in general, just investing yourself fully with passion.

01:03:14,178 --> 01:03:15,134
SPEAKER_1:  It really does pay off.

01:03:15,362 --> 01:03:17,470
SPEAKER_1:  But that said also school.

01:03:18,402 --> 01:03:19,550
SPEAKER_1:  I feel like...

01:03:20,546 --> 01:03:24,254
SPEAKER_1:  doesn't get enough credit like high school in particular middle school and high school

01:03:24,834 --> 01:03:26,686
SPEAKER_1:  because it's general education.

01:03:29,218 --> 01:03:33,534
SPEAKER_1:  I think if you're, especially if you're lucky you have good teachers, but honestly.

01:03:33,794 --> 01:03:34,430
SPEAKER_1:  I haven't.

01:03:34,914 --> 01:03:40,222
SPEAKER_1:  Mostly the textbooks themselves were good teachers. It's a one chance in life. You have to

01:03:40,802 --> 01:03:42,910
SPEAKER_1:  really explore a subject.

01:03:43,170 --> 01:03:45,566
SPEAKER_1:  Fuck grades, like getting good grades.

01:03:46,882 --> 01:03:49,246
SPEAKER_1:  is attention I would say with actual learning.

01:03:49,538 --> 01:03:50,302
SPEAKER_1:  That is true.

01:03:51,682 --> 01:03:56,990
SPEAKER_1:  Just get a biology textbook and to explore ideas in biology and allowing yourself to be

01:03:57,410 --> 01:03:57,918
SPEAKER_1:  uh...

01:03:58,210 --> 01:03:59,358
SPEAKER_1:  inspired.

01:03:59,586 --> 01:04:01,118
SPEAKER_1:  by the beauty of it.

01:04:02,594 --> 01:04:07,742
SPEAKER_1:  Yeah, I don't know. I think that really, really, really pays off and you never get a chance to do that again.

01:04:08,290 --> 01:04:09,182
SPEAKER_1:  Maybe not even.

01:04:09,538 --> 01:04:11,678
SPEAKER_1:  Textbooks like reading, straight up reading.

01:04:12,066 --> 01:04:12,446
SPEAKER_1:  I think.

01:04:12,706 --> 01:04:15,998
SPEAKER_1:  I think if you read, this is the one time in life you get a chance to read.

01:04:16,866 --> 01:04:19,710
SPEAKER_1:  Really read. Like, read a book a day read.

01:04:20,066 --> 01:04:20,958
SPEAKER_1:  You can...

01:04:21,186 --> 01:04:22,238
SPEAKER_1:  really invest.

01:04:23,010 --> 01:04:25,822
SPEAKER_1:  You can really grow by reading. I mean, you almost-

01:04:26,050 --> 01:04:27,925
SPEAKER_1:  All those guys talk about it.

01:04:27,925 --> 01:04:32,350
SPEAKER_0:  very rare that you meet like a dumb person who reads a lot. I don't know if that's ever happened in my life.

01:04:32,578 --> 01:04:36,030
SPEAKER_1:  Yeah, dumb or not successful. And the cool thing is.

01:04:36,386 --> 01:04:41,566
SPEAKER_1:  It seems like the reading, it's like investment, the reading you do early on in high school.

01:04:41,986 --> 01:04:44,062
SPEAKER_1:  pays off way more than the reading you do later.

01:04:44,706 --> 01:04:47,678
SPEAKER_1:  uh... so like the the really influential

01:04:48,034 --> 01:04:48,606
SPEAKER_1:  Reading.

01:04:49,090 --> 01:04:54,814
SPEAKER_1:  is during those high school years, because you're basically learning from others.

01:04:55,202 --> 01:04:56,510
SPEAKER_1:  the mistakes they've made.

01:04:57,058 --> 01:04:58,590
SPEAKER_1:  the solutions to problems.

01:04:59,042 --> 01:05:01,470
SPEAKER_1:  You're basically learning the shortcuts to life.

01:05:02,146 --> 01:05:05,310
SPEAKER_1:  Like whatever the hell you want to do, music, read from the best people.

01:05:05,794 --> 01:05:08,958
SPEAKER_1:  uh... that the music theory like learn music theory learn

01:05:09,410 --> 01:05:12,830
SPEAKER_1:  I'll read biographies about jazz musicians, blues musicians.

01:05:13,058 --> 01:05:16,254
SPEAKER_1:  See their like, see all the mistakes, see what they did, see the shortcuts.

01:05:16,482 --> 01:05:18,974
SPEAKER_1:  If you want to do podcasting, read about other podcasts. If you want to...

01:05:19,202 --> 01:05:22,174
SPEAKER_1:  Do streamer read about other streamers, physicists and so on.

01:05:22,626 --> 01:05:26,270
SPEAKER_1:  I feel like you figure out all the mistakes and get to a shortcut through life.

01:05:26,690 --> 01:05:29,438
SPEAKER_1:  because most people show up to college without having done that.

01:05:29,890 --> 01:05:31,902
SPEAKER_1:  And now you get a chance to shortcut your way.

01:05:32,162 --> 01:05:32,606
SPEAKER_1:  past them.

01:05:33,090 --> 01:05:34,590
SPEAKER_1:  Yeah, 100%.

01:05:35,010 --> 01:05:36,958
SPEAKER_1:  But nobody really teaches you that.

01:05:37,282 --> 01:05:38,494
SPEAKER_1:  They're like, go to school.

01:05:39,330 --> 01:05:41,598
SPEAKER_1:  this from this time to that time.

01:05:41,922 --> 01:05:43,134
SPEAKER_1:  that you're shut up.

01:05:43,458 --> 01:05:45,758
SPEAKER_1:  This is just what you do. Eat your broccoli.

01:05:46,050 --> 01:05:47,838
SPEAKER_0:  I think it's like there's two huge problems. One.

01:05:48,194 --> 01:06:09,345
SPEAKER_0:  is now that I'm older, because you don't know anything as a kid, you can't really criticize adults as a kid, because you're a kid. You're ageist, if I may say so. I am, I am super ageist. As I get older, I get even more ageist. There are a lot of people where I argue, they're like, man dude, you're really 22, aren't you? I can tell every word you say, there's seeps of like 22 year oldness, but that's okay, I love that for you. You know, I could just.

01:06:09,345 --> 01:06:17,758
SPEAKER_1:  say because you mentioned this your wife is a fellow streamer Melina you mentioned that this is a source of fights for the two of you that

01:06:18,306 --> 01:06:19,774
SPEAKER_1:  And I could just feel that.

01:06:20,002 --> 01:06:22,302
SPEAKER_1:  There is truth to what you're saying, which is like.

01:06:22,754 --> 01:06:24,958
SPEAKER_1:  All right, you're saying that because you're 22.

01:06:25,250 --> 01:06:30,695
SPEAKER_1:  Just wait until you're 25 and you won't be saying that anymore. Sure. Now that is the most annoying.

01:06:30,695 --> 01:06:33,511
SPEAKER_0:  for people to hear. Yeah, you can't ever say that, of course. Because it's-

01:06:33,511 --> 01:06:34,910
SPEAKER_1:  actually usually true.

01:06:35,618 --> 01:06:36,062
SPEAKER_1:

01:06:36,450 --> 01:06:37,022
SPEAKER_1:  because.

01:06:37,474 --> 01:06:45,054
SPEAKER_1:  We do go through phases in life, and you can understand that most things are phases. So just in general you can say, just wait.

01:06:45,762 --> 01:06:46,206
SPEAKER_1:  Just wait.

01:06:46,530 --> 01:06:51,230
SPEAKER_1:  You won't see this. You won't feel this way again. I could say that to you. You could say that to yourself

01:06:51,522 --> 01:06:57,118
SPEAKER_1:  Just wait, whatever you're feeling like, just wait. In five, 10 years, it'll be a different person and you will laugh.

01:06:57,410 --> 01:06:59,230
SPEAKER_1:  at the things you take seriously now.

01:06:59,522 --> 01:07:03,646
SPEAKER_1:  that they're causing you pain now. All that kind of stuff. But people, I hate hearing that.

01:07:03,906 --> 01:07:21,662
SPEAKER_0:  Anyway, absolutely. I think the joke that I always say is like, if I could literally step into a time machine and I could come back out and see myself as a 17 year old and I could say, hey, I am literally you from the future. You see the time machine and I would look at me and I would see the time machine and I would give myself the best advice in the world and I would be the most successful person.

01:07:21,890 --> 01:07:32,894
SPEAKER_0:  I would ignore all of it. Even knowing it came from myself, I'd be like, this guy sold out, this dude doesn't know what the fuck he's talking about. Like, nah, I'll figure it out better. Like, he must've made some, that's what I would think is the 17, even if I knew it was myself in the future, I would just 100% never believe it.

01:07:33,186 --> 01:07:38,622
SPEAKER_0:  And knowing that is very frustrating, but I keep that in mind when I deal with younger people. That's why I always stay on stream when I'm talking to-

01:07:38,882 --> 01:07:44,062
SPEAKER_0:  Like there's been stuff with like Sneakos, another girl on my stream called Lab. When I see the way, I see the mistakes they're making.

01:07:44,290 --> 01:07:53,182
SPEAKER_0:  Oftentimes because I've made all of these mistakes, sometimes in the most public and horrible fashion ever, but I'm never like a mentor. I'm not gonna sit there and like tell you like, oh, do this or that or that or that. It's like.

01:07:53,442 --> 01:07:58,238
SPEAKER_0:  i don't know if you're gonna listen to me and i don't want to condescend to you and you know you figure stuff out i'll be here if you want to talk about it but yeah

01:07:58,786 --> 01:08:12,446
SPEAKER_0:  There was a one of those stories, there was a company that didn't work with me because I was very adamant on defending like very radical notions about language and racial slurs and everything when I was like 22 or whatever. And there was a company and they said, well, we don't want to work with this guy for an event.

01:08:12,738 --> 01:08:15,678
SPEAKER_0:  And after they'd said that, I'd written an article on my website.

01:08:15,906 --> 01:08:31,774
SPEAKER_0:  called the company was Gigabyte, they make motherboards. I said, fuck Gigabyte in the ass. That was the title to my article. And it was like, well, if they don't wanna work with me, I'm gonna blow them up and never do anything ever with them again. And it was just like, looking back at it now, obviously as an older person, like, hey, you need to pump the brakes and chill. You're destroying yourself.

01:08:32,034 --> 01:08:39,486
SPEAKER_0:  But yeah, as a young person, it's like, yeah, you're 22. Of course you think that you can say whatever and do whatever. And as long as you're good at what you're doing, you've got the whole world behind you. And yeah, cheers.

01:08:40,418 --> 01:08:43,710
SPEAKER_1:  Well, let's go there. You have a history of using offensive language.

01:08:44,002 --> 01:08:45,566
SPEAKER_1:  like the R word.

01:08:46,274 --> 01:08:49,438
SPEAKER_1:  the N word including the N word with a hard R.

01:08:50,178 --> 01:08:52,222
SPEAKER_1:  uh... calling women bitches

01:08:53,186 --> 01:08:54,878
SPEAKER_1:  talking about rape.

01:08:55,106 --> 01:08:56,990
SPEAKER_1:  in a nonchalant way.

01:08:57,666 --> 01:08:58,462
SPEAKER_1:  Um...

01:08:59,554 --> 01:09:01,086
SPEAKER_1:  What part of that do you regret?

01:09:01,602 --> 01:09:02,718
SPEAKER_1:  What part of that do you not?

01:09:03,298 --> 01:09:04,702
SPEAKER_0:  Language is very complicated.

01:09:05,186 --> 01:09:12,606
SPEAKER_0:  When it comes to stuff relating to slurs, there's been like a whole trajectory of feelings on...

01:09:13,442 --> 01:09:15,317
SPEAKER_0:  everything related to language so my free

01:09:15,317 --> 01:09:16,990
SPEAKER_1:  personally and for the Internet as a whole.

01:09:17,090 --> 01:09:19,262
SPEAKER_0:  Yeah, I don't care about the internet. For me personally.

01:09:19,522 --> 01:09:24,286
SPEAKER_0:  I'm early twenties, I'll say like 22, 23, I think probably when I first started streaming.

01:09:24,674 --> 01:09:26,110
SPEAKER_0:  My feeling is that

01:09:26,338 --> 01:09:30,814
SPEAKER_0:  Any word is just a word, and if it hurts you, that's your fault. Take responsibility for yourself.

01:09:31,266 --> 01:09:36,254
SPEAKER_0:  This probably came from my background of being a really independent person, so that's just kind of like the mind that I had for everything.

01:09:36,802 --> 01:09:37,310
SPEAKER_0:  and

01:09:38,082 --> 01:09:40,702
SPEAKER_0:  They were basically, they were like a collection of experiences that I had.

01:09:41,026 --> 01:09:43,486
SPEAKER_0:  And as I grew, I started to realize, like, okay.

01:09:44,226 --> 01:09:49,726
SPEAKER_0:  I feel differently about some of these words depending on the context and I can see how they can affect other people depending on the context.

01:09:49,954 --> 01:09:51,518
SPEAKER_0:  So as I've kind of like grown.

01:09:51,778 --> 01:09:54,430
SPEAKER_0:  I think I've developed a more sophisticated understanding of...

01:09:54,658 --> 01:10:07,134
SPEAKER_0:  how different words are used and how they affect people, whether they like it or not, and more importantly, whether I like it or not. And that words can, even if I don't want it to be, they can be a vehicle for emboldening certain types of ideas that I don't want to embolden.

01:10:07,490 --> 01:10:19,646
SPEAKER_0:  And yeah, that's kind of been the whole growth. I've been lucky that in the time that I came up on the internet, I was able to learn these lessons because if I was trying to learn those same lessons today, I would have been completely destroyed because I had insane views on language like 10 years ago.

01:10:20,162 --> 01:10:23,614
SPEAKER_1:  We could talk about the past, we could talk about the present. Let's talk about the past first.

01:10:23,970 --> 01:10:26,462
SPEAKER_1:  How do you deal with the fact that there's videos of you?

01:10:26,914 --> 01:10:28,542
SPEAKER_1:  in the past saying.

01:10:29,026 --> 01:10:31,614
SPEAKER_1:  the N word including the N word with a hard R.

01:10:32,194 --> 01:10:34,910
SPEAKER_0:  So generally... And what's the contest? Can you give me like...

01:10:35,010 --> 01:10:36,885
SPEAKER_1:  Yeah, so what would be the con?

01:10:36,885 --> 01:10:38,014
SPEAKER_0:  usually when I

01:10:38,370 --> 01:10:41,374
SPEAKER_0:  Lay out this defense. It's not because I wouldn't have used the N-word.

01:10:41,666 --> 01:10:48,382
SPEAKER_0:  Um, generally, whenever I said the N word, it was usually in an example of like, this is something that like a racist person would say. I don't think I've ever.

01:10:48,674 --> 01:10:51,742
SPEAKER_0:  on the internet and I don't think I've ever called anybody like the Edward with a hard R.

01:10:52,066 --> 01:11:03,806
SPEAKER_0:  Not because I wouldn't have but just because it wasn't in my vocabulary. I played RTS real-time strategy and we use the the f slur for gay people. That's what I use that one a ton I've called people that a ton in the past.

01:11:04,162 --> 01:11:05,287
SPEAKER_0:  So I should actually just

01:11:05,287 --> 01:11:07,166
SPEAKER_1:  as a small tangent. Go for it.

01:11:07,682 --> 01:11:08,446
SPEAKER_1:  And this is what I-

01:11:08,674 --> 01:11:10,238
SPEAKER_1:  like to explore with you.

01:11:11,682 --> 01:11:14,302
SPEAKER_1:  There's a ruthlessness to the language.

01:11:14,786 --> 01:11:16,894
SPEAKER_1:  in the gaming world. yen euioioioioioioioioioioioi

01:11:17,346 --> 01:11:18,590
SPEAKER_1:  There's different communities.

01:11:18,818 --> 01:11:19,998
SPEAKER_1:  They have different...

01:11:20,482 --> 01:11:21,246
SPEAKER_1:  flavors.

01:11:21,474 --> 01:11:24,574
SPEAKER_1:  of language of hate speech essentially.

01:11:25,154 --> 01:11:27,742
SPEAKER_1:  and there's also a humor to it.

01:11:29,698 --> 01:11:30,270
SPEAKER_1:  Witch.

01:11:31,682 --> 01:11:36,414
SPEAKER_1:  really bothers me in a dark way that I haven't been able to really think through

01:11:37,378 --> 01:11:39,678
SPEAKER_1:  because humor seems to be a kind of...

01:11:40,354 --> 01:11:43,422
SPEAKER_1:  catalyst for hate. It seems to normalize hate.

01:11:44,162 --> 01:11:45,694
SPEAKER_1:  Like, you say...

01:11:46,338 --> 01:11:49,534
SPEAKER_1:  Basically, it's like Louis C.K. says a lot of edgy things.

01:11:50,178 --> 01:11:55,710
SPEAKER_1:  but you take something Lucy Kay says and do it in a non-funny way and do it over and over and over and keep

01:11:56,386 --> 01:11:57,598
SPEAKER_1:  uh, increasing.

01:11:57,890 --> 01:11:58,942
SPEAKER_1:  The hatefulness of it.

01:11:59,298 --> 01:11:59,966
SPEAKER_1:  vitriol

01:12:00,322 --> 01:12:01,278
SPEAKER_1:  and somehow you.

01:12:02,114 --> 01:12:04,062
SPEAKER_1:  Find yourself like Alice in Wonderland.

01:12:04,386 --> 01:12:06,942
SPEAKER_1:  in a world full of hate where there is no good in.

01:12:07,202 --> 01:12:09,534
SPEAKER_1:  evil is all the same. In fact, the good.

01:12:10,274 --> 01:12:14,590
SPEAKER_1:  is to be mocked and the evil is to be celebrated for the humor of it.

01:12:14,850 --> 01:12:18,110
SPEAKER_1:  basically not taking the ideas of evil seriously.

01:12:18,626 --> 01:12:22,398
SPEAKER_1:  And I don't know what it, it reveals something about human nature that you can let go.

01:12:22,626 --> 01:12:24,446
SPEAKER_1:  the moral relativism that

01:12:25,250 --> 01:12:26,814
SPEAKER_1:  can happen when you do that kind of stuff.

01:12:27,074 --> 01:12:28,350
SPEAKER_1:  at the same time.

01:12:28,610 --> 01:12:30,014
SPEAKER_1:  I'm a fan of dark humor.

01:12:31,234 --> 01:12:32,158
SPEAKER_1:  when done well.

01:12:32,706 --> 01:12:35,550
SPEAKER_1:  Anyway, for people who are not familiar, I just wanted to mention...

01:12:36,322 --> 01:12:36,798
SPEAKER_1:  that

01:12:37,666 --> 01:12:38,686
SPEAKER_1:  some of the worst.

01:12:40,162 --> 01:12:42,142
SPEAKER_1:  hate speech that ends in LOL.

01:12:42,466 --> 01:12:47,230
SPEAKER_1:  happens in gaming communities. Yeah, the... And that's where you come from in certain parts.

01:12:47,330 --> 01:12:51,870
SPEAKER_0:  So a lot of people don't remember this or don't know this because they're younger, but way back in the day.

01:12:52,098 --> 01:13:06,014
SPEAKER_0:  in the late nineties, early mid 2000s of the internet. The way that online kind of like shit talk worked was you were just trying to ramp up to the most insanely edgy, crazy stuff you could say to like provoke a reaction.

01:13:06,338 --> 01:13:08,766
SPEAKER_0:  Have you ever heard of something called the aristocrats?

01:13:09,346 --> 01:13:10,846
SPEAKER_0:  That's like a joke, the joke.

01:13:11,106 --> 01:13:12,958
SPEAKER_1:  Oh yeah, the joke, yeah, there's a movie on it, yeah.

01:13:13,250 --> 01:13:25,662
SPEAKER_0:  Okay, basically every single like shit talk back and forth on the internet was like that. Like what is the most increasingly depraved, and back then you didn't get banned for slurs or anything on any of these chat rooms. So it was just like insane world to walk into.

01:13:25,922 --> 01:13:30,622
SPEAKER_0:  and I was fully 100% a part of, a product of, and a contributor to.

01:13:30,882 --> 01:13:37,214
SPEAKER_1:  that were so that probably still goes on the internet in some way and that probably still goes on the internet in maybe

01:13:37,602 --> 01:13:39,134
SPEAKER_1:  more pacified way.

01:13:39,266 --> 01:13:42,270
SPEAKER_0:  only in darker parts of the internet. I'd say for the most part, most.

01:13:42,530 --> 01:13:50,174
SPEAKER_0:  Well, compared to back then, compared to 20 years ago, the internet is way cleaned up now. There are still gonna be boards you can go on or parts of the internet where you see that type of hammer, but...

01:13:50,402 --> 01:13:59,199
SPEAKER_0:  not know when near as mainstream like back then you could open your mic on Xbox live and hear some insane stuff when that first started nowhere near what you hear today although there's still

01:13:59,199 --> 01:14:04,574
SPEAKER_1:  those elements of escalation that happened that just seems to be part of human nature on the internet the

01:14:04,866 --> 01:14:08,894
SPEAKER_1:  because we don't get the feedback of actually hurting people directly. So the

01:14:09,122 --> 01:14:09,950
SPEAKER_1:  the trolling.

01:14:10,722 --> 01:14:15,006
SPEAKER_1:  Like for the walls, you'll do like whatever, like you will still escalate.

01:14:15,298 --> 01:14:16,286
SPEAKER_1:  within the bounds.

01:14:16,514 --> 01:14:20,094
SPEAKER_1:  You're just saying that there's more bonds now on Reddit, there's more bounds and so on.

01:14:20,450 --> 01:14:23,774
SPEAKER_1:  There's moderators that yell at you.

01:14:24,002 --> 01:14:26,750
SPEAKER_1:  that ban you and so on if you cross those bounds.

01:14:27,202 --> 01:14:29,758
SPEAKER_1:  overall that basic human instinct to escalate.

01:14:30,530 --> 01:14:30,878
SPEAKER_1:  Oh.

01:14:31,362 --> 01:14:33,758
SPEAKER_1:  especially under the veil of anonymity is still there.

01:14:34,114 --> 01:14:35,239
SPEAKER_1:  I don't know, it's dark.

01:14:35,239 --> 01:14:40,830
SPEAKER_0:  Yeah, just there's a lot of different ways to look at it and there's different ways you can break that art like for instance Like you mentioned dark humor

01:14:41,058 --> 01:14:41,982
SPEAKER_0:  and you say that like...

01:14:42,274 --> 01:14:42,718
SPEAKER_0:

01:14:43,362 --> 01:14:45,982
SPEAKER_0:  Sometimes dark humor is funny and sometimes it's not.

01:14:46,338 --> 01:14:53,598
SPEAKER_0:  I think that it's really important to dig into and figure out like why certain things are funny. Can I give you an example? Yeah, go. It's from your subreddit. Oh boy.

01:14:53,922 --> 01:14:57,278
SPEAKER_1:  No, that made me laugh and I felt wrong about it. Oh no.

01:14:58,338 --> 01:15:00,213
SPEAKER_1:  So this is a...

01:15:00,213 --> 01:15:02,270
SPEAKER_0:  I already know what this is, yeah.

01:15:02,402 --> 01:15:02,814
SPEAKER_1:  Yeah.

01:15:03,554 --> 01:15:06,430
SPEAKER_1:  So this is a trolley problem. To me it connects because I've-

01:15:06,914 --> 01:15:14,046
SPEAKER_1:  Think about the, it keeps, because I worked on autonomous vehicles, the trial problem, the philosophical thought experiment keeps brought up a lot.

01:15:14,370 --> 01:15:17,470
SPEAKER_1:  You know, when AI is part of making the decision, do I kill?

01:15:17,858 --> 01:15:24,478
SPEAKER_1:  three people here or five people here and they I makes that decision. How do you do that calculus? And this, this particular, there's a

01:15:25,986 --> 01:15:26,878
SPEAKER_1:  There's a deep...

01:15:27,394 --> 01:15:30,686
SPEAKER_1:  So it's satire that reveals some kind of flaw in society.

01:15:31,234 --> 01:15:33,406
SPEAKER_1:  I feel like that's what dark humor does.

01:15:33,634 --> 01:15:35,102
SPEAKER_1:  Successful dark humor does.

01:15:35,234 --> 01:15:36,542
SPEAKER_0:  And I don't know if this is law. Hmm.

01:15:36,994 --> 01:15:39,614
SPEAKER_0:  I feel like there's a certain brand of dark humor.

01:15:39,874 --> 01:15:40,862
SPEAKER_0:  And I think the reason...

01:15:41,378 --> 01:15:43,166
SPEAKER_0:  I think the reason is why it's good.

01:15:43,746 --> 01:15:49,534
SPEAKER_0:  or why it is good humor. I think it's because it, I don't think it necessarily reveals a flaw. Sometimes I feel like it reveals like a kind of virtue, I think.

01:15:49,826 --> 01:15:54,495
SPEAKER_0:  Like, if you look at this particular thing... Can I explain what we're... Yeah, go for it. Just listen.

01:15:54,495 --> 01:15:58,558
SPEAKER_1:  The title of the Reddit post is, you know what to pick.

01:15:59,106 --> 01:16:00,478
SPEAKER_1:  And it says.

01:16:00,834 --> 01:16:08,190
SPEAKER_1:  Five people are going to die either way, but if you flip the lever the trolley will do a sick fucking loop first

01:16:08,962 --> 01:16:09,470
SPEAKER_1:  and

01:16:09,826 --> 01:16:11,518
SPEAKER_1:  Also the top comment.

01:16:12,706 --> 01:16:13,118
SPEAKER_1:  is.

01:16:13,442 --> 01:16:21,246
SPEAKER_1:  A question saying, which I think is also part of the dark humor that's successful. Can I get the gender and ethnic backgrounds of the groups first?

01:16:21,570 --> 01:16:25,470
SPEAKER_1:  And the top answer is both groups are each comprised of five.

01:16:25,954 --> 01:16:27,934
SPEAKER_1:  White orphaned cis male.

01:16:29,666 --> 01:16:30,942
SPEAKER_1:  Heavy meth users.

01:16:31,330 --> 01:16:33,950
SPEAKER_1:  who are consistently in and out of drug rehab.

01:16:34,466 --> 01:16:36,926
SPEAKER_1:  All who identifies right wing extremists.

01:16:37,122 --> 01:16:38,878
SPEAKER_0:  Humor is so, it's such a sophisticated-

01:16:39,202 --> 01:16:44,830
SPEAKER_0:  thing that we engage in, humor is like really complicated. But I would argue that like hopefully the humor here

01:16:45,122 --> 01:16:46,462
SPEAKER_0:  shows the virtue of like.

01:16:46,914 --> 01:17:06,078
SPEAKER_0:  This is obviously horrible, but that's kind of why it's funny. It's funny because it's such a horrible question to ask. Like, do we kill five people in a boring way or in a really entertaining way? And it's like, that's really, that's really, and then when you ask even more, like, what are the ethnic backgrounds? Like, that's even worse to say that, you know? So I feel like that's like the type of, there's a way that you can engage with dark humor it's like, oof, like.

01:17:06,370 --> 01:17:11,838
SPEAKER_0:  It's funny because it's so wrong and so taboo. And we all know that it's wrong and taboo and that's kind of where the shared laugh comes from.

01:17:12,002 --> 01:17:22,206
SPEAKER_1:  So for me, the question that asking the diversity question is a sophisticated way of revealing the absurdity of asking about diversity when it's talking about human life.

01:17:22,498 --> 01:17:48,063
SPEAKER_0:  Oh, interesting, because the way that I took that was, I think it reveals the absurdity of how people will weigh different ethnic backgrounds so differently when it comes to value of human life. Like I'm actually thinking of that in terms of like an immigration related question, where people are really keen and quick to dehumanize like black or brown people. So like the question is like, well, if five of them are brown and five are white, well, I know which one I'm gonna pull the lever for. That's how I read that. But it's satirizing that aspect. Yeah, exactly, yes, of course, yeah.

01:17:48,063 --> 01:17:49,598
SPEAKER_1:  That's what I mean. That that's the floor.

01:17:50,178 --> 01:17:51,742
SPEAKER_1:  To me at least.

01:17:52,066 --> 01:17:52,926
SPEAKER_1:  It showed.

01:17:53,602 --> 01:17:55,070
SPEAKER_1:  that humanity

01:17:55,842 --> 01:18:01,790
SPEAKER_1:  or social networks that are easy to be outraged and love the outrage and the chaos.

01:18:03,426 --> 01:18:06,558
SPEAKER_1:  Twitter and social networks will pull that lever.

01:18:07,042 --> 01:18:09,982
SPEAKER_1:  Like they would, they would always try to maximize the fun.

01:18:10,466 --> 01:18:13,310
SPEAKER_1:  And there's like a, there's a sick aspect to.

01:18:13,698 --> 01:18:16,350
SPEAKER_1:  all the atrocities, all the tragedies that happen in the world.

01:18:16,866 --> 01:18:21,694
SPEAKER_1:  that we kind of always lean towards the outrageous narrative.

01:18:22,242 --> 01:18:23,070
SPEAKER_1:  Weaved around it.

01:18:23,458 --> 01:18:24,414
SPEAKER_1:  dumb

01:18:25,154 --> 01:18:29,214
SPEAKER_1:  Yeah, the one that leads to the most clicks to the most.

01:18:30,050 --> 01:18:31,966
SPEAKER_1:  attention to the most outraged.

01:18:32,194 --> 01:18:37,502
SPEAKER_1:  to all that kind of stuff. So that's almost like a satire of society.

01:18:37,794 --> 01:18:39,710
SPEAKER_1:  when they are faced with tragedy.

01:18:40,546 --> 01:18:42,174
SPEAKER_1:  they will maximize.

01:18:42,594 --> 01:18:43,422
SPEAKER_1:  I'm trying to think of...

01:18:43,810 --> 01:18:45,086
SPEAKER_1:  A word that's not fun.

01:18:46,210 --> 01:18:46,686
SPEAKER_0:  entertainment.

01:18:47,106 --> 01:18:48,638
SPEAKER_1:  Maximize the entertainment, yeah.

01:18:49,154 --> 01:18:52,350
SPEAKER_0:  This is a big criticism I give, especially to conservative crowds.

01:18:52,610 --> 01:19:38,174
SPEAKER_0:  You know, left leaning people, everybody doesn't. I don't like when people blame the media for the state of the media today. I very much believe that everything in society is a feedback loop, and that if you're really unhappy with the state of the media, I think that the media is a good reflection for what people wanna see. Because there is a room right now in the United States where somebody could start a company where all they do is completely factual reporting, they don't have a political slant, and they're not giving you these sensationalist narratives or stories, and that media company would fail in two weeks because people don't wanna see that. Generally, people really wanna see the like, show me the guy that really believes in what I say, that calls the other guy an idiot, the guy that are screaming on TV or on the radio, like, this is what I really want. And people will engage in that, and that feedback loop will continue for generations. And then all of a sudden people are like, why is the media so biased? Why is the media driving so many narratives? And it's like, well, what do you mean? Exactly what you wanna see.

01:19:39,010 --> 01:19:46,174
SPEAKER_0:  And that's frustrating for me. That's one of my big kind of when I defend establishments or when I talk about like the interplay between citizen and.

01:19:47,042 --> 01:19:48,414
SPEAKER_0:  and all these institutions we have.

01:19:48,674 --> 01:20:01,598
SPEAKER_0:  that the institutions are very much a reflection of the population, at least in democratic societies. And I think that people very much try to elude the personal responsibility or the country's responsibility to why some of them look the way that they do.

01:20:03,074 --> 01:20:05,662
SPEAKER_1:  But that takes us back to the N word with a hard R.

01:20:05,890 --> 01:20:06,206
SPEAKER_0:  Sure.

01:20:06,498 --> 01:20:06,910
SPEAKER_0:  Why?

01:20:07,746 --> 01:20:18,238
SPEAKER_0:  For the particular examples that I was giving, for the particular conversations that I was having, if you're gonna have challenging conversations around certain words, I think you should probably be able to say them, otherwise it feels really ridiculous to me.

01:20:18,562 --> 01:20:19,774
SPEAKER_0:  That's like why- Do you still believe that?

01:20:20,130 --> 01:20:26,814
SPEAKER_0:  Um, for com- yes, in- not like calling people those words, but in having conversations about those words, I would say that I still believe that, yeah.

01:20:27,138 --> 01:20:30,526
SPEAKER_1:  But don't you think as you said, that using those words...

01:20:32,386 --> 01:20:35,742
SPEAKER_1:  actually gives motivation and strength to...

01:20:36,002 --> 01:20:37,662
SPEAKER_1:  people who have hate in their hearts.

01:20:38,146 --> 01:20:50,718
SPEAKER_0:  I think depending on the context of what's going on, I think that that's gonna be a big driver in terms of how people are going to perceive or take it. So in a conversation about the N-word, I don't think I would normally say the N-word, I would just talk about.

01:20:51,042 --> 01:21:03,518
SPEAKER_0:  the word much the same way that like in a movie, like in Django, people use the N word. Should that be censored in that movie or in the context of that movie, is it being employed in a way where these aren't good people, you're not supposed to like them and that's what the audience walks away with.

01:21:04,354 --> 01:21:08,126
SPEAKER_1:  Yeah, but that context is different than conversation. It feels like in conversation.

01:21:08,706 --> 01:21:11,358
SPEAKER_1:  You using that word normalizes it.

01:21:11,938 --> 01:21:12,414
SPEAKER_1:  and that.

01:21:12,706 --> 01:21:17,022
SPEAKER_1:  Normalizing that word is going to make it easier for people who use that word

01:21:17,250 --> 01:21:18,942
SPEAKER_1:  in a hateful way to use it.

01:21:19,458 --> 01:21:22,526
SPEAKER_1:  Same with the F word, the F slur.

01:21:23,490 --> 01:21:24,510
SPEAKER_1:  If you use that...

01:21:25,506 --> 01:21:27,582
SPEAKER_1:  casually and normalize it.

01:21:28,706 --> 01:21:30,046
SPEAKER_1:  in a way that's not hateful.

01:21:30,690 --> 01:21:32,286
SPEAKER_1:  You're using words that's not hateful.

01:21:32,834 --> 01:21:33,150
SPEAKER_1:  But you-

01:21:33,442 --> 01:21:35,326
SPEAKER_1:  the side effect is that it normalizes it.

01:21:35,586 --> 01:21:37,822
SPEAKER_1:  than people who do use it in a hateful way.

01:21:38,466 --> 01:21:39,934
SPEAKER_1:  would be more likely to use it.

01:21:40,290 --> 01:21:40,958
SPEAKER_1:  Therefore...

01:21:41,954 --> 01:21:44,766
SPEAKER_1:  mathematically looking at the equation of the number of times

01:21:45,410 --> 01:21:50,718
SPEAKER_1:  the N word or the F word is used throughout the world, it increases the number of times it's used in a hateful way.

01:21:51,330 --> 01:21:52,455
SPEAKER_1:  Yeah, I think that human-

01:21:52,455 --> 01:21:54,174
SPEAKER_0:  And you're part of that problem, Stephen.

01:21:54,466 --> 01:21:57,758
SPEAKER_0:  I don't I don't agree. I understand. I understand the thought process.

01:21:58,018 --> 01:22:00,382
SPEAKER_0:  but I don't know if using certain words.

01:22:00,738 --> 01:22:06,046
SPEAKER_0:  within different contexts is going to necessarily normalize like the hateful use of that word.

01:22:06,306 --> 01:22:06,782
SPEAKER_0:  Um.

01:22:07,202 --> 01:22:45,694
SPEAKER_0:  that is an argument that I've heard people use, somebody will say like, okay, well, hold on, that should never be used ever, because by virtue of you normalizing it, even in an inoffensive environment, you increase the proclivity for people to use it in a potentially more offensive environment. And my argument is always like, no, I don't think that crossover exists. But if you did wanna take that argument, and maybe you do feel this way, I think that you get really problematic when you run into communities that do use certain words that people would say, well, they should be allowed to do it. So for instance, if you think that any utterance of the N word at all is highly problematic and might increase hatred, then like the entire rap industry has to dramatically change the way that they engage with the N word. And obviously a lot of people that criticize people's use of the N word aren't gonna turn to rappers and say, well, you guys can't say it either.

01:22:45,922 --> 01:22:46,590
SPEAKER_1:  No, it's who.

01:22:46,946 --> 01:22:49,182
SPEAKER_1:  I mean, it's who uses the N word, that's what.

01:22:49,730 --> 01:22:51,998
SPEAKER_1:  It's not, so it's not just the word. It's the...

01:22:52,994 --> 01:22:53,982
SPEAKER_1:  It is.

01:22:54,530 --> 01:22:55,646
SPEAKER_1:  context dependent.

01:22:56,066 --> 01:22:56,446
SPEAKER_1:  Uh...

01:22:57,154 --> 01:23:00,126
SPEAKER_1:  but I would say that you as a white person.

01:23:00,418 --> 01:23:01,886
SPEAKER_1:  having conversations.

01:23:03,458 --> 01:23:06,910
SPEAKER_1:  The context there is the kind that would lead to an increase in hate.

01:23:07,330 --> 01:23:09,246
SPEAKER_0:  Do you think the N word should be censored in the dictionary?

01:23:09,538 --> 01:23:09,918
SPEAKER_1:  No.

01:23:10,242 --> 01:23:13,598
SPEAKER_1:  and I believe there's a Wikipedia page on it and it's not censored.

01:23:14,338 --> 01:23:17,662
SPEAKER_1:  Yeah, I don't I think it should be in the dictionary. I think the context of

01:23:17,954 --> 01:23:19,262
SPEAKER_1:  casual conversation.

01:23:20,162 --> 01:23:22,910
SPEAKER_1:  Like I said, I just believe that on the internet.

01:23:24,034 --> 01:23:25,086
SPEAKER_1:  having humor.

01:23:25,570 --> 01:23:27,870
SPEAKER_1:  having fun conversations as you have.

01:23:28,354 --> 01:23:29,470
SPEAKER_1:  and your streams.

01:23:30,594 --> 01:23:31,038
SPEAKER_1:  that.

01:23:31,362 --> 01:23:35,487
SPEAKER_1:  leads to the normalization of the word without any educational value.

01:23:35,487 --> 01:23:38,183
SPEAKER_0:  I would agree with that. I think I would agree with that.

01:23:38,183 --> 01:23:39,390
SPEAKER_1:  Sorry, so there's a difference.

01:23:39,618 --> 01:23:40,254
SPEAKER_1:  between the

01:23:40,642 --> 01:23:42,878
SPEAKER_1:  F's learn N-word and both I think.

01:23:43,778 --> 01:23:53,790
SPEAKER_1:  should not be used in a fun way, but the F word was used in a fun way for a long time. For sure. I'll tell you something that bothers me about your streams.

01:23:54,178 --> 01:23:55,166
SPEAKER_1:  What? Now you're stream-

01:23:55,458 --> 01:23:57,918
SPEAKER_1:  your streams and basically every other stream.

01:23:58,498 --> 01:24:02,174
SPEAKER_1:  is the casual use of the R word. Oh, the ableism, yeah.

01:24:02,594 --> 01:24:05,150
SPEAKER_1:  I don't know if it's about the able. I don't even know.

01:24:06,178 --> 01:24:08,803
SPEAKER_1:  Listen it's complicated, I'm not like virtue signaling here.

01:24:08,803 --> 01:24:21,726
SPEAKER_0:  No, ableism isn't a virtue signal. I mean, it's a legitimate, yeah. Like I get emails from fans that say like, hey, like I deal with this particular issue. Every time you use this word, it kind of feels like you're attacking me. Like just like so it's a valid concept.

01:24:21,986 --> 01:24:26,014
SPEAKER_1:  It's just something cuts wrong for me. Like for example, I'm not bothered by.

01:24:26,722 --> 01:24:29,182
SPEAKER_1:  I am bothered by the excessive use of the word fuck.

01:24:29,506 --> 01:24:29,854
SPEAKER_0:  Okay.

01:24:30,306 --> 01:24:30,878
SPEAKER_1:  but not.

01:24:31,682 --> 01:24:33,054
SPEAKER_1:  in the same way that moderate

01:24:33,378 --> 01:24:34,503
SPEAKER_1:  Use of the word fuck.

01:24:34,503 --> 01:24:37,662
SPEAKER_0:  What is it I'm curious in when somebody calls somebody in our word?

01:24:38,434 --> 01:24:41,086
SPEAKER_0:  What is the feeling that you get that makes you feel bad about it?

01:24:42,466 --> 01:24:44,542
SPEAKER_1:  It signals to me that you don't...

01:24:45,858 --> 01:24:47,582
SPEAKER_1:  Give a damn about

01:24:51,746 --> 01:24:53,182
SPEAKER_1:  people who are struggling.

01:24:54,050 --> 01:24:55,678
SPEAKER_1:  in ways that you are not struggling.

01:24:56,098 --> 01:24:56,606
SPEAKER_1:  Like that.

01:24:57,090 --> 01:24:58,238
SPEAKER_1:  that signals to me.

01:24:58,498 --> 01:24:59,198
SPEAKER_1:  Like, um...

01:24:59,586 --> 01:25:01,342
SPEAKER_1:  about the experience of others.

01:25:02,146 --> 01:25:13,438
SPEAKER_0:  Do you think that there are other words also that could convey like a similar feeling to your work? Because it feels like you've drawn a pretty special circle around because like I imagine I go, oh, this guy's an uneducated dumb fucker. You're a networker.

01:25:13,666 --> 01:25:14,014
SPEAKER_0:  like

01:25:14,850 --> 01:25:17,374
SPEAKER_0:  to those who are also that circle keep changing.

01:25:17,890 --> 01:25:19,015
SPEAKER_0:  which you can, which is fine, it does.

01:25:19,015 --> 01:25:24,702
SPEAKER_1:  And I think that's the whole point with the culture. I'm trying to feel my feelings kind of.

01:25:25,058 --> 01:25:27,774
SPEAKER_1:  you know i'm a human being that exists in a social context that

01:25:28,418 --> 01:25:31,294
SPEAKER_1:  we're all evolving that language together and just feels wrong.

01:25:31,810 --> 01:25:32,542
SPEAKER_1:  You know, the word...

01:25:32,930 --> 01:25:37,150
SPEAKER_1:  bitch for example. It really bought like I've heard on your streams and in general.

01:25:37,666 --> 01:25:38,206
SPEAKER_1:  calling.

01:25:38,562 --> 01:25:40,894
SPEAKER_1:  a woman a stupid bitch.

01:25:41,410 --> 01:25:42,878
SPEAKER_1:  really bothers me.

01:25:43,330 --> 01:25:46,302
SPEAKER_1:  But it's not just the word bitch, it's context. For example,

01:25:46,914 --> 01:25:48,542
SPEAKER_1:  Me personally, I'm speaking to me personally.

01:25:48,834 --> 01:25:49,950
SPEAKER_1:  Like, badass bitch.

01:25:51,842 --> 01:25:52,967
SPEAKER_1:  is different than stupid.

01:25:52,967 --> 01:25:56,766
SPEAKER_0:  Sure, like a bad bitch or something that's different. Yeah, of course. Way different.

01:25:56,962 --> 01:26:00,574
SPEAKER_1:  I think it speaks to a bigger sense of civility.

01:26:00,866 --> 01:26:03,166
SPEAKER_1:  and respect for human beings.

01:26:03,394 --> 01:26:04,478
SPEAKER_1:  They're not like you.

01:26:05,314 --> 01:26:08,222
SPEAKER_1:  That's the feeling that I'm bothering. So..... rests.

01:26:08,706 --> 01:26:10,814
SPEAKER_1:  I guess what I'm trying to say here is...

01:26:12,674 --> 01:26:14,462
SPEAKER_1:  just because people speak.

01:26:14,754 --> 01:26:16,030
SPEAKER_1:  in this kind of way.

01:26:16,834 --> 01:26:19,070
SPEAKER_1:  in the gaming world and streams.

01:26:19,938 --> 01:26:21,086
SPEAKER_1:  Doesn't mean that.

01:26:21,378 --> 01:26:23,390
SPEAKER_1:  you like a lot of people look up to you.

01:26:23,746 --> 01:26:24,574
SPEAKER_1:  It doesn't mean...

01:26:25,058 --> 01:26:26,526
SPEAKER_1:  young people especially.

01:26:27,042 --> 01:26:30,814
SPEAKER_1:  doesn't mean that you don't have the responsibility to sort of stand alone from the crowd.

01:26:31,138 --> 01:26:33,534
SPEAKER_1:  Because you're somebody that values the power of

01:26:33,954 --> 01:26:35,038
SPEAKER_1:  effective discourse.

01:26:36,322 --> 01:26:36,958
SPEAKER_1:  and

01:26:38,946 --> 01:26:45,342
SPEAKER_1:  to be effective discourse, there's some level of civility. So you can be the sort of the beacon of civility in that world.

01:26:45,730 --> 01:26:47,870
SPEAKER_1:  versus giving in to the...

01:26:48,770 --> 01:26:50,334
SPEAKER_1:  the derogatory words.

01:26:50,594 --> 01:26:51,902
SPEAKER_1:  Cause like, you have to...

01:26:52,866 --> 01:26:54,846
SPEAKER_1:  You have to lift people out of that world.

01:26:55,170 --> 01:26:56,638
SPEAKER_1:  Out of the muck of-

01:26:57,474 --> 01:26:58,046
SPEAKER_1:  Um.

01:26:58,786 --> 01:27:04,670
SPEAKER_1:  What I would say is like drama in ineffective discourse. It's like, I think that's one of your missions, right? It's like.

01:27:05,154 --> 01:27:09,182
SPEAKER_1:  to inspire the world through conversation, through debate, through effective discourse.

01:27:10,018 --> 01:27:14,270
SPEAKER_1:  So I guess I'm just calling out that I think using our word for me personally.

01:27:14,626 --> 01:27:15,646
SPEAKER_1:  as a fan that

01:27:16,674 --> 01:27:17,950
SPEAKER_1:  believes in your mission.

01:27:18,626 --> 01:27:19,838
SPEAKER_1:  It just makes you look-

01:27:20,866 --> 01:27:23,390
SPEAKER_1:  ineffective and bad and uninspiring to

01:27:23,746 --> 01:27:28,286
SPEAKER_1:  young people that look up to you. Because those young people are going to use those words that you're using.

01:27:28,674 --> 01:27:30,590
SPEAKER_1:  and they'll do it much less effectively.

01:27:30,850 --> 01:27:31,966
SPEAKER_1:  That's the problem.

01:27:32,290 --> 01:27:34,430
SPEAKER_0:  I guess the challenge is always just like finding the line.

01:27:34,754 --> 01:27:46,014
SPEAKER_0:  Like my vocabulary shifted dramatically from, even from like two or three years ago, I think my vocabulary shifted quite a bit as we've kind of gotten rid of some words and some things are kind of coming out.

01:27:46,274 --> 01:27:49,438
SPEAKER_0:  The R word is one that has kind of gone out and come back and gone out and come back.

01:27:49,762 --> 01:27:53,886
SPEAKER_0:  that one we've definitely gone back and forth on. I know there are different thoughts about it in different communities on the internet.

01:27:54,210 --> 01:27:55,870
SPEAKER_1:  This isn't sh- I mean I'm just telling you.

01:27:56,546 --> 01:27:57,214
SPEAKER_1:  from me.

01:27:57,794 --> 01:27:58,622
SPEAKER_1:  It cuts.

01:27:59,426 --> 01:28:01,310
SPEAKER_1:  and I'm not a social justice warrior type.

01:28:01,890 --> 01:28:02,974
SPEAKER_1:  it costs pretty hard.

01:28:03,746 --> 01:28:05,854
SPEAKER_0:  What you're saying is I'm going to lose a subscriber if I'm...

01:28:06,178 --> 01:28:08,053
SPEAKER_0:  No, it's not a subscriber.

01:28:08,053 --> 01:28:14,878
SPEAKER_1:  I know you're in. I actually have to empathize harder because I'm like, maybe this is not a very good person. That's what I feel.

01:28:15,266 --> 01:28:17,726
SPEAKER_1:  Like if you're so carelessly using that word.

01:28:18,274 --> 01:28:20,478
SPEAKER_1:  that maybe you're not actually thinking deeply about.

01:28:21,474 --> 01:28:30,846
SPEAKER_1:  the suffering in the world. Like to be a student of human nature, you really have to think about other humans and other experiences that are unlike your own. Yeah, of course. And so that's the sense I get. But at the same time.

01:28:31,298 --> 01:28:33,790
SPEAKER_1:  You're also like the grandpa.

01:28:34,178 --> 01:28:35,134
SPEAKER_1:  I mean, ages.

01:28:35,458 --> 01:28:39,806
SPEAKER_1:  who's trying to be cool with the young kids. A lot of the reason young kids look up to you.

01:28:40,226 --> 01:28:42,558
SPEAKER_1:  is like you also know the language of the internet.

01:28:42,946 --> 01:28:45,054
SPEAKER_0:  Yeah, but I mean it doesn't- that's not an excuse to use-

01:28:45,442 --> 01:28:53,406
SPEAKER_0:  that we think shouldn't be used. I guess the question that I would have, because it's always a struggle, and to some extent it's kind of happened, is let's say that like three years ago,

01:28:53,730 --> 01:29:00,062
SPEAKER_0:  I would have said I'm no longer saying the R word. That's just, I'm just gonna get rid of that in my vocabulary. Like is there a chance that today-

01:29:00,322 --> 01:29:03,518
SPEAKER_0:  we would be having a conversation about like, why do you call people dumb fucks?

01:29:04,098 --> 01:29:07,422
SPEAKER_0:  I think is that really appropriate? Like does this attack at the core of like somebody's like.

01:29:07,650 --> 01:29:12,606
SPEAKER_0:  level of intelligence, education, opportunities in life? Like, is that where they- You don't think so?

01:29:12,706 --> 01:29:13,502
SPEAKER_1:  I think that's a.

01:29:13,794 --> 01:29:15,102
SPEAKER_1:  As the kids say, cope.

01:29:15,490 --> 01:29:21,865
SPEAKER_0:  You really think so? I think that's a cope. Because the words have definitely moved in a way where it's like, this was okay, now it's not. This is okay, now it's not. And I think that you're still gets to listen to it more.

01:29:21,865 --> 01:29:25,886
SPEAKER_1:  and your ground by using, listen, you could, you could.

01:29:26,658 --> 01:29:27,358
SPEAKER_1:  But...

01:29:27,618 --> 01:29:32,030
SPEAKER_1:  I think it's better to use those words if you want to defend the ground.

01:29:32,290 --> 01:29:33,182
SPEAKER_1:  Word stand on.

01:29:33,698 --> 01:29:35,646
SPEAKER_1:  to use them rarely and deliberately.

01:29:36,386 --> 01:29:38,398
SPEAKER_1:  versus how you currently use them.

01:29:38,786 --> 01:29:39,614
SPEAKER_1:  which is...

01:29:40,130 --> 01:29:45,566
SPEAKER_1:  to express an emotion like you, I'm going to be honest, you use the R word.

01:29:45,922 --> 01:29:47,294
SPEAKER_1:  Not when you're at your best.

01:29:47,650 --> 01:29:48,734
SPEAKER_1:  True.

01:29:49,154 --> 01:29:52,990
SPEAKER_0:  And so that's not that's generally that could be true for a lot of swearing to that. But yeah, I know.

01:29:53,186 --> 01:29:57,790
SPEAKER_1:  No, but like, you know that our word is offensive, you know, and there's part of it is like.

01:29:58,178 --> 01:29:58,878
SPEAKER_1:  D-duh.

01:29:59,362 --> 01:29:59,902
SPEAKER_1:  You

01:30:00,130 --> 01:30:01,118
SPEAKER_1:  Tell yourself.

01:30:01,762 --> 01:30:07,294
SPEAKER_1:  that you're still kind of fighting political correctness by using it a little bit when you say it.

01:30:07,554 --> 01:30:17,598
SPEAKER_0:  No, I don't think so. I think I'm trying to think in terms of like, where is the virtue where like there's a whole bunch of arguments for why some words are okay, some words aren't okay or whatever. And I try to like think more along those lines rather than

01:30:17,986 --> 01:30:22,238
SPEAKER_0:  But there's going to be a lot of phrases where, like if the R word has come out,

01:30:22,498 --> 01:30:29,182
SPEAKER_0:  conversation is over. I know that like things my brain is shut down the person thanks is but there's like a there's a lot of words also in terms of like

01:30:29,410 --> 01:30:36,734
SPEAKER_0:  it like if you ever hear me so like fucking moron in a debate it's like it's done like this conversation is over there's no way that anything productive is happening past that point

01:30:36,994 --> 01:30:38,814
SPEAKER_1:  I think fucking moron is not.

01:30:39,074 --> 01:30:41,822
SPEAKER_1:  I think it's ineffective, it's not civil, but it's not.

01:30:42,818 --> 01:30:44,126
SPEAKER_1:  It doesn't bother me in the way.

01:30:45,218 --> 01:30:46,462
SPEAKER_1:  is basically when you...

01:30:47,074 --> 01:30:50,430
SPEAKER_1:  Speaking away that I know there's a group that's going to be hurt by that.

01:30:51,170 --> 01:30:55,102
SPEAKER_1:  not only do I think about the hurt that group experiences, I think of you.

01:30:55,426 --> 01:30:56,350
SPEAKER_1:  as the lesser.

01:30:56,770 --> 01:30:57,534
SPEAKER_1:  intellectual.

01:30:57,858 --> 01:30:59,998
SPEAKER_1:  Like there's a lesser person who's thinking about the world.

01:31:00,578 --> 01:31:02,558
SPEAKER_1:  What bothers me the most is

01:31:03,010 --> 01:31:04,766
SPEAKER_1:  just what kind of...

01:31:05,346 --> 01:31:12,734
SPEAKER_1:  mindset that inspires in young people, especially when you're a public figure and a lot of people look up to you. So I definitely don't think. bringtblatt.com

01:31:13,282 --> 01:31:14,334
SPEAKER_1:  So this idea.

01:31:15,202 --> 01:31:18,494
SPEAKER_1:  The R word is not the battleground of expanding.

01:31:19,202 --> 01:31:21,374
SPEAKER_1:  the Orton window of discourse.

01:31:22,274 --> 01:31:24,638
SPEAKER_1:  Okay, like I don't think.

01:31:25,026 --> 01:31:25,790
SPEAKER_1:  It'll lead to

01:31:26,082 --> 01:31:26,782
SPEAKER_1:  DUMB FUCK

01:31:27,906 --> 01:31:28,894
SPEAKER_1:  being cancelled.

01:31:29,218 --> 01:31:30,974
SPEAKER_1:  of the two years later

01:31:31,234 --> 01:31:33,662
SPEAKER_1:  Unless that word is hurting.

01:31:33,890 --> 01:31:35,934
SPEAKER_1:  people's experience, which.

01:31:36,258 --> 01:31:39,486
SPEAKER_1:  I don't foresee that happening. I think legitimately.

01:31:40,066 --> 01:31:40,958
SPEAKER_1:  Our word and

01:31:41,186 --> 01:31:42,238
SPEAKER_1:  F slur and

01:31:42,850 --> 01:31:44,286
SPEAKER_1:  calling women bitches.

01:31:45,378 --> 01:31:50,526
SPEAKER_1:  It context matters here too, like of course, but just the way I've heard you use it.

01:31:50,818 --> 01:31:52,382
SPEAKER_1:  It is not, it's from emotion.

01:31:52,642 --> 01:31:56,574
SPEAKER_1:  and it's from frustration and it ultimately is rooted in disrespect.

01:31:57,346 --> 01:32:01,374
SPEAKER_1:  I don't, I think it's ineffective. And of course, like who gets to say

01:32:01,762 --> 01:32:02,430
SPEAKER_1:  I don't know.

01:32:02,946 --> 01:32:03,870
SPEAKER_1:  But I'm saying...

01:32:04,322 --> 01:32:06,270
SPEAKER_1:  somebody who would like I admire.

01:32:06,914 --> 01:32:08,574
SPEAKER_1:  effective conversations.

01:32:09,154 --> 01:32:10,878
SPEAKER_1:  and I admire great humor.

01:32:11,394 --> 01:32:12,190
SPEAKER_1:  Dark humor.

01:32:12,546 --> 01:32:13,022
SPEAKER_1:  Wit.

01:32:14,146 --> 01:32:15,806
SPEAKER_1:  To me, oftentimes...

01:32:16,130 --> 01:32:17,438
SPEAKER_1:  the use of the R word.

01:32:18,210 --> 01:32:20,702
SPEAKER_1:  In the way you've used it in the way I see the community use it.

01:32:21,122 --> 01:32:24,414
SPEAKER_1:  is none of those things. It contributes not at all to the humor and so on.

01:32:24,962 --> 01:32:27,294
SPEAKER_1:  Now I can see it might contribute to the

01:32:27,906 --> 01:32:30,206
SPEAKER_1:  to the camaraderie of that particular group.

01:32:30,722 --> 01:32:33,406
SPEAKER_1:  especially when they normalize the use of that word.

01:32:34,082 --> 01:32:35,902
SPEAKER_1:  You kind of take some of the edge off.

01:32:36,290 --> 01:32:37,246
SPEAKER_1:  But you forget.

01:32:37,506 --> 01:32:38,558
SPEAKER_1:  that there's a...

01:32:39,362 --> 01:32:41,182
SPEAKER_1:  A large number of other people that

01:32:42,402 --> 01:32:47,582
SPEAKER_1:  have the chemistry, don't hear the music of the friendship that you have, the relationship you have.

01:32:47,938 --> 01:32:48,990
SPEAKER_1:  Instead they hear

01:32:49,314 --> 01:32:51,070
SPEAKER_1:  The normalization of a hateful word.

01:32:51,330 --> 01:32:55,262
SPEAKER_1:  and it ultimately has an impact that's hateful. and then people like me show up.

01:32:55,778 --> 01:32:57,598
SPEAKER_1:  You know, I haven't watched much of your stuff.

01:32:58,178 --> 01:33:02,206
SPEAKER_1:  It turns me off from like a couple of times your content came.

01:33:02,754 --> 01:33:07,294
SPEAKER_1:  came before me and I listened to it a little bit, turned me off completely. I didn't understand.

01:33:08,066 --> 01:33:10,302
SPEAKER_1:  how good your heart is. i didn't understand.

01:33:10,690 --> 01:33:11,038
SPEAKER_1:  How?

01:33:11,458 --> 01:33:12,990
SPEAKER_1:  your mission of actually

01:33:13,698 --> 01:33:16,926
SPEAKER_1:  do you write do you radicalize people help people like your

01:33:17,218 --> 01:33:19,166
SPEAKER_1:  uh... and increase the level of

01:33:19,618 --> 01:33:24,606
SPEAKER_1:  good faith discourse in the world. I didn't understand any of that cause like what I was hearing is pretty rough.

01:33:25,026 --> 01:33:30,654
SPEAKER_1:  the R award type of stuff. And I just feel like the benefit cost analysis is heavy on the cost.

01:33:31,042 --> 01:33:31,454
SPEAKER_1:  Gotcha.

01:33:31,810 --> 01:33:33,982
SPEAKER_1:  That's why I just have to sort of call this out.

01:33:34,274 --> 01:33:37,566
SPEAKER_1:  Okay. I think it, and I straight up think it's wrong.

01:33:38,722 --> 01:33:40,478
SPEAKER_0:  But that's my own, that's my idea. Why do you think it's wrong?

01:33:41,410 --> 01:33:44,574
SPEAKER_1:  because it's hurting people without any benefit to you whatsoever.

01:33:45,026 --> 01:33:50,366
SPEAKER_0:  When you say hurting people, do you mean the person I'm using it at or do you think there's like the... No, no, no, no, no. You're talking about the affected third group. The third group.

01:33:51,266 --> 01:33:55,774
SPEAKER_0:  It's good feedback, right? I always consider everything, especially I respect you a lot. You're a really smart guy.

01:33:56,610 --> 01:33:58,110
SPEAKER_0:  something that I always kind of like.

01:34:00,194 --> 01:34:03,582
SPEAKER_0:  fight over in terms of like language or like who to attack or what to attack or what to do.

01:34:03,810 --> 01:34:04,574
SPEAKER_0:  is that um...

01:34:05,122 --> 01:34:07,806
SPEAKER_0:  It's very hard to draw, like what boxes.

01:34:08,290 --> 01:34:10,782
SPEAKER_0:  uh... are ok insult to wonders what are

01:34:11,138 --> 01:34:14,750
SPEAKER_0:  So for instance, if I call somebody like a Nazi with a lot of vitriol.

01:34:15,202 --> 01:34:17,406
SPEAKER_0:  I am okay with every single

01:34:17,698 --> 01:34:19,582
SPEAKER_0:  Nazi being negatively affected by that.

01:34:20,002 --> 01:34:20,414
SPEAKER_0:  because...

01:34:20,642 --> 01:34:21,054
SPEAKER_0:  No

01:34:21,986 --> 01:34:43,870
SPEAKER_0:  Category intrinsically calls upon at some level of moral condemnation for me, right? Whereas like if I'm out there I try not to do like image related jokes, right? I don't want to call you like oh, you're a fat fucking loser because there's a lot of people that are fat that are overweight Where I don't want them to feel bad. I don't want them I'm not trying to call you out or like insult you so there's like a lot of you say cost-benefit I like I like a lot of collateral damage from a word like that where there's no purpose in doing

01:34:44,514 --> 01:34:44,926
SPEAKER_0:  Um.

01:34:45,250 --> 01:34:53,278
SPEAKER_0:  So certain words are easy to get rid of. They're off the table, right? Epsler, N word, like these are not words you call people because there's so much collateral it's not worth it.

01:34:53,922 --> 01:34:54,366
SPEAKER_0:  We've got.

01:34:54,754 --> 01:35:07,326
SPEAKER_0:  some words where it's like if you have some form of like mental thing, it is a bad thing, you're not a bad person, but just using that word could feel like a collateral damage to those people. And then there's other categories of words, so like if I say that like...

01:35:07,746 --> 01:35:10,622
SPEAKER_0:  This person is like, they're a stupid fucking Republican.

01:35:10,882 --> 01:35:12,926
SPEAKER_0:  Right? There's probably some Republicans that-

01:35:13,666 --> 01:35:15,806
SPEAKER_0:  aren't dumb that I don't want to feel called out by that.

01:35:16,130 --> 01:35:20,734
SPEAKER_0:  Like are those types of phrases that you think should be completely removed as well? Or I'm kind of curious now.

01:35:20,834 --> 01:35:22,238
SPEAKER_1:  This completely removed.

01:35:22,530 --> 01:35:23,838
SPEAKER_1:  Just so we're clear.

01:35:24,834 --> 01:35:26,206
SPEAKER_1:  I'm not referring to censorship.

01:35:26,530 --> 01:35:29,905
SPEAKER_0:  Oh no, I'm not even talking about this, I'm just a person like emotionally like Remove this

01:35:29,905 --> 01:35:31,134
SPEAKER_1:  wrong word though like I

01:35:31,362 --> 01:35:32,446
SPEAKER_1:  care about.

01:35:34,050 --> 01:35:38,878
SPEAKER_1:  I'm not trying to listen to people on the internet saying that you shouldn't say that word that's not good I mean

01:35:40,034 --> 01:35:40,990
SPEAKER_1:  I'm trying to look.

01:35:41,378 --> 01:35:42,718
SPEAKER_1:  your mind and heart.

01:35:43,266 --> 01:35:44,766
SPEAKER_1:  And the reason we're talking today.

01:35:45,218 --> 01:35:47,486
SPEAKER_1:  is you're betraying your gift.

01:35:47,810 --> 01:35:48,126
SPEAKER_1:  Mm-hmm.

01:35:48,258 --> 01:35:49,534
SPEAKER_0:  You're better than this.

01:35:49,890 --> 01:35:58,581
SPEAKER_0:  You think it's indicative of like a more flippant thought process where it's like, the only way you can say that word is if you're ignoring the hurt and suffering of those people. And if you're somebody that says- Even those people-

01:35:58,581 --> 01:36:00,158
SPEAKER_1:  You're ignoring.

01:36:00,514 --> 01:36:01,758
SPEAKER_1:  the

01:36:02,050 --> 01:36:03,134
SPEAKER_1:  state of language.

01:36:03,426 --> 01:36:07,294
SPEAKER_1:  Cause I think you're getting to the point. Cause it's not about a single word. It's about like a

01:36:07,650 --> 01:36:08,382
SPEAKER_1:  It's music.

01:36:08,802 --> 01:36:10,846
SPEAKER_1:  And I just feel like there is a...

01:36:11,426 --> 01:36:12,574
SPEAKER_1:  All right, so I know.

01:36:12,866 --> 01:36:15,518
SPEAKER_1:  It's a strong note that ruins the melody.

01:36:15,810 --> 01:36:24,318
SPEAKER_1:  Gotcha. And I don't think I can say, you know, you shouldn't use the R word or whatever. I'm just speaking to, I'm just listening to music and reviewing the final result.

01:36:24,802 --> 01:36:25,982
SPEAKER_1:  It's not necessarily-

01:36:26,242 --> 01:36:28,734
SPEAKER_1:  is maybe one use of the word the r word.

01:36:29,602 --> 01:36:31,934
SPEAKER_1:  uh... strategically a part of the actual

01:36:32,226 --> 01:36:32,574
SPEAKER_1:  Like.

01:36:33,026 --> 01:36:34,910
SPEAKER_1:  or when you've built up a camaraderie.

01:36:35,202 --> 01:36:37,214
SPEAKER_1:  that's sandwiched in in

01:36:37,666 --> 01:36:38,046
SPEAKER_1:  Like.

01:36:38,274 --> 01:36:46,590
SPEAKER_1:  some love but then you try to reveal their because you're talking about a lot of is a bunch of drama you have a but you have friends with whom you're worrying and stuff

01:36:46,850 --> 01:36:47,294
SPEAKER_1:  And there are.

01:36:47,554 --> 01:36:50,590
SPEAKER_1:  all a little bit beautifully insane.

01:36:50,818 --> 01:36:55,998
SPEAKER_1:  And you've said that you are becoming more and more insane. It's beautiful to watch. It's just the human condition laid before us.

01:36:56,258 --> 01:36:59,966
SPEAKER_1:  Wonderful. And some of that is swearing and so on. So it's a tricky thing.

01:37:00,866 --> 01:37:01,342
SPEAKER_1:  Um...

01:37:01,826 --> 01:37:03,390
SPEAKER_1:  the whole skill of-

01:37:04,290 --> 01:37:07,998
SPEAKER_1:  discourse just like it is with dark humor is walking that line. I just feel like

01:37:08,578 --> 01:37:09,502
SPEAKER_1:  It's a...

01:37:10,242 --> 01:37:16,862
SPEAKER_1:  Overuse of the R word and I don't want to die in that ground because I don't think it's that that represent There's certain things like that.

01:37:17,954 --> 01:37:19,806
SPEAKER_1:  It feels like it ruins the music.

01:37:20,098 --> 01:37:20,766
SPEAKER_1:  I don't

01:37:21,122 --> 01:37:24,094
SPEAKER_1:  You know, it's the same like a dumb Republican or dumb Democrat. I don't.

01:37:24,898 --> 01:37:26,398
SPEAKER_1:  Yeah, that ruins it too a little bit.

01:37:26,690 --> 01:37:27,998
SPEAKER_1:  Depends on how you use it.

01:37:28,514 --> 01:37:30,142
SPEAKER_1:  You can be lazy with that.

01:37:30,562 --> 01:37:36,990
SPEAKER_1:  You know, like even overuse of the word, I think, bots is what's used for people who don't think or something. I don't actually know the definition.

01:37:37,410 --> 01:37:39,582
SPEAKER_1:  I'm offended on behalf of robots.

01:37:39,906 --> 01:37:40,766
SPEAKER_1:  Uh, but...

01:37:41,090 --> 01:37:43,715
SPEAKER_0:  That might be a compliment soon.

01:37:43,715 --> 01:37:46,014
SPEAKER_1:  Exactly. But I guess bot means you don't think.

01:37:46,274 --> 01:37:48,149
SPEAKER_0:  Yeah, you're like an NPC you just copy paste.

01:37:48,149 --> 01:37:54,974
SPEAKER_1:  Again, I'm a fan on behalf of NPCs. I count myself as one. There's a sense if you say bots too much.

01:37:55,970 --> 01:37:58,398
SPEAKER_1:  that you're just dismissing people.

01:37:59,234 --> 01:38:00,798
SPEAKER_1:  Everything I say is right.

01:38:01,762 --> 01:38:03,454
SPEAKER_1:  Anyone that disagrees with me is a bot.

01:38:04,226 --> 01:38:08,030
SPEAKER_1:  That's lazy too. Sometimes it's funny, sometimes it's effective.

01:38:08,514 --> 01:38:12,734
SPEAKER_1:  Basically saying a lot of people in the mainstream media or something that are bots. Okay, that's

01:38:13,282 --> 01:38:14,750
SPEAKER_1:  a little bit of that is affected

01:38:15,874 --> 01:38:17,982
SPEAKER_1:  Too much, it becomes ineffective.

01:38:18,306 --> 01:38:23,518
SPEAKER_1:  And I'm trying to speak to that. Yeah, and I'm just the reason we're highlighting clear examples.

01:38:24,130 --> 01:38:25,150
SPEAKER_1:  like the N-word.

01:38:26,210 --> 01:38:27,902
SPEAKER_1:  Joe Rogan had to contend with that.

01:38:28,322 --> 01:38:29,086
SPEAKER_1:  Hi, other, yeah.

01:38:29,826 --> 01:38:33,374
SPEAKER_1:  I think it's ineffective. It makes you less effective at discourse.

01:38:33,762 --> 01:38:36,766
SPEAKER_1:  Like like you've talked about many times language is a tricky one

01:38:37,666 --> 01:38:39,806
SPEAKER_0:  It's always hard because you talk about like constructing a melody.

01:38:40,066 --> 01:38:42,238
SPEAKER_0:  There's not one melody that sounds good to everyone.

01:38:42,850 --> 01:38:45,726
SPEAKER_0:  but there are probably certain notes that like, if you got rid of them.

01:38:46,338 --> 01:38:52,291
SPEAKER_0:  everybody's talking like it about as much and you don't really lose anything as a whole other part of an audience that might be more willing to listen and of

01:38:52,291 --> 01:38:56,926
SPEAKER_1:  And it's not about losing the magic of that melody. Like you don't want to be vanilla. Mm-hmm.

01:38:57,762 --> 01:39:01,534
SPEAKER_1:  I just feel like there's stuff that doesn't need to be there. Yeah, for sure. It's fat.

01:39:02,242 --> 01:39:03,230
SPEAKER_1:  But then again, you're...

01:39:03,458 --> 01:39:05,310
SPEAKER_1:  The other thing that people should understand.

01:39:06,210 --> 01:39:09,630
SPEAKER_1:  that might be listening to this, you're streaming many hours a day.

01:39:10,370 --> 01:39:12,245
SPEAKER_1:  for many years. I don't know what's up.

01:39:12,245 --> 01:39:13,342
SPEAKER_0:  11 or 12 I think, yeah.

01:39:13,570 --> 01:39:14,430
SPEAKER_0:  Started in 2010.

01:39:14,626 --> 01:39:17,726
SPEAKER_1:  And so one of the things that people can do is just clip out anything.

01:39:18,274 --> 01:39:19,742
SPEAKER_1:  You're going through the full...

01:39:20,130 --> 01:39:21,534
SPEAKER_1:  human experience of emotion.

01:39:21,922 --> 01:39:22,942
SPEAKER_1:  Anger.

01:39:23,170 --> 01:39:23,678
SPEAKER_1:  Fear.

01:39:24,098 --> 01:39:25,246
SPEAKER_1:  frustration all of it.

01:39:25,698 --> 01:39:26,910
SPEAKER_1:  So of course, it's going to be...

01:39:27,138 --> 01:39:29,182
SPEAKER_1:  moments when you're not the best version of yourself.

01:39:30,850 --> 01:39:32,766
SPEAKER_1:  Anything else to say about the language?

01:39:33,218 --> 01:39:38,654
SPEAKER_0:  complicated. I'm still always trying to figure it out, you know. There are opinions that I have that have changed throughout the years.

01:39:39,074 --> 01:39:44,702
SPEAKER_0:  possible that the R word has always been the next one on the chopping block that we're all kind of looking at but people always worried about that treadmill.

01:39:44,930 --> 01:39:55,326
SPEAKER_0:  But it's possible in a year or two I'll have a different view on it or all have changed away some of the words I use. It's always like a work in progress. There's always like different communities that feel different ways about different words.

01:39:56,162 --> 01:39:58,238
SPEAKER_1:  Yep, but do you acknowledge that there's people out there?

01:39:59,138 --> 01:40:00,478
SPEAKER_1:  they're never gonna talk to you.

01:40:02,114 --> 01:40:03,358
SPEAKER_1:  They're never gonna.

01:40:03,842 --> 01:40:08,222
SPEAKER_1:  think of you as a good man because you use the N word with the hard R.

01:40:08,738 --> 01:40:11,838
SPEAKER_0:  In the past? I mean, yeah, those people exist, but...

01:40:12,482 --> 01:40:14,782
SPEAKER_0:  I mean, there are some people that are beyond.

01:40:15,266 --> 01:40:15,966
SPEAKER_0:  My reach.

01:40:16,194 --> 01:40:17,022
SPEAKER_0:  which I'm okay with.

01:40:17,282 --> 01:40:20,446
SPEAKER_0:  Like there's going to be some people because of things that have been involved or even ideas that I have now.

01:40:20,674 --> 01:40:22,942
SPEAKER_0:  that might make them beyond my reach.

01:40:23,458 --> 01:40:28,862
SPEAKER_0:  um... some of the said earlier is right here i think the goal is to like identify what are the elements that you can cut out

01:40:29,122 --> 01:40:30,686
SPEAKER_0:  that aren't integral to your message.

01:40:30,914 --> 01:40:32,446
SPEAKER_0:  but it could be alienating too.

01:40:32,930 --> 01:40:40,830
SPEAKER_0:  more people and those are probably the things that you identify but I think that you can get lost in yourself or lost in the internet or lost in a you know

01:40:41,122 --> 01:40:45,310
SPEAKER_0:  the outside of yourself if you're trying to appeal to every single person. That's just never going to be the case.

01:40:45,858 --> 01:41:15,294
SPEAKER_0:  And for, I actually, I like that I've had the journey that I've had on the internet that you can find me saying and defending a lot of insane stuff 10 years ago, because I think it shows like a level of progress. And I think I do get a lot of respect and buy into certain communities where it's like, I'm not just some random dude telling you that like, oh, you shouldn't say, you know, the F word or the N word. Like I'm a guy that's been there, that's done it, that's defended it. And you can see my whole past, my whole history is laid bare for you to watch every of, you know, thousands of hours of it. But I can show that like there's growth and evolution and change that can happen in a person. So.

01:41:15,490 --> 01:41:17,758
SPEAKER_1:  Yeah, and you're honest about that growth.

01:41:18,338 --> 01:41:20,702
SPEAKER_1:  It's a tricky thing because people just call it.

01:41:21,218 --> 01:41:21,534
SPEAKER_1:  bring up.

01:41:22,114 --> 01:41:23,614
SPEAKER_1:  stuff from your past. For sure.

01:41:24,098 --> 01:41:27,902
SPEAKER_1:  I hope we figure out as a civilization a mechanism.

01:41:28,994 --> 01:41:30,238
SPEAKER_1:  clearly say this was...

01:41:30,498 --> 01:41:32,926
SPEAKER_1:  This is me two years ago. This is me five years ago.

01:41:33,282 --> 01:41:35,198
SPEAKER_1:  I'm a different person and like

01:41:36,226 --> 01:41:41,566
SPEAKER_1:  Because Twitter doesn't care about that. These social mechanisms that bring stuff up doesn't care about that.

01:41:42,210 --> 01:41:44,062
SPEAKER_1:  It's like one stupid thing you say.

01:41:44,674 --> 01:41:46,174
SPEAKER_1:  It becomes like a scarlet letter.

01:41:46,786 --> 01:41:49,022
SPEAKER_1:  And I don't know how to fight that. It's tricky to fight that.

01:41:49,282 --> 01:41:50,366
SPEAKER_1:  Have you ever seen Men in Black?

01:41:50,978 --> 01:41:51,358
SPEAKER_1:  Yes.

01:41:51,650 --> 01:42:17,502
SPEAKER_0:  When K and J are on the bench and he says, person is smart, but people are stupid, dumb, finicky animals or whatever, there's something that changes for human dynamics when there is a group of people that make it so hard to control. Like I think one-on-one, anybody can sit across on somebody and admit to some horrible stuff. I used to be, I abused my husband when I was 20 and now I'm 35 and I see what's wrong or I did this, I was addicted to whatever and I made these mistakes. So one-on-one, it's always easy.

01:42:17,730 --> 01:42:26,270
SPEAKER_0:  but in group environments that in-group, out-group, tribalistic thing of identifying one thing and then coming to destroy a person's life is like, it's such a huge-

01:42:26,594 --> 01:42:27,646
SPEAKER_0:  like impulse we have.

01:42:27,938 --> 01:42:28,478
SPEAKER_0:  And I think.

01:42:28,898 --> 01:42:31,710
SPEAKER_0:  Probably when we were like hunter-gatherers in the forest. Probably good.

01:42:31,970 --> 01:42:32,990
SPEAKER_0:  because you really want to.

01:42:33,250 --> 01:42:42,686
SPEAKER_0:  push weird people out or anything like that. But now on the internet, when we can hunt for any dissenting opinion and just with ruthless precision destroy somebody's life over it is a pretty scary dynamic.

01:42:43,426 --> 01:42:45,502
SPEAKER_1:  I think one of the mechanisms that could fix it...

01:42:45,986 --> 01:42:47,774
SPEAKER_1:  is make it super easy.

01:42:48,194 --> 01:42:52,478
SPEAKER_1:  for each individual person to analyze all the stupid shit they themselves have said in the past

01:42:52,866 --> 01:42:54,142
SPEAKER_1:  Like a full recording.

01:42:55,938 --> 01:42:57,758
SPEAKER_1:  because I think people are just honestly.

01:42:58,562 --> 01:43:00,958
SPEAKER_1:  paint a very rosy picture to their own brain of

01:43:01,346 --> 01:43:02,110
SPEAKER_1:  of who they-

01:43:02,466 --> 01:43:07,262
SPEAKER_1:  have been in the past. Yeah, of course. If we can have empathy for the fact that we've said stupid shit.

01:43:07,490 --> 01:43:08,318
SPEAKER_1:  or we're drunk.

01:43:08,898 --> 01:43:12,030
SPEAKER_1:  the ridiculous things you say, the offensive things you might have said.

01:43:12,386 --> 01:43:14,590
SPEAKER_1:  they found some things you might have done. I just feel like-

01:43:15,298 --> 01:43:16,318
SPEAKER_1:  that would give us.

01:43:16,962 --> 01:43:18,462
SPEAKER_1:  the ammunition.

01:43:19,106 --> 01:43:25,662
SPEAKER_1:  to have empathy for others that are like, okay, yeah, this guy five years ago said this, maybe that doesn't represent them.

01:43:26,466 --> 01:43:28,382
SPEAKER_1:  doesn't represent who they are anymore than

01:43:28,770 --> 01:43:30,750
SPEAKER_1:  Stuff I said five years ago represents.

01:43:31,106 --> 01:43:32,254
SPEAKER_1:  who I am today.

01:43:32,514 --> 01:43:34,174
SPEAKER_1:  I feel like technology can actually enable that.

01:43:34,818 --> 01:43:39,331
SPEAKER_0:  Maybe, although you're talking about more recording and more stuff which people are already wary of, but um...

01:43:39,331 --> 01:43:40,062
SPEAKER_1:  It's a...

01:43:40,482 --> 01:43:41,822
SPEAKER_1:  Double-edged sword.

01:43:42,178 --> 01:43:46,654
SPEAKER_1:  I think there is going to be more and more recording. We have to figure out how to do that in the way that respects.

01:43:46,914 --> 01:43:54,142
SPEAKER_1:  people privacy and gives them ownership of their data and so on. I've looked at the search history I've done on Google, which for most people is available.

01:43:54,562 --> 01:43:55,998
SPEAKER_1:  like your Google search history.

01:43:56,354 --> 01:43:58,654
SPEAKER_1:  and it's fascinating to watch the evolution of a human being.

01:43:59,714 --> 01:44:01,086
SPEAKER_1:  It doesn't seem like the same person.

01:44:01,474 --> 01:44:02,910
SPEAKER_1:  It's like a different person, for sure.

01:44:03,426 --> 01:44:07,038
SPEAKER_0:  It's weird. It's also hard too with the internet today. I'm going to be a just again.

01:44:07,330 --> 01:44:10,590
SPEAKER_0:  but now all of the people are thrown together, you know? where it's like

01:44:10,914 --> 01:44:13,086
SPEAKER_0:  Like I don't want a 27 year old judging.

01:44:13,378 --> 01:44:20,446
SPEAKER_0:  There you go again. Like a 15 or 16 year old. Like obviously he's in high school. There was that story that came out of the, there was a kid that saved the recording of.

01:44:20,738 --> 01:44:34,238
SPEAKER_0:  I think it was like some white girl. I think that she like got her driver's license and she was like, I can drive now, N words with the A or whatever, it was dumb, she shouldn't have said it. But I think she was like 15 or 16 when she TikTok this or whatever. And he held on to that recording until she applied and got accepted to college.

01:44:34,466 --> 01:44:37,438
SPEAKER_0:  three years later and then he released it to get her kicked out of college.

01:44:37,826 --> 01:44:38,174
SPEAKER_0:  Damn.

01:44:39,202 --> 01:44:46,110
SPEAKER_0:  If everything that I had ever said as like a 15, 16 year old was like immortalized on the internet, my life wouldn't have even begun.

01:44:46,530 --> 01:44:50,398
SPEAKER_0:  And those are insanely high standards to hold people to.

01:44:50,690 --> 01:45:00,542
SPEAKER_0:  Not that like obviously you shouldn't be saying those, you shouldn't be saying certain words or whatever, but you have to be able to make mistakes in adolescence. Like everybody does, we all did. Everybody did it growing up, you know.

01:45:01,730 --> 01:45:05,342
SPEAKER_1:  Why do you think there is so much misogyny in the streaming community?

01:45:06,146 --> 01:45:09,214
SPEAKER_1:  and how can you fight it? cause you've shown

01:45:10,018 --> 01:45:15,358
SPEAKER_1:  a lot of interest in fighting it, trying to decrease or eliminate misogyny from your community.

01:45:16,002 --> 01:45:17,278
SPEAKER_0:  I think it's really difficult.

01:45:17,666 --> 01:45:20,158
SPEAKER_0:  I think that eliminating racism is easier than eliminating...

01:45:20,578 --> 01:45:21,246
SPEAKER_0:  Misogyny.

01:45:21,538 --> 01:45:23,582
SPEAKER_0:  Because I don't on anywhere.

01:45:24,194 --> 01:45:32,894
SPEAKER_0:  Because I think fundamentally, I don't think there's that much difference between like white people and black people and brown people and Asian people or whatever. You know, we have different cultures and stuff, but at the end of the day, we're all people.

01:45:33,442 --> 01:45:33,950
SPEAKER_0:  But I think they're.

01:45:34,210 --> 01:45:36,062
SPEAKER_0:  Are differences between men and women?

01:45:36,418 --> 01:45:40,510
SPEAKER_0:  like throughout all of history and time, and then even today in every culture.

01:45:40,802 --> 01:45:52,446
SPEAKER_0:  And when real differences do exist, it's harder to account for them in a way that can we have conversations with each other without it becoming very gendered in a negative way, right? Negative way of gendering something, maybe like a misogynistic way of doing it.

01:45:52,962 --> 01:45:53,598
SPEAKER_1:  Of course.

01:45:54,466 --> 01:45:55,998
SPEAKER_1:  It's unclear to me that.

01:45:56,258 --> 01:45:58,078
SPEAKER_1:  It's so difficult to, um...

01:45:59,330 --> 01:46:03,902
SPEAKER_1:  to avoid the negative gendering versus the positive because there's a lot of positive to the...

01:46:04,130 --> 01:46:06,430
SPEAKER_1:  the tension, the dance between the different genders and so on.

01:46:06,658 --> 01:46:09,118
SPEAKER_1:  Maybe in this particular moment in history, it's not.

01:46:09,922 --> 01:46:13,822
SPEAKER_1:  but it's not trivial to me that racism is easier to eliminate. It's an interesting.

01:46:14,082 --> 01:46:17,054
SPEAKER_1:  hypothesis just because there's more biological difference.

01:46:17,506 --> 01:46:18,366
SPEAKER_1:  two-man women.

01:46:18,690 --> 01:46:19,815
SPEAKER_1:  That means it's harder to eliminate.

01:46:19,815 --> 01:46:20,222
SPEAKER_0:

01:46:20,834 --> 01:46:28,542
SPEAKER_0:  I don't know if this is true, I hear this a lot, I feel like I read this somewhere, but I need to get a better source for it repeated everywhere, but I've heard that like in the US military, for instance, they've gotten exceedingly.

01:46:28,898 --> 01:46:37,726
SPEAKER_0:  well, they do an exceedingly good job at getting different people of different races to integrate. And it's like not a huge problem once you're through basic training, all the training, everything.

01:46:38,242 --> 01:46:56,621
SPEAKER_0:  but for different sexes, it still represents a significant problem that the military hasn't figured out. And I actually looked at like, well, what's the military doing? Because if something was solvable, like can we sleep for four hours a night and be healthy? If we could, I bet the military would know. So I kind of look sometimes to them to see their integration, but it might be that there are other issues there that make it- Yeah, it feels like the military is a very particular kind of- For sure. Yeah, it could be.

01:46:56,621 --> 01:46:59,902
SPEAKER_1:  the actual task at hand might.

01:47:00,386 --> 01:47:01,118
SPEAKER_1:  bias.

01:47:01,698 --> 01:47:02,823
SPEAKER_1:  the difficulty of the process.

01:47:02,823 --> 01:47:03,966
SPEAKER_0:  Potentially, yeah.

01:47:04,450 --> 01:47:06,206
SPEAKER_0:  There's been a lot of interesting.

01:47:06,530 --> 01:47:07,582
SPEAKER_0:  talk about like...

01:47:08,098 --> 01:47:10,558
SPEAKER_0:  women integrating into male groups.

01:47:10,786 --> 01:47:14,878
SPEAKER_0:  And how do you do this in a way where everybody is happy with the outcome?

01:47:15,266 --> 01:47:15,870
SPEAKER_0:  and

01:47:16,354 --> 01:47:17,758
SPEAKER_0:  There's not like issues.

01:47:18,082 --> 01:47:21,822
SPEAKER_0:  I think Jordan Peterson spoke about this a little bit. And then workplace culture speaks about this a bit.

01:47:22,306 --> 01:47:23,710
SPEAKER_0:  Would you happen to remember?

01:47:24,290 --> 01:47:27,710
SPEAKER_0:  I want to say it was like five or 10 years ago. There was a big tech conference.

01:47:27,938 --> 01:47:33,374
SPEAKER_0:  and there were two guys behind a woman and they made a joke about like a USB dongle, or like dongle was a dick.

01:47:33,634 --> 01:47:41,310
SPEAKER_0:  And this woman turned around, she tweeted pictures of them, spoke about misogyny, and then that blew up into a huge ordeal that like, yeah.

01:47:41,602 --> 01:47:43,998
SPEAKER_0:  There was this interesting phenomenon that...

01:47:44,898 --> 01:47:45,470
SPEAKER_0:  N A

01:47:46,466 --> 01:47:49,534
SPEAKER_0:  less misogynistic and more inclusive workplace environment.

01:47:50,114 --> 01:47:51,742
SPEAKER_0:  some women might end up feeling...

01:47:52,226 --> 01:47:52,990
SPEAKER_0:  Worse.

01:47:53,378 --> 01:48:16,254
SPEAKER_0:  because in a more misogynistic environment, you're thinking like, okay, that's a woman, she doesn't get our humor, I'm gonna treat her in a very indifferent, very dispassionate, cold way and whatever, and then I'm gonna have my boys over here. And then you've got these environments where they're a little bit more warmer, and it's like, oh cool, we're gonna bring this woman into our environment, and we're gonna make all the same types of crass jokes we did before, and it's actually worse now. Another woman feels even more otherized, it's like, oh my God, why do you talk like this?

01:48:16,610 --> 01:48:23,262
SPEAKER_0:  I think that internet communities, especially online ones that do like political debate and video games, are very much like big boys clubs.

01:48:23,682 --> 01:48:35,166
SPEAKER_0:  So it's not enough to just say, you can't be misogynistic to get rid of misogyny. There's always gonna be an othering effect on women. There's a lot of like behaviors that are unintuitive that you have to account for and you've got to try to like push that back.

01:48:35,522 --> 01:48:38,206
SPEAKER_0:  And that's just a very, very, very challenging thing to do.

01:48:38,562 --> 01:48:49,246
SPEAKER_0:  I like to deal with concrete examples more. So here's a concrete example. And this is like a recent initiative in my community because I'm trying to like be, because misogyny hasn't been fixed anywhere on the internet and I'm curious about other ways that I can push my community to do this.

01:48:49,474 --> 01:48:49,886
SPEAKER_0:  Um.

01:48:50,338 --> 01:49:13,150
SPEAKER_0:  I don't think you should almost ever make a comment on a woman's appearance ever, if they're appearing in like some political or professional manner. Even if it's a positive comment, I think it's equally bad to a negative comment. It's just never good to do. And that's kind of an unintuitive thing. Cause it's like, well, a woman appears, wow, she's really cute. It seems like a nice comment. You're being nice, you know, she looks cute, but it's like, it's not at all the point of why she's there. And just by saying that, you're kind of like otherizing her as like a person to like.

01:49:13,634 --> 01:49:16,542
SPEAKER_0:  think she looks good rather than listening to anything she has to say.

01:49:17,122 --> 01:49:20,222
SPEAKER_1:  Well, there's a lot of stuff that you're saying and.

01:49:22,306 --> 01:49:24,478
SPEAKER_1:  that is a part of massaging, it's almost like.

01:49:24,962 --> 01:49:25,758
SPEAKER_1:  obvious.

01:49:26,082 --> 01:49:27,518
SPEAKER_1:  Like any woman will tell you that.

01:49:27,650 --> 01:49:30,275
SPEAKER_0:  A woman will, yeah, but they're not in these spaces and a lot of the guys don't know.

01:49:30,275 --> 01:49:32,542
SPEAKER_1:  I think what that requires.

01:49:33,250 --> 01:49:34,622
SPEAKER_1:  is just empathy.

01:49:35,522 --> 01:49:39,710
SPEAKER_1:  You don't need, you don't need, you need to consider the female experience.

01:49:40,354 --> 01:49:47,134
SPEAKER_1:  That's it. Like you have to either read about or talk with women. You learn, like the low hanging fruit is very easy to learn.

01:49:47,426 --> 01:49:49,502
SPEAKER_1:  It feels like just a level of social skill.

01:49:50,978 --> 01:49:53,598
SPEAKER_1:  often times in internet communities is quite low.

01:49:54,242 --> 01:49:55,934
SPEAKER_0:  I disagree, I don't like to say.

01:49:56,258 --> 01:50:01,822
SPEAKER_0:  And here's the problem with empathy is it's very hard to have empathy for experiences that are so outside of your own.

01:50:02,178 --> 01:50:04,958
SPEAKER_0:  Well, maybe some people. There might be some people that can do it. I can't.

01:50:05,250 --> 01:50:07,125
SPEAKER_0:  There's a lot of stuff that I had to learn.

01:50:07,125 --> 01:50:08,574
SPEAKER_1:  women are half the population.

01:50:08,834 --> 01:50:09,374
SPEAKER_0:  but they're women.

01:50:10,946 --> 01:50:11,582
SPEAKER_0:  They're different.

01:50:11,874 --> 01:50:12,190
SPEAKER_1:  t

01:50:13,730 --> 01:50:14,855
SPEAKER_1:  different. awesome fighter.

01:50:14,855 --> 01:50:20,062
SPEAKER_0:  We'll talk about it. We'll write it down. They're not totally different. They're totally different. So here's an example, okay? So here's an example.

01:50:21,026 --> 01:50:24,798
SPEAKER_0:  Especially for me, my archetype makes up a lot of the internet.

01:50:25,026 --> 01:50:25,406
SPEAKER_0:  Wait.

01:50:25,634 --> 01:50:26,014
SPEAKER_0:  man.

01:50:26,466 --> 01:50:26,878
SPEAKER_0:  Um...

01:50:27,106 --> 01:50:29,790
SPEAKER_0:  There's never been a point. The name of a beautiful woman.

01:50:29,922 --> 01:50:33,297
SPEAKER_1:  who might be a dancer. What's the backstory? From New Orleans or from...

01:50:33,297 --> 01:50:42,043
SPEAKER_0:  I haven't thought that through yet. It's ambiguous, okay. Like an open world. An open world, I want you to project wherever you want Destiny the Dancer to be from. That's in your mind, okay.

01:50:42,043 --> 01:50:45,118
SPEAKER_1:  Alright, I'll save that for later tonight. Yeah, okay.

01:50:45,986 --> 01:50:47,134
SPEAKER_0:  as a white guy.

01:50:47,522 --> 01:50:53,918
SPEAKER_0:  I don't know if there's ever been a spot that I've been in where I've been made to feel like I don't belong there just by virtue of who I am.

01:50:54,146 --> 01:50:59,358
SPEAKER_0:  I actually don't, it's impossible for me to empathize that because I don't even have that experience.

01:50:59,842 --> 01:51:01,694
SPEAKER_0:  If you go back eight, nine years.

01:51:01,954 --> 01:51:05,310
SPEAKER_0:  One of the big issues that came up was harassment in gaming against women.

01:51:05,666 --> 01:51:09,086
SPEAKER_0:  And I was one of the big debaters against that saying that like

01:51:09,346 --> 01:51:25,023
SPEAKER_0:  Sure, women might get harassment, but everybody gets harassment. If you're a woman and you're in gaming and you get harassed, congratulations, you're being treated like a man. What you're actually asking for is for us to actually treat you differently. You don't wanna be insulted. You don't wanna be treated like a man. And that's actually misogyny, is women making that argument.

01:51:25,023 --> 01:51:25,662
SPEAKER_1:  stand by that.

01:51:26,274 --> 01:51:27,070
SPEAKER_0:  Is that a problem if I do?

01:51:28,002 --> 01:51:28,574
SPEAKER_0:  No, I'm just kidding.

01:51:29,026 --> 01:51:33,822
SPEAKER_0:  Okay, hold on. It's a little while after. I disagree with it. Sure, okay. That's good, you should.

01:51:34,338 --> 01:51:38,046
SPEAKER_0:  A little while later, I had a friend, Jessica, super cool girl.

01:51:38,306 --> 01:51:42,590
SPEAKER_0:  We go to play games, she was between jobs, and she's like, I've got like two months, and we're going to grind CSGO.

01:51:42,850 --> 01:51:49,342
SPEAKER_0:  And I'm like, okay, this is awesome. Let's do it. CSGO Counter-Strike, Global Offensive, shooter game, FPS, microphones.

01:51:49,794 --> 01:51:52,094
SPEAKER_0:  First day we start playing, okay? Hop into our first game.

01:51:52,322 --> 01:52:02,622
SPEAKER_0:  Obviously she talks everybody's making that is that a 12 year old boy? Why aren't you making sandwiches blah blah blah? Yeah, okay, whatever play our first game play our second game same jokes third game fourth game by like the fourth or fifth game

01:52:03,266 --> 01:52:13,374
SPEAKER_0:  I was actually starting to feel triggered. Like every time the game started, I was like, can you just like talk so we can get over like the stupid fucking jokes? It's so fucking stupid. And you hear the same fucking joke every single time.

01:52:13,698 --> 01:52:14,302
SPEAKER_0:  and it took.

01:52:14,530 --> 01:52:17,214
SPEAKER_0:  one day of that experience for me to realize.

01:52:17,506 --> 01:52:32,158
SPEAKER_0:  It's not about being insulted. It's like this othering feeling that you don't belong. And I've never felt that because I'm a white guy. Like it's not to be like virtue singular. So, but like there's just, there's no places where it's like, you're white, you don't belong here. You're a guy, you don't belong here. Like I've never felt that, not inclusion. And playing with her.

01:52:32,674 --> 01:52:34,046
SPEAKER_0:  There's a different feeling.

01:52:34,434 --> 01:52:39,294
SPEAKER_0:  when it's the same types of jokes coming from a group of people to make you feel like you don't belong there.

01:52:39,714 --> 01:52:40,094
SPEAKER_0:  Where I was like.

01:52:40,354 --> 01:52:42,270
SPEAKER_0:  Damn, this actually feels really bad.

01:52:42,530 --> 01:52:57,278
SPEAKER_0:  And it feels bad in a different way where it's like, if you call me like an F slur or any other type of swear word or insult, like, yeah, you can call me that. But at the end of the day, like, we're all kind of the same. We're all white dudes and we call each other names, but like, this is a woman and this is not her place and she doesn't belong here.

01:52:58,242 --> 01:53:02,718
SPEAKER_0:  kind of the analogy that I would make, because after getting these experiences, I would learn this afterwards.

01:53:03,298 --> 01:53:05,598
SPEAKER_0:  If I tell you that there's another guy in a room.

01:53:05,826 --> 01:53:10,366
SPEAKER_0:  And you need to think of the worst insults ever for that person without ever knowing anything about them or meeting them.

01:53:10,818 --> 01:53:14,910
SPEAKER_0:  If I tell you that it's like a white straight guy and you have to write insults, you're fucked.

01:53:15,170 --> 01:53:16,478
SPEAKER_0:  Maybe you can do like, School Shooter?

01:53:16,802 --> 01:53:19,230
SPEAKER_0:  There's not really much you can say at the end of the day.

01:53:19,458 --> 01:53:26,787
SPEAKER_0:  But if I tell you it's a woman, whoo, we could, there are so many different jokes you can write. If it's a black person, so many different racist things we can say. For sure.

01:53:26,787 --> 01:53:28,734
SPEAKER_1:  I can come up with a lot of stuff for a white guy.

01:53:28,866 --> 01:53:31,491
SPEAKER_0:  In terms of stuff that is just intrinsic to him being a white guy

01:53:31,491 --> 01:53:32,798
SPEAKER_1:  Yeah, like there's...

01:53:33,442 --> 01:53:35,614
SPEAKER_1:  Really? What are you talking about?

01:53:36,162 --> 01:53:39,262
SPEAKER_1:  There's a lot, the internet has sharpened that sword.

01:53:39,522 --> 01:53:42,897
SPEAKER_0:  In terms of like jokes that are targeted at his sex or-

01:53:42,897 --> 01:53:43,582
SPEAKER_1:  cells.

01:53:44,066 --> 01:53:44,958
SPEAKER_1:  virgin.

01:53:45,794 --> 01:54:37,575
SPEAKER_0:  Weak. Some of the incel version, maybe, yeah, that's getting there, sure. That's for sure. That's recent though, sorry, I'm older on the internet. We didn't have those words way back then. That wasn't the best thing. When I was making these analogies, that incel and virgin wasn't- Back in my day, we didn't have general relativity. There were no incels back then. None of us had sex, we just accepted it. We were all computer gamers. Nobody had sex and played video games back then, okay? People don't remember that. There wasn't the Big Bang Theory. You were just a loser that was stuck in a room. You guys didn't even know sex existed. Exactly. So you can use it as an incel. We had to download sexual pictures, and it was like two minutes and you didn't even know if you were gonna get the right thing by the time it finished loading. But what I'm saying is like, okay, I think you agree that if somebody gives you a race, like a black person who's a woman, we can write very cutting, scathing insults for that person that are very authorizing. Or words that would really hurt if they're spoken to. Yeah, that are very cutting to the person. But for a white guy, it's kind of hard because that's the default. There's not as much authorizing of those people. Yeah, that's kind of the point. For a white guy, just like black people, is it kind of a normal stuff? Yeah, I don't think it is. And I think it's something that often reminds me of myself too. When I was four, I think it was the aim of kind of the whole series. So I already have friends that I, and I think I respect my friends because I have my friends around. So, many people then roots to that compared to my brother, and I think he looks at it like that. But also, yeah, so that's another challenge, the large political complexity of people and also in real terms what is your background.

01:54:37,575 --> 01:54:38,430
SPEAKER_1:  insults you have.

01:54:38,882 --> 01:54:41,566
SPEAKER_1:  from Y guy to Y guy, the insults are much harsher.

01:54:41,826 --> 01:54:44,894
SPEAKER_1:  So when you start to apply the same kind of harshness to other groups.

01:54:45,314 --> 01:54:58,014
SPEAKER_0:  you can make them feel like they really don't belong. And that other rising effect is something that's very hard for me. I can't really empathize with it, because I've never felt it. So I have to intellectualize it and then sympathize with it. It's like a whole process I have to go through. And then I try to walk other people through that.

01:54:58,562 --> 01:55:02,782
SPEAKER_0:  If you're a white guy on the internet, which is a lot of the internet, you really don't know what that feels like. You've never felt like that before.

01:55:02,946 --> 01:55:05,502
SPEAKER_1:  Well, so you're now in a leadership position.

01:55:05,986 --> 01:55:10,846
SPEAKER_1:  Grandpa Destiny. So that's a lot of people look up to you for that

01:55:11,522 --> 01:55:12,510
SPEAKER_1:  for that sort of.

01:55:13,058 --> 01:55:14,526
SPEAKER_1:  Pathway to empathy. Apartments center.

01:55:15,618 --> 01:55:21,438
SPEAKER_1:  how not to otherize. I mean, you have felt otherizing. You mentioned high school people like not being.

01:55:22,466 --> 01:55:37,694
SPEAKER_0:  Yeah, but those are always for things that like, it's different to insult somebody for a non-immutable characteristic. Like, okay, you think poorly about me because I'm like not enough money, or I don't have money, but I could get more money, and I could change that. But it's different for somebody to really attack you for like your gender or attack you for like your race.

01:55:37,954 --> 01:55:40,734
SPEAKER_1:  A lot of the attacks that hit the hardest is not about gender.

01:55:41,474 --> 01:55:41,790
SPEAKER_1:  It's.

01:55:42,562 --> 01:55:44,830
SPEAKER_1:  It's, I do think that they're like.

01:55:45,090 --> 01:55:47,262
SPEAKER_1:  the way women are attacked on the internet.

01:55:47,970 --> 01:55:49,374
SPEAKER_1:  It's the same kind of attacks you would

01:55:50,082 --> 01:55:51,998
SPEAKER_1:  towards other guys, but you go harsher.

01:55:52,642 --> 01:55:54,046
SPEAKER_0:  I feel like they're fundamentally different.

01:55:54,562 --> 01:55:56,126
SPEAKER_0:  I feel like when we're attacking guys.

01:55:56,450 --> 01:55:58,046
SPEAKER_0:  I'm not usually attacking you.

01:55:58,530 --> 01:55:59,198
SPEAKER_0:  on like.

01:55:59,874 --> 01:56:01,118
SPEAKER_0:  the virtue of you.

01:56:01,602 --> 01:56:02,558
SPEAKER_0:  being a guy.

01:56:02,786 --> 01:56:12,161
SPEAKER_0:  But like if it's a woman and she's typing something like, oh, did your boyfriend type that for you? Or like, what are you even doing here? Like, don't you, shouldn't you be trying to find a husband or like, oh, you're like a stupid kind of, like go start an OnlyFans?

01:56:12,161 --> 01:56:15,006
SPEAKER_1:  But the stupidity, the intelligence aspect is what's the tech.

01:56:15,106 --> 01:56:21,758
SPEAKER_0:  Yeah, but it's so much different. Like you can call a guy stupid, but that's because he's a guy that's being stupid. But when you call a woman stupid, she's stupid because she's a woman.

01:56:21,954 --> 01:56:26,398
SPEAKER_1:  Yeah, but I honestly think that women are called stupid more than men.

01:56:26,658 --> 01:56:27,454
SPEAKER_1:  internet.

01:56:27,810 --> 01:56:30,494
SPEAKER_1:  There's nothing to do like the attack.

01:56:30,882 --> 01:56:32,030
SPEAKER_1:  is not gendered.

01:56:32,290 --> 01:56:32,734
SPEAKER_1:  It's.

01:56:33,250 --> 01:56:36,606
SPEAKER_1:  the gender inspires an increased level of attack.

01:56:37,314 --> 01:56:38,558
SPEAKER_0:  I feel like it is gendered.

01:56:38,850 --> 01:56:39,774
SPEAKER_0:  I wish we had data.

01:56:40,738 --> 01:56:42,366
SPEAKER_0:  Have you ever heard of the XKCD comics?

01:56:42,658 --> 01:56:47,422
SPEAKER_0:  It's a really good comic where, and this is something that I've dealt with a lot in my community, okay?

01:56:47,714 --> 01:56:48,670
SPEAKER_0:  There's a guy at a board.

01:56:49,538 --> 01:56:50,622
SPEAKER_0:  fucks up a math equation.

01:56:51,042 --> 01:56:52,574
SPEAKER_0:  And it's like, wow, you suck at math.

01:56:52,962 --> 01:56:54,814
SPEAKER_0:  And then the next panelist is a girl that does it.

01:56:55,106 --> 01:56:57,406
SPEAKER_0:  And she fucks it up and it's like, wow, women suck at math.

01:56:57,922 --> 01:57:01,566
SPEAKER_0:  And there's like that feeling that happens where when I bring on.

01:57:02,082 --> 01:57:06,590
SPEAKER_0:  I want us names, but they're like YouTube people that I've brought on that have crazy opinions. And when they're men,

01:57:06,850 --> 01:57:12,894
SPEAKER_0:  That person is crazy. Oh my God, he said the crazy stuff. He's so dumb, he's so crazy, so stupid. But when it's a woman,

01:57:13,186 --> 01:57:20,382
SPEAKER_0:  It's like, oh my God, why do you always bring dumb women here? Why do so many women on the internet have crazy opinions? There's a different like minority character that has to like stand it.

01:57:20,706 --> 01:57:22,942
SPEAKER_0:  and like represent like their whole group.

01:57:23,362 --> 01:57:25,237
SPEAKER_0:  where like white men don't typically have to.

01:57:25,237 --> 01:57:29,438
SPEAKER_1:  Speaking of groups versus individuals, yes. But then what I feel happens.

01:57:29,826 --> 01:57:31,102
SPEAKER_1:  is then another.

01:57:31,490 --> 01:57:36,254
SPEAKER_1:  person from that group comes another woman comes and people before she says anything.

01:57:37,154 --> 01:57:39,166
SPEAKER_1:  will already feel like.

01:57:39,682 --> 01:57:40,807
SPEAKER_1:  They're ready without a time.

01:57:40,807 --> 01:57:41,534
SPEAKER_0:  For sure.

01:57:41,794 --> 01:57:43,294
SPEAKER_0:  but they're ready for the attack because she's a woman.

01:57:43,778 --> 01:57:47,358
SPEAKER_0:  They're gonna call her, she's stupid because she's a woman, not because she says something, but just because she's a woman.

01:57:48,450 --> 01:57:49,246
SPEAKER_1:  So like, uh...

01:57:49,506 --> 01:57:50,270
SPEAKER_1:  The group.

01:57:51,458 --> 01:58:02,302
SPEAKER_1:  in their brain accumulates all the negative characteristics of the individuals they've met. Not the positive, the negative. And it becomes like this ball of stickiness. And then that becomes the bias for their...

01:58:02,562 --> 01:58:05,886
SPEAKER_1:  judgment of a new person that comes with white men.

01:58:06,146 --> 01:58:09,630
SPEAKER_1:  There's more of a blank slate in terms of bias of how they analyze the person.

01:58:10,018 --> 01:58:14,014
SPEAKER_1:  with any of the minority group there basically make a judgment.

01:58:15,074 --> 01:58:19,870
SPEAKER_1:  based on the negative characteristics of the individuals that met in the past. I just, that leads to a system.

01:58:20,194 --> 01:58:21,726
SPEAKER_1:  Well, you're just harsher.

01:58:22,178 --> 01:58:23,294
SPEAKER_1:  or minority groups.

01:58:23,522 --> 01:58:24,286
SPEAKER_1:  and towards women.

01:58:24,802 --> 01:58:25,470
SPEAKER_0:  How do you solve that?

01:58:25,698 --> 01:58:30,302
SPEAKER_0:  The most important thing for any problem ever is step one is to be aware of it. If you're not aware of it.

01:58:30,690 --> 01:58:31,262
SPEAKER_0:  then you're

01:58:31,618 --> 01:58:32,958
SPEAKER_0:  hopelessly lost at sea.

01:58:33,282 --> 01:59:06,558
SPEAKER_0:  But yeah, the first thing I like to say is just like, be aware of it. Like I've had, there's a girl that I've had on recently and she says a lot of, in my opinion, kind of crazy things, but people will use her as like, this is why women shouldn't be here. This is like, she's crazy and she's a woman and blah, blah, blah. But I can bring in a guy who says similarly dumb things and he's evaluated on his own merits, cause it's a guy, you know? There's never ever, ever been a case where I brought a stupid guy on stream and everybody's like, this guy makes me hate men. This guy makes me hate white people. That has never happened. But then there's like other women that come on and it's like, now I know why incels exist. Or I totally understand where Red Pill ideology comes from, you know? The kinds of statements are kind of true.

01:59:06,818 --> 01:59:09,310
SPEAKER_0:  When you're making these observations over and over and over and over again, it-

01:59:09,826 --> 01:59:18,206
SPEAKER_0:  It damages your ability to individually perceive somebody. And then two people that make the same statements, one can be perceived more harshly just because of that like group bias you've got built up.

01:59:18,402 --> 01:59:23,230
SPEAKER_1:  I think there's something about streaming that just brings that out of people. Like, because you have to talk for like seven hours.

01:59:23,554 --> 01:59:34,494
SPEAKER_1:  So you're like, all right, well, whatever psychological issues and complexities I have, I'm going to explore them for some magnified magnified work. And then it's the Gerard easy talked about the mimetic

01:59:35,042 --> 01:59:37,022
SPEAKER_1:  uh... theories of gerardian

01:59:37,378 --> 01:59:38,238
SPEAKER_1:  Like whatever.

01:59:39,010 --> 01:59:44,478
SPEAKER_1:  the things that are very similar and you're going to magnify the conflicts that you have and you're going to explore the

01:59:44,994 --> 01:59:47,070
SPEAKER_1:  all the different perspectives on those different conflicts.

01:59:47,458 --> 01:59:47,774
SPEAKER_1:  and

01:59:48,130 --> 01:59:50,526
SPEAKER_1:  I mean, I don't know if it's just anecdotal, but.

01:59:51,170 --> 01:59:53,950
SPEAKER_1:  It's nice to have women on stream. I think the dynamic.

01:59:54,530 --> 02:00:03,326
SPEAKER_1:  Do you guys have as wonderful as this really interesting. So it's just a female voice in general. I love having women on the podcast.

02:00:03,778 --> 02:00:07,966
SPEAKER_1:  the female voice I feel like is under heard on the internet. Thanks for all the support on Patreon!

02:00:08,194 --> 02:00:12,062
SPEAKER_1:  And I would love the internet to be a place where women feel safe to speak.

02:00:12,994 --> 02:00:13,374
SPEAKER_1:  Alright.

02:00:13,730 --> 02:00:14,718
SPEAKER_1:  Given that you're...

02:00:15,106 --> 02:00:17,566
SPEAKER_1:  Like we talked about a progressive with.

02:00:17,986 --> 02:00:19,550
SPEAKER_1:  non-standard progressive use.

02:00:19,842 --> 02:00:21,886
SPEAKER_1:  See, you're very pro-free speech.

02:00:22,114 --> 02:00:22,430
SPEAKER_1:  Mm-hmm.

02:00:22,658 --> 02:00:23,742
SPEAKER_1:  Procapitalism.

02:00:24,642 --> 02:00:26,910
SPEAKER_1:  So given that, it's very interesting that you're also...

02:00:27,330 --> 02:00:30,078
SPEAKER_1:  pro-establishment and pro-institutions.

02:00:30,306 --> 02:00:30,654
SPEAKER_1:  Mhm.

02:00:30,978 --> 02:00:35,230
SPEAKER_1:  So right now if you look at the world, there's a significant distrust of institutions.

02:00:35,714 --> 02:00:39,102
SPEAKER_1:  at least in sort of public intellectual discourse.

02:00:39,458 --> 02:00:45,150
SPEAKER_1:  What is the nature of your support for government and institutions? Can you make the case for and against them?

02:00:46,594 --> 02:00:47,646
SPEAKER_0:  Broadly speaking.

02:00:48,514 --> 02:00:49,598
SPEAKER_0:  There is a...

02:00:49,986 --> 02:00:51,262
SPEAKER_0:  synergistic effect.

02:00:51,618 --> 02:00:53,150
SPEAKER_0:  when two humans come together.

02:00:53,474 --> 02:00:54,270
SPEAKER_0:  If I can speak.

02:00:54,562 --> 02:00:55,422
SPEAKER_0:  very

02:00:55,746 --> 02:01:01,214
SPEAKER_0:  broadly in terms of, we'll say, utility, okay? my happiness with one person might be ten.

02:01:01,698 --> 02:01:03,326
SPEAKER_0:  The happiness of the other person might be 10.

02:01:03,618 --> 02:01:10,590
SPEAKER_0:  When they come together, it's like 50 between the two of them. There's like this synergistic effect when humans work together that the sum is

02:01:10,978 --> 02:01:15,103
SPEAKER_0:  greater than all the individual parts or whatever. There's like an emergent thing that happens there. There's a-

02:01:15,103 --> 02:01:16,603
SPEAKER_1:  Passes a possibility

02:01:16,603 --> 02:01:21,566
SPEAKER_0:  of that. Yeah, a possibility. Sure. Things could go really wrong. There could be a cannibalistic tribe that all hates each other. Sure.

02:01:22,370 --> 02:01:23,495
SPEAKER_0:  For the purpose of this, there's a-

02:01:23,495 --> 02:01:24,245
SPEAKER_1:  their failure.

02:01:24,245 --> 02:01:28,222
SPEAKER_0:  modes but yes. Okay sure yeah. Well I think broadly speaking...

02:01:28,514 --> 02:01:49,534
SPEAKER_0:  Are you gonna be the well actually guy? Okay, if you wanna well, okay. Well, actually, sometimes cannibalism is actually good for both. True, yeah, sometimes things do go wrong. But I think broadly speaking, the fact that you're sitting here in clothing that you didn't make, and I'm sitting here on an airplane that I don't know how to fly, or Bill, like right, there's a lot of cool stuff that happens when people come together and they make civilizations.

02:01:49,794 --> 02:01:52,222
SPEAKER_0:  and part of that civilization building.

02:01:52,610 --> 02:02:24,926
SPEAKER_0:  is the fact that we can specialize and it's the fact that we can offload a bunch of trust onto third parties that we delegate the power to make important decisions about our lives, right? I don't know anything about how to like build like a combustion engine, but I know that when I push the button on my car, it's gonna drive around and the fumes aren't gonna kill me and I can park it in garages and the building is not gonna collapse. And the only reason all of this works is because I've offloaded a lot of trust onto these third party things. And I would say that the pillars of these third party things that society has built on are roughly speaking institutions.

02:02:25,378 --> 02:02:27,102
SPEAKER_0:  So that might be the institution of.

02:02:27,362 --> 02:02:48,734
SPEAKER_0:  peer review for scientific articles. It might be the institution of voting for government, right? Or the ability for us to vote in that whole process. It might be, yeah, the FDA, like all of these institutions are things that they need to exist because we don't have the time or the capability to individually sort through all of these things individually. We have to rely on some third party to do it.

02:02:49,634 --> 02:02:50,046
SPEAKER_0:  Okay.

02:02:50,146 --> 02:02:51,422
SPEAKER_1:  So you believe.

02:02:51,906 --> 02:02:53,694
SPEAKER_1:  At scale, the-

02:02:54,050 --> 02:02:54,942
SPEAKER_1:  We're together.

02:02:55,330 --> 02:02:58,705
SPEAKER_1:  We're greater than the sum of our parts. That's the case for institutions.

02:02:58,705 --> 02:02:59,262
SPEAKER_0:  Absolutely.

02:02:59,618 --> 02:03:02,334
SPEAKER_1:  What about the inefficiencies of bureaucracy?

02:03:02,818 --> 02:03:05,246
SPEAKER_1:  Is there some aspect when, at scale,

02:03:06,626 --> 02:03:09,886
SPEAKER_1:  different dynamics come into play than they do when there's two people together.

02:03:10,210 --> 02:03:13,086
SPEAKER_1:  Two people that love each other, the birds and the bees.

02:03:13,410 --> 02:03:16,958
SPEAKER_1:  Is there some aspect that leads more to cannibalism at scale?

02:03:17,250 --> 02:03:21,022
SPEAKER_1:  So like corruption, inefficiencies that do to bureaucracy and so on.

02:03:21,250 --> 02:03:22,110
SPEAKER_0:  Bureaucracy.

02:03:22,338 --> 02:03:23,038
SPEAKER_0:  which is not.

02:03:23,650 --> 02:03:56,350
SPEAKER_0:  I hate it when people try to say bureaucracy is government because bureaucracy exists a ton in private environments as well, right? In businesses and everything. Bureaucracy introduces its own set of problems, but I mean, a bureaucracy is necessary because it's coordinating all of the underlying things in order to create something that's greater than the sum of its parts, right? Like all of the software developers in the world are useless without being paired with good designers in order to make their products usable by a person. And the coordination of those people and the coordination of increasingly more and more things necessitates some level of bureaucracy. I think we always say bureaucracy when it's like.

02:03:56,738 --> 02:04:10,910
SPEAKER_0:  a bad, it's like a slur on us. Like you're a bureaucrat, you're bureaucratic. The bureaucracy is slowing everything down. It's like, sure, the bureaucracy slows things down, but bureaucracy also gives us things like, you know, safe medicine and safe water to drink for most of the US or safe buildings to live in or safe cars to drive.

02:04:11,330 --> 02:04:17,822
SPEAKER_1:  So the managers in institution versus like the software developers and designers the managers is the bureaucracy.

02:04:18,242 --> 02:04:21,054
SPEAKER_1:  the reason bureaucracy is used as a slur.

02:04:21,346 --> 02:04:21,982
SPEAKER_1:  is that.

02:04:22,306 --> 02:04:23,998
SPEAKER_1:  something about human nature.

02:04:24,930 --> 02:04:27,294
SPEAKER_1:  leads to bureaucracy often growing.

02:04:28,898 --> 02:04:29,950
SPEAKER_1:  growing indefinitely.

02:04:30,370 --> 02:04:35,326
SPEAKER_1:  sometimes coming less and less efficient without a foot me this is what capitalism can come in

02:04:35,746 --> 02:04:37,598
SPEAKER_1:  that capitalism puts a

02:04:38,274 --> 02:04:41,470
SPEAKER_1:  pressure on the bureaucracy not to grow too much because

02:04:42,178 --> 02:04:43,998
SPEAKER_1:  You want the bureaucracy to be useful.

02:04:44,546 --> 02:04:44,894
SPEAKER_1:  but

02:04:45,122 --> 02:04:45,950
SPEAKER_1:  NOT

02:04:46,210 --> 02:04:46,878
SPEAKER_1:  large.

02:04:47,202 --> 02:04:47,518
SPEAKER_0:  Yeah.

02:04:47,778 --> 02:04:49,653
SPEAKER_0:  And to be a certain size, of course.

02:04:49,653 --> 02:04:51,198
SPEAKER_1:  the minimum size.

02:04:51,842 --> 02:04:55,710
SPEAKER_1:  to get the job done. And so capitalism provides that mechanism.

02:04:57,826 --> 02:04:58,558
SPEAKER_1:  Government.

02:04:59,586 --> 02:05:00,510
SPEAKER_1:  does not always.

02:05:00,962 --> 02:05:07,102
SPEAKER_1:  And so that's the criticism of government, of institutions, where it can grow without a significant mechanism that says.

02:05:07,650 --> 02:05:10,974
SPEAKER_1:  there's a cost to bureaucracy that's not being accounted for here.

02:05:11,234 --> 02:05:12,030
SPEAKER_1:  We're just paying.

02:05:12,258 --> 02:05:13,374
SPEAKER_1:  for the increasing.

02:05:13,730 --> 02:05:16,350
SPEAKER_1:  size of government without the benefit.

02:05:16,930 --> 02:05:29,406
SPEAKER_0:  Yeah, government is a special institution because it doesn't have to show itself to be financially viable. And we kind of live in a capitalist economy where that's generally the case. So government gets its powers from votes from the people, which introduces a whole new set of

02:05:29,762 --> 02:05:32,030
SPEAKER_0:  possible positives and possible negatives, right?

02:05:32,290 --> 02:05:47,550
SPEAKER_0:  Having something, for instance, that gives food or shelter to homeless people, maybe you don't want that to have to run at a profit. But giving an organization that can self-justify its budgets perpetually and indefinitely growing, maybe that's not the best thing. Yeah, we always have to figure out how to do the constraints there.

02:05:48,258 --> 02:05:51,646
SPEAKER_1:  What about the corrupting nature of power?

02:05:52,450 --> 02:05:54,398
SPEAKER_1:  That comes with institutions as well.

02:05:54,498 --> 02:05:59,326
SPEAKER_0:  Absolutely. So then you better pick your style of institution very carefully.

02:05:59,682 --> 02:06:03,550
SPEAKER_0:  The democratic institution we have in the United States today, I think works very well.

02:06:03,874 --> 02:06:13,246
SPEAKER_0:  But I mean, there are other styles of government that have been tried in the past that I think lend themselves more to corruption. Not to say that, by the way, there's not corruption in the United States. Of course, there's gonna be varying levels of corruption not like all.

02:06:13,666 --> 02:06:14,078
SPEAKER_0:  Um.

02:06:14,306 --> 02:06:17,950
SPEAKER_0:  at all levels, but you run into this interesting problem where...

02:06:18,242 --> 02:06:22,366
SPEAKER_0:  Authoritarian regimes can act with ruthless precision and swiftness.

02:06:22,658 --> 02:06:25,982
SPEAKER_0:  because they don't have to ask any questions. They just do, do, do, do, do, and that's it.

02:06:26,242 --> 02:06:26,590
SPEAKER_0:  Um.

02:06:26,946 --> 02:06:49,598
SPEAKER_0:  The problem is, it's an authoritarian regime. They're prone to missteps. They're slow to respond to changing or evolving needs. There was an interesting study that was put out a while ago that showed that every single famine that happened around the world, almost 98% of them, happened under authoritarian regimes where freedom of speech is very limited. It's very rare for a famine to happen under democracy because press and everything makes the government more responsive to the needs of the people.

02:06:49,954 --> 02:06:56,830
SPEAKER_0:  Power can corrupt, there are levels of corruption, but you have to have like a system of checks and balances on all of those different levels to make sure it doesn't run off the rails, I guess.

02:06:57,058 --> 02:06:59,806
SPEAKER_0:  and do a sick loop-de-looping, you know, half the population gets.

02:07:00,930 --> 02:07:04,510
SPEAKER_1:  Nice callback. There's a lot of people that will listen to you say that.

02:07:04,802 --> 02:07:10,590
SPEAKER_1:  The democracy in the United States is working pretty damn well and they will spit out the drink if they're drinking a drink.

02:07:11,330 --> 02:07:15,454
SPEAKER_1:  and be very upset. Can you make the case that they're right and you're wrong?

02:07:16,290 --> 02:07:27,518
SPEAKER_0:  When I make the case that- He's the steel man. They're right, yeah. Well, the steel man for them is that people have a lot of problems on the day to day. And when they look and they see what government is doing they might see potholes.

02:07:27,778 --> 02:07:28,830
SPEAKER_0:  outside their house.

02:07:29,058 --> 02:07:35,806
SPEAKER_0:  homeless people all over their downtown. And the United States just approved another X billion amount of dollars for Ukraine.

02:07:36,130 --> 02:07:41,310
SPEAKER_0:  or they might be living in a city where half the factories are shut down, a lot of their people out of work.

02:07:41,538 --> 02:07:55,038
SPEAKER_0:  but the president is on the TV talking about how to find jobs for immigrants coming in from Mexico. And for these people, they have problems that exist in their lives. Some of them are paying taxes to alleviate these problems. And then when they listen to the government talk, they're like, oh, you're a

02:07:55,362 --> 02:07:57,950
SPEAKER_0:  It feels like the government is not responding to the needs that they have.

02:07:58,242 --> 02:08:20,830
SPEAKER_0:  And then that's one problem. Then on top of that, you've got all of these people working in alternative media that can show you, well, look at this politician wasting this much money, or look at him double speaking here or there. Look at Hillary Clinton saying she's got a private position and a public position. Look at how all of these politicians have family members that are getting rich because of their relationships with people in Congress. Look at the revolving door between capitalist companies and the government. How can you look at all of that?

02:08:21,154 --> 02:08:26,029
SPEAKER_0:  take into account that the government's not responding to your needs and then really feel like it's a government by the people and for the people.

02:08:26,029 --> 02:08:27,550
SPEAKER_1:  Yeah, this was very good.

02:08:27,874 --> 02:08:29,886
SPEAKER_1:  Good steel man and good question.

02:08:30,402 --> 02:08:31,774
SPEAKER_1:  How can you, how can you?

02:08:32,066 --> 02:08:35,294
SPEAKER_1:  How can you tell that they're not just politicians that care more about

02:08:35,874 --> 02:08:38,014
SPEAKER_1:  continuously winning the elections versus

02:08:38,530 --> 02:08:39,934
SPEAKER_1:  being running government.

02:08:40,098 --> 02:08:50,814
SPEAKER_0:  Effectively. They should care about winning the elections. That's the first misconception. A lot of people say this guy only cares about getting voted in. This guy, like he doesn't even believe about in fracking or abortion. He just changed his opinion to get voted in.

02:08:51,138 --> 02:09:06,297
SPEAKER_0:  Anytime somebody says that, you just say, that's really good. You want them to change their opinions so they get voted in. That's the whole point of a democracy. You don't want them to be made obstinate. You don't want them to say, I'm not changing my opinion no matter what the people want. You want them to evolve and adopt new opinions based on what the population, their constituents are voting for. Yeah, but the cynical...

02:09:06,297 --> 02:09:07,294
SPEAKER_1:  take is that they're.

02:09:07,714 --> 02:09:13,342
SPEAKER_1:  the surface they're changing their opinion, but that there's a boys club or boys means the elite.

02:09:14,114 --> 02:09:14,718
SPEAKER_1:  UNDER

02:09:15,266 --> 02:09:17,086
SPEAKER_1:  in the smoke-filled rooms.

02:09:17,762 --> 02:09:22,718
SPEAKER_1:  uh... in secret there actually have their own agenda and they're following that agenda and they're just saying

02:09:22,946 --> 02:09:25,374
SPEAKER_1:  anything publicly to placate the public.

02:09:25,890 --> 02:09:27,390
SPEAKER_1:  based on whatever the...

02:09:27,906 --> 02:09:28,990
SPEAKER_1:  the new trends are.

02:09:29,570 --> 02:09:30,366
SPEAKER_0:  So

02:09:30,626 --> 02:09:32,702
SPEAKER_0:  Here is... Yeah, I understand.

02:09:33,122 --> 02:09:34,782
SPEAKER_0:  Somebody asked me this question and it-

02:09:35,778 --> 02:09:42,174
SPEAKER_0:  I 180'd completely. Um, I was a Bernie Sanders supporter in 2016 and my, my single issue voting.

02:09:42,786 --> 02:09:43,742
SPEAKER_0:  thing was lobbying.

02:09:44,034 --> 02:09:50,078
SPEAKER_0:  I thought that lobbying, the government was corrupt, they weren't responding to these people. It was completely destroyed my faith and the government everything.

02:09:50,402 --> 02:09:54,238
SPEAKER_0:  And I had one question posed to me by a conservative that used to come on my stream and shout at me and he said

02:09:54,786 --> 02:09:57,054
SPEAKER_0:  And then he asked me, can you think of any?

02:09:58,114 --> 02:09:58,494
SPEAKER_0:  Any-

02:09:58,722 --> 02:10:00,894
SPEAKER_0:  popular opinion that the American public has.

02:10:01,186 --> 02:10:07,038
SPEAKER_0:  the government is unresponsive to. Is there some big piece of legislation or policy or whatever that people want that the government isn't doing?

02:10:08,002 --> 02:10:10,526
SPEAKER_0:  When they asked me that, I couldn't think of a single good answer.

02:10:10,978 --> 02:10:12,103
SPEAKER_0:  I'm like, oh jeez.

02:10:12,103 --> 02:10:14,014
SPEAKER_1:  There's drugs.

02:10:14,338 --> 02:10:15,966
SPEAKER_0:  It's not. And that's,

02:10:16,066 --> 02:10:17,941
SPEAKER_1:  Legalization of drug. Hold on a sec. Yeah.

02:10:17,941 --> 02:10:21,726
SPEAKER_0:  Go for it. Oh shoot, you're doing the Joe Rogan thing. You're pushing back because I brought up weed. Go ahead.

02:10:23,170 --> 02:10:24,935
SPEAKER_0:  I'm sorry. I have become-

02:10:24,935 --> 02:10:25,406
SPEAKER_1:  meme.

02:10:27,650 --> 02:10:28,670
SPEAKER_1:  I don't even...

02:10:29,122 --> 02:10:40,638
SPEAKER_1:  I don't want to interrupt your, your, cause there's means upon means upon means I can go with here. But no, cause people bring up, okay, there's no issues. There's no issues that the government is not representing of the public.

02:10:40,930 --> 02:10:44,990
SPEAKER_0:  So here's the issue. So somebody will bring up like, well, what about the legalization of drugs? Okay.

02:10:45,474 --> 02:10:48,414
SPEAKER_0:  The first issue people have is one, they look at national polling.

02:10:48,674 --> 02:10:58,526
SPEAKER_0:  Very few things are decided on a national level. So that's the first huge mistake. Arguably a lot of BLM made mistakes in this arena where they're saying like, why isn't the government doing anything about policing?

02:10:58,754 --> 02:11:02,878
SPEAKER_0:  Federal government can't do anything about policing. That's gonna be your, sometimes that's gonna be your state government, sometimes your local city government.

02:11:03,106 --> 02:11:13,150
SPEAKER_0:  the people that like elect like your chief of police, your police commissioner, that's coming from your mayor. So you've got people looking one, at the wrong parts of the government to even figure out the solutions to the problem. Two.

02:11:13,762 --> 02:11:15,518
SPEAKER_0:  oftentimes for pulling.

02:11:15,778 --> 02:11:24,286
SPEAKER_0:  Questions are vague enough that you can pull very high, but when you get into the weeds on things, no pun intended, you start to realize like, oh shoot, this is more complicated than I thought.

02:11:24,578 --> 02:11:35,262
SPEAKER_0:  I don't know the numbers in particular for legalization of marijuana, but this is what I'm going to guess is the case. If you poll and you say, should we legalize marijuana, that number might poll at like 65-70%.

02:11:36,322 --> 02:11:40,830
SPEAKER_0:  but that's including people that are in favor of medical marijuana. If you were to pull like, should we legalize?

02:11:41,122 --> 02:11:43,806
SPEAKER_0:  should we decriminalize recreational use of marijuana?

02:11:44,034 --> 02:11:52,670
SPEAKER_0:  that number might drop to like 52%. And then if you pull like, should we completely legalize, not just keep criminalized, but completely legalize recreationalism or whatever, that number might drop to like 40%.

02:11:53,090 --> 02:12:03,646
SPEAKER_0:  There's like all these different ways you can pull around issues where people are like, oh no, we broadly agree on this topic. But when you really figure out, well, do you, do we really agree or is it just like broad consensus around a thing that's never gonna show up like in a piece of legislation?

02:12:04,002 --> 02:12:05,790
SPEAKER_0:  A really good example, one example I do know is...

02:12:06,018 --> 02:12:08,766
SPEAKER_0:  Socialized healthcare. I think if you pulled there was a time

02:12:09,314 --> 02:12:16,382
SPEAKER_0:  a few years ago where if you poll America, do you think every American citizen should have access to free healthcare?

02:12:16,770 --> 02:12:18,942
SPEAKER_0:  answer that poll at like 74% yes.

02:12:19,458 --> 02:12:20,414
SPEAKER_0:  But when you asked...

02:12:20,642 --> 02:12:24,798
SPEAKER_0:  should the government be the sole provider of healthcare, it dropped to like 26%.

02:12:25,026 --> 02:12:26,046
SPEAKER_0:  dropped 50 points.

02:12:26,338 --> 02:12:35,838
SPEAKER_0:  And you could see it was both asking questions about single payer, but the way that it was asked was so different that even if you all, it looks like there's consensus, there's not nearly as much consensus as people think around certain ideas.

02:12:36,674 --> 02:12:37,799
SPEAKER_0:  Yeah, we are gonna...

02:12:37,799 --> 02:12:39,742
SPEAKER_1:  You're right, you're right, you're right, you're right.

02:12:40,994 --> 02:12:49,278
SPEAKER_1:  that polls, the way you ask the polls really matters. When you ask, should the government be in charge of a thing, that also biases the answer.

02:12:49,762 --> 02:12:52,702
SPEAKER_1:  Right? Like because there's such a negative.

02:12:53,090 --> 02:12:56,862
SPEAKER_1:  experience with government creating a dot gov site that runs the thing.

02:12:57,218 --> 02:12:57,854
SPEAKER_1:  But sometimes.

02:12:58,562 --> 02:13:01,278
SPEAKER_1:  Sometimes I think if you dig in, if you have a.

02:13:01,506 --> 02:13:04,094
SPEAKER_1:  One hour conversation with each individual citizen.

02:13:05,218 --> 02:13:09,214
SPEAKER_1:  I think you will understand that yes, there is support for socialized medicine.

02:13:09,442 --> 02:13:10,567
SPEAKER_1:  Like it's not.

02:13:10,567 --> 02:13:11,742
SPEAKER_0:  The argument has to be made though.

02:13:12,674 --> 02:13:21,695
SPEAKER_0:  What do you mean? Like if you just ask a conservative like what about single payer? They're gonna tell you no. You might be able to build up to an argument for it, but you're gonna have to make the case for it. No, but I thought we're

02:13:21,695 --> 02:13:22,590
SPEAKER_1:  talking about.

02:13:23,362 --> 02:13:25,886
SPEAKER_1:  the feeling deep inside your mind and heart.

02:13:26,114 --> 02:13:28,062
SPEAKER_1:  Does the government represent that?

02:13:28,290 --> 02:13:28,606
SPEAKER_1:  Oh.

02:13:28,930 --> 02:13:30,718
SPEAKER_1:  So it's not like some shallow.

02:13:31,298 --> 02:13:32,446
SPEAKER_1:  surface layer.

02:13:32,994 --> 02:13:33,886
SPEAKER_1:  public opinion.

02:13:34,370 --> 02:13:38,078
SPEAKER_1:  does the government effectively represent what the people want?

02:13:38,786 --> 02:13:41,598
SPEAKER_1:  not a shallow survey but a deeply what they want.

02:13:41,922 --> 02:13:48,926
SPEAKER_1:  I'm not actually that familiar with the debates over healthcare, but let's maybe look at an easier one. Maybe you'll say it's harder.

02:13:49,378 --> 02:13:49,790
SPEAKER_1:  War.

02:13:50,434 --> 02:13:54,110
SPEAKER_0:  war is a really good example where the government was very responsive i think to the

02:13:54,402 --> 02:13:54,782
SPEAKER_0:  people.

02:13:55,074 --> 02:13:56,062
SPEAKER_1:  You think so.

02:13:56,290 --> 02:13:57,502
SPEAKER_1:  Iraq, Afghanistan.

02:13:58,434 --> 02:14:00,030
SPEAKER_1:  The government didn't manipulate.

02:14:00,834 --> 02:14:01,758
SPEAKER_1:  public opinion.

02:14:02,018 --> 02:14:09,310
SPEAKER_0:  There's an argument to be made that they did in terms of like WMD and everything, but after 9-11, were you in the United States after 9-11?

02:14:09,538 --> 02:14:11,413
SPEAKER_0:  After 9-11, I legit-

02:14:11,413 --> 02:14:12,190
SPEAKER_1:  accusatory.

02:14:12,482 --> 02:14:13,854
SPEAKER_1:  Like, where were you on 9-11?

02:14:14,690 --> 02:14:15,294
SPEAKER_1:  Oh

02:14:15,586 --> 02:14:17,118
SPEAKER_0:  Checking, okay. All right.

02:14:17,538 --> 02:14:23,678
SPEAKER_1:  I have evidence and witnesses. No, okay. I'm very defensive right now. It's very strange.

02:14:23,778 --> 02:14:25,022
SPEAKER_0:  Look into it.

02:14:25,442 --> 02:14:30,110
SPEAKER_0:  Alex Jones. I think after 9-11, we could have gone to country, we could have gone to war with any country in the world.

02:14:30,466 --> 02:14:46,302
SPEAKER_0:  we were ready because all of America was like, oh my God, and they pointed to Iraq and the reasons for the WMDs was kind of dumb, but I don't think we even needed WMDs to go to Iraq. We could have just said, you know, Saddam Hussein was giving medical aid to Taliban, Al-Qaeda, Iraq, let's go, and we would have gone for it.

02:14:46,690 --> 02:14:47,230
SPEAKER_0:  But um...

02:14:47,490 --> 02:15:10,110
SPEAKER_0:  post-Iraq, Iraq was for a while popular and then became obviously deeply unpopular, Iraq and Afghanistan. And I think you could see that influence other foreign policy that the United States had. For instance, we opted more towards drone warfare than troops on the ground for places like Yemen. We opted more towards sending money and help instead of boots on the ground for places like Syria. And I think that a lot of that was in response to how unpopular...

02:15:10,338 --> 02:15:24,894
SPEAKER_0:  the Iraq stuff had became. And when you looked at a lot of elections afterwards, even for Obama, like one of the defining characteristics of a lot of campaigns were like, I'm gonna close Guantanamo Bay, I'm gonna get us out of foreign wars, even up to Trump, I'm going into, I'm not gonna stop doing all this weird stuff in the Middle East.

02:15:25,090 --> 02:15:26,215
SPEAKER_1:  but they didn't still withdraw.

02:15:26,215 --> 02:15:32,958
SPEAKER_0:  from a gas then they didn't withdraw but they definitely like tapered off and weren't like as aggressively pushing those types of conflicts because they knew it was unpopular

02:15:33,090 --> 02:15:33,694
SPEAKER_1:  but I think.

02:15:33,954 --> 02:15:39,870
SPEAKER_1:  If you also consider perfect information or good information, if you ask a lot of people

02:15:41,378 --> 02:15:43,902
SPEAKER_1:  Are you okay spending this amount of money?

02:15:44,770 --> 02:15:48,286
SPEAKER_1:  for this purpose, so military conflict in Iraq and Afghanistan.

02:15:48,514 --> 02:15:49,982
SPEAKER_1:  I think almost from the very beginning.

02:15:50,306 --> 02:15:50,942
SPEAKER_1:  It was a no.

02:15:51,522 --> 02:15:54,558
SPEAKER_1:  After 9-11, I feel like maybe like a few days after 9-11.

02:15:54,722 --> 02:15:58,097
SPEAKER_0:  Like, what was the name?

02:15:58,097 --> 02:16:00,222
SPEAKER_1:  There's some memes and so on, yes, but...

02:16:00,514 --> 02:16:02,814
SPEAKER_1:  The nature of the public support for the war.

02:16:04,194 --> 02:16:08,350
SPEAKER_1:  Was there public support in 2003, which is when the invasion happened?

02:16:08,962 --> 02:16:15,337
SPEAKER_0:  I feel like initially there was a lot I remember seeing it on, but then I also lived in a Republican household and I was not very like media savvy at that time. And I don't know if the name

02:16:15,337 --> 02:16:18,750
SPEAKER_1:  sure that public support had to do with WMDs or with 911.

02:16:19,458 --> 02:16:21,333
SPEAKER_0:  because the weird. Came about WMD.

02:16:21,333 --> 02:16:28,510
SPEAKER_1:  But I wonder what is the name if you were to poll people and let's say hypothetically there was above 50% support

02:16:28,898 --> 02:16:30,814
SPEAKER_1:  for the war, what would be the nature of that support?

02:16:31,714 --> 02:16:32,094
SPEAKER_1:  and

02:16:32,834 --> 02:16:35,774
SPEAKER_1:  to what degrees the government actually representing.

02:16:36,322 --> 02:16:37,918
SPEAKER_1:  the will of the people versus

02:16:38,370 --> 02:16:38,910
SPEAKER_1:  some.

02:16:39,394 --> 02:16:42,878
SPEAKER_1:  complex mechanism like the military industrial complex.

02:16:43,138 --> 02:16:46,654
SPEAKER_1:  is manipulating the narrative that's controlling public opinion.

02:16:47,234 --> 02:16:48,766
SPEAKER_1:  And then there's the media that

02:16:49,218 --> 02:16:50,302
SPEAKER_1:  uh, gets.

02:16:50,658 --> 02:16:52,446
SPEAKER_1:  a lot of attention by being divided.

02:16:52,674 --> 02:16:54,238
SPEAKER_1:  and how they're shaping the narrative.

02:16:55,042 --> 02:16:56,766
SPEAKER_1:  through the mechanism of division.

02:16:56,994 --> 02:16:57,566
SPEAKER_1:  So what.

02:16:58,242 --> 02:17:06,117
SPEAKER_0:  There's a lot of complicated things out there. It's not just like the people and then the government and that's, yeah, for sure I agree that there are gonna be different elements at play. and I will be very proud.

02:17:06,117 --> 02:17:06,590
SPEAKER_1:  much.

02:17:06,818 --> 02:17:07,422
SPEAKER_1:  of those.

02:17:07,906 --> 02:17:13,918
SPEAKER_1:  elements that lead us astray can be attributed to the largeness of the different systems.

02:17:14,242 --> 02:17:16,414
SPEAKER_1:  and the different institutions.

02:17:16,706 --> 02:17:17,150
SPEAKER_1:  like

02:17:17,794 --> 02:17:20,478
SPEAKER_1:  the media institutions and government.

02:17:21,218 --> 02:17:23,518
SPEAKER_1:  the institutions that have a monopoly on violence.

02:17:23,842 --> 02:17:25,214
SPEAKER_1:  put it this way. Put it this way.

02:17:25,698 --> 02:17:26,814
SPEAKER_1:  One way to define government.

02:17:27,458 --> 02:17:28,190
SPEAKER_0:  It's complicated.

02:17:28,450 --> 02:17:31,966
SPEAKER_0:  There's definitely going to be different institutions at play. But I think that like-

02:17:32,450 --> 02:17:41,342
SPEAKER_0:  All I would say is, in reference to my original point, when there becomes broad consensus around a thing, I think the government will usually follow. It's not gonna fight. It's gonna follow more often than not.

02:17:41,634 --> 02:17:46,462
SPEAKER_0:  But I think that a lot of times I think Americans think that there's more consensus around certain issues

02:17:46,722 --> 02:17:50,206
SPEAKER_0:  there actually are. So like a really good example we're on that war point too.

02:17:50,530 --> 02:17:51,006
SPEAKER_0:  Um.

02:17:51,426 --> 02:17:53,182
SPEAKER_0:  What caused like the lowest dip?

02:17:53,410 --> 02:17:54,590
SPEAKER_0:  in Biden's approval rating.

02:17:55,490 --> 02:17:57,758
SPEAKER_0:  I'm pretty sure it was right after we pulled out of Afghanistan.

02:17:58,114 --> 02:17:58,526
SPEAKER_0:  which

02:17:58,914 --> 02:18:03,966
SPEAKER_0:  I think if I would have asked people like a year before, like let's assume that we could pull out of Afghanistan.

02:18:04,258 --> 02:18:11,838
SPEAKER_0:  The government's probably gonna collapse after we leave because they just don't have the will to fight, they don't have the support, they don't whatever, it's just not gonna work. But like no Americans are gonna die.

02:18:12,162 --> 02:18:16,766
SPEAKER_0:  Maybe a couple other people will go, but like, no, America's gonna die, we're gonna get out of here this time. Would you support that? I think broadly speaking.

02:18:17,154 --> 02:18:20,798
SPEAKER_0:  I think more than 60 or 70% of Americans are like, yeah, that would be fine.

02:18:21,282 --> 02:18:30,014
SPEAKER_0:  But then when it actually plays on TV, when we see the people hanging onto the planes, when we see like helicopter embassies, some of the courts and politicians, well now it's like, oh my God, this was horrible and I was so botched.

02:18:30,242 --> 02:18:34,558
SPEAKER_0:  And it was so like, it could have gone so much better. It's like, well, could it have gone better? Like maybe, maybe not, but I mean.

02:18:34,882 --> 02:18:37,438
SPEAKER_0:  It seems like you can have consensus around a certain opinion.

02:18:38,402 --> 02:18:45,342
SPEAKER_0:  The way that things play out and the way that people actually feel, it's actually way, way, more complicated and there's not usually this broad consensus opinion.

02:18:46,434 --> 02:18:47,559
SPEAKER_0:  Alright, yeah, go ahead. Sauce

02:18:47,559 --> 02:18:48,702
SPEAKER_1:  to believe that I mean

02:18:49,378 --> 02:18:50,590
SPEAKER_1:  just to lay my cards out.

02:18:50,946 --> 02:18:51,870
SPEAKER_1:  on the table.

02:18:53,954 --> 02:18:54,942
SPEAKER_1:  I have a-

02:18:55,522 --> 02:18:56,030
SPEAKER_1:  faith.

02:18:56,866 --> 02:18:58,814
SPEAKER_1:  in the power of effective government.

02:19:00,130 --> 02:19:00,574
SPEAKER_1:  I just.

02:19:01,986 --> 02:19:02,942
SPEAKER_1:  have, uh...

02:19:03,298 --> 02:19:05,374
SPEAKER_1:  a lot of concern about what happens.

02:19:05,634 --> 02:19:07,966
SPEAKER_1:  as institutions grow in size. For sure.

02:19:08,322 --> 02:19:10,590
SPEAKER_1:  and I just have a lot of worry about the natural.

02:19:10,850 --> 02:19:13,758
SPEAKER_1:  corrupting influence on the individuals and

02:19:14,146 --> 02:19:19,134
SPEAKER_1:  on the system as a whole. Like the boys club nature of it. I don't know, there must be a better term.

02:19:19,426 --> 02:19:20,446
SPEAKER_1:  But basically they...

02:19:21,282 --> 02:19:24,350
SPEAKER_1:  They agree to the game and they play the game and there's a

02:19:24,706 --> 02:19:27,742
SPEAKER_1:  generational aspect momentum to the game.

02:19:27,970 --> 02:19:30,718
SPEAKER_1:  and they more and more stop being responsive to.

02:19:31,234 --> 02:19:34,462
SPEAKER_1:  the people that they represent. I just feel like there is that mechanism.

02:19:35,106 --> 02:19:35,614
SPEAKER_1:  and...

02:19:35,842 --> 02:19:37,150
SPEAKER_1:  I think the nice thing.

02:19:37,858 --> 02:19:41,918
SPEAKER_1:  Democracy, elections are resistance to that natural human mechanism.

02:19:42,274 --> 02:19:45,662
SPEAKER_1:  Also, the balances of power is a resistance to that mechanism.

02:19:46,050 --> 02:19:52,062
SPEAKER_1:  In some ways, the media that reveals the bullshit of politicians is also a resistance to that labor

02:19:52,322 --> 02:19:54,526
SPEAKER_1:  It's hard to be full of shit as a politician.

02:19:54,850 --> 02:19:56,222
SPEAKER_1:  because people will try to catch you on it.

02:19:56,674 --> 02:19:57,406
SPEAKER_1:  So there's a...

02:19:57,666 --> 02:19:58,526
SPEAKER_1:  honesty.

02:19:58,850 --> 02:20:02,270
SPEAKER_1:  method there that keeps you honest. It's the sun degree, but.

02:20:02,850 --> 02:20:04,318
SPEAKER_1:  It still feels like...

02:20:06,722 --> 02:20:09,406
SPEAKER_1:  It still feels like politicians are gonna politician.

02:20:10,402 --> 02:20:12,990
SPEAKER_0:  Yeah, they definitely play their games, that is true.

02:20:13,378 --> 02:20:17,214
SPEAKER_0:  There's probably always gonna be that meta-narrative over like, governance.

02:20:17,634 --> 02:20:36,030
SPEAKER_0:  that just develops as like you have to form relationships and play games to get legislation passed and everything. The only reason why I don't like it when people attack institutions is because one, institutions are incredibly important, arguably paramount, no, they are, to keeping society running. And two, I think sometimes when we shift the blame on the institutions too much,

02:20:36,258 --> 02:20:40,702
SPEAKER_0:  I think that we lose sight of what the real problems are. So for instance, in the United States today.

02:20:40,962 --> 02:20:43,678
SPEAKER_0:  People might be very critical of the government not getting much done.

02:20:44,098 --> 02:20:46,750
SPEAKER_0:  but then everybody turns their eyes to the government for being ineffective.

02:20:46,978 --> 02:20:57,630
SPEAKER_0:  But what I would argue is I would say the government is actually incredibly effective and it's showcasing the will of the American people really well right now, which is we are historically more divided than we have ever been.

02:20:58,018 --> 02:21:14,334
SPEAKER_0:  And if I were to just look at the people and I were to say, we have a historic divide that is getting rapidly blown apart by things like the internet and the media, right? If that exists, well, what would I expect that government to look like? I wouldn't expect that government to be governing very effectively. I would expect that government to show that legitimate divide in people.

02:21:14,498 --> 02:21:17,694
SPEAKER_1:  Do you think that divide, we have a perception of a large divide?

02:21:18,210 --> 02:21:19,358
SPEAKER_1:  between left and right.

02:21:19,970 --> 02:21:21,918
SPEAKER_1:  Do you think that's a real divide that's in this country?

02:21:22,242 --> 02:21:24,318
SPEAKER_0:  Narrow the language. What do you mean by real divide?

02:21:25,410 --> 02:21:35,518
SPEAKER_1:  Do you think there is that divide in ideology that there's a large number of people that believe a certain set of policies and the different set of policies? Or is it just the perception on Twitter?

02:21:35,650 --> 02:21:51,294
SPEAKER_0:  No, I think there is a large divide in terms of belief. I don't think there's very much divide between any people in terms of like what they, like on the most fundamental levels want in terms of like human beings. But in terms of like Democrat versus Republican right now, I think there is a huge divide in terms of the direction they want to see the country go and what they believe.

02:21:51,586 --> 02:21:54,846
SPEAKER_0:  really in what they even believe is reality, right? Unfortunately, that's what we've gotten to.

02:21:55,970 --> 02:21:58,782
SPEAKER_1:  Can I just speak about the mechanism of the left and right here?

02:21:59,042 --> 02:22:01,246
SPEAKER_1:  maybe on the mimetic rivalry aspect.

02:22:01,794 --> 02:22:06,110
SPEAKER_1:  Is there some aspect to the left on which you're a part of that attacks their own?

02:22:07,586 --> 02:22:10,366
SPEAKER_1:  for ideological impurity more than the right does.

02:22:10,594 --> 02:22:12,318
SPEAKER_0:  Is it the bigotry of small differences?

02:22:12,802 --> 02:22:14,590
SPEAKER_0:  There's a concept where...

02:22:15,170 --> 02:22:15,742
SPEAKER_0:  Um...

02:22:16,162 --> 02:22:22,430
SPEAKER_0:  When you're near somebody who is very slightly different than you, you want to destroy it, but when you're with somebody that's way different than you, you don't.

02:22:22,722 --> 02:22:23,198
SPEAKER_0:  Um...

02:22:23,554 --> 02:22:32,062
SPEAKER_0:  I think the left does it, but I think the right does it too. I didn't realize it until I started dipping more into conservative communities, but oh my God, the people from the Daily Wire and the people from Turning Point and-

02:22:32,322 --> 02:22:39,998
SPEAKER_0:  the America first, but all these different groups of people hate each other and they fight each other so much they hire and fire sometimes employees they talk

02:22:40,226 --> 02:22:56,734
SPEAKER_0:  smack about each other. I think there's a lot of political division between both sides. I think that the left just kind of gets highlighted more because it's like the internet and a lot of the internet spaces have a lot of left leaning people. So you see like the crazy communists and the crazy progressives and the crazy center left liberals and the crazy blah, blah, blah. Whereas like a lot of the right leaning people have kind of been.

02:22:56,994 --> 02:22:58,814
SPEAKER_0:  pushed off of the main areas of the internet now.

02:22:59,522 --> 02:23:03,006
SPEAKER_1:  Interesting. My sense was that it's hard to exist on the center left.

02:23:04,002 --> 02:23:07,198
SPEAKER_1:  but maybe because I just don't have the full spectrum view.

02:23:07,426 --> 02:23:11,551
SPEAKER_1:  of the political divide. It felt like central art is a difficult position to occupy.

02:23:11,551 --> 02:23:12,574
SPEAKER_0:  definitely say so.

02:23:12,738 --> 02:23:15,363
SPEAKER_1:  I don't know if it's that difficult to be said, right?

02:23:15,363 --> 02:23:22,494
SPEAKER_0:  it's very difficult to be center right. I think actually maybe even more difficult because a center right person might be somebody who's like conservative.

02:23:22,850 --> 02:23:25,342
SPEAKER_0:  but not a fan of Trump and you're like over.

02:23:25,954 --> 02:23:33,630
SPEAKER_0:  like looking like Liz Cheney, right? You've had politicians that are just like, they didn't back the Trump stuff and now they're gone. Or you might be like Senator Wright, but like you don't think the election was stolen.

02:23:33,922 --> 02:23:37,534
SPEAKER_0:  And now you're like, half the Republican Party's looking at you like you're crazy, you know?

02:23:37,794 --> 02:23:38,238
SPEAKER_0:  Um...

02:23:38,370 --> 02:23:40,862
SPEAKER_1:  That's true. Yeah, that's true. I think, uh,

02:23:41,218 --> 02:23:42,686
SPEAKER_1:  Ben Shapiro or who I'm talking with.

02:23:42,946 --> 02:23:45,630
SPEAKER_1:  I think he publicly spoke against Trump.

02:23:46,370 --> 02:23:49,662
SPEAKER_0:  He did initially, but I felt like he softened his language upon him pretty significantly, but...

02:23:49,826 --> 02:23:51,678
SPEAKER_1:  So there's a significant pressure to kinda...

02:23:52,034 --> 02:23:53,909
SPEAKER_1:  out a certain kind of messaging.

02:23:53,909 --> 02:23:58,430
SPEAKER_0:  which the whole Republican Party is feeling right now. Geez, that two years from now, that election is gonna be insane.

02:23:59,330 --> 02:24:04,894
SPEAKER_1:  It's just hard. Okay, so to generalize, it's hard to be in the center. It feels like for sure this center and then like.

02:24:05,474 --> 02:24:06,686
SPEAKER_1:  do like a random walk.

02:24:08,002 --> 02:24:09,694
SPEAKER_1:  among the policies around that.

02:24:10,498 --> 02:24:13,758
SPEAKER_1:  I don't know what that mechanism is. I mean, it makes people like me.

02:24:14,210 --> 02:24:15,454
SPEAKER_1:  not feel good.

02:24:15,938 --> 02:24:16,894
SPEAKER_1:  being in the center.

02:24:17,378 --> 02:24:19,134
SPEAKER_1:  It seems like people are just not nice.

02:24:19,522 --> 02:24:20,606
SPEAKER_1:  to people in the center.

02:24:21,058 --> 02:24:22,494
SPEAKER_1:  the public.

02:24:22,882 --> 02:24:24,030
SPEAKER_1:  The Twitter Machine.

02:24:24,258 --> 02:24:27,134
SPEAKER_1:  is not nice to the people who are open-minded in the center.

02:24:27,842 --> 02:24:29,278
SPEAKER_1:  Is that, there's some truth to that.

02:24:29,506 --> 02:24:30,302
SPEAKER_0:  Two reasons for that.

02:24:30,562 --> 02:24:35,134
SPEAKER_0:  One is because I think a lot of people that market themselves as center are legitimately spineless cowards.

02:24:35,426 --> 02:24:36,606
SPEAKER_0:  and deserved to be called out.

02:24:36,834 --> 02:24:37,959
SPEAKER_0:  I'm like.

02:24:37,959 --> 02:24:41,182
SPEAKER_1:  I've never killed a man, but today might be my first. Oh no.

02:24:41,282 --> 02:24:41,758
SPEAKER_0:  Um.

02:24:42,242 --> 02:24:45,022
SPEAKER_1:  There I take over like I told you I'll take over your stream.

02:24:45,506 --> 02:24:49,822
SPEAKER_0:  With the AI, we'll see. Is that guy gonna be streaming in the background? Hey, fellas.

02:24:50,850 --> 02:24:52,670
SPEAKER_0:  Okay, gotcha, gotcha, gotcha.

02:24:53,218 --> 02:24:55,843
SPEAKER_0:  Gotcha. Lots of gotchas. Lots of gotchas. Okay.

02:24:55,843 --> 02:25:04,638
SPEAKER_1:  and decrease the amount, which already is a pretty low level of emotion. Just decrease it completely. When people are screaming at you and it's like,

02:25:04,930 --> 02:25:08,391
SPEAKER_1:  accusing stuff just remain calm. Absolutely. Most of our sharing about Madonna rumours outs the

02:25:08,391 --> 02:25:09,854
SPEAKER_0:  the gas lighter strategy.

02:25:10,722 --> 02:25:12,597
SPEAKER_0:  Okay, so what were we talking about?

02:25:12,597 --> 02:25:13,347
SPEAKER_1:  I don't.

02:25:13,347 --> 02:25:14,334
SPEAKER_0:

02:25:14,594 --> 02:25:19,469
SPEAKER_0:  I don't even, I don't ever identify a center anything because it's got such a bad reputation because so- Fuck that, I sta-

02:25:19,469 --> 02:25:20,382
SPEAKER_1:  center.

02:25:20,642 --> 02:25:21,598
SPEAKER_1:  with a spine.

02:25:22,082 --> 02:25:26,142
SPEAKER_1:  It's called being open-minded and it's not center left and right. Those are just labels.

02:25:26,306 --> 02:25:29,918
SPEAKER_0:  Here's a really good quote my mom said to me when I was really young. She said Stevie.

02:25:30,306 --> 02:25:32,574
SPEAKER_0:  Don't ever let your mind be so open that your brain falls out.

02:25:32,962 --> 02:25:34,837
SPEAKER_0:  And that's what I find that a lot of center people do.

02:25:34,837 --> 02:25:36,286
SPEAKER_1:  That's not what she told me last night.

02:25:36,770 --> 02:25:38,462
SPEAKER_1:  Why are you like this?

02:25:38,786 --> 02:25:39,262
SPEAKER_1:

02:25:39,554 --> 02:25:54,046
SPEAKER_0:  Sorry. Okay, I'm glad I can bring that. I'm glad you feel like this is a safe space. Like I said, people are not judgmental. If you wanna talk about fucking my mom, you know what, you're totally within your rights. I didn't say that, you said that. That's totally great, I support that. She's a beautiful woman. Her husband probably wouldn't be too happy about it, but you know.

02:25:54,594 --> 02:25:57,502
SPEAKER_1:  I didn't say there was any sexual relations. It was just that.

02:25:57,762 --> 02:26:07,454
SPEAKER_1:  having a conversation with her. You projected that, that says more by you than me. Anyway, go ahead about Spinalis Center. Spinalis Center. There is some aspects to that, which is.

02:26:07,682 --> 02:26:10,462
SPEAKER_1:  like amorphous. To me center means you.

02:26:10,754 --> 02:26:11,166
SPEAKER_1:  Youth.

02:26:12,034 --> 02:26:15,747
SPEAKER_1:  think freely about each individual policy without being st-

02:26:15,747 --> 02:26:24,734
SPEAKER_0:  Some ideal, yeah, but a lot of people don't do that. They call themselves centrist, but then they just, they're anti-establishment essentially on everything. I don't know your position on like the vaccines or anything.

02:26:25,026 --> 02:26:41,223
SPEAKER_0:  But like I met a lot of like free and open thinkers who are like, you know what? I'm open to everything and it's an experimental vaccine and I'm going to eat hydroxy, Clark, when an Ivermectin, because that's what the institutions are telling me not to take. And I think Fauci got too much money from that company and these are, but I'm an open thinker and I'm and they would open thinker.

02:26:41,223 --> 02:26:44,158
SPEAKER_1:  I'm at MIT, what do you think my position on vaccines is exactly?

02:26:44,642 --> 02:26:50,718
SPEAKER_0:  I hear a lot of crazy things from a lot of people. You might be from MIT, but I know you're from the internet. People from the internet are weird and crazy.

02:26:51,778 --> 02:26:53,342
SPEAKER_0:  Well, I, uh, who knows.

02:26:53,634 --> 02:26:56,222
SPEAKER_1:  I don't like arrogance and I have criticized.

02:26:56,898 --> 02:27:00,341
SPEAKER_1:  scientists during COVID, a lot of people, scientists included, have

02:27:00,341 --> 02:27:01,630
SPEAKER_0:  arrogance. Which is fair.

02:27:02,082 --> 02:27:06,366
SPEAKER_0:  But, and I think there's a lot of good criticism to be made of different.

02:27:07,042 --> 02:27:09,822
SPEAKER_0:  scientific and medical establishments over a lot of stuff.

02:27:10,914 --> 02:27:21,374
SPEAKER_0:  Nobody can make those good criticisms because they're too like obsessed over like just trying to have the anti-establishment answer. And that is what is upsetting me the most. Like I think there are good conversations to be had.

02:27:22,146 --> 02:27:22,622
SPEAKER_0:  about.

02:27:22,882 --> 02:27:40,798
SPEAKER_0:  a lot of stuff related to how we handle the coronavirus. You know, were lockdowns effective? Was there enough data to support the huge measures we took? You know, why didn't we have the option to show I was infected a month ago? Why do I need to be vaccinated? Why wasn't that option everything in the United States? I don't think it was. There are really good questions to be asked there.

02:27:41,154 --> 02:28:07,902
SPEAKER_0:  but all the people asking the questions are also trying to tell you that ivermectin and monoclonal antibodies are the way to go for everything. And the vaccine is evil and they're just gonna turn you gay like the frogs. And it's like, Jesus, like you can't, there's like no place to reasonably criticize from because all of the people that are criticizing aren't doing it with an open mind or, you know, they're not reading studies or doing anything. They're saying like, I do my own research, which means they listen to whatever the last guy on Joe Rogan said, and now they're parroting that opinion. Easy now, easy now, bro. Last guy on Joe Rogan, not Joe Rogan.

02:28:08,226 --> 02:28:16,990
SPEAKER_0:  That Robert Malone guy on Joe Rogan got me real fired up. That's one guest. People see him as like the father of mRNA technology. He published one paper, okay? What do you mean people?

02:28:17,218 --> 02:28:18,206
SPEAKER_1:  which people.

02:28:18,434 --> 02:28:23,309
SPEAKER_0:  think that. Dope broken fans. I get like I run into these people. I start arguing with people and they start setting me. Well, what about-

02:28:23,309 --> 02:28:24,158
SPEAKER_1:  I'm your Rogan fan.

02:28:24,386 --> 02:28:26,462
SPEAKER_1:  and I appreciate the vaccine.

02:28:26,562 --> 02:28:28,871
SPEAKER_0:  That's good. I'm glad you do. But there's definitely- Sorry.

02:28:28,871 --> 02:28:33,886
SPEAKER_1:  But you said there's a type, what's the type? What's the type of Joe Rogan fan? Anti-establishment.

02:28:34,882 --> 02:28:38,910
SPEAKER_1:  I think that's not Joe Rogan, that's a general public discourse, it's a default.

02:28:39,202 --> 02:28:42,110
SPEAKER_1:  and his establishment on the right and the left.

02:28:42,434 --> 02:28:44,990
SPEAKER_1:  That's the default easy thing to go to.

02:28:45,186 --> 02:28:54,782
SPEAKER_0:  I think Joe Rogan fans are definitely a certain type of anti-establishment though. Like I could guess to Joe Rogan fan. Like if I were to do general population versus Joe Rogan fan who do you think is more likely to be anti-vaccine?

02:28:55,682 --> 02:28:56,574
SPEAKER_1:  Do you have data on this?

02:28:57,186 --> 02:29:01,438
SPEAKER_1:  Are you just guessing? Just guessing. Yeah, I think you are actually judging.

02:29:01,698 --> 02:29:03,006
SPEAKER_1:  I am. Calendar

02:29:03,362 --> 02:29:04,702
SPEAKER_1:  Because I think you're also.

02:29:06,242 --> 02:29:12,702
SPEAKER_1:  The beautiful thing about podcasting this could be similar streaming is there's a large number of people that just listen.

02:29:13,026 --> 02:29:15,038
SPEAKER_1:  Like what does it mean to be a Joe Rogan fan?

02:29:15,586 --> 02:29:18,078
SPEAKER_0:  I don't think you just listen. I think people listen and absorb.

02:29:18,466 --> 02:29:19,262
SPEAKER_0:  the information.

02:29:19,394 --> 02:29:24,222
SPEAKER_1:  I would say that Joe Rogan fan base is as divided than the vaccine is the general public.

02:29:24,642 --> 02:29:25,054
SPEAKER_1:  Gotcha.

02:29:25,314 --> 02:29:28,670
SPEAKER_0:  Man, I'm gonna look for polling data on that. I'm sure somebody's gotta have done it out there, but-

02:29:28,802 --> 02:29:33,677
SPEAKER_1:  No, but you're basically revealing the fact they have no data, you're using your own judgment for sure.

02:29:33,677 --> 02:29:49,127
SPEAKER_0:  Based on how he's had conversations about his experience with the coronavirus and then based on the guests that have come on that have talked and echoed a lot of like anti-vax talking points and been completely unchallenged and then based on statements he's made about like myocarditis and the vaccine and everything as well. So it's the level of GTA.

02:29:49,127 --> 02:29:50,627
SPEAKER_1:  challenge or not that he's doing.

02:29:50,627 --> 02:29:55,870
SPEAKER_0:  Well, yeah, and then what his true positions are and then the types of guests he typically chooses to bring on to talk about the vaccines. Yeah

02:29:56,098 --> 02:30:00,062
SPEAKER_1:  Okay, but that represents somehow a deep anti-establishment.

02:30:00,450 --> 02:30:00,830
SPEAKER_1:  feeling.

02:30:01,506 --> 02:30:04,990
SPEAKER_1:  Versus just the vaccine. I mean, I've seen the vaccine and other things being.

02:30:05,986 --> 02:30:07,166
SPEAKER_1:  A thing that broke people.

02:30:07,650 --> 02:30:10,622
SPEAKER_0:  I think all the coronavirus, that whole one or two years broke.

02:30:11,106 --> 02:30:12,231
SPEAKER_0:  A lot of people.

02:30:12,231 --> 02:30:14,238
SPEAKER_1:  There's a lot of emotion and emotion quickly.

02:30:14,594 --> 02:30:16,766
SPEAKER_1:  solidified into an opinion.

02:30:17,090 --> 02:30:19,038
SPEAKER_1:  that almost had nothing to do with like...

02:30:19,298 --> 02:30:23,550
SPEAKER_1:  like thinking through and updating your knowledge that's all you just need to know.

02:30:23,682 --> 02:30:29,246
SPEAKER_0:  made up your mind. Yeah, but I think a lot of it comes from that anti-establishment place. Like what the vaccine represents, the ultimate.

02:30:29,538 --> 02:30:31,390
SPEAKER_0:  of establishment. It was a huge

02:30:31,714 --> 02:30:34,302
SPEAKER_0:  private company backed by a huge

02:30:34,658 --> 02:30:35,934
SPEAKER_0:  uh... public government

02:30:36,194 --> 02:30:45,662
SPEAKER_0:  and there's Fauci and there's Biden and there's Pfizer and there's all these countries locking us up in our homes telling us to do a thing. Like the vaccine was like the ultimate like.

02:30:45,890 --> 02:31:10,750
SPEAKER_0:  submission tool to like show you that the government owns you. Not only do you have to get injected once, it's a series. And then you gotta get boosters and it's like, they're trying to keep you under their thumb and it's, that's the control. I feel like that vaccine became like the ultimate rallying cry between like, do you support, are you a sellout that is gonna believe whatever the government tells the sheep to take, or are you gonna be like the guy that stands against the crowd and gets fired from his job and pulls his kids from school because they're not gonna let the evil Fauci medicine, you know, jab them in the arm.

02:31:11,138 --> 02:31:13,758
SPEAKER_1:  And the funny thing is the crowd that stands against.

02:31:14,690 --> 02:31:17,854
SPEAKER_1:  the institution is not larger than the crowd of sheep.

02:31:18,146 --> 02:31:19,271
SPEAKER_1:  There's like one sheep stand.

02:31:19,271 --> 02:31:22,526
SPEAKER_0:  Sure. Yeah. Or it feels that way sometimes. One vaccine.

02:31:22,658 --> 02:31:27,710
SPEAKER_1:  Well, okay, what's the defense of institutions? How do you regain the trust of institutions?

02:31:29,314 --> 02:31:31,838
SPEAKER_1:  First of all, do you think that there's ways in which?

02:31:32,290 --> 02:31:34,334
SPEAKER_1:  WHL CDC failed.

02:31:34,914 --> 02:31:39,806
SPEAKER_1:  And do you think there's criticism towards Pfizer and the big pharma companies that deserve it?

02:31:40,098 --> 02:31:41,223
SPEAKER_1:  Damn, dude, it's the pharmac-

02:31:41,223 --> 02:31:49,214
SPEAKER_0:  I'm not sure for CDC and WHO. So here's a criticism that I have of all of academia and I feel it stronger stronger every day

02:31:49,634 --> 02:31:51,070
SPEAKER_0:  I don't think it's enough.

02:31:51,522 --> 02:31:58,526
SPEAKER_0:  to be a researcher or to be correct about issues, academia needs to increase its ability to communicate.

02:31:58,850 --> 02:32:11,377
SPEAKER_0:  Um, it is just an, uh, an unbelievable, unmitigated failure that academics are unwilling to wade into the complicated topics, uh, that exists today because other people are, you know, first you call.

02:32:11,377 --> 02:32:14,206
SPEAKER_1:  me spineless and then you call me a bad communicator.

02:32:14,306 --> 02:32:17,086
SPEAKER_0:  But no, look, you're here, you're doing it, so you get props from me, okay? Good job.

02:32:17,378 --> 02:32:20,318
SPEAKER_0:  That mother- Like so many but I'm sure you've I'm sure

02:32:20,546 --> 02:32:22,494
SPEAKER_0:  that you must have.

02:32:23,202 --> 02:32:23,998
SPEAKER_0:  heard another.

02:32:24,354 --> 02:32:30,142
SPEAKER_0:  a fellow academic, a fellow colleague, expressed some amount of frustration about, like, in their specific discipline.

02:32:30,370 --> 02:32:42,270
SPEAKER_0:  They know something to be true and they know that like a lot of the messaging is like wrong or bad in the public about it, but they're never gonna step out and say anything because either one, they're very measured and careful with their tech, which they feel is incompatible with what people wanna hear or two.

02:32:42,530 --> 02:32:47,405
SPEAKER_0:  they're really worried that they might be incorrect. So they're gonna be cautious while everybody else is going out in like hardcore.

02:32:47,405 --> 02:32:54,238
SPEAKER_1:  And they also don't have the support of institutions for them to go out on a limb. Yeah, that too. So like to take risks. For example, I've heard that with.

02:32:54,786 --> 02:32:55,646
SPEAKER_1:  Lab leak theory.

02:32:55,906 --> 02:32:58,686
SPEAKER_1:  I've had a lot of biologists, viologists, friends that are like...

02:32:58,914 --> 02:33:01,022
SPEAKER_1:  Yeah, it's obviously leaked from the lab.

02:33:01,506 --> 02:33:02,558
SPEAKER_1:  Like early on.

02:33:02,946 --> 02:33:05,973
SPEAKER_0:  Oh, maybe, okay. We can fight over this one, but sorry. Let's go.

02:33:05,973 --> 02:33:08,382
SPEAKER_1:  We can fight over this. Like they.

02:33:08,674 --> 02:33:09,886
SPEAKER_1:  Okay, I should sort of.

02:33:10,658 --> 02:33:15,422
SPEAKER_1:  backstep and say like that's like you talk about shooting the shit you haven't really investigated but your gut

02:33:15,682 --> 02:33:17,374
SPEAKER_1:  Like this doesn't make any sense.

02:33:17,730 --> 02:33:19,486
SPEAKER_1:  They would never say that publicly. Of course.

02:33:20,034 --> 02:33:25,255
SPEAKER_1:  Mostly because you're saying like, what they would all say is like, we want to see data. Yeah.

02:33:25,255 --> 02:33:26,558
SPEAKER_0:  Which would be good, which is fine.

02:33:26,658 --> 02:33:37,086
SPEAKER_1:  So they're going with like, like this is too many coincidence in the same place. That's the, the logic, but they don't want to say anything because there's no data you need to have evidence. You need to have actual evidence to say one way or the other.

02:33:37,506 --> 02:33:38,174
SPEAKER_1:  There's that.

02:33:38,466 --> 02:33:45,310
SPEAKER_1:  But there's also just like you said, I mean, effective communication. You're a fan of Sean Carroll. Oh, yes.

02:33:45,570 --> 02:33:47,614
SPEAKER_0:  He's like one of the only people in this whole planet.

02:33:47,906 --> 02:33:50,302
SPEAKER_0:  that I like besides you. I love dsoc now.

02:33:50,498 --> 02:33:52,126
SPEAKER_1:  Any time Sean Carroll's brought up.

02:33:52,386 --> 02:33:53,182
SPEAKER_1:  as evidence.

02:33:53,730 --> 02:34:01,694
SPEAKER_1:  There's a smile that comes over your face. I love it. Of like joy. Of like a little kid thinking about Santa Claus. Okay, I love Sean Carroll too.

02:34:01,826 --> 02:34:19,133
SPEAKER_0:  I love Sean Carroll because I hate this divide between like you're either STEM or you're like philosophy, arts and all that other stuff. And the two worlds can never cross. And I love that it was so good at physics, but like explores and pays attention to all of the like sociological stuff too. It's so rare to find that quality in a person. He's legit.

02:34:19,133 --> 02:34:23,454
SPEAKER_1:  one of the really, really, really specialized, but you don't have to be a chancre. You can be just a little.

02:34:23,970 --> 02:34:26,078
SPEAKER_1:  better at educating another person in the.

02:34:26,498 --> 02:34:30,526
SPEAKER_1:  in the medical and the health space is somebody named Andrew Huberman, a friend of mine.

02:34:30,978 --> 02:34:33,374
SPEAKER_1:  from Stanford, he's an incredible educator.

02:34:33,986 --> 02:34:35,710
SPEAKER_1:  There's a kind of process in science.

02:34:36,290 --> 02:34:39,646
SPEAKER_1:  they usually call it review or survey papers where you basically

02:34:39,970 --> 02:34:41,918
SPEAKER_1:  summarize all that's going on.

02:34:42,178 --> 02:34:51,326
SPEAKER_1:  integrate it and like draw wisdom from it and also project like where's the discipline heading and Andrew does that basically on all these sub components of the different stuff going on in

02:34:51,554 --> 02:34:55,902
SPEAKER_1:  in neuroscience and biology, neurobiology, all that. He's able to, he does a.

02:34:56,546 --> 02:34:57,918
SPEAKER_1:  podcast called Huberman Lab.

02:34:58,146 --> 02:35:02,654
SPEAKER_1:  where he just summarizes on and is able to explain what does that actually mean for your

02:35:03,266 --> 02:35:11,646
SPEAKER_1:  for your life in terms of protocols of how to make your life better. I feel like people should be able to do that more and more. But with viral, virology and.

02:35:11,874 --> 02:35:13,598
SPEAKER_1:  Oh boy, that's a tricky one.

02:35:14,114 --> 02:35:15,262
SPEAKER_1:  That's a really tricky one.

02:35:15,586 --> 02:35:17,054
SPEAKER_0:  I wish that people could have...

02:35:17,282 --> 02:35:21,694
SPEAKER_0:  honest conversations like I attack a lot of people that do the lab leak theory stuff, but truly...

02:35:22,050 --> 02:35:29,854
SPEAKER_0:  we should be able to have that conversation publicly. It just, it always feels like the people that are having the conversation don't ever really wanna have the conversation. They're not being honest. Like, every, like.

02:35:30,210 --> 02:35:38,046
SPEAKER_0:  I'm a guy that like does his own research and it's so boring reading studies and a lot of it I can only do abstracts and like I like it's so much work.

02:35:38,402 --> 02:35:52,478
SPEAKER_0:  But I'll never ever say that about myself. I'm a guy that does his own research because every time I hear somebody say that, they don't do any research. When they say they do their own research, what they mean is they've seen one podcast and their opinion on this- What podcast is that? Definitely not mine, because if it was mine, I'm criticizing anything they say.

02:35:52,738 --> 02:35:55,646
SPEAKER_0:  But yeah, so like LabLeak is another one where it's like, well how do you know it's LabLeak?

02:35:56,194 --> 02:36:09,886
SPEAKER_0:  how do I know it's lab leak? Because Fauci lied and Hunter Biden, and it's like, okay, come on, you haven't engaged with it at all. There's really interesting research that shows there's a really strong study that shows that there's like a high degree of certainty that it came from the wet markets.

02:36:10,242 --> 02:36:23,518
SPEAKER_0:  very, very high degree of certainty. And there was an article that came out recently where it's like Senate concludes that virus actually came from the Wuhan Virology Lab or whatever. And that whole article, if you actually read it, it never says that in the article. I don't know why they tweeted it with that headline.

02:36:23,874 --> 02:36:24,318
SPEAKER_0:  Um.

02:36:24,546 --> 02:36:25,022
SPEAKER_0:  But yeah, it's.

02:36:25,314 --> 02:36:26,174
SPEAKER_0:  to back up, I'm sorry.

02:36:26,530 --> 02:36:27,454
SPEAKER_0:  I think we should have.

02:36:27,746 --> 02:36:29,278
SPEAKER_0:  Good, you should be sorry. Yeah.

02:36:29,826 --> 02:36:37,470
SPEAKER_0:  I'm not sorry actually. I get to ramble here. Okay. I'm here for a long time. I rescind my apology. Okay. I actually rescind my apology.

02:36:37,826 --> 02:36:47,486
SPEAKER_0:  We should be able to have challenging conversations about things, but you gotta, man, be well-read on both sides. Not this like, I do my own research, so I don't believe anything that Fauci says. Like, come on, dude, you can do better than that. Not you personally, but...

02:36:48,098 --> 02:36:48,478
SPEAKER_1:  Gotcha.

02:36:52,034 --> 02:36:55,198
SPEAKER_1:  So for you who don't know, that's the catch phrase.

02:36:55,810 --> 02:36:57,950
SPEAKER_1:  Gotcha. Through all tragedy.

02:36:58,210 --> 02:37:01,182
SPEAKER_1:  and triumph through all the roller coaster of life.

02:37:01,442 --> 02:37:03,070
SPEAKER_1:  Your response to it is gotcha.

02:37:04,258 --> 02:37:10,942
SPEAKER_1:  It's a election. Let me jump to that before I continue to with political discourse.

02:37:11,234 --> 02:37:19,646
SPEAKER_1:  Um, psychologically you are in a lot of heated debates and you're usually super calm under fire until you're not. Sometimes you lose your temper.

02:37:19,874 --> 02:37:21,502
SPEAKER_1:  completely. We're saying the same thing about, L A B H R Y a

02:37:21,890 --> 02:37:23,326
SPEAKER_1:  That's like your opinion, man.

02:37:23,618 --> 02:37:27,743
SPEAKER_1:  Let me ask you about your psychology. What are psychologically your strengths and weaknesses?

02:37:27,743 --> 02:37:28,702
SPEAKER_0:  or self aware about.

02:37:29,154 --> 02:37:34,526
SPEAKER_0:  I think I'm very non-judgmental, so I can entertain a lot of different thoughts without agreeing with them or condoning them.

02:37:34,754 --> 02:37:36,670
SPEAKER_0:  I think that's a really big benefit to me.

02:37:36,994 --> 02:37:39,710
SPEAKER_0:  Um, for whatever reason, I seem to be.

02:37:40,162 --> 02:37:41,854
SPEAKER_0:  like pretty calm and dealing with.

02:37:42,114 --> 02:37:48,030
SPEAKER_0:  annoying people. It's why I got promoted at the casino so fast. I could deal with like drunks or whatever. Like it just didn't affect me that much.

02:37:48,386 --> 02:37:49,918
SPEAKER_1:  What percent of the population is annoying?

02:37:51,234 --> 02:38:01,573
SPEAKER_0:  depends on how you're engaging with them. Most people aren't really annoying ever. But if you're doing like a political debate, what percentage is annoying? I guess it depends on who I'm debating and what the topic is.

02:38:01,573 --> 02:38:04,190
SPEAKER_1:  I guess I'm trying to point out the fact that sometimes.

02:38:04,482 --> 02:38:05,630
SPEAKER_1:  You can say...

02:38:06,754 --> 02:38:10,078
SPEAKER_1:  that reveals something about you if you think a large percent of people are annoying.

02:38:10,210 --> 02:38:21,982
SPEAKER_0:  Well, I would say working graveyard shift when alcohol is involved, that percentage of people goes very, very, very high. Or to be more fair, actually, it's not a high percentage, truly. But if you're a server, one bad customer can ruin the rest of your shift.

02:38:22,210 --> 02:38:26,335
SPEAKER_0:  So you only need like one or two people acting in that manner to just like totally throw you off

02:38:26,335 --> 02:38:27,550
SPEAKER_1:  and you're able to.

02:38:27,874 --> 02:38:29,790
SPEAKER_1:  At least these days, not.

02:38:30,338 --> 02:38:32,286
SPEAKER_1:  allow that one customer to throw you off.

02:38:32,450 --> 02:38:36,222
SPEAKER_0:  Yeah, I'm very much like a I noticed especially after having a son

02:38:36,482 --> 02:38:39,742
SPEAKER_0:  There's something about like six year old kids or whatever where it's like...

02:38:40,002 --> 02:38:47,358
SPEAKER_0:  If they get mad, they're never gonna be mad for that long. Like they'll move on. Like that's my mentality. I'm like a six year old kid. Like I might be mad about something, but I'll get over it in like 30 minutes or an hour.

02:38:48,194 --> 02:38:58,046
SPEAKER_0:  I'm pretty good about not carrying that through. It was very rare that I'll hold a grudge against anybody or be angry about something or really disaffected by something over the long term. That almost never happens to me.

02:38:58,466 --> 02:39:00,254
SPEAKER_1:  What are your weaknesses psychologically?

02:39:01,218 --> 02:39:03,870
SPEAKER_0:  I still have a problem with projecting.

02:39:04,386 --> 02:39:12,286
SPEAKER_0:  I think we all probably do, but like my mind onto others, it's like, if I understand this and I've said this, you should understand it and if you're not, you're dumb. That's like an issue that I-

02:39:12,514 --> 02:39:14,206
SPEAKER_0:  I still have that where I project too much.

02:39:14,690 --> 02:39:16,565
SPEAKER_1:  What about like holding grudges and stuff like that?

02:39:16,565 --> 02:39:22,014
SPEAKER_0:  I never hold grudges. I'm like the least grudgy person ever. It's kind of a meme on my community because anybody can always like come back

02:39:22,306 --> 02:39:24,862
SPEAKER_0:  Um, as long as they're acting different. Yeah. What about this?

02:39:25,090 --> 02:39:26,965
SPEAKER_1:  As long as they're acting.

02:39:26,965 --> 02:39:50,238
SPEAKER_0:  I mean, all right. The reason why I say that is because, so for instance, nobody likes this, but I have a strong stance on apologies, and then I hate them. I don't ever want to hear an apology. I don't care about them ever. They don't mean anything to me. If you did something bad, as long as you've like fixed the behavior and you're not doing that thing, then we're generally chill. So like, there's been a lot of people that have been involved in weird stuff with me, but then like they go off, they do their thing and they come back and it's like, okay, cool. As long as you don't do it again, like we're fine. Like it's all good.

02:39:51,586 --> 02:39:52,734
SPEAKER_1:  I'm sorry you feel that way.

02:39:54,274 --> 02:39:56,222
SPEAKER_1:  It's not your fault, Stephen. It's not your fault.

02:39:56,450 --> 02:39:57,086
SPEAKER_1:  Okay, gotcha.

02:39:57,634 --> 02:39:59,806
SPEAKER_1:  You've said plenty of negative stuff.

02:40:00,226 --> 02:40:02,270
SPEAKER_1:  Positive stuff, negative stuff about Hassan.

02:40:02,562 --> 02:40:07,678
SPEAKER_1:  Yeah, this is my podcast. I get to get you to force you to say positive things. What do you love?

02:40:07,970 --> 02:40:09,342
SPEAKER_1:  Oh no. I'm all about you.

02:40:09,538 --> 02:40:09,982
SPEAKER_0:  Love.

02:40:10,274 --> 02:40:15,134
SPEAKER_0:  go back to grill me on the our word stuff we can make me compliment us on this is gonna be a harder conversation

02:40:15,330 --> 02:40:17,438
SPEAKER_1:  All right. Hey, we're justoshowing obten happier.

02:40:17,666 --> 02:40:20,286
SPEAKER_1:  We're going to get you to feel emotions. Okay.

02:40:20,770 --> 02:40:24,670
SPEAKER_1:  So for people who don't know, he's another popular political streamer.

02:40:25,090 --> 02:40:26,238
SPEAKER_1:  I think you had a...

02:40:26,786 --> 02:40:36,286
SPEAKER_1:  as the kids call it, a bridge burning over Bernie Sanders. I don't know, my research is very limited on this. But what do you respect and love most about Hassan?

02:40:37,314 --> 02:40:38,526
SPEAKER_0:  He puts in a lot of work.

02:40:38,850 --> 02:40:43,326
SPEAKER_0:  when he was like growing his stream from 2000 concurrent viewers to 15,000, he was streaming like

02:40:43,714 --> 02:40:46,110
SPEAKER_0:  was like 12 hours a day, like every single day.

02:40:46,498 --> 02:40:48,446
SPEAKER_0:  So that was that. I'm gonna get a lot of work.

02:40:48,706 --> 02:40:55,081
SPEAKER_0:  Um, he does seem to be pretty good at networking and like socializing and making the correct friends and connections to continue to build his business.

02:40:55,081 --> 02:40:58,814
SPEAKER_1:  What about him as a political thinker? I know you don't think I leave him on that.

02:40:59,202 --> 02:41:00,327
SPEAKER_1:  And in that regard, what I think that's-

02:41:00,327 --> 02:41:00,894
SPEAKER_0:  Thanks for watching!

02:41:01,282 --> 02:41:02,238
SPEAKER_1:  Oh man.

02:41:02,754 --> 02:41:04,629
SPEAKER_1:  I honestly want to push back on that.

02:41:04,629 --> 02:41:05,278
SPEAKER_0:  Because... Show your face...

02:41:05,858 --> 02:41:07,838
SPEAKER_0:  I have zero respect for him as a political thinker.

02:41:08,610 --> 02:41:13,598
SPEAKER_0:  There's not going to be almost anything. So you can't- I admire the fact that-

02:41:13,986 --> 02:41:14,782
SPEAKER_0:  through no.

02:41:15,202 --> 02:41:26,279
SPEAKER_0:  actual capability or ability of his own, he manages to wind up at some of the correct answers just because he's towing the line. So that is good job for him on that. He's got a lot of correct opinions, just he has no idea why. So I think that's undeserved.

02:41:26,279 --> 02:41:29,918
SPEAKER_1:  I think that's too harsh, man. The reason I bring that up is I feel like there is-

02:41:30,754 --> 02:41:32,702
SPEAKER_1:  A deep grudge in there, somehow.

02:41:33,122 --> 02:41:33,790
SPEAKER_1:  So you're.

02:41:34,178 --> 02:41:37,694
SPEAKER_1:  the father and also since you're so old, the grandfather.

02:41:38,114 --> 02:41:39,454
SPEAKER_1:  of the uh...

02:41:39,714 --> 02:41:42,014
SPEAKER_1:  political debate on stream, on livestream.

02:41:42,306 --> 02:41:43,742
SPEAKER_1:  political debater. So

02:41:44,674 --> 02:41:46,366
SPEAKER_1:  There could be some grudge about that.

02:41:46,978 --> 02:41:53,086
SPEAKER_1:  Split that happened or not enough credit given or all that kind of stuff. I just I just think he's somebody that

02:41:53,474 --> 02:41:54,302
SPEAKER_1:  has a

02:41:55,074 --> 02:41:59,902
SPEAKER_1:  a left-leaning ideology that's different than yours. He was a Bernie supporter, right? And I guess you were not.

02:42:00,674 --> 02:42:02,654
SPEAKER_1:  Can you explain to me where the division is?

02:42:03,010 --> 02:42:06,494
SPEAKER_0:  He exemplifies everything that I absolutely hate about politics.

02:42:06,914 --> 02:42:09,118
SPEAKER_0:  Which is shallow engagement.

02:42:09,378 --> 02:42:11,422
SPEAKER_0:  uh, heavily ideologically driven.

02:42:11,842 --> 02:42:12,967
SPEAKER_0:  and you're not ideological.

02:42:12,967 --> 02:42:13,717
SPEAKER_1:  We're different

02:42:13,717 --> 02:42:14,238
SPEAKER_0:  Absolutely.

02:42:14,786 --> 02:42:18,302
SPEAKER_1:  That's what we're talking about like the free thinker in the real

02:42:18,466 --> 02:42:23,390
SPEAKER_0:  meaning of that word. Yeah, so the way, let me qualify it. Issue by issue thinking. Let me qualify what I mean when I say that.

02:42:23,618 --> 02:42:26,014
SPEAKER_0:  I spent a lot of time, unfortunate time.

02:42:26,274 --> 02:42:29,790
SPEAKER_0:  delving into the boring world of philosophy. I spent a lot of time thinking about like.

02:42:30,050 --> 02:42:33,502
SPEAKER_0:  What are my ethical positions? How do I feel about myself?

02:42:33,730 --> 02:42:40,222
SPEAKER_0:  the people around me and how that relates to the world around me. And then from all of these positions, I think you might've used the phrase first principles earlier.

02:42:40,450 --> 02:42:46,014
SPEAKER_0:  From these kind of like first principles, out of that is where all of my political positions are built out of.

02:42:46,530 --> 02:43:15,117
SPEAKER_0:  like full stop. So if you ask me a question like, how do you feel about like the right to own a firearm or how do you feel about social healthcare? Like we can walk through, well, this is how I feel about it as like a thing from the government. This is where the government gets its power. This is ethically how groups of people are supposed to function. This is morally how we relate to each other. And personally, this is how I feel like, like I'll be able to do every single political belief back there. It's not like I'm telling you, like if I were to ask Hassan, what do you feel about this political topic? He's gonna tell me what progressives are supposed to say. I don't know what he thinks about it. I don't know if he-

02:43:15,117 --> 02:43:21,310
SPEAKER_1:  Don't you think that's a cynical take? Why is he just because his views coincide with the mainstream narrative?

02:43:21,634 --> 02:43:24,574
SPEAKER_1:  mainstream viewpoints of progressive thinkers.

02:43:25,378 --> 02:43:26,782
SPEAKER_1:  Why does that mean he's not thinking?

02:43:27,554 --> 02:43:33,374
SPEAKER_0:  Because this engagement with every subject is incredibly shallow, 100% predictable. Like I could write like a-

02:43:33,986 --> 02:43:39,591
SPEAKER_0:  I could probably program a script to like give you every single potential answer you could have to any single question you could give.

02:43:39,591 --> 02:43:41,091
SPEAKER_1:  and I think that's a pretty cynical take.

02:43:41,091 --> 02:43:44,841
SPEAKER_0:  Okay, it could be the case that his brain perfectly aligns with every single mainstream

02:43:44,841 --> 02:43:46,750
SPEAKER_1:  I don't know if you know it is perfectly aligned.

02:43:47,106 --> 02:43:50,718
SPEAKER_1:  Because I think you're just taking a very select, just like streamers do of each other.

02:43:51,010 --> 02:43:52,958
SPEAKER_1:  a very select slice.

02:43:53,186 --> 02:43:54,206
SPEAKER_1:  that represents.

02:43:54,466 --> 02:43:55,678
SPEAKER_1:  the perfect alignment.

02:43:55,970 --> 02:44:02,206
SPEAKER_1:  as opposed to looking at a person struggling with ideas and thinking through ideas and then giving them a pass like a lot of people.

02:44:02,434 --> 02:44:04,350
SPEAKER_1:  Like I give you a pass on.

02:44:05,346 --> 02:44:08,542
SPEAKER_1:  just the fact that you say a lot of crazy shit on stream for drama.

02:44:09,218 --> 02:44:12,190
SPEAKER_0:  Like, which is- I don't say things for drama. It might be dramatic, but-

02:44:13,090 --> 02:44:15,870
SPEAKER_1:  I mean, you've evolved as a fish evolves.

02:44:16,162 --> 02:44:16,766
SPEAKER_1:  legs.

02:44:17,026 --> 02:44:20,798
SPEAKER_1:  You've evolved a mechanism boat which creates controversy.

02:44:21,122 --> 02:44:26,590
SPEAKER_1:  that you could say it's not intentioned, but it happens. I think the extremists kind of learn that kind of.

02:44:27,074 --> 02:44:30,142
SPEAKER_1:  So I'm sure Hassan does the same kind of stuff.

02:44:30,466 --> 02:44:33,566
SPEAKER_1:  And so like underneath it, there's still thinking being this.

02:44:33,890 --> 02:44:36,094
SPEAKER_1:  that's contending with political ideas.

02:44:36,322 --> 02:44:38,238
SPEAKER_0:  you know it's not a really good job of hiding it

02:44:38,658 --> 02:45:24,510
SPEAKER_0:  There are other political figures that I really don't like that I wouldn't say the same thing about. So like, I don't know if you have Vosh written in there. I'm like, okay, that's a person that he also split out of my community and grew up to something. And now he hates me and he's an anti-fan community. And they all hate me. Okay, tell me something you love about what my shit is. I can tell you a lot of things about Vosh. I think Vosh legitimately thinks through a lot of his political positions. I admire or did admire that he has like his own like positions he would take someone's country to people further left than him. He's got some positions that don't fit his ideology kind of at all. Like he's his own independent thinker, rhetorically he's very effective. He was willing to sit down and do research for like his debates and everything. He would spend a lot of time practicing like his rhetorical effectiveness and navigating conversations. He intentionally and purposefully built like a community that exemplified his values. Yeah, I've got a lot. I don't.

02:45:25,058 --> 02:45:27,683
SPEAKER_0:  we are completely split and hate each other now. but like I had loss like 2 years ago with most people. for witnesses she says... She says

02:45:27,683 --> 02:45:30,773
SPEAKER_1:  Why why why first of all hate is a strong what why?

02:45:30,773 --> 02:45:31,166
SPEAKER_0:  the heat.

02:45:31,554 --> 02:45:35,518
SPEAKER_0:  Okay, I don't hate him, but he hates me because we had a couple of really big debates. What happened?

02:45:35,874 --> 02:45:39,249
SPEAKER_0:  Well one had to do with whether or not you should live your values and

02:45:39,249 --> 02:45:45,613
SPEAKER_1:  Can you give me the story that's a charitable interpretation? I always give charitable interpretation. You don't. I absolutely do.

02:45:45,613 --> 02:45:46,942
SPEAKER_0:  You don't. Wait, name one time a-

02:45:47,778 --> 02:45:58,339
SPEAKER_0:  five minutes ago, you talking about Hassan. Everything I said about Hassan is true. There is no steel man there, okay? That's not charitable. That's, I'm sorry. If you can prove me wrong, I would love for you to do it. Okay.

02:45:58,339 --> 02:46:07,294
SPEAKER_1:  my gut instinct. Usually when somebody feels strongly about another person in that way, it's not coming from a place of data and reason. It's coming from a place of reason.

02:46:07,522 --> 02:46:08,734
SPEAKER_1:  from a place of emotion.

02:46:09,186 --> 02:46:16,958
SPEAKER_1:  It's coming from a place of resentment and grudge and all that kind of stuff. Yeah, I understand. There's emotions deep in there. So the gacha is hiding.

02:46:17,442 --> 02:46:20,638
SPEAKER_1:  The got you is the surface of an iceberg.

02:46:21,282 --> 02:46:23,907
SPEAKER_1:  and there's a deep ocean underneath that you yourself have not seen

02:46:23,907 --> 02:46:26,157
SPEAKER_0:  explored I disagree but I understand why

02:46:26,157 --> 02:46:28,382
SPEAKER_1:  is actually a doorway the young

02:46:28,770 --> 02:46:30,046
SPEAKER_1:  Laugh as a dory.

02:46:30,306 --> 02:46:31,431
SPEAKER_1:  for you to explore the

02:46:31,431 --> 02:46:42,974
SPEAKER_0:  I understand why you think the way you do and you should you shouldn't believe me and I understand that because if somebody told me the same thing I think you probably just really don't like this person for a reason or two.

02:46:43,330 --> 02:46:44,670
SPEAKER_0:  I understand why you think that way, okay.

02:46:45,122 --> 02:47:02,334
SPEAKER_0:  The reality is though, for any political person that I disagree with, like I can give them a fair shake. It's one of the few things I think I do exceedingly well on my stream. Even with Hassan, there's been drama that he's been involved in. And I've like very, when I'm involved in drama, he'll always throw me under the bus. But when he's involved in stuff, I'll always say like, oh, like I think Hassan was right here. Or I think that he meant this.

02:47:02,594 --> 02:47:03,006
SPEAKER_0:  Um.

02:47:03,362 --> 02:47:08,478
SPEAKER_0:  There was a thing that came up once we're on a live stream fail. He was getting roasted because he referred to somebody.

02:47:08,834 --> 02:47:10,302
SPEAKER_0:  He used the expression shitskin.

02:47:10,818 --> 02:47:11,710
SPEAKER_0:  to refer to somebody's.

02:47:12,034 --> 02:47:12,798
SPEAKER_0:  like the way they look.

02:47:13,282 --> 02:47:13,790
SPEAKER_0:  and

02:47:14,306 --> 02:47:19,038
SPEAKER_0:  I have only ever heard that in the context of 4chan people talking about like Indians or like black people.

02:47:19,618 --> 02:47:20,766
SPEAKER_0:  like it's a racial thing.

02:47:21,122 --> 02:47:22,078
SPEAKER_0:  but I could tell.

02:47:22,786 --> 02:47:28,702
SPEAKER_0:  Context and everything that he was saying he was insulting some guy. I think it was kind of like in cell virgin ever He was going for like acne skin.

02:47:29,026 --> 02:47:36,670
SPEAKER_0:  I think that's what he meant when he said it. And there were a whole bunch of people that were insulting, like, oh my God, did he just say racist term? I was like, no, I don't think he was racist. I think he was like, he was just reaching for words, and that's what came out.

02:47:36,994 --> 02:47:38,869
SPEAKER_0:  Um, so like that's an example of me being.

02:47:38,869 --> 02:47:47,166
SPEAKER_1:  But didn't you criticize them for something? I was trying to like Google why the hell you guys split up because I thought your friends you should be like

02:47:47,298 --> 02:47:50,375
SPEAKER_0:  We slid up over our Kamala Harris video, but go ahead. What were you?...

02:47:50,375 --> 02:47:53,694
SPEAKER_1:  I feel like you criticized them over something.

02:47:54,658 --> 02:48:00,205
SPEAKER_1:  And I'm, okay, this is very vague memory, but you criticize them over something and I felt that criticism wasn't.

02:48:00,205 --> 02:48:00,702
SPEAKER_0:  charitable.

02:48:01,026 --> 02:48:02,151
SPEAKER_0:  Was it Pete Buttigieg stuff?

02:48:02,151 --> 02:48:04,638
SPEAKER_1:  Yeah, Peter Buttigieg, yes, yes, yes, yes, yes. Yeah, so.

02:48:04,866 --> 02:48:09,918
SPEAKER_0:  I've said this a million times, but no amount of context or no amount of nuances is ever acceptable to people. I don't-

02:48:10,338 --> 02:48:11,774
SPEAKER_0:  Think Hasan is homophobic.

02:48:12,034 --> 02:48:21,470
SPEAKER_0:  But I think the comments made about Pete, booty judge were really homophobic. That's what he said. Yeah, and there were a lot of people making a lot of comments that made me really uncomfortable.

02:48:21,698 --> 02:48:25,237
SPEAKER_0:  about Pete Buttigieg that was insane to me.

02:48:25,237 --> 02:48:26,014
SPEAKER_1:  by

02:48:26,274 --> 02:48:27,070
SPEAKER_1:  Come to the faade.

02:48:27,618 --> 02:48:34,974
SPEAKER_0:  No, but it was an environment of progressives, all the progressives were attacking Pete, and I felt like his gayness became-

02:48:35,266 --> 02:48:37,141
SPEAKER_0:  Like the subject.

02:48:37,141 --> 02:48:38,641
SPEAKER_1:  Why throw Hassan under the bus?

02:48:38,641 --> 02:48:41,662
SPEAKER_0:  He was jumping along with all of those types of like insults

02:48:42,210 --> 02:48:43,934
SPEAKER_1:  You don't think you've done the same kind of stuff?

02:48:44,034 --> 02:48:46,439
SPEAKER_0:  If I do, call me out at it and I'll probably say I shouldn't have done that.

02:48:46,439 --> 02:48:51,779
SPEAKER_1:  what the R-word was about. That's a good call out. No, but like your friend, like you should privately tell him, right?

02:48:51,779 --> 02:48:52,190
SPEAKER_0:  Right?

02:48:52,482 --> 02:48:54,366
SPEAKER_0:  Well no, by then we were sworn enemies, so...

02:48:54,818 --> 02:48:58,558
SPEAKER_0:  So that wasn't the reason you- No, no, no. It was over a Kamala Harris video. It's war on enemies.

02:48:59,106 --> 02:49:07,934
SPEAKER_0:  He hates me. What am I supposed to... Listen, for all of these people, I will accept them back into my life if they ever want to come back in at any point in time, but usually they're the ones that are saying like... If they correct themselves, right?

02:49:08,770 --> 02:49:13,438
SPEAKER_0:  No, I'm not expecting anybody to do it. So here's the deal with Vashana-san. These are like the three, we're the three.

02:49:13,890 --> 02:49:23,011
SPEAKER_0:  Guys, none of us will talk to each other. Hassan because he won't give clout to anybody and Vash because he thinks I'm bad faith. And then neither of them will talk to me because they both hate me.  anxious

02:49:23,011 --> 02:49:26,878
SPEAKER_1:  I should go on a camping trip together. It's like brokeback mountain but three way.

02:49:27,394 --> 02:49:35,102
SPEAKER_1:  and just like rejoin, refine, refine the patient for each other. Honestly, just from the internet perspective, for me as a just stepping into this world.

02:49:35,682 --> 02:49:36,158
SPEAKER_1:  Um,

02:49:36,738 --> 02:49:45,374
SPEAKER_1:  There's some aspect to which you have a responsibility. I hate that word. You have an opportunity. I wish you guys a d-

02:49:45,858 --> 02:49:47,294
SPEAKER_1:  kind of be the beacon of like.

02:49:47,810 --> 02:49:50,435
SPEAKER_1:  uh... forgiveness and friendship and my camaraderie

02:49:50,435 --> 02:49:53,987
SPEAKER_0:  Yeah, I agree. And even if we disagree, it would be really good content for us to argue.

02:49:53,987 --> 02:49:56,990
SPEAKER_1:  Shit talk, like friends shit talk. Sure. There's a guy in there like I knew he hired me.

02:49:57,218 --> 02:49:58,526
SPEAKER_1:  Like the fact that you guys don't-

02:49:59,074 --> 02:49:59,998
SPEAKER_1:  talk to each other.

02:50:00,834 --> 02:50:03,038
SPEAKER_1:  Like I would love for you to shit talk publicly.

02:50:03,490 --> 02:50:12,286
SPEAKER_1:  with the camaraderie always there. Like there's love in the beginning, love in the end, but you beat the shit out of each other in the middle. And that's what live streaming is for, with political discourses, that's...

02:50:12,578 --> 02:50:21,822
SPEAKER_1:  That's great political discourse. Versus, I think what underlies it is some jealousy and so on. You get this many followers. bye

02:50:22,178 --> 02:50:24,053
SPEAKER_0:  I just want to make sure you're clear to your eyes. Everybody has

02:50:24,053 --> 02:50:25,726
SPEAKER_1:  to your audience.

02:50:26,114 --> 02:50:29,095
SPEAKER_1:  I'm sure you have flaws and I'm just not in this.

02:50:29,095 --> 02:50:30,590
SPEAKER_0:  It's hard to find, you know, because I'm-

02:50:30,754 --> 02:50:33,118
SPEAKER_1:  You're only flies, you're too modest. Yeah.

02:50:33,538 --> 02:50:39,486
SPEAKER_1:  So why did you guys split up? Because I would love it, honestly. Just let me just put that idea out there for you guys to.

02:50:40,258 --> 02:50:52,799
SPEAKER_0:  to make up and so yeah it's out there of course as everybody talks me Vashana son it's crazy that like the three largest like political debate left-leaning people online like can't do any type of content or collaboration at all it's so stupid

02:50:52,799 --> 02:50:55,870
SPEAKER_1:  What was the reason you guys split up? The Kamala Harris?

02:50:55,970 --> 02:51:03,582
SPEAKER_0:  So Hassan's entry into kind of like the Twitch political debate world was in, I think 2018, I think he did a debate with Charlie Kirk.

02:51:03,970 --> 02:51:16,574
SPEAKER_0:  And he reached out to me to kind of like review that debate to like go on to go over it on stream. And he came on, we went over it and then we kind of friendship developed. We hung out in real life. I think when I came to LA, I think I slept on his couch. We played with his dog. We were like kind of friends.

02:51:16,866 --> 02:51:17,310
SPEAKER_0:  Um.

02:51:18,082 --> 02:51:19,614
SPEAKER_0:  And as time went on...

02:51:20,066 --> 02:51:21,822
SPEAKER_0:  I think he was a little bit more...

02:51:22,370 --> 02:51:23,102
SPEAKER_0:  uh...

02:51:23,490 --> 02:51:34,526
SPEAKER_0:  He was farther left than he led on. So like I was a social Democrat, he was a social Democrat. But back in those days, like 2018, when people said they were a social Democrat, they really meant socialist, but they just didn't wanna say it. So he was farther left than me and we had a lot of-

02:51:34,882 --> 02:51:48,478
SPEAKER_0:  deep divides in our approach to politics. Whereas like I was very much like a first principles, this is my whole political position. And he was very much kind of like a, this is like the political ideology I'm involved in. And this is kind of like the field that I kind of like navigate in.

02:51:48,738 --> 02:51:56,510
SPEAKER_0:  So there were a couple instances where these divides would be laid very bare. One was when it was either him or the young Turks.

02:51:56,738 --> 02:51:57,566
SPEAKER_0:  I think it was him.

02:51:58,466 --> 02:51:59,838
SPEAKER_0:  There was a shooting in a neighborhood.

02:52:00,130 --> 02:52:03,166
SPEAKER_0:  where a very young black child gets killed by a white shooter.

02:52:03,650 --> 02:52:12,542
SPEAKER_0:  and they did a video about like hate crimes and how hate crimes are on the rise between races and white people are evil and blah blah blah. Not that, but like white people committing hate crimes against black people.

02:52:12,834 --> 02:52:14,398
SPEAKER_0:  And I remember saying to him, I was like...

02:52:14,946 --> 02:52:15,390
SPEAKER_0:  Hey.

02:52:15,938 --> 02:52:38,942
SPEAKER_0:  We don't have all the data yet for this. It feels really bad to make videos about this beforehand because it's the same type of shit that happens at airports. You know, is there a thing going on? Was it a brown person? Are they Muslim? It's Islamic extremism. We see this played out so many times in recent history, probably not a good idea to jump to conclusions. And he's like, well, no, you don't understand. Like it's not that big a deal, whatever. And obviously as the story goes, tale as old as time, the data comes out, it was just an errant.

02:52:39,170 --> 02:52:44,382
SPEAKER_0:  shot there was like gang violence shot goes out of nowhere hits a kid in the car it wasn't like a hate crime the guy was trying to kill a kid

02:52:44,930 --> 02:52:48,830
SPEAKER_0:  Yeah, we basically we bump up against a few kind of political disagreements like this.

02:52:49,186 --> 02:52:59,070
SPEAKER_0:  and an annoying thing is happening in my community where Hasan is like the serious political figure because he's from the Young Turks and I'm just kind of like I do politics but I also game and anytime I criticize the sun people like destiny

02:52:59,298 --> 02:53:07,173
SPEAKER_0:  you need to be more respectful he does this full-time if you're gonna bring criticisms you need to be like really well read and researched because he's got a you know more serious whatever which I thought was ridiculous

02:53:07,173 --> 02:53:09,278
SPEAKER_1:  Otherwise, if people don't know, he worked at

02:53:09,762 --> 02:53:10,887
SPEAKER_1:  the young Turks.

02:53:10,887 --> 02:53:14,398
SPEAKER_0:  which is like the largest left leaning YouTube channel probably or at least at the time.

02:53:15,458 --> 02:53:22,590
SPEAKER_0:  So finally, he did a video on... Skip ahead to some more minor discriminations. He does a video on Kamala Harris. He calls it Kamala Harris.

02:53:22,914 --> 02:53:26,174
SPEAKER_0:  and it's like seven or eight horrible things about Kamala Harris. And I'm like, okay.

02:53:26,402 --> 02:53:30,302
SPEAKER_0:  I know at least one or two of these things are not fully accurate, so I'm going to do all the research.

02:53:30,562 --> 02:53:40,638
SPEAKER_0:  I'm gonna have all the sources and we're gonna have a long conversation about it so that now when I provide criticism to him, it's not gonna be like this horrible, like just me saying something flippantly or whatever, it's gonna be like substantial criticism.

02:53:41,122 --> 02:53:41,822
SPEAKER_0:  So I was on a f-

02:53:42,050 --> 02:53:43,198
SPEAKER_0:  Plane ride.

02:53:43,650 --> 02:53:47,774
SPEAKER_0:  JFK to Orlando, whatever, flying to Sweden, is my wife.

02:53:48,002 --> 02:53:48,446
SPEAKER_0:  and

02:53:49,090 --> 02:53:53,150
SPEAKER_0:  On the plane, I review all of the video, all the data, do all the research and I write everything. It's like, okay.

02:53:53,666 --> 02:53:54,014
SPEAKER_0:  I get.

02:53:54,402 --> 02:53:55,294
SPEAKER_0:  to my arm.

02:53:55,586 --> 02:53:56,574
SPEAKER_0:  my wipes.

02:53:56,962 --> 02:53:58,622
SPEAKER_0:  Dad's house, and I'm-

02:53:59,010 --> 02:54:03,294
SPEAKER_0:  at the table, we're having a conversation like, hey, we should talk about the Kamala Harris stuff.

02:54:03,650 --> 02:54:05,982
SPEAKER_0:  And he's like, okay, well, let's do it. And we go over it.

02:54:06,306 --> 02:54:06,846
SPEAKER_0:  and

02:54:07,650 --> 02:54:21,886
SPEAKER_0:  I'll leave to the audience to watch the video. Enough people will say this, I feel pretty confident in saying this. I was pretty reasonable, pretty measured, pretty calm the whole time, and I think he started to get increasingly irritated that I was levying more and more serious criticisms at the quality of work that he did.

02:54:22,114 --> 02:54:30,014
SPEAKER_0:  Probably because he felt a little bit intimidated, I think, by my willingness to dive through political stuff. There have been a couple of awkward blubs where, like, on, um...

02:54:30,274 --> 02:54:43,934
SPEAKER_0:  there's like a show called the Raj Royale where sometimes politics would come up and Hassan would kind of try to explain something and there was another person one time in the show that made the joke it's like instead of Hassan taking 10 minutes to explain this, can Destiny just come here and explain it in 30 seconds and he like exploded that he got so

02:54:44,322 --> 02:54:45,278
SPEAKER_0:  fucking mad at that.

02:54:45,506 --> 02:54:54,942
SPEAKER_0:  Um, so yeah, I think that when I made that kind of call out or critique of him over the Kamala Harris stuff, he's probably feeling like increasingly irritated, threatened, agitated. And then that's kind of what began the huge.

02:54:55,202 --> 02:54:56,327
SPEAKER_1:  split from ours.

02:54:56,327 --> 02:54:57,438
SPEAKER_0:  think you were a dick at all.

02:54:58,114 --> 02:54:59,294
SPEAKER_0:  i don't think so that conversation

02:54:59,746 --> 02:55:01,406
SPEAKER_0:  especially given that like.

02:55:01,634 --> 02:55:03,550
SPEAKER_0:  at that point because this is still 20.

02:55:03,778 --> 02:55:05,790
SPEAKER_0:  18 or 20, this might be 2019.

02:55:06,018 --> 02:55:09,150
SPEAKER_0:  I'm still known at that point as being very aggressive.

02:55:09,378 --> 02:55:27,934
SPEAKER_0:  towards conservatives or all writers. Oh, I gotcha. Yeah, so, and with lefties is what I call them. I think I'm being like very gentle. Like my conversation starts with conservatives, like you're a fucking idiot, you're so dumb. Like that's how I'm like doing. So like with him, I'm like, well, don't you think that like, this is like a little bit of like an inconsistent presentation of how like, I feel like I'm being nice. But I always leave to the audience so they can go and watch.

02:55:28,194 --> 02:55:34,769
SPEAKER_0:  that Kamala Harris video Destiny of Sun if they think that I was being a dickhead. But a lot of people watching said I was being pretty gentle. Wow let me see.

02:55:34,769 --> 02:55:39,102
SPEAKER_1:  As a new fan of this space, I hope you guys make up and I hope.

02:55:39,394 --> 02:55:48,702
SPEAKER_1:  You guys fight it out in the space of discourse and ideas. Me too. And also with empathy, understanding what the strength of the other person is, what their buttons are and.

02:55:49,154 --> 02:55:49,982
SPEAKER_1:  You know, there's like...

02:55:50,338 --> 02:55:52,318
SPEAKER_1:  an unspoken rule that you don't press the button.

02:55:53,442 --> 02:55:54,238
SPEAKER_1:  You sure need to.

02:55:54,722 --> 02:55:56,894
SPEAKER_1:  unless you're doing it mutually and it's fun.

02:55:57,186 --> 02:56:02,302
SPEAKER_1:  because you know you just want to piss each other off so yeah that's kind of like what friends do you don't cross a certain line

02:56:02,530 --> 02:56:02,878
SPEAKER_1:  uh...

02:56:03,170 --> 02:56:05,054
SPEAKER_1:  but then other than that, you fight it out.

02:56:05,410 --> 02:56:06,494
SPEAKER_1:  Okay, let's step back.

02:56:06,850 --> 02:56:08,894
SPEAKER_1:  One other super interesting aspect.

02:56:09,346 --> 02:56:11,550
SPEAKER_1:  of your world view is your big supporter.

02:56:12,066 --> 02:56:12,734
SPEAKER_1:  of Biden.

02:56:13,666 --> 02:56:17,534
SPEAKER_1:  Can you explain what you love about Biden? Do you love Biden more than Sean Carroll?

02:56:18,530 --> 02:56:20,574
SPEAKER_0:  Sean Carroll's just like in another world of...

02:56:21,410 --> 02:56:23,285
SPEAKER_0:  I feel like I'm...

02:56:23,285 --> 02:56:26,142
SPEAKER_1:  Culturally appropriating you by saying gotcha now.

02:56:26,658 --> 02:56:27,783
SPEAKER_1:  It's so convenient.

02:56:27,783 --> 02:56:33,383
SPEAKER_0:  It's an easy word. You just I know I we're on the same wavelength. Okay, we're synchronizing. That's good I mean it is really interesting

02:56:33,383 --> 02:56:36,990
SPEAKER_1:  because even the people that support Biden usually don't say they love.

02:56:37,634 --> 02:56:39,550
SPEAKER_1:  sort of they don't support it strongly you know.

02:56:39,714 --> 02:56:40,798
SPEAKER_0:  ideologically.

02:56:41,090 --> 02:57:01,854
SPEAKER_0:  Philosophically, the reason why I like Biden is because he's really committed to this bringing the left and right together, which is something we so desperately need in the country. And his statements over and over again of like, I'm not the Democrat president or the Republican president, I'm the president of the United States. His desire to bring Republicans together to work on things like the infrastructure bill, that's...

02:57:02,498 --> 02:57:08,469
SPEAKER_0:  so incredibly needed and I have a huge amount of respect and admiration for him for trying to push through on that message.

02:57:08,469 --> 02:57:16,798
SPEAKER_1:  Do you think then it's unfortunate that he made that comment about MAGA? MAGA Republicans? Yeah, I mean I forget what the comment was but MAGA Republicans are-

02:57:17,026 --> 02:57:18,151
SPEAKER_1:  not good people kind of Anna IC

02:57:18,151 --> 02:57:20,478
SPEAKER_0:  I watched the full video and

02:57:20,802 --> 02:57:22,398
SPEAKER_0:  He's right, there is this.

02:57:22,690 --> 02:57:32,830
SPEAKER_0:  toxic aspect and it's hard to call out because they're always going to spend like, oh, he hates our Republicans. He's not. If you watch the quote, he's very specifically calling out like this, this group of people that think that the election was fraudulent.

02:57:33,122 --> 02:57:34,078
SPEAKER_0:  Is it clear?

02:57:34,370 --> 02:57:36,286
SPEAKER_0:  It is what he meant by we bring it up.

02:57:38,434 --> 02:57:38,878
SPEAKER_0:  Uh oh.

02:57:39,234 --> 02:57:47,006
SPEAKER_0:  I remember watching our stream, he was like, if you said it, yeah, that's bad. You can probably like YouTube, MAGA, Republicans, Biden. But like, it feels like it's pretty clear he's talking about the people that are like election denying.

02:57:47,906 --> 02:57:49,031
SPEAKER_0:  Too much of what's happening.

02:57:49,031 --> 02:57:51,166
SPEAKER_1:  in our country today is not.

02:57:51,522 --> 02:57:52,126
SPEAKER_0:  normal.

02:57:53,826 --> 02:57:55,966
SPEAKER_0:  Donald Trump and the migrant Republicans.

02:57:56,610 --> 02:57:58,078
SPEAKER_0:  representing extremism.

02:57:58,594 --> 02:58:00,766
SPEAKER_0:  that threatens the very foundations.

02:58:01,122 --> 02:58:02,142
SPEAKER_0:  of our republic.

02:58:03,234 --> 02:58:04,359
SPEAKER_0:  Now I want to be very clear.

02:58:04,359 --> 02:58:04,798
SPEAKER_1:  whatever

02:58:05,378 --> 02:58:06,910
SPEAKER_1:  Listen to this part.

02:58:07,618 --> 02:58:07,998
SPEAKER_1:  Thank you.

02:58:08,962 --> 02:58:10,087
SPEAKER_1:  Not every public.

02:58:10,087 --> 02:58:13,118
SPEAKER_0:  and not even the majority of Republicans are mega Republicans.

02:58:14,274 --> 02:58:16,149
SPEAKER_0:  Not every Republican embraces their exp...

02:58:16,149 --> 02:58:17,310
SPEAKER_1:  ideology.

02:58:18,082 --> 02:58:18,846
SPEAKER_1:  I know.

02:58:19,650 --> 02:58:22,526
SPEAKER_1:  because I've been able to work with these mainstream Republicans.

02:58:23,554 --> 02:58:24,798
SPEAKER_1:  But there's no question.

02:58:25,538 --> 02:58:29,534
SPEAKER_1:  that the Republican Party today is dominated, driven, and intimidated.

02:58:30,370 --> 02:58:32,638
SPEAKER_1:  by Donald Trump and the MAGA Republicans.

02:58:33,698 --> 02:58:35,902
SPEAKER_1:  And that is a threat to this country.

02:58:36,674 --> 02:58:39,486
SPEAKER_1:  I disagree with that man, he didn't clearly say...

02:58:40,258 --> 02:58:42,654
SPEAKER_1:  Extremist ideology. He didn't say the

02:58:43,362 --> 02:58:45,987
SPEAKER_1:  people that doubt the validity of the election. I mean, that's.

02:58:45,987 --> 02:58:46,558
SPEAKER_0:  Donald Trump.

02:58:47,074 --> 02:58:47,518
SPEAKER_1:  No, but-

02:58:47,778 --> 02:58:48,318
SPEAKER_1:  this.

02:58:48,450 --> 02:58:55,575
SPEAKER_0:  That's all the candidates that Donald Trump is supporting. How many, what is it like 40, 50, how many candidates right now that are mega candidates are election- NO BLESS.

02:58:55,575 --> 02:58:59,198
SPEAKER_1:  There's, you know, 80 million or whatever people voted for Donald Trump.

02:58:59,586 --> 02:59:02,078
SPEAKER_1:  You could say that's the MAGA Republicans.

02:59:02,402 --> 02:59:05,118
SPEAKER_1:  So to me, it sounded like he.

02:59:05,506 --> 02:59:06,878
SPEAKER_1:  was referring to

02:59:07,490 --> 02:59:11,262
SPEAKER_1:  Not even the majority. I mean, that's one nice, helpful clarifying.

02:59:12,002 --> 02:59:17,118
SPEAKER_1:  statement. But it's basically there's the mainstream Republicans and then there's those that voted for Donald Trump.

02:59:17,410 --> 02:59:18,398
SPEAKER_1:  That's the way I heard it.

02:59:18,658 --> 02:59:21,694
SPEAKER_0:  Okay. And it's like, so maybe you should have done a better job at clarifying, but.

02:59:22,178 --> 02:59:25,726
SPEAKER_0:  I feel like there's a clear, there is a huge problem.

02:59:26,082 --> 02:59:29,457
SPEAKER_0:  with this group of Americans that think that like the election is stolen. It feels like that's what he's trying to call.

02:59:29,457 --> 02:59:30,462
SPEAKER_1:  No matter.

02:59:31,522 --> 02:59:33,022
SPEAKER_1:  If that's what he meant.

02:59:33,762 --> 02:59:35,742
SPEAKER_1:  Even flirting with that line?

02:59:36,194 --> 02:59:38,558
SPEAKER_1:  is not a person who's bringing people together.

02:59:39,202 --> 02:59:45,822
SPEAKER_0:  I feel like extending a hand to the like, most, I've worked with Republicans in Congress, not even a majority of Republicans are like this.

02:59:46,818 --> 02:59:47,943
SPEAKER_0:  No, but why say not-

02:59:47,943 --> 02:59:50,270
SPEAKER_1:  the majority of Republicans that like this say.

02:59:50,626 --> 02:59:51,806
SPEAKER_1:  like weird like a

02:59:52,482 --> 02:59:53,406
SPEAKER_1:  one country.

02:59:53,698 --> 02:59:55,006
SPEAKER_1:  We believe the same thing. So like.

02:59:55,266 --> 02:59:57,141
SPEAKER_1:  Focus on the uniting part versus.

02:59:57,141 --> 02:59:59,518
SPEAKER_0:  He does before and after, that was 50 seconds, okay?

02:59:59,714 --> 03:00:08,830
SPEAKER_1:  You never, the point is you never say something like that. Listen, like that, you've spoken about the Bosnia speech, which is your favorite of his. I want back to it and listen to it.

03:00:09,346 --> 03:00:16,062
SPEAKER_0:  Before I move to that, just on this, it's really hard for him to call out that group of election deniers, I think, without it always feeling like. Why call them out?

03:00:16,802 --> 03:00:17,278
SPEAKER_0:  because it's

03:00:17,602 --> 03:00:20,574
SPEAKER_0:  arguably one of the most destructive forces that exist in this country today.

03:00:21,186 --> 03:00:22,302
SPEAKER_0:  Did it destroy anything?

03:00:22,946 --> 03:00:23,934
SPEAKER_1:  They're trying to.

03:00:24,322 --> 03:00:24,702
SPEAKER_1:  Did it?

03:00:25,954 --> 03:00:26,846
SPEAKER_0:  It didn't, did it?

03:00:27,330 --> 03:00:31,455
SPEAKER_0:  So does that mean we don't call it out? We wait till next time? Because calling it out is-

03:00:31,455 --> 03:00:33,534
SPEAKER_1:  is giving fuel to the division.

03:00:34,242 --> 03:00:34,558
SPEAKER_1:  Like.

03:00:34,786 --> 03:00:37,790
SPEAKER_1:  the people that doubted the validity of the election.

03:00:38,146 --> 03:00:40,670
SPEAKER_1:  That's anger, that's frustration with the other side.

03:00:40,930 --> 03:00:41,982
SPEAKER_1:  You heal that.

03:00:42,210 --> 03:00:47,198
SPEAKER_1:  as opposed to saying all those people that believed that at any time are idiots.

03:00:47,714 --> 03:00:48,766
SPEAKER_1:  They're un-American.

03:00:49,186 --> 03:00:54,430
SPEAKER_0:  I mean, they don't think the election was real. I don't know if Biden has the ears of these people at all. I don't know what he can do for.

03:00:55,042 --> 03:01:00,958
SPEAKER_1:  There's people that believe the same thing on the in 2016 with the Russian hacking, right? There's this, hold on.

03:01:01,410 --> 03:01:01,758
SPEAKER_1:  Yes.

03:01:02,626 --> 03:01:04,542
SPEAKER_0:  That is a super not fair comparison.

03:01:05,442 --> 03:01:07,454
SPEAKER_0:  They were definitely the mainstream.

03:01:07,682 --> 03:01:08,638
SPEAKER_0:  Democrat opinion.

03:01:08,994 --> 03:01:09,470
SPEAKER_0:  was that.

03:01:09,922 --> 03:01:10,654
SPEAKER_0:  Russian

03:01:11,010 --> 03:01:11,550
SPEAKER_0:  Um...

03:01:12,002 --> 03:01:14,590
SPEAKER_0:  intrusion in terms of like social media and stuff happen.

03:01:14,850 --> 03:01:20,574
SPEAKER_0:  But there was never a claim that like the election was stolen. No, or at least I don't know of any mainstream Democrat that supported that.

03:01:20,802 --> 03:01:33,886
SPEAKER_0:  Donald Trump is not just saying there was interference and blah, blah, blah. Donald Trump is literally saying the election was literally stolen, that vote boxes were, ballot boxes were hidden, that vote tallies were manipulated, that I think the claim is there's a huge gulf difference between the two.

03:01:34,018 --> 03:01:35,774
SPEAKER_1:  So you can attack Donald Trump.

03:01:37,538 --> 03:01:40,958
SPEAKER_1:  I believe it's not the words of a uniter to attack.

03:01:42,210 --> 03:01:43,774
SPEAKER_1:  people that believe that.

03:01:45,122 --> 03:01:46,622
SPEAKER_1:  You could argue maybe it's okay.

03:01:47,266 --> 03:01:49,598
SPEAKER_1:  but especially not being super clear about that.

03:01:50,018 --> 03:01:52,382
SPEAKER_1:  about who you're referring to as the MAGA Republicans.

03:01:52,674 --> 03:01:54,206
SPEAKER_1:  Okay, because MAGA

03:01:55,170 --> 03:01:56,094
SPEAKER_1:  is a hat.

03:01:57,858 --> 03:01:58,942
SPEAKER_1:  and a slogan.

03:01:59,618 --> 03:02:00,894
SPEAKER_1:  that refers to...

03:02:01,794 --> 03:02:04,990
SPEAKER_1:  Whatever the number is, 70 million people, however, that voted for Donald Trump.

03:02:05,858 --> 03:02:06,206
SPEAKER_1:  Like.

03:02:06,338 --> 03:02:11,134
SPEAKER_0:  all the Republicans that consider themselves mega Republicans, what percentage of them do you think believe the election was stolen?

03:02:12,386 --> 03:02:15,582
SPEAKER_0:  I feel like that number is, I don't have the pump, I feel like the number is like probably more than 70%.

03:02:17,058 --> 03:02:18,933
SPEAKER_1:  What's a mega Republican? Maybe-

03:02:18,933 --> 03:02:22,270
SPEAKER_0:  Maybe I'm not from the- Like a Trump-supporting Republican, a MAGA Republican, they're there for Trump.

03:02:23,202 --> 03:02:27,239
SPEAKER_1:  What's the difference between somebody that voted for Trump and a MAGA Republican and a MAGA Republican?

03:02:27,239 --> 03:02:30,334
SPEAKER_0:  So my mom is a MAGA Republican.

03:02:30,722 --> 03:02:38,750
SPEAKER_0:  If Trump ran independently and DeSantis ran under the Republican ticket, my mom would vote for Trump. She'll follow him to the end of the earth. That's like a MAGA Republican.

03:02:38,914 --> 03:02:41,502
SPEAKER_1:  I think it's easy to mistake that distinction.

03:02:42,178 --> 03:02:43,806
SPEAKER_1:  in these kinds of political speeches.

03:02:44,098 --> 03:02:46,142
SPEAKER_1:  As to me, anybody who voted for Trump.

03:02:46,754 --> 03:02:51,422
SPEAKER_1:  can easily in the context of the speech be interpreted as a republicn

03:02:51,842 --> 03:02:52,222
SPEAKER_0:  Gotcha.

03:02:55,074 --> 03:02:58,430
SPEAKER_0:  I understand what you're saying. Maybe you could have been more clear, but I think in listening to that...

03:02:58,658 --> 03:02:59,038
SPEAKER_0:  like

03:02:59,746 --> 03:03:05,959
SPEAKER_0:  I think it's pretty obvious who he's talking about, but I guess if you have an emotional response to it, I can understand the emotional response, but there's a lot of people- I don't have a-

03:03:05,959 --> 03:03:07,646
SPEAKER_1:  I just don't like.

03:03:07,970 --> 03:03:12,734
SPEAKER_1:  I think I'm with, what is it, Michelle Obama. They go low, we go high.

03:03:13,442 --> 03:03:14,270
SPEAKER_1:  Meaning like...

03:03:14,722 --> 03:03:18,366
SPEAKER_1:  To me, a uniter doesn't participate in derision.

03:03:18,530 --> 03:03:24,905
SPEAKER_0:  Sure, a uniter might not, but a leader has to be able to accurately assess the situation before him and make people aware of what's going on. You mean all

03:03:24,905 --> 03:03:30,110
SPEAKER_1:  the impeachment trials, all the censoring from social media, all of that didn't do the job.

03:03:30,402 --> 03:03:33,342
SPEAKER_0:  That's not his job. I don't know about censoring any of that. Maybe.

03:03:33,506 --> 03:03:36,286
SPEAKER_1:  His job is to inspire a nation to unite a nation.

03:03:36,834 --> 03:03:39,678
SPEAKER_0:  How can he do that when half the people don't believe that he was even legitimately elected?

03:03:40,194 --> 03:03:47,966
SPEAKER_0:  Like I think he's done a good job at working on legislation and doing stuff that hopefully benefits all Americans, but I think it's important to recognize that like there is a contingent of Americans that

03:03:48,386 --> 03:03:50,261
SPEAKER_0:  Don't even believe it. Like this is really crazy.

03:03:50,261 --> 03:03:54,846
SPEAKER_1:  I find you have people that recognize that and are fighting that and are constantly screaming that from the rooftops.

03:03:55,234 --> 03:03:55,934
SPEAKER_1:  His job.

03:03:56,642 --> 03:03:59,198
SPEAKER_1:  is to be the inspiring figure.

03:03:59,554 --> 03:04:03,678
SPEAKER_1:  that makes the majority of Americans be proud for him to be a president.

03:04:04,194 --> 03:04:05,630
SPEAKER_1:  of the nation they love.

03:04:05,954 --> 03:04:08,414
SPEAKER_1:  And that's what the uniting aspect is.

03:04:08,706 --> 03:04:10,718
SPEAKER_1:  is you remind people.

03:04:11,074 --> 03:04:14,449
SPEAKER_1:  that we are one and we love this country. I love the ideas that it represents.

03:04:14,449 --> 03:04:17,246
SPEAKER_0:  Should be does that another press that speech like a 20 minute speech, isn't it?

03:04:17,506 --> 03:04:18,558
SPEAKER_1:  But that's a fuck up.

03:04:19,074 --> 03:04:28,446
SPEAKER_1:  You just don't participate in that division. Anyway, I understand. I understand. I just wanted to push back on the saying one of his strengths is that he's a...

03:04:29,794 --> 03:04:31,230
SPEAKER_1:  He's uniting, but yes.

03:04:31,650 --> 03:04:32,062
SPEAKER_1:  that

03:04:33,154 --> 03:04:38,718
SPEAKER_1:  That is an ideal, that is a goal, is a great one, and he is one that espouse that goal.

03:04:39,266 --> 03:04:41,022
SPEAKER_1:  for a long time. Do you think...

03:04:41,698 --> 03:04:44,062
SPEAKER_1:  What else? From policy perspective and so on.

03:04:44,546 --> 03:04:48,702
SPEAKER_0:  I thought the way he's handled Ukraine and everything thus far has been almost perfect. I think he did a really good job.

03:04:49,250 --> 03:04:56,606
SPEAKER_0:  and at the political maneuvering of bringing other countries into the fold, at establishing clearly like what our mission was in relation to Ukraine. I thought you did a good job there.

03:04:56,962 --> 03:05:04,126
SPEAKER_0:  I admire him for pulling out of Afghanistan. Even it was a little bit rough around the edges, like we got out and we're gone. No American loss or lost.

03:05:05,026 --> 03:05:09,534
SPEAKER_0:  the domestic policies passed more major legislation than I think anybody thought possible.

03:05:09,826 --> 03:05:12,926
SPEAKER_0:  the green energy stuff for the last bill, the infrastructure bill.

03:05:13,282 --> 03:05:17,406
SPEAKER_0:  A lot of the coronavirus relief I thought was really good, especially the expansion of the child tax credit.

03:05:17,634 --> 03:05:22,590
SPEAKER_0:  So from a policy perspective, foreign and domestic, I think he's been successful. Rhetorically, I think he's been successful.

03:05:23,106 --> 03:05:26,302
SPEAKER_0:  generally been above board in terms of like not attacking people being too divisive.

03:05:26,530 --> 03:05:28,510
SPEAKER_0:  He's trying to bring people together and work on them.

03:05:28,866 --> 03:05:30,142
SPEAKER_1:  What do you think about the sort of?

03:05:30,562 --> 03:05:31,710
SPEAKER_1:  popular in the media.

03:05:32,258 --> 03:05:34,014
SPEAKER_1:  criticism of his mental decline.

03:05:34,338 --> 03:05:36,478
SPEAKER_1:  Do you think he's experiencing much of his life?

03:05:37,346 --> 03:05:39,262
SPEAKER_1:  What do you think? Spellingcheese

03:05:40,034 --> 03:05:40,958
SPEAKER_0:  Yeah, maybe a little bit.

03:05:41,250 --> 03:05:43,006
SPEAKER_0:  But he's still doing a good job, so, you know.

03:05:43,330 --> 03:05:45,205
SPEAKER_1:  not from a speech perspective, you mean from a...

03:05:45,205 --> 03:05:52,318
SPEAKER_0:  Yeah, I'm analyzing it as a job. Yeah, from a speech perspective, maybe not the greatest, but yeah, I mean, he's definitely what is he like 8081? How old is he?

03:05:52,482 --> 03:05:54,590
SPEAKER_1:  I lose track after so many years. Yeah.

03:05:56,258 --> 03:05:59,701
SPEAKER_1:  But you did say that he's probably going to run in 2024.

03:05:59,701 --> 03:06:00,638
SPEAKER_0:  he's probably going to win.

03:06:01,186 --> 03:06:04,766
SPEAKER_0:  Did I say that? That he's probably going to win? No way. Did I say that? He's probably going to run.

03:06:05,250 --> 03:06:15,614
SPEAKER_0:  who knows who will win. But I think, I feel like the incumbent advantage is so strong. You really gonna throw that away? Like, there's been like one or two times in history in the US, right, where like the non-incumbent, the parties put somebody else up.

03:06:16,194 --> 03:06:16,702
SPEAKER_0:  Yeah.

03:06:16,802 --> 03:06:20,094
SPEAKER_1:  I mean, the concern is like the, just the age and the.

03:06:20,578 --> 03:06:22,622
SPEAKER_1:  the metal decline, just the...

03:06:23,426 --> 03:06:25,630
SPEAKER_1:  the wear and tear of the campaign.

03:06:25,986 --> 03:06:32,222
SPEAKER_1:  All of that kind of stuff. All of the speech you have to make, the debates and all that kind of stuff. Yeah, I guess we'll see what happens.

03:06:32,514 --> 03:06:32,862
SPEAKER_0:  What?

03:06:33,122 --> 03:06:39,134
SPEAKER_0:  the least excited uh i mean two years when i was a long time and his current mental state yeah he could run and

03:06:39,938 --> 03:06:41,662
SPEAKER_0:  You could do a possible job in two years.

03:06:42,050 --> 03:06:45,118
SPEAKER_0:  Man, I don't know. I've seen videos of Bill Clinton recently. He's looking pretty rough.

03:06:45,570 --> 03:06:47,710
SPEAKER_0:  Um, you know, if Biden is looking a lot more rough.

03:06:48,290 --> 03:06:52,670
SPEAKER_0:  worse for wear in two years then maybe they actually do have to dig out another person.

03:06:53,122 --> 03:06:54,494
SPEAKER_0:  uh... for running out

03:06:56,706 --> 03:06:57,598
SPEAKER_1:  What do you think about?

03:06:57,922 --> 03:06:58,366
SPEAKER_1:  Trump.

03:06:58,914 --> 03:06:59,358
SPEAKER_1:  When

03:06:59,810 --> 03:07:02,302
SPEAKER_1:  He won in 2016, I think is when you...

03:07:03,170 --> 03:07:08,862
SPEAKER_1:  came to fruition politically speaking. So what do you think is winning the 2016 election?

03:07:09,506 --> 03:07:10,398
SPEAKER_1:  represents.

03:07:11,426 --> 03:07:12,382
SPEAKER_0:  So for me.

03:07:13,410 --> 03:07:18,142
SPEAKER_0:  Trump, the reason why I got into politics was Trump was like this new.

03:07:18,882 --> 03:07:22,206
SPEAKER_0:  epistemic force in American politics that like

03:07:22,626 --> 03:07:26,974
SPEAKER_0:  You kind of have to like flirt with facts before, even if you wanted to be non-factual.

03:07:27,650 --> 03:07:28,670
SPEAKER_0:  Super didn't care.

03:07:28,930 --> 03:07:32,382
SPEAKER_0:  Lying was like a first language to him, just like in speaking in terms of like...

03:07:32,610 --> 03:07:40,830
SPEAKER_0:  the the way that he used language to just say to you what he felt like you needed to hear to support him and not care at all about what is going on about.

03:07:41,058 --> 03:07:44,542
SPEAKER_0:  Yeah, that's what Trump represented to me in terms of like

03:07:44,898 --> 03:07:53,022
SPEAKER_0:  things that I cared about. He also represents a lot more, obviously, that there was this undercurrent of American opinion that a lot of people didn't know still existed, and it did, he got elected.

03:07:53,282 --> 03:07:57,246
SPEAKER_0:  uh... that the overton window was misidentified by even a large amount of the republican party

03:07:57,506 --> 03:08:00,894
SPEAKER_0:  that populism was a lot more popular than a lot of people figured, you know?

03:08:01,314 --> 03:08:02,910
SPEAKER_0:  Yeah, there's a lot that I guess you represent on you.

03:08:03,106 --> 03:08:04,990
SPEAKER_1:  Do you think Trump should have been banned from Twitter?

03:08:06,338 --> 03:08:10,581
SPEAKER_1:  Can you make the case for and against it? So you're a big supporter of free speech. Yeah.

03:08:10,581 --> 03:08:11,070
SPEAKER_0:  So.

03:08:11,586 --> 03:08:13,461
SPEAKER_0:  The case in favor of it.

03:08:13,461 --> 03:08:14,430
SPEAKER_1:  should be brought back.

03:08:15,618 --> 03:08:16,478
SPEAKER_0:  der

03:08:16,770 --> 03:08:19,422
SPEAKER_0:  Yeah, because if he gets brought back, there's a higher chance that I'll be brought back, so.

03:08:19,650 --> 03:08:21,438
SPEAKER_0:  supporting that all the way. Thank you, Elon.

03:08:21,762 --> 03:08:22,887
SPEAKER_0:  unban my account.

03:08:22,887 --> 03:08:23,390
SPEAKER_1:  Hahaha

03:08:24,386 --> 03:08:25,630
SPEAKER_1:  because he called me.

03:08:25,858 --> 03:08:27,733
SPEAKER_1:  weak spine I'm gonna have to message you

03:08:27,733 --> 03:08:32,414
SPEAKER_0:  on. Okay, at Omnidestiny, it was a verified Twitter account. Omnidestiny. No, no, I'm just kidding.

03:08:32,578 --> 03:08:36,926
SPEAKER_1:  Why'd you get banned from Twitter, Destiny? I don't know. I'll add that to Elon.

03:08:37,250 --> 03:08:39,454
SPEAKER_1:  I saw that there was a screenshot.

03:08:39,714 --> 03:08:40,414
SPEAKER_1:  of you.

03:08:41,218 --> 03:08:43,843
SPEAKER_1:  referring to the rape of somebody

03:08:43,843 --> 03:08:46,843
SPEAKER_0:  Okay, that was on an older Twitter account and that was a bad tweet.

03:08:46,843 --> 03:08:49,886
SPEAKER_1:  multiple Twitter accounts.

03:08:50,274 --> 03:08:52,158
SPEAKER_1:  go around the bands that you keep getting.

03:08:52,354 --> 03:08:53,182
SPEAKER_0:  Okay, hold on.

03:08:53,538 --> 03:09:02,974
SPEAKER_0:  You're slandering me a lot right now. Let's get the facts straight. I don't even remember why my first time I got banned, but it was a wild account. I tweeted some wildly inappropriate things. Do you regret?

03:09:03,330 --> 03:09:09,566
SPEAKER_0:  I don't like that word. I'm gonna give the answer that most people give. It's like, I don't regret it, because I learned a lot. So I'm glad I had the bad experiences that I did. Why don't you like the word regret?

03:09:10,178 --> 03:09:10,558
SPEAKER_0:  I think.

03:09:11,074 --> 03:09:12,798
SPEAKER_0:  If we look at where we are.

03:09:13,762 --> 03:09:14,750
SPEAKER_0:  How do you feel about determinism?

03:09:17,570 --> 03:09:25,859
SPEAKER_0:  I believe in the hardest of determinism. That's who I am, okay? So who I am today is the culmination of everything that's occurred in the past. I believe-

03:09:25,859 --> 03:09:28,030
SPEAKER_1:  I believe you speaking out, sorry, it's an inter...

03:09:28,258 --> 03:09:29,630
SPEAKER_1:  I believe in you.

03:09:30,402 --> 03:09:33,470
SPEAKER_1:  Speaking about regret is a nice way to communicate.

03:09:34,178 --> 03:09:37,886
SPEAKER_1:  in this deterministic world, you've analyzed the acts of the past.

03:09:38,178 --> 03:09:42,467
SPEAKER_1:  and you're no longer that person. Yeah, of course, for sure. That's what regret you.

03:09:42,467 --> 03:09:48,525
SPEAKER_0:  Okay, thanks for giving me the human explanation. Okay, true. So in that sense, there's a lot of things I've done that I regret.

03:09:48,525 --> 03:09:50,238
SPEAKER_1:  What are you? You're not human, you're a bot?

03:09:51,330 --> 03:09:53,246
SPEAKER_0:  NPC is my preferred. Game is a cod Yumother.

03:09:53,538 --> 03:09:58,622
SPEAKER_0:  I wish I would have been smart enough at the time to not have to have made those mistakes.

03:09:58,882 --> 03:10:03,774
SPEAKER_0:  There we go. Good job. But yeah, obviously really dumb, really crazy off the wall tweets.

03:10:04,002 --> 03:10:06,718
SPEAKER_0:  But that account got banned, but then I made another account.

03:10:08,450 --> 03:10:21,278
SPEAKER_0:  I can't believe I'm giving you a history of my Twitter accounts. But another account called Omnidestiny. It's an honor. And that was my, I got verified. I was cool. They let me have that account because originally they banned it. And I said, appeal. And I was like, oh, let me have one more. And back then, Twitter was cool. And they're like, OK, go for it.

03:10:21,538 --> 03:10:27,422
SPEAKER_0:  And that account lasted for a long time. And I don't actually know 100% why that account got banned.

03:10:27,906 --> 03:10:33,054
SPEAKER_0:  I believe that the tweet that showed up in the final, I got banned for hate speech.

03:10:33,346 --> 03:10:34,622
SPEAKER_0:  And it was because I was

03:10:34,946 --> 03:10:36,254
SPEAKER_0:  There was a picture that I tweeted.

03:10:36,482 --> 03:10:44,830
SPEAKER_0:  with three different alt-righters that are kind of like neo-Nazi people, and they were all like mixed race people. And I said like, alt-right looks like a Disney Channel original movie.

03:10:45,154 --> 03:10:48,830
SPEAKER_0:  in terms of racial composition. And somehow they got flagged for...

03:10:49,058 --> 03:10:57,630
SPEAKER_0:  instigating violence against minorities, I think. And I think that's the tweet that got me banned, because I think that's what showed up in the final report. But I don't know, maybe there were other reasons because nobody ever communicates, but.

03:10:57,858 --> 03:10:59,198
SPEAKER_0:  Ever since that account went under.

03:10:59,490 --> 03:11:01,118
SPEAKER_0:  It's just been renovating ever since, so.

03:11:02,178 --> 03:11:12,894
SPEAKER_0:  I'll ban evading ever since. So all my new accounts that I'm gonna ban just get banned because they finally figure out it's me and then they ban evade. There's like one dude at Twitter HQ who's like constantly looking for my new accounts and then they get me.

03:11:14,274 --> 03:11:15,006
SPEAKER_0:  Anyway, yeah.

03:11:15,234 --> 03:11:16,574
SPEAKER_0:  So post...

03:11:17,250 --> 03:11:22,846
SPEAKER_0:  Post Trump world. Do you think, okay, I mean this- Oh, should he be banned? Oh, you asked me to make both cases.

03:11:23,106 --> 03:11:23,518
SPEAKER_0:  um...

03:11:24,130 --> 03:11:24,926
SPEAKER_0:  Should he be banned?

03:11:25,218 --> 03:11:39,742
SPEAKER_0:  I mean damn dude, when you're tweeting out shit that's arguably leading to stuff like January 6th, I can understand why, because it's like, what else is this wild dude going to tweet out? Like is he going to start instigating other violent events? So I'm sympathetic towards the like, okay, well he can't just be here saying stuff like this, that's insane, we're going to ban him.

03:11:40,130 --> 03:11:43,358
SPEAKER_0:  I'm some of those instigating. Yeah, you're instigating.

03:11:43,522 --> 03:11:44,647
SPEAKER_1:  violence in the

03:11:44,647 --> 03:11:48,094
SPEAKER_0:  physical world. Yeah, like if I were to tweet stuff like that, I would get banned probably.

03:11:48,706 --> 03:11:49,566
SPEAKER_0:  On the flip side.

03:11:49,890 --> 03:11:57,118
SPEAKER_0:  This is the president of the United States. It seems like he's like doing presidential decree by social media sometimes. Like is it really right that one public.

03:11:57,602 --> 03:12:00,190
SPEAKER_0:  or private, I should say, one private company can...

03:12:00,898 --> 03:12:06,238
SPEAKER_0:  like erase the president of the United States words from the eyes of a lot of Americans that are using these social media feeds.

03:12:06,690 --> 03:12:08,062
SPEAKER_0:  And one big one.

03:12:08,546 --> 03:12:10,302
SPEAKER_1:  which I for sure am against.

03:12:10,914 --> 03:12:12,062
SPEAKER_1:  is the permanent ban.

03:12:12,706 --> 03:12:16,734
SPEAKER_0:  Yeah, I don't like that. I hate that. Even in my community, if somebody comes back over like a year...

03:12:16,866 --> 03:12:19,491
SPEAKER_1:  I mean, did you just compare yourself to the president?

03:12:19,491 --> 03:12:21,918
SPEAKER_0:  No, I can find myself to Twitter banning the president of the United States.

03:12:22,178 --> 03:12:25,150
SPEAKER_0:  Let me put it this way, if I ban Donald Trump in my chat room, I don't ban him in a year.

03:12:26,082 --> 03:12:26,782
SPEAKER_1:  A year.

03:12:27,330 --> 03:12:30,750
SPEAKER_1:  What's the process for unbanning Donald Trump? What would he have to do?

03:12:31,010 --> 03:12:35,454
SPEAKER_0:  Usually people send me an email and they're like, listen, I did this stuff, I'm sorry I was dumb. I'll give them another chance.

03:12:35,714 --> 03:12:38,078
SPEAKER_1:  But a year, what if they send an email a month later?

03:12:38,626 --> 03:12:39,486
SPEAKER_0:  Use the Alabana.

03:12:39,778 --> 03:12:48,894
SPEAKER_0:  That's actually my problem. I ban pretty quickly in my community, but if you ever ask me to come back. You're a big softy. Yeah, I usually let them back, yeah. Well, because I used to be the worst type internet person and I think I'm.

03:12:49,154 --> 03:12:57,073
SPEAKER_0:  a little bit better than I used to be. Now that you're older. Yeah, now that I've matured, yeah, of course. Age bestows a wisdom that just can't be gotten any other way. What's your?

03:12:57,073 --> 03:13:00,926
SPEAKER_1:  sense in general is there something interesting you could say about your view on free speech?

03:13:01,282 --> 03:13:03,518
SPEAKER_1:  It seems like one of those terms it's also over.

03:13:03,906 --> 03:13:06,750
SPEAKER_1:  Overused to mean a lot of different things. What does it mean to you?

03:13:06,882 --> 03:13:09,758
SPEAKER_0:  if you have a democratic style of governance.

03:13:09,986 --> 03:13:11,646
SPEAKER_0:  You are interesting people.

03:13:11,906 --> 03:13:21,470
SPEAKER_0:  with one of the most awesome and radical of responsibilities. And that's saying that you're going to pick the people that are gonna make some of the hardest decisions in all of human history. If you're gonna trust people.

03:13:21,698 --> 03:13:25,630
SPEAKER_0:  vote correctly, you have to be able to trust them to have open and honest dialogue with each other.

03:13:25,890 --> 03:13:47,582
SPEAKER_0:  whether that's Nazis or KKK people or whoever talking, you have to believe that your people are going to be able to rise above and make the correct determinations when they hear these types of speeches. And if you're so worried that somebody is gonna hear a certain political figure and they're gonna be completely radicalized instantly, then what that tells me is that you don't have enough faith in humans for democracy to be a viable institution, which is fine.

03:13:47,842 --> 03:13:52,190
SPEAKER_0:  You can be anti-democratic, but I don't think you can be pro-democracy and anti-free speech.

03:13:52,738 --> 03:13:53,502
SPEAKER_0:  within reason.

03:13:53,922 --> 03:13:55,797
SPEAKER_1:  So what's the within reason? Hi I'm

03:13:55,797 --> 03:14:03,902
SPEAKER_0:  You can't post like child porn or something on Twitter, where people try to get you on that stuff. Or like direct calls to violence are probably not, you shouldn't be tweeting out like, meet up tomorrow and go bomb, blah, blah, blah.

03:14:04,002 --> 03:14:07,646
SPEAKER_1:  So do you think it's okay to allow racism and anti-semitism and...

03:14:08,386 --> 03:14:09,502
SPEAKER_1:  I hate speech.

03:14:10,946 --> 03:14:13,374
SPEAKER_0:  Hate speech, yes, because that's.

03:14:13,634 --> 03:14:14,814
SPEAKER_0:  can be very broadly defined.

03:14:15,042 --> 03:14:19,966
SPEAKER_0:  I can understand there being some basic rules of like no slurs on like a platform.

03:14:20,322 --> 03:14:25,310
SPEAKER_0:  that gets into like acceptable forms of moderation or like excessive harassment and bullying I can understand.

03:14:25,570 --> 03:14:26,814
SPEAKER_0:  But past that...

03:14:27,234 --> 03:14:33,723
SPEAKER_0:  when the moderation becomes ideological, I get a little bit nervous because there's a whole other-

03:14:33,723 --> 03:14:36,318
SPEAKER_1:  Yeah, of course it's all a gray area, but...

03:14:36,770 --> 03:14:39,998
SPEAKER_1:  when it feels like ideology has seeped into the censorship.

03:14:40,290 --> 03:14:41,214
SPEAKER_1:  Not good. Yeah.

03:14:41,602 --> 03:14:46,238
SPEAKER_1:  which it's so fascinating to think, especially now that Elon bought Twitter, how do you-

03:14:46,722 --> 03:14:48,158
SPEAKER_1:  Engineer a system.

03:14:48,578 --> 03:14:49,182
SPEAKER_1:  that

03:14:49,922 --> 03:14:51,614
SPEAKER_1:  prevents ideology from seeping in.

03:14:52,162 --> 03:14:53,694
SPEAKER_1:  and nevertheless is able to.

03:14:54,498 --> 03:15:00,510
SPEAKER_1:  Create a platform that has healthy conversations because if you have one guy who's just screaming nonsense non-stop

03:15:01,570 --> 03:15:02,622
SPEAKER_1:  It has this effect.

03:15:02,946 --> 03:15:06,046
SPEAKER_1:  where the quiet voices at the back of the room are silenced. Yeah.

03:15:06,530 --> 03:15:06,910
SPEAKER_1:  like.

03:15:07,330 --> 03:15:10,014
SPEAKER_1:  That's what you usually don't talk about. Like if you let-

03:15:10,242 --> 03:15:16,318
SPEAKER_1:  one annoying, loud person in, that's actually censoring the voice of a lot of people that would like to speak, but they don't get a chance.

03:15:16,418 --> 03:15:39,710
SPEAKER_0:  That's one of the things, especially around trans discourse, I have to constantly do that reminder for my audience. So when I'm dealing with these types of people on the internet, a lot of them might seem really crazy, a lot of these types of people might seem insane, but in the real world, outside of the crazy Twitter activist world, the vast majority of people you're meeting from LGBT communities are the coolest, normalist people. All they want is the right to live their life in the way they want to and to be unobstructed. And like, yeah.

03:15:40,066 --> 03:15:48,894
SPEAKER_0:  but people will get this impression of like an online activist, like a vegan or LGBT person or whatever. And then they think that every single person in real life is like that. And it's a really negative.

03:15:49,154 --> 03:15:51,710
SPEAKER_0:  stereotype and then even the other people in that group.

03:15:52,354 --> 03:15:53,470
SPEAKER_1:  Oh, is Maria coming over?

03:15:53,730 --> 03:15:54,814
SPEAKER_1:  Oh yeah, I don't know if that's her.

03:15:55,426 --> 03:15:58,590
SPEAKER_1:  Okay, Malina just joined us. What were we talking about?

03:15:58,786 --> 03:16:01,054
SPEAKER_0:  Was it interesting? You were saying that-

03:16:01,410 --> 03:16:09,566
SPEAKER_0:  You were going to talk to Elon about getting at Omni destiny, the verified Twitter account on ban. I said that so it sounds like a lot. That's so gracious of you. I can't even believe you would do that for me.

03:16:09,666 --> 03:16:14,942
SPEAKER_1:  And then you admitted that you tried to evade the band multiple times, which I'm sure would be very looked up.

03:16:15,330 --> 03:16:21,342
SPEAKER_0:  You know, I heard that in Norway, in their prison system, they don't actually punish you for trying to escape jail because that's like the natural human thing to do. They hug you?

03:16:21,858 --> 03:16:30,483
SPEAKER_0:  I don't know if they but they don't punish you because of course you're trying to be free That's all I'm trying to be on Twitter. I'm just trying to be free. Well, that's the natural human Yeah, that's the natural human of course, it's the Banyan Man

03:16:30,483 --> 03:16:31,233
SPEAKER_1:  destructive force.

03:16:31,233 --> 03:16:38,398
SPEAKER_0:  You know, I'm a positive a force for good. That's right. Oh my console to get banned for bad new vanishing I don't get banned for doing bad things. And I'm progressive show. I'm like far left.

03:16:38,754 --> 03:16:39,294
SPEAKER_0:  I love.

03:16:40,162 --> 03:16:42,846
SPEAKER_1:  progressive process that this is what you criticize us on for being.

03:16:43,778 --> 03:16:52,291
SPEAKER_0:  I show them from a place of first principles, not from a mindless AI echoing kind of thing, you know? Okay. So you're a free thinking bot. Yeah, exactly.

03:16:52,291 --> 03:16:55,646
SPEAKER_1:  Well, I'm sure we'll return to some politics. That was beautiful.

03:16:55,970 --> 03:16:56,414
SPEAKER_1:  Heh.

03:16:56,674 --> 03:16:58,366
SPEAKER_1:  Malia, can you tell us about...

03:16:58,786 --> 03:17:00,414
SPEAKER_1:  yourself you're also a fellow streamer.

03:17:00,770 --> 03:17:04,638
SPEAKER_0:  Yes. I stream and I started streaming because I met him basically.

03:17:04,866 --> 03:17:06,590
SPEAKER_0:  Kind of, but I don't do the politics.

03:17:06,850 --> 03:17:07,966
SPEAKER_0:  I do like travels.

03:17:08,290 --> 03:17:09,566
SPEAKER_0:  or talk about relationships.

03:17:10,434 --> 03:17:12,094
SPEAKER_0:  to my audience basically.

03:17:12,226 --> 03:17:17,101
SPEAKER_1:  You're from that part of the world, right? Sweden. Yeah. So did you escape from prison and they didn't?

03:17:17,101 --> 03:17:20,851
SPEAKER_0:  That was Norway. That was different.

03:17:20,851 --> 03:17:25,406
SPEAKER_1:  really I've been to Sweden a bunch of times. I love it. There's a tech sector that that's really

03:17:25,858 --> 03:17:27,454
SPEAKER_1:  Like flourishing. Where did you go?

03:17:27,714 --> 03:17:29,214
SPEAKER_1:  Which city? Stop.

03:17:29,474 --> 03:17:34,206
SPEAKER_1:  I think I gave a few lectures there. There's a vibrant tech sector, it was cool. And people are super nice.

03:17:34,914 --> 03:17:35,358
SPEAKER_1:  Yeah.

03:17:35,682 --> 03:17:40,382
SPEAKER_0:  We're friendly. We're not like very deep. Like we're not really how much deep conversation is like a meadow.

03:17:40,482 --> 03:17:43,294
SPEAKER_1:  There's not many intellectuals that come from Sweden.

03:17:43,490 --> 03:17:49,182
SPEAKER_0:  We don't really speak very highly of ourselves, we kind of like just chill all the time. We don't make a scene, we don't, we're just like...

03:17:49,506 --> 03:17:50,270
SPEAKER_0:  You know

03:17:50,594 --> 03:18:12,382
SPEAKER_0:  Do you know what the name for that is? There's a specific name for it. Jan Delagen. Yeah, Delagen. Yeah, Jan Delagen, yeah. Oh, there's a philosophy behind it. When you're part of Sweden or Norway, you don't talk too highly of yourself because it's seen as kind of rude. Think of America except the exact opposite. You don't even really wanna make yourself into a victim too much. You don't wanna be too much of anything. You're just sticking to the group. So make big scene about yourself.

03:18:13,026 --> 03:18:14,206
SPEAKER_1:  But that said, you came.

03:18:14,722 --> 03:18:15,230
SPEAKER_1:  here.

03:18:15,458 --> 03:18:18,083
SPEAKER_1:  and you were you put yourself in front of the camera and

03:18:18,083 --> 03:18:21,310
SPEAKER_0:  Yes, do you understand how weird that is for my friends in Sweden?

03:18:21,890 --> 03:18:27,515
SPEAKER_0:  I just didn't talk about myself and just like make a big deal about myself for hours every day. Was that like terrifying?

03:18:27,515 --> 03:18:29,015
SPEAKER_1:  And did you have anxiety about that? No.

03:18:29,015 --> 03:18:32,382
SPEAKER_0:  because I don't see them but then I come back and I'm like ooh.

03:18:32,578 --> 03:18:36,382
SPEAKER_1:  Also, what do you feel like when you're actually streaming? Do you feel like you're just alone in a room?

03:18:36,642 --> 03:18:37,767
SPEAKER_1:  and one and one two

03:18:37,767 --> 03:18:46,887
SPEAKER_0:  No, I see I see Chad I'm thinking other like a little fairies. They're not really real. They're just like out there I don't know what they look like. I just see little names and they're just cute just colors, you know

03:18:46,887 --> 03:18:48,387
SPEAKER_1:  talking a little fairies and

03:18:48,387 --> 03:18:53,726
SPEAKER_0:  That's what I do. Is that how you feel, Boy Chat? They're demons for me. They're demons? My Anna Farries.

03:18:54,114 --> 03:18:56,739
SPEAKER_1:  Are they so as chat a source of stress or happiness like.

03:18:56,739 --> 03:19:02,814
SPEAKER_0:  Is there a community? No, for me, that's a source of happiness. I've been very intentional with the construction of my community, so I'm really happy with where it's at.

03:19:03,426 --> 03:19:04,551
SPEAKER_0:  How are you able to actually have-

03:19:04,551 --> 03:19:06,801
SPEAKER_1:  of deep political discourse while playing a video.

03:19:06,801 --> 03:19:07,678
SPEAKER_0:  game at the same time.

03:19:08,322 --> 03:19:09,886
SPEAKER_0:  I have a really good chat room.

03:19:10,114 --> 03:19:18,078
SPEAKER_0:  in terms of like the way that people engage in conversations. Like I was one of the earliest people to embrace the philosophy of like, I am in total control of what.

03:19:18,338 --> 03:19:19,294
SPEAKER_0:  people watch me think?

03:19:19,682 --> 03:19:28,894
SPEAKER_0:  that I have a high level of responsibility for how they conduct themselves, and that if I conduct myself in a certain way, I can expect a certain level of conduct from them. And for the most part, it's worked pretty well for the past.

03:19:29,346 --> 03:19:30,430
SPEAKER_0:  You know, nine or 10 years, yeah.

03:19:30,978 --> 03:19:35,230
SPEAKER_1:  What about the actual playing of the game? Like you're able to parallelize the brain like.

03:19:35,618 --> 03:19:36,030
SPEAKER_1:  Oh.

03:19:36,514 --> 03:19:39,139
SPEAKER_1:  I guess seems like Factorio seems like a super complex game.

03:19:39,139 --> 03:19:42,366
SPEAKER_0:  Yeah, I don't actually think that's possible. I don't think multitasking for a human brain is possible.

03:19:42,690 --> 03:19:57,927
SPEAKER_0:  If you see me playing a game, usually what's happening is the conversation is like, I've had it a million times, so I'm not thinking about it, I've automated that. Or if the conversation is very challenging, then if you really watch what's happening again, I'm probably just running around in circles, because I have to think about the conversation. Okay, because with...

03:19:57,927 --> 03:20:02,622
SPEAKER_1:  It looks like a lot of stuff is going on. Sometimes, yeah. So it's hard for.

03:20:02,850 --> 03:20:05,475
SPEAKER_1:  a person who hasn't played the game to detect that you're not actually...

03:20:05,475 --> 03:20:10,302
SPEAKER_0:  like you're super intelligent and multitask or does it come off as like he's not interested in this conversation at all.

03:20:10,530 --> 03:20:12,405
SPEAKER_0:  Yeah. Yeah, there's a coolness.

03:20:12,405 --> 03:20:14,014
SPEAKER_1:  like when you're not paying attention.

03:20:14,242 --> 03:20:14,558
SPEAKER_1:  like.

03:20:15,746 --> 03:20:19,871
SPEAKER_1:  If you're looking elsewhere, like you're checking your phone, you're too cool for this conversation.

03:20:19,871 --> 03:20:41,310
SPEAKER_0:  Yeah, the reality is though, is if you watch, it was easier to see in Minecraft, because in Minecraft when there was a challenging conversation, if you watch me play, I'm literally just running around and jumping in circles, because I have to think about the conversation 100%. I can't do a complicated task and think about the conversation. Or like the people always joke in my chat like, oh no, the notepad came out. If it's a really challenging conversation, I'll get rid of the game and I'll bring out a notepad and I'll start writing stuff down to keep track of what's going on.

03:20:42,210 --> 03:20:44,990
SPEAKER_1:  So what kind of stuff do you stream? So advice?

03:20:45,090 --> 03:20:48,574
SPEAKER_0:  You talk about relationships. Yeah, like either I talk to chat or I travel around, basically.

03:20:48,930 --> 03:20:49,534
SPEAKER_0:  I encourage you.

03:20:49,826 --> 03:20:55,070
SPEAKER_0:  have a conversation so we like go to countries. I've been to like Italy, I was in Italy for like...

03:20:55,330 --> 03:20:57,790
SPEAKER_0:  one and a half months just like traveling around alone.

03:20:58,338 --> 03:20:59,774
SPEAKER_0:  Going to cities, like.

03:21:00,098 --> 03:21:02,302
SPEAKER_0:  having like my camera with me and like streaming.

03:21:02,658 --> 03:21:03,198
SPEAKER_0:  powers.

03:21:03,778 --> 03:21:05,662
SPEAKER_1:  Where's the coolest place you've been to?

03:21:06,082 --> 03:21:06,782
SPEAKER_1:  ever

03:21:06,978 --> 03:21:09,406
SPEAKER_0:  It's probably New Zealand. New Zealand? No.

03:21:09,666 --> 03:21:12,830
SPEAKER_0:  After it is probably going to be Italy, I think. Because I like history.

03:21:13,090 --> 03:21:15,742
SPEAKER_1:  Also both history because New Zealand is also beautiful.

03:21:16,610 --> 03:21:19,518
SPEAKER_1:  It was both natural beauty and historical beauty.

03:21:19,778 --> 03:21:20,318
SPEAKER_1:  Yeah.

03:21:20,514 --> 03:21:24,702
SPEAKER_0:  For sure. I think I just really like the Polynesian sort of culture. I think it's very interesting.

03:21:25,154 --> 03:21:30,142
SPEAKER_0:  like the ocean people and it's just really beautiful. People are very relaxed, chilled, they're very far away.

03:21:30,594 --> 03:21:34,398
SPEAKER_0:  which is interesting as well, because whenever they talk about politics, so they talk about...

03:21:34,786 --> 03:21:35,518
SPEAKER_0:  Um...

03:21:35,874 --> 03:21:37,758
SPEAKER_0:  It's like the world, it feels really far away.

03:21:38,594 --> 03:21:40,478
SPEAKER_1:  So where's home for you? Is Austin home?

03:21:41,730 --> 03:21:44,355
SPEAKER_1:  Did you? It's home for me. A human being.

03:21:44,355 --> 03:21:47,355
SPEAKER_0:  Yeah, we travel we've lived in a lot of places and traveled around

03:21:47,355 --> 03:21:49,502
SPEAKER_1:  So that's what you think of home is like

03:21:50,114 --> 03:21:51,710
SPEAKER_0:  I think so, yeah.

03:21:51,970 --> 03:21:56,766
SPEAKER_0:  I mean, if they're gonna be a place, it's probably gonna be like my childhood places, probably.

03:21:57,250 --> 03:22:00,798
SPEAKER_0:  Like my old country house or something like that. We don't have it anymore, but...

03:22:01,058 --> 03:22:02,974
SPEAKER_0:  Like that's like home for me, I guess.

03:22:03,266 --> 03:22:04,350
SPEAKER_1:  So how'd you guys meet each other?

03:22:05,122 --> 03:22:06,238
SPEAKER_1:  You're currently married.

03:22:06,530 --> 03:22:07,006
SPEAKER_0:  Yes.

03:22:07,554 --> 03:22:08,158
SPEAKER_0:  to each other, yeah.

03:22:08,290 --> 03:22:10,983
SPEAKER_1:  Yeah. To each other. Okay.

03:22:10,983 --> 03:22:11,710
SPEAKER_0:  than healthy food.

03:22:11,938 --> 03:22:13,813
SPEAKER_0:  Just making sure we're on the same page. Bym intensifies

03:22:13,813 --> 03:22:14,238
SPEAKER_1:  cool.

03:22:14,594 --> 03:22:15,230
SPEAKER_1:  How'd you guys meet?

03:22:15,874 --> 03:22:17,822
SPEAKER_0:  I was watching his YouTube stuff, like...

03:22:18,338 --> 03:22:23,166
SPEAKER_0:  2018, I think, because it was the Swedish election around that time and I was interested in politics.

03:22:23,714 --> 03:22:25,182
SPEAKER_0:  And then, um...

03:22:25,506 --> 03:22:28,670
SPEAKER_0:  I think he said in one of his videos that he had an Instagram.

03:22:28,898 --> 03:22:31,134
SPEAKER_0:  and that he needed people to stop DMing him.

03:22:31,394 --> 03:22:36,990
SPEAKER_0:  that wasn't cutipies. And then I messaged him and said, am I a cutipie? And then you're like, two minutes.

03:22:37,346 --> 03:22:40,510
SPEAKER_0:  And then that's when I was in New Zealand.

03:22:41,346 --> 03:22:45,534
SPEAKER_0:  And I guess you wanted to escape America or like LA for a little bit.

03:22:46,146 --> 03:22:47,271
SPEAKER_0:  and uh...

03:22:47,271 --> 03:22:49,662
SPEAKER_1:  Where were you mentally there?

03:22:50,306 --> 03:22:52,158
SPEAKER_1:  because we've talked to this timeline.

03:22:52,610 --> 03:22:53,758
SPEAKER_1:  Where's 2018?

03:22:54,146 --> 03:22:55,454
SPEAKER_1:  Was it 1819?

03:22:55,842 --> 03:22:56,830
SPEAKER_1:  Where is the low point?

03:22:57,538 --> 03:23:00,510
SPEAKER_0:  or something a little pic car incorrect finale

03:23:01,186 --> 03:23:04,030
SPEAKER_0:  2010. Oh, okay. 2018 was probably your peak.

03:23:04,834 --> 03:23:08,959
SPEAKER_0:  Every day, now is my peak. What do you mean? That was my peak. Say that.

03:23:08,959 --> 03:23:12,709
SPEAKER_1:  Nobody ever admits being past their prime.

03:23:12,709 --> 03:23:36,542
SPEAKER_0:  Well, I mean, my friend was... Okay, it was around, it was probably around the time where you were getting a lot of lefties through your community and you were really like thinking about that they would go too far. Maybe that was, I think that was still when Hasan and Vash were both in my community. Exactly. So I would say it feels like there was not really like much issues when it come to like to your stuff or like your work stuff back then. Oh, something we didn't talk about is that like, there were no politics on Twitch. I exclusively inhabited that.

03:23:36,802 --> 03:23:45,485
SPEAKER_0:  for like two years because nobody else did it because it was a really toxic environment for politics so for a couple of years as it grew like the I kind of grew the whole space because it wasn't nobody was doing it yet what did that look like

03:23:45,485 --> 03:23:46,526
SPEAKER_1:  like you're having.

03:23:48,098 --> 03:23:49,223
SPEAKER_1:  political debates, political.

03:23:49,223 --> 03:24:00,638
SPEAKER_0:  discourse. Yeah, mainly like going into YouTube people to try to argue with them or just doing politics on stream like reading stories, researching stuff, talking about stuff. But there's not like other people on Twitch to debate about politics because there was no politics. It was, yeah.

03:24:00,994 --> 03:24:01,918
SPEAKER_1:  Was there a debate?

03:24:02,210 --> 03:24:05,310
SPEAKER_1:  in the space of communism, socialism, social democrat.

03:24:05,570 --> 03:24:06,366
SPEAKER_1:  Democrats.

03:24:06,690 --> 03:24:09,694
SPEAKER_1:  Are you trying to outline your own position during that time?

03:24:09,890 --> 03:24:27,902
SPEAKER_0:  I think it was mainly me fighting against conservatives because it was like Trump stuff. And then it was coming off the back of like, there was this movement called Gamergate and there was all this anti-SJW stuff on the internet. And I was like the SJW, like the progressive that was fighting on the progressive side of things. So I think that's what I was known for. But I was fighting with people off of Twitch because on Twitch there weren't very many political discussions happening.

03:24:28,290 --> 03:24:31,134
SPEAKER_1:  So you were holding the SJW flag. Yep.

03:24:31,778 --> 03:24:32,254
SPEAKER_1:  and

03:24:32,706 --> 03:24:37,054
SPEAKER_1:  To what degree do you still hold it? What's the best? The Steelman case for SJW.

03:24:37,218 --> 03:24:46,791
SPEAKER_0:  I mean, like, I'm still very much that SJW from 2018, 2019, but the positions have moved so much farther left that some people might not call me that anymore, I'm not sure. That's not who I'm talking to.

03:24:46,791 --> 03:24:49,246
SPEAKER_1:  basically what is social justice for you?

03:24:49,858 --> 03:24:51,733
SPEAKER_1:  being sensitive to the experience of others.

03:24:51,733 --> 03:24:57,534
SPEAKER_0:  Yeah, being sensitive and empathetic towards the experience of others and then trying to build a better world that suits as many different types of people as possible.

03:24:57,986 --> 03:24:59,422
SPEAKER_0:  while being aware of their names.

03:24:59,810 --> 03:25:00,126
SPEAKER_0:  Okay.

03:25:01,186 --> 03:25:10,430
SPEAKER_1:  So you guys met what's your from your perspective is that did she she she telling lies is it accurate? No, it's pretty accurate Okay, when'd you guys actually meet?

03:25:11,106 --> 03:25:32,606
SPEAKER_0:  I flew out in 2019. 19, yeah, like in February. Yeah, basically there was like weird stuff happening in LA. I just come off of kind of a weird, not kind of sort of relationship and I just wanted to like go away for a while. Another company reached out to me and they had like a fun streaming device and they said they'd sponsor a trip if I went somewhere. And I was like, oh, well, I know this person. I know a couple of people in New Zealand. Malina is one of them. It's like, I'll go to New Zealand. It'll be fun.

03:25:33,026 --> 03:25:35,038
SPEAKER_0:  And yeah, I did that for two weeks.

03:25:35,298 --> 03:25:36,158
SPEAKER_0:  Believe in love?

03:25:37,090 --> 03:25:37,726
SPEAKER_0:  Hehehehe

03:25:38,466 --> 03:25:42,531
SPEAKER_1:  I feel like you're, you lack the gotcha got us into this. I'm not sure.

03:25:42,531 --> 03:25:45,022
SPEAKER_0:  to which you have human emotions. I have quite a few.

03:25:45,186 --> 03:25:45,758
SPEAKER_1:  Okay.

03:25:46,338 --> 03:25:51,998
SPEAKER_1:  From your perspective, when did you fall in love with Meli Mel?

03:25:52,354 --> 03:25:54,430
SPEAKER_0:  the minute I saw her.

03:25:54,946 --> 03:25:59,134
SPEAKER_0:  I don't know, our first two weeks together were a lot of fun. We had a lot of chemistry in person.

03:25:59,522 --> 03:26:00,222
SPEAKER_0:  Um...

03:26:00,450 --> 03:26:09,854
SPEAKER_0:  I was kind of shocked that I wasn't thinking about it. Cause it was like, we spent like a week together and you said, I really want to tell you something. And you were like stalling that for the longest time. I think she was.

03:26:10,594 --> 03:26:14,014
SPEAKER_0:  Oh, he said that like, I love you. No, he basically just said like.

03:26:14,402 --> 03:26:19,678
SPEAKER_0:  I really like you and it never really happens. That's what he said. I was like, oh, and I thought, hey, I thought.

03:26:21,474 --> 03:26:25,342
SPEAKER_0:  But let's still run, we said Trump getting banned from Twitter, is that what we were talking about before?

03:26:25,794 --> 03:26:30,206
SPEAKER_0:  Oh, yeah. Hey, you agree to me coming on here. Of course, I'm going to be doing this.

03:26:30,370 --> 03:26:31,934
SPEAKER_1:  So how long did that take? Two weeks you said?

03:26:32,066 --> 03:26:40,702
SPEAKER_0:  That took like a week. No, I don't know. I think it was just like. The thing is my mind processes information so quickly. Two weeks to somebody like you is actually like years for me.

03:26:40,802 --> 03:26:43,422
SPEAKER_1:  Oh, like me. Yeah. So there was like a lot of like.

03:26:43,746 --> 03:26:44,871
SPEAKER_1:  factorial type of strategic.

03:26:44,871 --> 03:26:45,950
SPEAKER_0:  Yeah, going on.

03:26:46,242 --> 03:26:47,902
SPEAKER_0:  I was seeing like all the events.

03:26:48,194 --> 03:26:54,569
SPEAKER_0:  like Doctor Strange or whatever in the Avengers when he's like singing to all the futures. Also when you saw me, you just saw the future. Yeah, I was looking at all. Hamilton, you know, we got theinota don' Hey,

03:26:54,569 --> 03:27:00,382
SPEAKER_1:  Yeah, you're doing like some game theoretic simulation of all the possible outcomes. Exactly. Okay

03:27:00,706 --> 03:27:01,214
SPEAKER_1:  Um...

03:27:01,346 --> 03:27:18,558
SPEAKER_0:  But no, yeah, it was probably pretty soon I realized that we had a lot of chemistry. I think before I left after my two weeks there, I was like, we need to make sure you get like a ticket to come visit me in the United States because it'll be fun and everything. And then I kind of decided that last minute too. It was like really like five hours before your flight back. We kind of realized because it was kind of like men is just like a one time thing and then.

03:27:19,106 --> 03:27:21,726
SPEAKER_0:  That was it, but we were like, oh no, this is a lot of fun, we should probably hang out again.

03:27:21,922 --> 03:27:22,782
SPEAKER_1:  So you realize you...

03:27:23,650 --> 03:27:24,222
SPEAKER_1:  miss each other.

03:27:24,546 --> 03:27:25,694
SPEAKER_1:  Yeah. Yeah.

03:27:26,466 --> 03:27:29,150
SPEAKER_1:  the melancholy side of love. Okay, when did you fall in love with a student?

03:27:29,730 --> 03:27:34,814
SPEAKER_0:  I thought he like hated me. I don't know. I thought not hated me. She still thinks I hate her. But I know.

03:27:35,074 --> 03:27:40,542
SPEAKER_0:  No, I remember what he said that he really liked me. I was kind of a little shocked about that, because I-

03:27:40,994 --> 03:27:47,550
SPEAKER_0:  I don't know, there was a lot of random things happening in New Zealand. It was a lot of fun, but it was definitely very interesting things that happened.

03:27:47,874 --> 03:27:52,990
SPEAKER_0:  because I was around a lot of other people as well, so I thought he might have had a really bad time.

03:27:53,250 --> 03:27:56,318
SPEAKER_0:  But when he said that I was thinking about it more and then we spent like...

03:27:56,866 --> 03:28:00,670
SPEAKER_0:  more time together like a week after that and then it felt like that was more like real.

03:28:00,898 --> 03:28:04,158
SPEAKER_0:  And I think when he was about to leave, I kind of realized like, no, I really like him.

03:28:04,674 --> 03:28:05,406
SPEAKER_1:  Do you guys ever?

03:28:05,954 --> 03:28:08,579
SPEAKER_1:  say love to each other, like I love you.

03:28:08,579 --> 03:28:09,534
SPEAKER_0:  Yeah, of course.

03:28:10,722 --> 03:28:12,597
SPEAKER_0:  Why would you ask that? What is he saying?

03:28:12,597 --> 03:28:15,390
SPEAKER_1:  Because I haven't I don't think I've heard you

03:28:15,618 --> 03:28:23,678
SPEAKER_1:  The only time I've heard is to talk about love is when you're like criticizing the the red pill community saying they don't ever talk about love and relationships

03:28:24,258 --> 03:28:29,822
SPEAKER_0:  Almost all the time I'm giving criticism to people, like I said, I'm kind of stepping in. I'm very disconnected from my own emotional experience because...

03:28:30,146 --> 03:28:32,771
SPEAKER_0:  I'm trying to talk within there, so it's pretty rare that I'll talk about-

03:28:32,771 --> 03:28:33,534
SPEAKER_1:

03:28:33,922 --> 03:28:35,038
SPEAKER_1:  experience exactly.

03:28:35,362 --> 03:28:44,483
SPEAKER_1:  Highly blunted, I guess. There's a lot, okay. What does that mean? I mean, what's deep in there? Is this just who you are genetically or are you running for?

03:28:44,483 --> 03:28:44,894
SPEAKER_0:  something.

03:28:45,570 --> 03:28:49,374
SPEAKER_0:  I think I have a pretty good understanding of myself. A lot of people make that accusation of me, but I don't think I am.

03:28:50,178 --> 03:28:51,966
SPEAKER_1:  This is just who you are. This is just who I am, yeah.

03:28:52,738 --> 03:28:53,918
SPEAKER_1:  There's not childhood stuff.

03:28:54,146 --> 03:28:54,750
SPEAKER_1:  Like trauma.

03:28:54,978 --> 03:28:56,094
SPEAKER_1:  Um, it's all sorted.

03:28:57,442 --> 03:28:58,750
SPEAKER_1:  You figured it all out? Yeah.

03:28:58,978 --> 03:29:00,062
SPEAKER_1:  in your old age?

03:29:00,322 --> 03:29:03,038
SPEAKER_0:  As I grow every year, I figure out more and more. He didn't mention.

03:29:03,266 --> 03:29:07,294
SPEAKER_1:  I think I heard this somewhere that this is a source of fights for the two of you, the H thing.

03:29:07,554 --> 03:29:10,462
SPEAKER_1:  I felt the ageism throughout this whole conversation.

03:29:10,754 --> 03:29:25,246
SPEAKER_0:  He's basically, he's saying that he gambles like with time. He's just like, I think she will be good later. And then just like, it's like an investment. Yeah. That's like what he's doing. When this treasury bond matures, I'm going to be able to cash out for a good. What do you think so far? Is the stocks going up or? He bought all but he's right.

03:29:25,506 --> 03:29:30,622
SPEAKER_0:  It's tumultuous. What's that mean? It's like Bitcoin. Oh my god. Like Bitcoin.

03:29:30,850 --> 03:29:31,614
SPEAKER_0:  Crypto mail.

03:29:31,874 --> 03:29:33,918
SPEAKER_1:  All right, if you guys don't mind.

03:29:34,178 --> 03:29:37,822
SPEAKER_1:  One interesting aspect of your relationship is you're in an open relationship.

03:29:38,466 --> 03:29:39,294
SPEAKER_1:  What's that like?

03:29:39,810 --> 03:29:43,486
SPEAKER_1:  from a game theoretic simulation perspective, what went into that calculation?

03:29:43,970 --> 03:29:47,358
SPEAKER_1:  And like, how does that? Like how that started or? Yeah, how did that start? Sure.

03:29:47,458 --> 03:29:51,934
SPEAKER_0:  The only relationships I've ever done has been open relationships since I was like in high school.

03:29:52,290 --> 03:29:55,518
SPEAKER_0:  because I didn't really understand, like, why wouldn't you be able to, like...

03:29:56,098 --> 03:29:59,358
SPEAKER_0:  do other things with other people, but then just like have your main partner basically.

03:29:59,650 --> 03:30:04,030
SPEAKER_1:  So what is an open relationship, generally speaking? That means you have one main partner.

03:30:04,130 --> 03:30:07,358
SPEAKER_0:  not a monogamous relationship, like you're somehow allowed, like in...

03:30:07,618 --> 03:30:10,590
SPEAKER_0:  different ways you can see other people sexually.

03:30:11,106 --> 03:30:13,182
SPEAKER_1:  sexually, but like, there's one main.

03:30:14,018 --> 03:30:21,918
SPEAKER_0:  It doesn't have to be there for some people, but I think it's probably easier and we probably don't really have time or the energy for like more than...

03:30:22,338 --> 03:30:24,446
SPEAKER_0:  like one person to like really like.

03:30:24,674 --> 03:30:25,982
SPEAKER_0:  What about like emotional?

03:30:26,850 --> 03:30:30,110
SPEAKER_0:  It's really complicated, there's a lot of complicated stuff going on under the hood there.

03:30:30,786 --> 03:30:31,390
SPEAKER_0:  Um...

03:30:32,098 --> 03:30:49,150
SPEAKER_0:  I think broadly speaking, you've got polyamorous relationships and you've got open relationships where polyamorous is like, oh, I've got three different girlfriends and we all hang out or sometimes even live together or three boyfriends or whatever. And then you've got open relationships, which is like, oh, you can basically hook up with other people. Then you've got like your main relationship and that's it.

03:30:49,378 --> 03:30:51,710
SPEAKER_0:  I think ours is probably somewhere in the middle of that.

03:30:51,938 --> 03:30:58,270
SPEAKER_0:  to where we've got long-term friends, some of them we hook up with, and that's how we, yeah, it's a delicate dance that-

03:30:58,722 --> 03:31:02,142
SPEAKER_0:  explodes every six months on its own. Does it explode? You guys fight over it?

03:31:02,434 --> 03:31:04,094
SPEAKER_0:  We fight over some things, yeah.

03:31:04,386 --> 03:31:07,646
SPEAKER_0:  I think it's mostly because a lot of people can't handle it.

03:31:08,194 --> 03:31:14,270
SPEAKER_0:  and they agree to something and then they realize they're way too cool. And then they get really obsessed and they think that they can like...

03:31:14,594 --> 03:31:15,902
SPEAKER_0:  Get in there and then it gets really dramatic.

03:31:16,546 --> 03:31:17,438
SPEAKER_1:  Have you figured it out?

03:31:18,178 --> 03:31:18,494
SPEAKER_1:  Mike.

03:31:18,978 --> 03:31:27,486
SPEAKER_0:  I feel like we figure out things more and more like when it comes to like what's a good person for us to hang out and what's not a good person for us to hang out with or

03:31:27,778 --> 03:31:32,574
SPEAKER_0:  Like I probably have more opinions on like who he hangs out with because he likes the fucking psychos.

03:31:32,770 --> 03:31:33,895
SPEAKER_1:  Yeah, so you...

03:31:33,895 --> 03:31:34,654
SPEAKER_0:  You like this, right?

03:31:35,106 --> 03:31:42,750
SPEAKER_0:  He likes the crazy ones, like the baby trap sort of women. That's the ones. And I don't like that because that affects me.

03:31:42,882 --> 03:31:46,846
SPEAKER_1:  that affects your game theoretic right.

03:31:47,266 --> 03:31:49,959
SPEAKER_1:  You like to surround yourself, like in general you've talked about.

03:31:49,959 --> 03:31:51,006
SPEAKER_0:  with crazy people.

03:31:51,746 --> 03:31:58,622
SPEAKER_0:  I say crazy and I really shouldn't. It's humorous. It's like, yeah. They're very unstable. Very, can be unstable, but people that are very unique.

03:31:58,882 --> 03:32:02,590
SPEAKER_0:  Like when I meet this person, that's like... Not boring. Yeah, not boring.

03:32:03,170 --> 03:32:05,470
SPEAKER_1:  and you said that you're progressively becoming.

03:32:05,954 --> 03:32:09,822
SPEAKER_0:  Not boring yourself. No, I think I'm pretty stable. I don't let them affect me much.

03:32:10,274 --> 03:32:26,398
SPEAKER_0:  So you don't think they affect your... No, if I've said that, I've said a joke. I think I've got my stuff really well figured out. It's what allows me to engage with people like this so easily because I can engage, I can make them feel seen and heard, and then if it gets insane, I can cut off and I can be chill. Very few things affect me in the long term. You guys experience jealousy?

03:32:27,522 --> 03:32:41,447
SPEAKER_0:  Usually like whenever I feel like he's not spending the like the amount of time that I'm asking for and he spends it on his Video games or his stream or like he sees someone else like more than he sees me or something like that That would like not be good because then it effects like are really

03:32:41,447 --> 03:32:41,982
SPEAKER_1:  relationship.

03:32:42,594 --> 03:32:43,902
SPEAKER_1:  Do you have a good sense of like?

03:32:44,258 --> 03:32:46,430
SPEAKER_1:  Is it literally time or is it?

03:32:46,914 --> 03:32:49,255
SPEAKER_1:  the energy put into the...

03:32:49,255 --> 03:32:52,094
SPEAKER_0:  It's probably like if he's with me.

03:32:52,354 --> 03:33:01,374
SPEAKER_0:  that like the attention in the time like when he hangs out with me and then there's also probably the time. So if I feel like something else is distracting too much, like it could be work or it could be a friend or it could be anything.

03:33:01,666 --> 03:33:04,606
SPEAKER_0:  Like if I feel like it starts to take away from like me.

03:33:04,834 --> 03:33:06,078
SPEAKER_0:  then I'm having an issue with it.

03:33:06,498 --> 03:33:11,294
SPEAKER_0:  I don't think he really cares much. I guess the only jealous that you experience is probably when you feel like, um,

03:33:12,162 --> 03:33:15,422
SPEAKER_0:  Like, if I get upset about him seeing someone too much.

03:33:15,810 --> 03:33:21,854
SPEAKER_0:  and then I go see someone more. And then he's like, why can I go see my friend more, like as much as you? So like, that's the sort of like.

03:33:22,178 --> 03:33:23,870
SPEAKER_0:  thing that we're trying to navigate on I guess.

03:33:24,994 --> 03:33:25,342
SPEAKER_0:  Mm-hmm.

03:33:25,602 --> 03:33:34,430
SPEAKER_0:  I think we are diametrically opposed sometimes in terms of how we view engagement with people or engagement with the world sometimes. So like on her end of the spectrum, like...

03:33:34,914 --> 03:33:35,422
SPEAKER_0:  Perfect.

03:33:35,938 --> 03:33:37,822
SPEAKER_0:  weak for her might be like

03:33:38,338 --> 03:33:39,198
SPEAKER_0:  being in a cabin.

03:33:39,874 --> 03:33:41,310
SPEAKER_0:  watching like Fireflies at night.

03:33:41,666 --> 03:34:10,750
SPEAKER_0:  going hiking every morning, going swimming at the beach, because it's like you're taking in like the grandeur of nature, you're like connected with yourself, you're like very at peace, everything is like chill and cool, there's the wind, the feeling of nature, everything, that's like her peak living experiences. I like being present. Yeah, and like my peak experiences are like people trying to destroy my life, like the challenge of like navigating really complicated discussion, like, you know, several different dramatic events unfolding in my career, like these things are like very, I like the stress and the action and the entertainment and everything's like very cool for me. So when we're together.

03:34:11,074 --> 03:34:20,955
SPEAKER_0:  She generally wants me to be more chill, but if I don't feel like I'm being stimulated a lot, then it's easy for my mind to wander. To wander somewhere else. That's kind of the issue. It's a very different way of engaging with a-

03:34:20,955 --> 03:34:21,918
SPEAKER_1:  How can you find?

03:34:22,786 --> 03:34:23,911
SPEAKER_1:  happiness and stillness.

03:34:23,911 --> 03:34:36,254
SPEAKER_0:  I feel like if we're just like aware of it and we're trying our best like whenever we like we're supposed to do this one thing so let's say that we want to go to New York and I'm like we should just like go out and do this one specific thing we try to find something that he enjoys doing like

03:34:36,514 --> 03:34:41,054
SPEAKER_0:  Now that we're in Texas, we can go shooting or do something fun that he enjoys, then we can do it.

03:34:41,570 --> 03:34:43,390
SPEAKER_0:  Um, and then I think like.

03:34:44,162 --> 03:35:05,982
SPEAKER_0:  Just like for me also to be aware that like when he spends a lot of time on crazy people, it's not because he like loves them or wants to be with them. It's just because he likes having his life destroyed. Like you said, which I don't really do. It's just a completely different thing. So like for me to like understand more like how he's thinking, because it's so different from mine, and for him to understand how I'm thinking about things and like what I prioritize.

03:35:06,306 --> 03:35:08,030
SPEAKER_0:  In my life, I think that's like how we navigate.

03:35:08,386 --> 03:35:12,286
SPEAKER_0:  But I think it's good, I think the differences can be good, like when we're finding a way, yeah.

03:35:12,482 --> 03:35:13,886
SPEAKER_1:  What I think you're.

03:35:14,210 --> 03:35:15,614
SPEAKER_1:  You're relatable.

03:35:16,322 --> 03:35:16,798
SPEAKER_1:  Ha!

03:35:17,090 --> 03:35:24,215
SPEAKER_0:  I'm more of a you-miss year in the eye. I'm definitely very difficult to get along with. If you're dating me for more than a few years, you get an award for that.

03:35:24,215 --> 03:35:28,715
SPEAKER_1:  war zone, that you've survived. Absolutely. You're like a veteran, you get medals.

03:35:28,715 --> 03:35:54,366
SPEAKER_0:  And it's always like, I think there's probably been like six different, I don't think she says it anymore, but there are like six different times in our relationship where she's like, is it always like this? Is this actually right? And like every next year it's like... You were lying in the beginning of about, like you were lying about that. Well, it got more. You were like, no, it's just like right now I'm having a huge argument online about saying the N-word in private, and it's just going to be like this, and I'm going to be streaming 24 hours a day. And I'm like, when are you going to go to bed? It's been a week.

03:35:55,586 --> 03:35:58,151
SPEAKER_1:  I did playing league come into into this.

03:35:58,151 --> 03:36:01,901
SPEAKER_0:  a little bit, but I'm clean of league like six months right now.

03:36:01,901 --> 03:36:04,414
SPEAKER_1:  What do you hate about legal aid? I never got- Bella, you hate that point huh.

03:36:06,722 --> 03:36:07,934
SPEAKER_1:  Speaking of which, I-

03:36:08,226 --> 03:36:11,774
SPEAKER_1:  my participation in League involved on the robot side. good

03:36:12,386 --> 03:36:13,511
SPEAKER_0:  That's an improvement.

03:36:13,511 --> 03:36:14,558
SPEAKER_1:   innovations. up.

03:36:14,882 --> 03:36:19,934
SPEAKER_1:  Both with Starcraft 2 and League of Legends because OpenAI and DeepMind.

03:36:20,418 --> 03:36:21,543
SPEAKER_1:  both participating in creating.

03:36:21,543 --> 03:36:25,758
SPEAKER_0:  I was a professional circle of two players, so I remember when the AI started to play.

03:36:25,986 --> 03:36:31,102
SPEAKER_0:  It's interesting the types of restrictions that you would have to put on like a gaming robot to make it like functional and not.

03:36:31,490 --> 03:36:33,150
SPEAKER_0:  totally unfair to the other side.

03:36:33,346 --> 03:36:38,494
SPEAKER_1:  Yeah, to make it human-like. Yeah, was that interesting to you, to see AI be able to play those video games?

03:36:38,754 --> 03:36:55,614
SPEAKER_0:  I think in some ways people think things are more complicated than they actually are. And I think video games is one of those things where we're like, oh my god, there's like a million possibilities at every second and who knows? And it's like, no, there's like three or four things going on at any point in time. And I'm willing to bet that like an AI could probably solve some of these games like pretty easily, especially if there are no constraints on how they can.

03:36:56,866 --> 03:36:58,686
SPEAKER_1:  Can I talk to you about relationships?

03:36:59,042 --> 03:37:03,486
SPEAKER_1:  We already have so yeah, I know but more generally speaking we didn't get a chance to talk

03:37:03,714 --> 03:37:06,238
SPEAKER_1:  about the Red Pill community. How so?

03:37:06,466 --> 03:37:09,502
SPEAKER_1:  Well, first of all, what is the Replica community, the Metasphere in general?

03:37:09,794 --> 03:37:12,094
SPEAKER_1:  I'd love to get both of your opinions on this. Sure.

03:37:13,026 --> 03:37:15,422
SPEAKER_1:  I know, I know you're probably not as.

03:37:16,098 --> 03:37:16,798
SPEAKER_1:  PAY

03:37:17,154 --> 03:37:18,279
SPEAKER_1:  and that's all.

03:37:18,279 --> 03:37:29,758
SPEAKER_0:  in a game that, like probably not as you, like as much as you, but I do have opinions. You do? Okay. I usually don't like speak out too much on it because I feel like there's like a language barrier. That's why I don't really do politics because-

03:37:30,018 --> 03:37:31,143
SPEAKER_0:  This is my second language.

03:37:31,143 --> 03:37:33,022
SPEAKER_1:  That's right. You have to know the

03:37:33,282 --> 03:37:38,398
SPEAKER_1:  A little bit like that, yeah. How to use derogatory terms every other sentence.

03:37:38,754 --> 03:37:40,629
SPEAKER_1:  so they understand you, right? beneftrALLY

03:37:40,629 --> 03:37:44,254
SPEAKER_0:  I don't know anything about that. It's too many and I talked about it. Good. You need to be able to like...

03:37:44,834 --> 03:37:47,166
SPEAKER_0:  speak really well for people to take you seriously.

03:37:47,682 --> 03:37:58,925
SPEAKER_0:  I think. And like that's a thing, like if I don't have like the words and I don't have the, like I can't pronounce things correctly. Yeah. And a yes all person searching for words looks stupid. Essentially, that's how people view it. So everybody.

03:37:58,925 --> 03:38:03,326
SPEAKER_1:  I have a podcast that people listen to and I mumble and they

03:38:03,554 --> 03:38:03,902
SPEAKER_1:  Yeah.

03:38:04,322 --> 03:38:05,726
SPEAKER_0:  Wait, what's your first language?

03:38:06,274 --> 03:38:07,294
SPEAKER_1:  Russian.

03:38:07,522 --> 03:38:10,462
SPEAKER_1:  But I speak both languages horribly. I just not.

03:38:11,266 --> 03:38:11,998
SPEAKER_1:  I'm not like...

03:38:12,322 --> 03:38:16,766
SPEAKER_1:  There is definitely a big disconnect between my brain and my mouth module.

03:38:17,250 --> 03:38:17,630
SPEAKER_1:  Like.

03:38:17,954 --> 03:38:24,030
SPEAKER_1:  I'm not able to generate the thoughts efficiently. Like the things you're able to do, like the da da da da da da, like speak like that, I'm not.

03:38:25,250 --> 03:38:29,278
SPEAKER_1:  It's very, very tough. Plus there's a huge amount of anxiety and social interaction that I have.

03:38:29,506 --> 03:38:30,910
SPEAKER_1:  which makes speaking even harder.

03:38:31,170 --> 03:38:31,646
SPEAKER_1:  Gotcha.

03:38:32,002 --> 03:38:32,350
SPEAKER_1:  Yeah.

03:38:33,378 --> 03:38:35,358
SPEAKER_0:  Yeah, it's tough. I understand. Sure.

03:38:35,842 --> 03:38:37,118
SPEAKER_0:  Okay. That's it.

03:38:37,346 --> 03:38:39,614
SPEAKER_1:  Yeah, the gotcha is both.

03:38:39,906 --> 03:38:41,886
SPEAKER_1:  a symbol of compassion.

03:38:42,370 --> 03:38:43,495
SPEAKER_1:  and derision.

03:38:43,495 --> 03:38:58,846
SPEAKER_0:  I'm just letting you know I understand what you're saying. I'm just gonna sit there and stare at you and sound like. No, you can just say like, yeah, I get it. Yeah, I get it, gotcha. No, no, gotcha sounds, no, it's so short. It's like, say a longer sentence, but that means the same thing.

03:38:59,234 --> 03:39:02,686
SPEAKER_0:  I understand you. Yeah, good. That's good. That's like, not-

03:39:03,138 --> 03:39:05,214
SPEAKER_0:  You get chills, you know? You get chills.

03:39:05,378 --> 03:39:11,907
SPEAKER_1:  You understand me. Yeah, it feels good. Yeah. I hear you. I hear you. I'm going to hold the other person's hand.

03:39:11,907 --> 03:39:14,462
SPEAKER_0:  You gotta put in some emotion there, okay? Show that you have some.

03:39:14,690 --> 03:39:16,318
SPEAKER_0:  I understand. Holy hoodies.

03:39:16,514 --> 03:39:17,118
SPEAKER_1:  Goodbye.

03:39:17,410 --> 03:39:19,646
SPEAKER_1:  Gotcha. What do you think about Red Pill?

03:39:20,130 --> 03:39:22,878
SPEAKER_1:  What is it, first of all, for B1RN?

03:39:23,426 --> 03:39:31,262
SPEAKER_0:  Yeah, the red pill community, obviously it's the matrix reference. The red pill that you take is when you realize what dating standards and norms really are in the world.

03:39:31,490 --> 03:39:40,478
SPEAKER_0:  that men are providers and have to become some great thing to hunt and attract, you know, the woman who are just kind of there floating around looking for people to give them the most resources.

03:39:40,706 --> 03:39:47,294
SPEAKER_0:  It's like coming to a realization of what the world of dating really is, broken away from the Hollywood standards and the romantic stuff that they try to sell you.

03:39:47,618 --> 03:39:48,743
SPEAKER_0:  stories..

03:39:48,743 --> 03:39:49,310
SPEAKER_1:  kind of.

03:39:49,858 --> 03:39:51,582
SPEAKER_1:  Maybe you can kind of educate me on this.

03:39:51,906 --> 03:39:53,950
SPEAKER_1:  but red pill used to be associated with

03:39:54,978 --> 03:39:55,806
SPEAKER_1:  Just...

03:39:57,282 --> 03:40:02,157
SPEAKER_1:  maybe anti-establishment use i don't know maybe maybe republican conservative you counselors

03:40:02,157 --> 03:40:12,862
SPEAKER_0:  Yeah, they use red pill a lot in like different communities. Like when you say the red pill community Yeah, that usually means dating the dating thing. But a lot of people say Trump voters. They're red pill Are you red-pilled on like politics or whatever people say stuff like that? Yeah

03:40:13,826 --> 03:40:19,870
SPEAKER_1:  And then there's like the Manosphere, that's all the similar type of stuff. And Andrew Tate is somebody that represents kind of-

03:40:20,546 --> 03:40:21,374
SPEAKER_1:  The Figurehead.

03:40:21,570 --> 03:40:25,118
SPEAKER_0:  of the Manosphere of like the red pill stuff. Yeah, I would say so. I'm pretty sure.

03:40:25,666 --> 03:40:26,590
SPEAKER_0:  Alright cool so

03:40:26,690 --> 03:40:30,558
SPEAKER_1:  What are some ideas that they represent and what do you think about them?

03:40:30,818 --> 03:40:37,950
SPEAKER_0:  I think they do a good job at speaking to disaffected young men who feel like the rest of the world has kind of left them behind or isn't willing to speak to them.

03:40:38,370 --> 03:40:41,342
SPEAKER_0:  and they do identify some true and real problems.

03:40:41,602 --> 03:40:51,966
SPEAKER_0:  Feels like on the left we have a really hard time doing like self-improvement or telling people how to better themselves. We focus too much on like structural or systemic issues rather than what can an individual do to uplift or empower themselves.

03:40:52,258 --> 03:40:54,942
SPEAKER_0:  And it also feels like they do a good job at speaking to.

03:40:55,170 --> 03:41:03,198
SPEAKER_0:  some of the positive aspects of masculinity, that it's okay to be like strong and brave and a soldier and a warrior and provide for your family and blah blah blah.

03:41:03,586 --> 03:41:08,062
SPEAKER_0:  So I was thinking those are like positive messages like self-improvement and everything that come from the red pill community

03:41:08,674 --> 03:41:09,694
SPEAKER_0:  What's the negative?

03:41:10,818 --> 03:41:20,862
SPEAKER_0:  I think the analysis on how men and women interact is a way too transactional. All of the romanticism and love and chemistry is totally sucked out of it. Everything is very like.

03:41:21,346 --> 03:41:26,046
SPEAKER_0:  sex based, like how do you basically have sex with the most amount of women possible and that's going to make you happy.

03:41:26,338 --> 03:41:40,606
SPEAKER_0:  And then I think people's motivation sometimes are just spoken about in such a shallow derogatory way that I don't think is always reflective of reality. Like woman only wants you because you make six figures and you're tall and a guy only wants you because he wants to have sex with you and blah. Like it feels like there's a lot of that going on a lot.

03:41:41,410 --> 03:41:46,943
SPEAKER_1:  Yeah. And that misses some fundamental aspects about relationships, about meaningful relationships and so on.

03:41:46,943 --> 03:41:53,086
SPEAKER_0:  I don't think I've never heard red pill people ever ever talk about like meaningful relationships it's always just how to get in one or how to have sex really.

03:41:53,890 --> 03:41:55,134
SPEAKER_1:  Well, what bothers you about?

03:41:55,458 --> 03:41:56,190
SPEAKER_1:  some of that.

03:41:56,738 --> 03:41:57,863
SPEAKER_1:  philosophy.

03:41:57,863 --> 03:42:03,358
SPEAKER_0:  people that are like the red pill people. I feel like their solution is something that doesn't actually work out.

03:42:03,714 --> 03:42:09,758
SPEAKER_0:  It works out for some people, people that makes a lot of money, is really successful in that sort of way.

03:42:10,178 --> 03:42:14,686
SPEAKER_0:  but it's not gonna help most men out there. I feel like it's just like a pointless...

03:42:14,914 --> 03:42:17,886
SPEAKER_0:  like speech to give to these like really lost guys.

03:42:18,210 --> 03:42:19,678
SPEAKER_0:  and they really do believe that they can make.

03:42:19,938 --> 03:42:21,566
SPEAKER_0:  they can become successful, they can...

03:42:21,794 --> 03:42:28,062
SPEAKER_0:  get money and like when they get all these things they can't get girls but most of them is not going to achieve that ever.

03:42:28,546 --> 03:42:30,421
SPEAKER_1:  to get the money part or become successful.

03:42:30,421 --> 03:42:35,198
SPEAKER_0:  just become a billionaire, you know? and you will get all the girls, which is true, but not everyone can do that.

03:42:35,778 --> 03:42:41,406
SPEAKER_0:  I feel like when these guys are speaking to these men, there's like, we just care about these men out there. You know, they need to hear this.

03:42:41,730 --> 03:42:43,102
SPEAKER_0:  It doesn't really help a lot of them.

03:42:43,522 --> 03:42:43,998
SPEAKER_1:  and

03:42:44,322 --> 03:42:45,662
SPEAKER_1:  It doesn't.

03:42:46,018 --> 03:42:48,062
SPEAKER_1:  inspire them to develop compassion.

03:42:48,898 --> 03:42:52,273
SPEAKER_1:  So it was the opposite sex, which is probably something required to have a meeting for.

03:42:52,273 --> 03:42:55,870
SPEAKER_0:  relationship. And also like they seem to complain a lot about women.

03:42:56,130 --> 03:43:01,694
SPEAKER_0:  Um, like only wanting men that have money and that's tall and that's muscular, whatever, you know, all those things.

03:43:02,146 --> 03:43:02,590
SPEAKER_0:  um...

03:43:03,010 --> 03:43:06,846
SPEAKER_0:  But they complain about that, but that's also kind of what they're trying to...

03:43:07,522 --> 03:43:14,878
SPEAKER_0:  make the men try to do for themselves. So they kind of like fall into the same sort of behavior. And it seems like they're kind of unaware of that as well.

03:43:15,650 --> 03:43:22,014
SPEAKER_0:  They're just playing a part of the game instead of trying to find a woman that doesn't look for those things and that are looking for

03:43:22,754 --> 03:43:23,870
SPEAKER_0:  Not those things, yeah.

03:43:24,290 --> 03:43:25,374
SPEAKER_1:  I actually would love to have-

03:43:25,890 --> 03:43:26,942
SPEAKER_1:  straight up data.

03:43:27,746 --> 03:43:28,222
SPEAKER_1:  on.

03:43:29,218 --> 03:43:29,694
SPEAKER_1:  people.

03:43:30,082 --> 03:43:33,086
SPEAKER_1:  in that world versus not in that world how often they get laid.

03:43:33,442 --> 03:43:33,822
SPEAKER_1:  Yeah.

03:43:34,498 --> 03:43:34,846
SPEAKER_1:  like.

03:43:35,106 --> 03:43:36,318
SPEAKER_1:  Literally, so.

03:43:37,090 --> 03:43:38,622
SPEAKER_1:  I think for sure.

03:43:39,202 --> 03:43:40,254
SPEAKER_1:  people in that world.

03:43:40,770 --> 03:43:47,070
SPEAKER_1:  have fewer meaningful long-term relationships they're fulfilling actually help them succeed in life

03:43:47,554 --> 03:43:49,726
SPEAKER_1:  that helps them be happy and content and all that kind of stuff.

03:43:50,338 --> 03:43:53,534
SPEAKER_1:  but just even the straight up, the shallow goal of getting laid.

03:43:55,042 --> 03:43:55,678
SPEAKER_1:  I wonder.

03:43:56,034 --> 03:44:00,382
SPEAKER_1:  Uh-huh. Because it's very possible that like just the roughness with which they...

03:44:00,706 --> 03:44:04,510
SPEAKER_1:  uh treat intellectually women that might lead to

03:44:04,738 --> 03:44:06,398
SPEAKER_1:  Lower success, not higher success.

03:44:06,626 --> 03:44:18,014
SPEAKER_0:  It's very adversarial, which I think is always disappointing. Anything that talks about men and women, I think it's good to acknowledge differences, but when it becomes adversarial, especially when you talk about sex, sex is something that men are getting and it's something that women are giving.

03:44:18,242 --> 03:44:23,454
SPEAKER_0:  And that type of like trade off and the way they talk about it is like, yeah, it sets people against each other in a really toxic way, I think.

03:44:23,586 --> 03:44:23,998
SPEAKER_1:  Mm.

03:44:25,090 --> 03:44:27,038
SPEAKER_1:  How do you talk to people from that world?

03:44:27,266 --> 03:44:28,190
SPEAKER_1:  from the Red Pill World.

03:44:28,514 --> 03:44:30,878
SPEAKER_1:  Like would you ever talk to somebody like Andrew Tate?

03:44:31,010 --> 03:44:38,046
SPEAKER_0:  Oh yeah, if I had the chance to. I've been on the Fresh and Fit podcast three times and then I've got a friend Sneak-o who's like very red pill that stuff.

03:44:39,490 --> 03:44:41,918
SPEAKER_0:  If I'm trying to talk to them, usually the...

03:44:42,210 --> 03:44:52,286
SPEAKER_0:  It's kind of like approaching it like a scared cat. The first thing you have to do is like be very gentle and say like, I understand your issues. I understand your complaints. I know that you're, I'm scary because you think I'm gonna say like toxic masculinity and feminism and all these.

03:44:52,514 --> 03:44:56,734
SPEAKER_0:  scary words at you. So the first thing is always to recognize it like a lot of what they talk about

03:44:57,026 --> 03:45:09,918
SPEAKER_0:  there are like true aspects to what they're talking about that people on the left won't recognize. So I think it's good to acknowledge those things that like men and women are kind of different. We do look for different things in general when it comes to relationships. It's okay to say that, there's nothing bad there.

03:45:10,498 --> 03:45:29,310
SPEAKER_0:  And then it'll usually be like, once I've got your trust and I'm in your bubble, like let's talk about the things that you want. And maybe some of the strategies that you're employing aren't necessarily gonna get you some of the things that you want. So for instance, if you're really worried about like shallow girls, like ruining your life, like Malina said, it's probably not best to build your entire worldview around trying to get shallow girls that are gonna ruin your life.

03:45:29,538 --> 03:45:38,302
SPEAKER_0:  Like if your way of attracting a girl is to go to the gym, get a whole bunch of money, and try to like flaunt your wealth as much as possible, you're gonna be attracting the very same type of women that you're here like decrying on your stream.

03:45:38,626 --> 03:45:46,814
SPEAKER_0:  I think we talked about that on the podcast. Like you probably want to have a woman that's going to be there if you lose your job. It's still there. Like that cares about the things that's not just your job.

03:45:47,522 --> 03:45:48,670
SPEAKER_0:  It's more stable.

03:45:48,930 --> 03:45:49,758
SPEAKER_1:  And also I don't

03:45:50,082 --> 03:45:51,966
SPEAKER_1:  help you become a great man.

03:45:52,866 --> 03:45:56,478
SPEAKER_1:  or grow, I feel like a great friendship and a partnership.

03:45:57,122 --> 03:46:03,934
SPEAKER_1:  Like it helps you make you a better person. Some of the most successful people I know, I mean they have families and there's clearly dynamic there that's like.

03:46:04,290 --> 03:46:09,086
SPEAKER_1:  that makes them, they wouldn't be that without. They're not an island, yeah. Yeah, and the kids actually are big.

03:46:09,410 --> 03:46:12,478
SPEAKER_1:  part of that too, like for most people, if you're like a good parrot.

03:46:12,898 --> 03:46:16,990
SPEAKER_1:  they make you step up somehow in life. You have to take responsibility for-

03:46:17,506 --> 03:46:19,806
SPEAKER_1:  getting your shit together and excelling.

03:46:20,098 --> 03:46:21,502
SPEAKER_1:  in ways that uh...

03:46:22,722 --> 03:46:25,022
SPEAKER_1:  I guess the philosophy of the right pull does not quite get to.

03:46:25,186 --> 03:46:27,678
SPEAKER_0:  That's always an interesting thing. I've asked that a couple of times where it's like...

03:46:28,034 --> 03:46:28,766
SPEAKER_0:  Would you let...

03:46:29,250 --> 03:46:30,078
SPEAKER_0:  your daughter.

03:46:30,498 --> 03:46:31,326
SPEAKER_0:  date Andrew Tate.

03:46:31,842 --> 03:46:33,982
SPEAKER_0:  it's always funny to watch them kind of like squirm around

03:46:34,210 --> 03:46:35,335
SPEAKER_0:  Those answers sometimes.

03:46:35,335 --> 03:46:38,622
SPEAKER_1:  But see if they don't have a daughter, like I don't have a...

03:46:38,850 --> 03:46:42,206
SPEAKER_1:  daughter, I think your whole philosophy changes once you have a daughter.

03:46:42,402 --> 03:46:49,342
SPEAKER_0:  Sure. Well, but even at that, like they can, they know that what they're answering, they feel a little bit weird about it. It's funny to watch them. Even they know it's like, ah, fuck.

03:46:49,890 --> 03:46:53,854
SPEAKER_1:  Well, they might say like, I want my daughter to date like a high value male.

03:46:54,594 --> 03:46:56,734
SPEAKER_1:  to the degree that he's a high value male, yes.

03:46:57,314 --> 03:46:58,910
SPEAKER_1:  but like I don't think you'll feel that way.

03:46:59,138 --> 03:47:02,046
SPEAKER_1:  the definition of high value changes completely. suspicious.

03:47:02,338 --> 03:47:03,646
SPEAKER_1:  Certainly the stereotypical.

03:47:04,386 --> 03:47:12,094
SPEAKER_1:  measures of value contribute to the calculation, but it's so much more than that. I think the chemistry of the whole thing is bigger. You've also mentioned...

03:47:12,738 --> 03:47:13,342
SPEAKER_1:  Body count.

03:47:13,826 --> 03:47:14,590
SPEAKER_1:  You guys.

03:47:14,882 --> 03:47:16,446
SPEAKER_1:  Both have a high body count.

03:47:16,706 --> 03:47:17,790
SPEAKER_1:  This body can't matter.

03:47:18,082 --> 03:47:18,782
SPEAKER_1:  or depends.

03:47:19,074 --> 03:47:22,974
SPEAKER_1:  Like you said, it's low in some people's eyes. It's high in other people's eyes.

03:47:23,202 --> 03:47:25,758
SPEAKER_1:  Does body count matter in relationships? Does the past matter?

03:47:26,498 --> 03:47:31,070
SPEAKER_0:  Well, the past matters. I don't think body count. To me, I don't really care. Not just as it is, no.

03:47:32,386 --> 03:47:34,142
SPEAKER_0:  I mean, it could be. Yeah.

03:47:34,466 --> 03:47:35,678
SPEAKER_0:  or the passes for your work

03:47:36,098 --> 03:47:39,134
SPEAKER_0:  Like somebody tells me like they have a 200 body count and they're 16.

03:47:39,362 --> 03:47:56,670
SPEAKER_0:  something's probably going on there that's not good. I was thinking about that too, like, because there could be like really young people that are having some sort of like mental problems going on. Or somebody's like 45 and they've like never had sex before, there's probably something going on, right? So it could be indicative, but if somebody's like in their 20s and they've had sex with, you know, 100 people or 50 people, whatever, it's, you know.

03:47:57,154 --> 03:47:58,110
SPEAKER_0:  It's more experience.

03:47:58,690 --> 03:47:59,166
SPEAKER_0:  Can we go?

03:48:00,162 --> 03:48:05,950
SPEAKER_1:  Okay, so that just represents your legs sexually open. And so it doesn't really necessarily mean any kind of.

03:48:06,466 --> 03:48:07,678
SPEAKER_0:  Not necessarily. It could though.

03:48:07,970 --> 03:48:09,790
SPEAKER_1:  The number alone doesn't mean anything.

03:48:11,426 --> 03:48:24,071
SPEAKER_0:  Well, you could meet a guy that's like, I just really, really like when I fuck a lot of people because it makes me so cool. You can meet someone like that, which is like, So the body count doesn't matter, but like where it comes from. Yeah, like why have you slept with the people that you slept with?

03:48:24,071 --> 03:48:28,990
SPEAKER_1:  Does it hurt like the romantic aspect of the relationship knowing that there's a lot of people in the past?

03:48:29,410 --> 03:48:30,686
SPEAKER_1:  Not for us, no.

03:48:31,202 --> 03:48:33,406
SPEAKER_1:  is a part of the relationship from the method romantic.

03:48:34,114 --> 03:48:35,806
SPEAKER_0:  For us? Yeah, I'd say so.

03:48:37,154 --> 03:48:40,670
SPEAKER_0:  What? You come out for such a cold first.

03:48:40,930 --> 03:48:47,006
SPEAKER_1:  No, I was just in my head thinking, I wanted to just say gotcha right there. Oh, nice. It's so judgmental.

03:48:47,106 --> 03:48:50,878
SPEAKER_0:  I think when it comes to the sex thing, there's always like the way that I explain it is and I understand like

03:48:51,138 --> 03:48:52,734
SPEAKER_0:  Um, I have to say this because

03:48:52,994 --> 03:48:57,118
SPEAKER_0:  I don't advocate for what I do for everybody or what she does for everybody because obviously there's a whole bunch of

03:48:57,442 --> 03:49:06,462
SPEAKER_0:  natural feelings of jealousy that pop up for a lot of people. But when people ask me, you know, it's always like, oh, like, isn't this like horrible that you guys are doing this and you don't love each other? From my perspective.

03:49:06,754 --> 03:49:07,454
SPEAKER_0:  I can have sex with.

03:49:07,746 --> 03:49:13,246
SPEAKER_0:  like any person and it can be sex like that's not like a special thing between two people in my eyes it's like anybody can have sex

03:49:13,474 --> 03:49:17,182
SPEAKER_0:  but there are like certain activities and ways you can spend time with each other.

03:49:17,474 --> 03:49:26,302
SPEAKER_0:  where you're like carving out these like precious little moments in time with a certain person that can do things that are special to that person. And those are the kind of like events that I remember more than anything else.

03:49:26,530 --> 03:49:28,094
SPEAKER_0:  So like the idea of like...

03:49:28,354 --> 03:49:38,910
SPEAKER_0:  Like, oh wow, I had sex with a person that was so special. Doesn't mean as much as like, you know, us traveling to like New Zealand or sharing some special moment, doing like some really fun activity or event or whatever. That's usually how I like it.

03:49:39,682 --> 03:49:41,086
SPEAKER_0:  So a shared intimate moment.

03:49:41,986 --> 03:49:45,214
SPEAKER_0:  I kind of agree, but I can definitely connect the romance with sex. Bye.

03:49:45,474 --> 03:49:49,054
SPEAKER_0:  I'm curious why you can't do that. That's where the red pill's right.

03:49:49,954 --> 03:49:51,079
SPEAKER_0:  We also talked about-

03:49:51,079 --> 03:49:55,134
SPEAKER_1:  misogyny, which is clearly the embodiment of that. What were you saying?

03:49:55,618 --> 03:49:57,886
SPEAKER_1:  So there's a connection between romance and.

03:49:58,018 --> 03:50:01,182
SPEAKER_0:  Yeah, I think it is because I think sex could be a lot of things.

03:50:01,474 --> 03:50:01,854
SPEAKER_0:  Right?

03:50:02,754 --> 03:50:04,382
SPEAKER_0:  It's some sort of bonding.

03:50:04,802 --> 03:50:06,238
SPEAKER_0:  I'd say in some way.

03:50:06,754 --> 03:50:15,902
SPEAKER_0:  They say that you really like BDSM. You kind of like, you become submissive to someone or you take control over someone. It's like a very bonding like intimate moment, I'd say.

03:50:16,354 --> 03:50:18,229
SPEAKER_1:  And that's romantic. The intimacy is romantic.

03:50:18,229 --> 03:50:25,182
SPEAKER_0:  I think it is. If you can show yourself as really submissive or weak, or you have absolutely no control over yourself and you let someone else do it,

03:50:25,410 --> 03:50:30,846
SPEAKER_0:  or you are the one being that, like you are the dominant for someone. I think that's a really like intimate thing because.

03:50:31,106 --> 03:50:32,894
SPEAKER_0:  you show like the weakest part of yourself.

03:50:33,186 --> 03:50:33,630
SPEAKER_0:  Kind of.

03:50:34,050 --> 03:50:35,646
SPEAKER_1:  I just feel like I personally.

03:50:38,018 --> 03:50:42,846
SPEAKER_1:  To me, some component of romantic, but to me, this is not judging to others. To me, maybe this call was brought up.

03:50:44,738 --> 03:50:46,270
SPEAKER_1:  The romance increases.

03:50:46,562 --> 03:50:48,062
SPEAKER_1:  If the number of intimate.

03:50:48,546 --> 03:50:49,566
SPEAKER_1:  interactions,

03:50:50,114 --> 03:50:51,422
SPEAKER_1:  are limited to one person.

03:50:53,026 --> 03:50:54,398
SPEAKER_1:  For me, for some reason...

03:50:55,074 --> 03:50:56,158
SPEAKER_1:  spreading it out.

03:50:57,794 --> 03:50:58,942
SPEAKER_1:  decreases.

03:50:59,362 --> 03:51:00,414
SPEAKER_1:  like, um...

03:51:00,706 --> 03:51:01,694
SPEAKER_1:  exponentially.

03:51:02,050 --> 03:51:03,742
SPEAKER_1:  the feeling of romance you feel.

03:51:04,162 --> 03:51:06,942
SPEAKER_1:  I don't know what that could be just like sort of having.

03:51:07,362 --> 03:51:08,926
SPEAKER_1:  grown up in the Soviet Union.

03:51:09,186 --> 03:51:13,822
SPEAKER_1:  There's a kind of, there's the fairy tale stories and you're kind of maybe living through them.

03:51:14,722 --> 03:51:18,046
SPEAKER_0:  Yeah, I mean, I think what you're saying is really normal. Like most people probably show that way.

03:51:18,818 --> 03:51:21,534
SPEAKER_1:  But because you guys are able to successfully not do that, I just,

03:51:22,562 --> 03:51:25,054
SPEAKER_1:  I want to question my own understanding of it.

03:51:25,282 --> 03:51:28,734
SPEAKER_1:  Like, why is that? Why is that? Am I being very, um...

03:51:29,218 --> 03:51:30,526
SPEAKER_1:  jealous for no reason like

03:51:30,850 --> 03:51:36,062
SPEAKER_1:  Maybe you can maximize the number of intimate experiences if you just open up and let go of the jealousy.

03:51:36,290 --> 03:51:37,415
SPEAKER_1:  I think, I feel like.

03:51:37,415 --> 03:51:40,734
SPEAKER_0:  in Sweden, like in Scandinavia, very extremely just sexually open.

03:51:41,154 --> 03:51:46,174
SPEAKER_0:  Like in general, we're not like super religious either. We're very like relaxed. We don't.

03:51:46,498 --> 03:51:53,246
SPEAKER_0:  Like we don't feel bad about ourselves. It's just like a different sort of thing. And I would say like it's, we're more progressive when it comes to feminism and stuff.

03:51:53,794 --> 03:51:54,142
SPEAKER_0:  So.

03:51:54,466 --> 03:52:03,497
SPEAKER_0:  It's more common that you will meet women with a higher body count than like when I meet like American girls, all of them have like vaginism, like super suppressed, like sexually in 

03:52:03,497 --> 03:52:04,247
SPEAKER_1:  Or did you just use?

03:52:04,247 --> 03:52:05,022
SPEAKER_0:  They have like...

03:52:05,282 --> 03:52:11,326
SPEAKER_0:  issues to like they can't relax during sex, which is hurts for them. Vaginismus. Vaginismus.

03:52:11,906 --> 03:52:15,550
SPEAKER_0:  So like I meet so many girls that are having like a lot of issues.

03:52:15,906 --> 03:52:16,510
SPEAKER_0:  with sex.

03:52:16,834 --> 03:52:20,286
SPEAKER_0:  and they have like a very low body count because they just can't relax or-

03:52:21,026 --> 03:52:24,094
SPEAKER_0:  Yeah, and usually they come from a very religious background.

03:52:24,482 --> 03:52:28,990
SPEAKER_0:  So they have just been told like you cannot wear that. You cannot be like that. You can't like, you know.

03:52:29,346 --> 03:52:29,854
SPEAKER_0:  and

03:52:30,146 --> 03:52:31,102
SPEAKER_0:  Like where I grew up.

03:52:31,362 --> 03:52:32,350
SPEAKER_0:  It was not like that at all.

03:52:32,578 --> 03:52:34,270
SPEAKER_0:  would you see it as more of like a casual thing?

03:52:35,138 --> 03:52:36,926
SPEAKER_1:  So then you can just maximize.

03:52:38,146 --> 03:52:39,271
SPEAKER_1:  The awesomeness is.

03:52:39,271 --> 03:52:46,526
SPEAKER_0:  Yeah, I guess I don't have trouble with it. Exactly. I think the important thing I think for everybody to realize is there's always pros and cons to everything.

03:52:46,754 --> 03:53:13,406
SPEAKER_0:  Like my lifestyle, like obviously I get to have a lot of fun experiences. That's like a huge pro and that's super cool. And if you're like a more monogamy brain person, you're not going to get those experiences, but if you're a monogamy brain person, like when you're sharing that special moment in time with somebody else, like that moment could be really, really, really special because now it's the thing that you're showing yourself and opening yourself up to another person and they're only trusting you to do that. And that's like a really special thing that only the two of you are sharing with each other. So, I mean, like there's always like pros and cons to everything. Like I think we both would say like.

03:53:13,634 --> 03:53:19,134
SPEAKER_0:  like doing an open relationship is probably not like, we would not recommend it. Yeah, I don't think we would, no.

03:53:20,098 --> 03:53:25,822
SPEAKER_1:  Yeah, I recently fasted for three days and I ate a chicken breast at the end of that and it was like the most delicious.

03:53:26,146 --> 03:53:26,942
SPEAKER_1:  food I've ever eaten.

03:53:27,298 --> 03:53:27,742
SPEAKER_1:  prove.

03:53:28,098 --> 03:53:30,974
SPEAKER_1:  So like there's some aspect of fasting and scarcity and so on that.

03:53:31,426 --> 03:53:33,886
SPEAKER_1:  And you have to figure out for your own psyche what...

03:53:34,050 --> 03:53:42,750
SPEAKER_0:  It's the best. It's good to be a little bored or like not do something or like work because you can just enjoy the time when you're doing something really fun is more fun. Otherwise, you're just going to get numb.

03:53:42,978 --> 03:53:44,062
SPEAKER_0:  in general, with everything.

03:53:44,194 --> 03:53:44,510
SPEAKER_1:  Yeah.

03:53:44,834 --> 03:53:46,462
SPEAKER_1:  Yeah, I personally just never get bored.

03:53:46,754 --> 03:53:49,086
SPEAKER_1:  Like, I guess the boring thing is exciting to me.

03:53:49,794 --> 03:53:50,334
SPEAKER_1:  I just

03:53:50,818 --> 03:53:51,943
SPEAKER_1:  You're like me.

03:53:51,943 --> 03:53:54,622
SPEAKER_0:  Because everything I like is boring.

03:53:54,946 --> 03:53:59,582
SPEAKER_1:  I gotta ask you, we talked about massaging, in the, he's trying to battle it out on the internet.

03:53:59,906 --> 03:54:00,958
SPEAKER_1:  What's your...

03:54:01,378 --> 03:54:03,038
SPEAKER_1:  What's your sense as a woman?

03:54:03,842 --> 03:54:07,966
SPEAKER_1:  about the level of massaging and the internet in the streaming community and how to fight it.

03:54:08,962 --> 03:54:16,382
SPEAKER_0:  For me, because I guess I get it every single day somehow, because I have an online, like I have a chat that goes live, right?

03:54:16,642 --> 03:54:24,926
SPEAKER_0:  And, but I have like mods moderating that all the time, so I don't really need to see much of it. I think it's just pretty annoying because you get to like see it all the time.

03:54:25,538 --> 03:54:27,710
SPEAKER_0:  Um, and it's become like background noise.

03:54:28,386 --> 03:54:37,598
SPEAKER_0:  Yeah, a little bit and it's like the same comments over and over again. But it's usually for me, I don't personally care that much. I understand that other people do, especially when it comes into like.

03:54:37,922 --> 03:54:39,678
SPEAKER_0:  when there's like a lot of sexism and stuff.

03:54:40,130 --> 03:54:46,558
SPEAKER_0:  And when there's a lot of men not taking women seriously, I definitely get that. And I used to get that even more, like a few years ago.

03:54:46,946 --> 03:54:52,958
SPEAKER_0:  with my accent and everything and I used to be blonde as well a few months ago. I feel like people wouldn't take me seriously because of that.

03:54:53,218 --> 03:54:54,398
SPEAKER_0:  Uh, that's a bit annoying.

03:54:54,754 --> 03:54:55,166
SPEAKER_0:  but.

03:54:55,746 --> 03:55:00,990
SPEAKER_0:  I feel like it's pretty easy to see through when someone acts that way, and for me personally I don't really care, but...

03:55:01,410 --> 03:55:07,838
SPEAKER_0:  Um, it's a bit annoying, like being online and like getting stuff every single day. Uh, I would say like the probably the worst thing is-

03:55:08,578 --> 03:55:11,710
SPEAKER_0:  When you feel like you put in a lot of effort into some sort of work.

03:55:12,258 --> 03:55:18,366
SPEAKER_0:  Everyone is just going to say, you just got that because you're a woman and you're attractive. And that's probably like the worst thing.

03:55:18,754 --> 03:55:20,222
SPEAKER_0:  Is there a way to fight that, you think?

03:55:20,514 --> 03:55:23,550
SPEAKER_0:  Yeah, I don't think you can. I think it just comes up all the time. It's just like...

03:55:23,778 --> 03:55:39,070
SPEAKER_0:  It is what it is, I guess. You just gotta keep doing whatever you do and not let it emotionally control you somehow. I think having more women in those spaces is always good. It's probably good, yeah. Like a lot of the guys you can tell online that they don't ever. Don't bring on the worst ones then. See, she's being, see, she just did it. She did the misogyny thing.

03:55:39,458 --> 03:55:44,254
SPEAKER_0:  By having some bad women on, she's saying all women, see? Well, you know it's true.

03:55:45,250 --> 03:55:45,918
SPEAKER_0:  Right?

03:55:46,082 --> 03:55:50,343
SPEAKER_1:  Simply I disagree with you and I'm older than both of you and therefore wiser, right?

03:55:50,343 --> 03:55:52,926
SPEAKER_0:  So we'll combine we're older than you. Thank you.

03:55:53,218 --> 03:55:56,830
SPEAKER_0:  The combined wisdom. Yeah, we've got combined age.

03:55:57,410 --> 03:56:09,822
SPEAKER_0:  It could be the same thing, also the age thing and the woman thing. A lot of people think that I'm just copying every single thing that he says, which I think is a bit annoying as well. I can never really like... A sonic user of that one. Yeah, which is a bit annoying.

03:56:10,274 --> 03:56:13,630
SPEAKER_0:  It was about the defending police. I like friendship.

03:56:13,730 --> 03:56:16,766
SPEAKER_1:  camaraderie and love and respect, which you.

03:56:17,378 --> 03:56:21,662
SPEAKER_1:  uh... both have had for a time and have lost and i would like you to regain it

03:56:22,114 --> 03:56:29,182
SPEAKER_1:  Let's try to increase not decrease the amount of love in the space. What do you think about some of the harshness of his language, which we talked about?

03:56:30,018 --> 03:56:33,118
SPEAKER_1:  our word in the past when you used n-word

03:56:33,890 --> 03:56:35,015
SPEAKER_1:  all that kind of stuff.

03:56:35,015 --> 03:56:36,515
SPEAKER_0:  what I used to do. I mean...

03:56:36,515 --> 03:56:42,782
SPEAKER_1:  No, like what do you think about it? Like do you give them advice? To not speak a certain way? No, like a little more civility?

03:56:43,138 --> 03:56:45,013
SPEAKER_1:  I was just trying to get a second opinion on this.

03:56:45,013 --> 03:56:56,702
SPEAKER_0:  Second opinion about... Normie people, non-internet people are way more extreme than... Yeah... She's way more extreme than I am. No, that's not true. Okay, so here's the thing for me, okay? I was not online until three years ago.

03:56:57,122 --> 03:57:02,462
SPEAKER_0:  at all. Like I would watch YouTube. That's pretty much all I would do. I wouldn't do anything else. Really, I didn't.

03:57:02,914 --> 03:57:04,350
SPEAKER_0:  I've stopped playing video games or anything.

03:57:04,802 --> 03:57:06,366
SPEAKER_0:  sound like extremely new to everything?

03:57:06,818 --> 03:57:07,454
SPEAKER_0:  Um...

03:57:07,778 --> 03:57:12,574
SPEAKER_0:  So when I came into this world and I started seeing clips from him in the past

03:57:12,898 --> 03:57:18,462
SPEAKER_0:  I don't think I really had much of an opinion because it just sounded like it was just a different, like words that we were using, but it didn't mean anything.

03:57:18,722 --> 03:57:19,806
SPEAKER_0:  That's what it feels like. It was just like...

03:57:20,098 --> 03:57:21,342
SPEAKER_0:  If you're saying the R word.

03:57:21,666 --> 03:57:27,486
SPEAKER_0:  It's because you just want to call someone stupid, but you want to like do it a little bit more. Like, but it's not like, it didn't feel like it was like a-

03:57:27,970 --> 03:57:32,222
SPEAKER_0:  It's not like race is more like, you know, it's not agreement on this side.

03:57:32,834 --> 03:57:43,518
SPEAKER_0:  So like if he was saying the F word because it was just like a word to like insult someone and he was like, I don't think he was ever, I don't think you were ever homophobic back in the day or anything like that. But I think it was just like a way.

03:57:43,810 --> 03:57:49,699
SPEAKER_0:  to express yourself maybe back then? I don't know, I didn't do it. There's no videos of me or anything because I wasn't even online back then.

03:57:49,699 --> 03:57:52,542
SPEAKER_1:  Yeah, so my case was, I definitely don't think.

03:57:52,898 --> 03:57:56,254
SPEAKER_1:  Steven is homophobic or as they're in those obviously.

03:57:56,546 --> 03:57:57,854
SPEAKER_1:  There's a good heart there.

03:57:58,306 --> 03:58:00,181
SPEAKER_1:  and a good mind. I was just saying.

03:58:00,181 --> 03:58:02,431
SPEAKER_0:  He just likes being mean.

03:58:02,431 --> 03:58:06,110
SPEAKER_1:  There's some you lose yourself and forget the bigger picture that...

03:58:06,498 --> 03:58:07,614
SPEAKER_1:  He's pushing for...

03:58:08,034 --> 03:58:12,222
SPEAKER_1:  more effective discourse on the internet. He's like an inspiration to a lot of people, especially now.

03:58:12,770 --> 03:58:18,046
SPEAKER_1:  of like how you can use effective conversation to make for better world to tror how to define historical

03:58:18,274 --> 03:58:20,478
SPEAKER_1:  and so on and then you lose some of that power.

03:58:21,186 --> 03:58:22,526
SPEAKER_1:  by losing yourself.

03:58:23,138 --> 03:58:27,166
SPEAKER_1:  in the language, just more language of emotion versus.

03:58:27,618 --> 03:58:29,493
SPEAKER_1:  communication. I would say...

03:58:29,493 --> 03:58:30,046
SPEAKER_0:  area.

03:58:30,498 --> 03:58:38,430
SPEAKER_0:  I would say something that is probably recently done in that case, because it's been joking about women a lot. It's women's fault, they're bad. It's been like-

03:58:38,818 --> 03:58:49,150
SPEAKER_0:  a lot of jokes when it comes to misogyny, I guess, in your community. And I think it's actually turned people a little bit that way. That's why we've done the recent misogyny. Yes, so I guess that's actually true because I don't think it was pretty.

03:58:49,410 --> 03:58:53,374
SPEAKER_0:  I don't think it was clear enough. I don't think it actually was. I think you did that mistake.

03:58:53,922 --> 03:58:57,022
SPEAKER_0:  Um, but I think back then I was even saying like, Hey, you should probably not.

03:58:57,250 --> 03:58:59,230
SPEAKER_0:  Like, you pro- you probably should not do that.

03:59:00,258 --> 03:59:03,742
SPEAKER_0:  Because it actually is pretty hard for me because whenever I come into his commuter, like his chat...

03:59:04,226 --> 03:59:08,190
SPEAKER_0:  People are just gonna spam, it's like a woman moment. It's a woman moment whenever I say something, it's kind of like...

03:59:08,514 --> 03:59:12,478
SPEAKER_0:  Yeah, it's getting pretty annoying, as I said, it's just annoying when you see it every single day.

03:59:13,282 --> 03:59:13,630
SPEAKER_0:  in.

03:59:13,762 --> 03:59:17,123
SPEAKER_1:  There you go, wisdom from somebody younger than you.

03:59:17,123 --> 03:59:18,078
SPEAKER_0:  wisdom can come from.

03:59:18,498 --> 03:59:22,623
SPEAKER_0:  All kind of people. Yeah, of course. Just sometimes very limited quantities.

03:59:22,623 --> 03:59:23,038
SPEAKER_1:  Okay.

03:59:23,554 --> 03:59:24,894
SPEAKER_1:  and learn something from anybody.

03:59:25,282 --> 03:59:28,286
SPEAKER_1:  What advice would you give to young people, the both of you?

03:59:29,378 --> 03:59:32,926
SPEAKER_1:  that you have both audiences where young people look up to you.

03:59:33,410 --> 03:59:36,766
SPEAKER_1:  in general, if you were to give advice to somebody in high school, like...

03:59:37,122 --> 03:59:37,502
SPEAKER_1:  Haru.

03:59:38,914 --> 03:59:41,278
SPEAKER_1:  Create a life that you can be proud of. What would you say?

03:59:42,914 --> 03:59:47,006
SPEAKER_0:  The most important thing that I've learned is to view people as different.

03:59:47,234 --> 03:59:48,350
SPEAKER_0:  and not better or worse?

03:59:48,642 --> 03:59:54,142
SPEAKER_0:  And when you view people as different instead of better or worse, you learn that there's almost something you can learn from anybody.

03:59:54,370 --> 04:00:12,510
SPEAKER_0:  Like be open and empathetic towards other people's experiences. Nobody does anything by random choice. Like there's always reasons why people act the way they do. And as long as you're willing to kind of like be open and receptive to the lived experiences of other people, you're going to be able to gather information and create like a more cohesive and better view of the world than any of your peers will.

04:00:13,698 --> 04:00:17,073
SPEAKER_1:  Do you have any kind of advice you can give to young folks?

04:00:17,073 --> 04:00:24,478
SPEAKER_0:  I feel like something that I see especially in America a lot is that a lot of people kind of get told what to do early on like in high school.

04:00:24,706 --> 04:00:26,366
SPEAKER_0:  They're supposed to become this thing.

04:00:26,594 --> 04:00:33,118
SPEAKER_0:  uh... like education wise like they're supposed to become a doctor or this thing or whatever and they can just like give up on things that they're actually passionate about

04:00:33,538 --> 04:00:40,414
SPEAKER_0:  So I think a lot of teenagers get really confused. They get an education and then they get that job and they hate everything and they think that...

04:00:40,770 --> 04:00:46,366
SPEAKER_0:  when they're reaching the job, when they're reaching the journey, they're gonna get happy. That's where the happiness is gonna be. But then when they-

04:00:46,850 --> 04:00:47,358
SPEAKER_0:  to there.

04:00:47,586 --> 04:00:53,310
SPEAKER_0:  They just hate everything and then they become really depressed. And I've seen this so much. Like I see this all the time.

04:00:53,570 --> 04:00:54,334
SPEAKER_0:  And it's...

04:00:54,626 --> 04:00:56,158
SPEAKER_0:  Pretty sad to me to see.

04:00:56,418 --> 04:01:00,702
SPEAKER_0:  so many people that are just wasting time and then they just get really confused and...

04:01:01,218 --> 04:01:09,758
SPEAKER_0:  I don't know, it's the same thing with relationships too, no one really knows what they want anymore. I feel like everyone is just kind of doing whatever like society is saying, or their parents are saying, or their friends are saying.

04:01:10,306 --> 04:01:10,846
SPEAKER_0:  Um...

04:01:11,266 --> 04:01:15,742
SPEAKER_0:  And they're never really doing anything that's super meaningful anymore. And like they don't...

04:01:16,130 --> 04:01:24,382
SPEAKER_0:  So what I would say is try to find something that is important to you. It could be anything really, like some sort of passion, maybe like your friends, maybe like.

04:01:24,642 --> 04:01:28,767
SPEAKER_0:  Like what matters to you? And like figuring those things out, I think is really important.

04:01:28,767 --> 04:01:32,517
SPEAKER_1:  comes from being able to listen to like some inner voice.

04:01:32,517 --> 04:01:38,910
SPEAKER_0:  It's really hard because you're living the life and like there's things happening around you. People tell you what to do and what not to do and you know.

04:01:39,138 --> 04:01:41,854
SPEAKER_0:  No one really has their own opinions. Everyone is just kind of like.

04:01:42,434 --> 04:01:45,086
SPEAKER_0:  listening to the cooler thing or you know.

04:01:45,410 --> 04:01:47,518
SPEAKER_1:  Except Steven, he seems to stay on his own.

04:01:47,650 --> 04:01:55,166
SPEAKER_0:  Yeah, I'd say so. Something I realized too, because we just went to TwitchCon and we were talking to a lot of streamers.

04:01:55,874 --> 04:01:58,494
SPEAKER_0:  uh... it was interesting i i thought it was interesting because the

04:01:59,394 --> 04:02:04,062
SPEAKER_0:  The few people that I feel like I, that seemed really cool and that I look up to, like in the streaming world.

04:02:04,386 --> 04:02:05,982
SPEAKER_0:  All of them wants to quit streaming.

04:02:06,498 --> 04:02:08,702
SPEAKER_0:  All I want to do is do it. No one wants to do it. That's all I said.

04:02:09,026 --> 04:02:10,430
SPEAKER_0:  and they're so successful.

04:02:10,690 --> 04:02:17,214
SPEAKER_0:  Like they are around successful people. They're working every single day. They're working hard. They're making so much money.

04:02:17,538 --> 04:02:21,630
SPEAKER_0:  and everyone is just complaining and like they're complaining about um

04:02:22,306 --> 04:02:33,886
SPEAKER_0:  Like not being able to see their partner or, you know, because they need to live somewhere else. And I see these things and they seem extremely unhappy. But it's so hard for them to just cut all their success.

04:02:34,146 --> 04:02:36,126
SPEAKER_0:  off because that's like what you...

04:02:36,354 --> 04:02:37,118
SPEAKER_0:  you know, learn.

04:02:37,506 --> 04:02:38,014
SPEAKER_0:  to do.

04:02:38,562 --> 04:02:42,046
SPEAKER_0:  And that's like supposed to be like your happiness, but it isn't. Everyone is really unhappy.

04:02:42,210 --> 04:02:43,358
SPEAKER_1:  Yeah, there's something about...

04:02:43,618 --> 04:02:47,838
SPEAKER_1:  maybe streaming is different, but YouTube folks too have interacted with a few.

04:02:49,090 --> 04:02:50,654
SPEAKER_1:  even in podcasting space.

04:02:51,106 --> 04:02:55,294
SPEAKER_1:  People become obsessed about the views and numbers and subscribers and stuff like that.

04:02:55,810 --> 04:02:56,222
SPEAKER_1:  uh

04:02:56,610 --> 04:02:57,854
SPEAKER_1:  So I turned, I never.

04:02:58,146 --> 04:03:00,670
SPEAKER_1:  talk about that. I don't pay attention to that.

04:03:01,442 --> 04:03:01,854
SPEAKER_1:  Uh...

04:03:02,114 --> 04:03:05,086
SPEAKER_1:  I feel like that's a drug that destroys.

04:03:05,602 --> 04:03:06,494
SPEAKER_1:  Your mind.

04:03:06,914 --> 04:03:11,134
SPEAKER_1:  your mind as an artist, the ability to create truly unique things.

04:03:11,650 --> 04:03:15,646
SPEAKER_1:  I'll see your mind in terms of the anxiety the ups and downs of the

04:03:16,610 --> 04:03:17,918
SPEAKER_1:  attention mechanism.

04:03:18,434 --> 04:03:19,934
SPEAKER_1:  uh and then also being

04:03:20,354 --> 04:03:20,734
SPEAKER_1:  Just.

04:03:20,962 --> 04:03:26,334
SPEAKER_1:  If something that you make is not popular but it meant a lot to you, you will think of it less.

04:03:26,626 --> 04:03:30,238
SPEAKER_1:  because it's not popular. That's a really dangerous thing and because

04:03:30,530 --> 04:03:34,302
SPEAKER_1:  Everyone around you is reinforcing. Like I'll get messages like.

04:03:34,818 --> 04:03:35,422
SPEAKER_1:  Wow.

04:03:35,650 --> 04:03:38,014
SPEAKER_1:  this thing got this many views or something.

04:03:38,594 --> 04:03:39,326
SPEAKER_1:  Great job.

04:03:40,450 --> 04:03:43,422
SPEAKER_1:  No, you don't get it. Like that's not, that's not.

04:03:43,682 --> 04:03:48,670
SPEAKER_1:  Everyone is enforcing this language of views and likes and so on.

04:03:49,026 --> 04:03:49,630
SPEAKER_1:  And that's.

04:03:49,858 --> 04:03:53,566
SPEAKER_1:  It's correlated of course, because truly impactful things will get a lot of attention.

04:03:53,954 --> 04:03:54,398
SPEAKER_1:  often.

04:03:56,098 --> 04:03:59,038
SPEAKER_1:  It's not on the individual local scale.

04:03:59,362 --> 04:04:00,638
SPEAKER_1:  like temporarily is.

04:04:01,890 --> 04:04:06,270
SPEAKER_1:  It can really fuck with your mind. I see that in the creators they become...

04:04:07,170 --> 04:04:07,678
SPEAKER_1:  Oh

04:04:07,970 --> 04:04:09,095
SPEAKER_1:  Addicts to the algorithm

04:04:09,095 --> 04:04:16,286
SPEAKER_0:  lost and chasing views. Like we know friends that we know cool people and then they start streaming and eventually they go they're like chasing the dragon of like

04:04:16,898 --> 04:04:22,974
SPEAKER_0:  And they change, like, yeah, it's like hard to engage for them anymore. This is something I've always said that, like, one of the-

04:04:23,266 --> 04:04:37,726
SPEAKER_0:  biggest blessings and biggest curses of humanity is we are very good at acclimating like you can become paralyzed you can have all sorts of horrible things happen to you and you'll get used to it and you'll be okay you're gonna have like a good baseline but it works the other way too and that you can get more and more and more and more and you acclimate to it almost immediately there's like

04:04:37,986 --> 04:04:52,318
SPEAKER_0:  This is a phenomenon that I bet it happens in the YouTube world, but I know what happens in the streaming world where you're streaming 1,000 viewers every day, huge event happens and you blow up and you got like 15,000 viewers for a day or two. And then it starts to go down and down and down and down and down. And then after all the drama stayed off,

04:04:52,546 --> 04:04:54,654
SPEAKER_0:  you're at like 3000 concurrent viewers.

04:04:54,914 --> 04:04:58,526
SPEAKER_0:  Now in the macro, you went from 1000 to 3000. That feels awesome.

04:04:58,786 --> 04:05:16,894
SPEAKER_0:  but you actually feel like shit the whole time because you're remembering when you had 10 or 15,000 and now everything feels horrible. And you'll see people climb over time. They're like, fuck, like, but whatever that one huge stream I had, like, I've never been able to, and it's like, dude, you're doing great. Yeah, that happens a lot. There's so many people that we know that we find super, super cool. They're passionate about things. They have so much interest.

04:05:17,282 --> 04:05:20,542
SPEAKER_0:  And then they just get like so addicted to these numbers and like all the...

04:05:20,834 --> 04:05:25,630
SPEAKER_0:  Everything is just ruined, like all the cool things about them is ruined because they stop doing the things that they actually like.

04:05:26,466 --> 04:05:31,783
SPEAKER_0:  to do something else that gives them more viewers and more money. And it's really sad to see. that that

04:05:31,783 --> 04:05:33,630
SPEAKER_1:  a sacrifice that seems...

04:05:34,434 --> 04:05:41,662
SPEAKER_1:  Temporary is that it it actually destroys you like for one time making a choice. I come across those choices often like

04:05:42,018 --> 04:05:43,518
SPEAKER_1:  I can do this. You can kind of know.

04:05:43,842 --> 04:05:45,534
SPEAKER_1:  what's going to be popular and not.

04:05:46,050 --> 04:05:49,342
SPEAKER_1:  And you have to ask yourself the question, like, is this going to sacrifice?

04:05:49,922 --> 04:05:59,390
SPEAKER_0:  Because if people are sacrificing intimate relationships, they're sacrificing time with their family, they're sacrificing time with things that they feel good about and that they like.

04:06:00,194 --> 04:06:00,670
SPEAKER_0:  and

04:06:01,090 --> 04:06:02,878
SPEAKER_0:  That's something I kind of realized last year.

04:06:03,202 --> 04:06:11,614
SPEAKER_0:  I was working so much and I was just grinding and grinding and grinding because it was kind of new for me and then new years came by and I was like wait what did I even do like the entire year?

04:06:11,970 --> 04:06:13,502
SPEAKER_0:  like I travel to a bunch of places.

04:06:13,858 --> 04:06:20,862
SPEAKER_0:  But nothing actually really meant anything to me because I felt like I was just working the entire time. I felt like I was just numb through the entire year and that was really scary.

04:06:21,474 --> 04:06:22,110
SPEAKER_0:  Um...

04:06:22,754 --> 04:06:24,030
SPEAKER_0:  Like I rendered a...

04:06:24,546 --> 04:06:29,214
SPEAKER_0:  Like a super pretty house, like for a week, with my dad and my sister, because I wanted to spend time with them.

04:06:29,602 --> 04:06:32,094
SPEAKER_0:  But the entire time I was just streaming.

04:06:32,546 --> 04:06:38,430
SPEAKER_0:  and I actually didn't ever like calm down and just like chill with them. And I like, that's like time I'll never get back.

04:06:38,850 --> 04:06:42,590
SPEAKER_0:  I don't give a shit about the money that I made that week, but I lost the time.

04:06:43,106 --> 04:06:50,846
SPEAKER_0:  And like that is really important to me. And yeah, and a lot of people are doing that. And I feel like, as you said, like you can definitely see that in like artists.

04:06:51,426 --> 04:07:00,030
SPEAKER_0:  for sure. I feel like if you look at like artists like back in the 60s or 70s, I feel like things were just so much better back then. And it feels like they were actually making music.

04:07:00,290 --> 04:07:03,134
SPEAKER_0:  that meant something to them. They were actually making art.

04:07:03,522 --> 04:07:14,782
SPEAKER_0:  And I feel like today everything is just kind of like whatever is cool, whatever sells, whatever, you know, sounds in a certain way. Everything is kind of the same thing. And everything that is very artistic and very cool is actually not that popular.

04:07:15,138 --> 04:07:15,582
SPEAKER_0:  at all.

04:07:16,226 --> 04:07:17,310
SPEAKER_0:  And that's kind of sad.

04:07:17,762 --> 04:07:21,438
SPEAKER_1:  I think. Yeah, of course there's now bigger mechanisms platforms to spread.

04:07:22,050 --> 04:07:23,102
SPEAKER_1:  Stuff Music

04:07:23,906 --> 04:07:26,910
SPEAKER_1:  So as long as you can be content with not being popular.

04:07:27,330 --> 04:07:28,455
SPEAKER_1:  I think you can still create.

04:07:28,455 --> 04:07:32,205
SPEAKER_0:  But not like when people get a little popular they get addicted to that so fast.

04:07:32,205 --> 04:07:33,054
SPEAKER_1:  Yeah, that's weird.

04:07:33,314 --> 04:07:37,438
SPEAKER_1:  You have been somewhat good, at least from my outsider perspective.

04:07:37,826 --> 04:07:39,294
SPEAKER_1:  Because I think you...

04:07:39,746 --> 04:07:43,294
SPEAKER_1:  I can at least imagine you making choices that could make you more popular.

04:07:43,618 --> 04:07:46,462
SPEAKER_1:  and you don't seem to make those choices.

04:07:46,978 --> 04:07:53,150
SPEAKER_0:  Like having orbits of prop line. But it is very intentional, like you said. And I made that choice at every single...

04:07:53,378 --> 04:07:54,238
SPEAKER_0:  stage of my life.

04:07:54,466 --> 04:07:58,366
SPEAKER_0:  One is because from the perspective of being a carpet cleaner, my life is way better than that.

04:07:58,594 --> 04:08:04,126
SPEAKER_0:  was or ever would have been. So I'm already doing way better than I ever thought. Somebody like me ever could be. But then too.

04:08:04,418 --> 04:08:04,958
SPEAKER_0:  I

04:08:05,186 --> 04:08:06,142
SPEAKER_0:  Super love my job.

04:08:06,402 --> 04:08:19,358
SPEAKER_0:  Every time I wake up, every time I fly to a place to do a podcast, every time I get to talk to really cool people, like every single part of my job, I super like. If there's something I don't like, I just cut it off because I don't care. Because I'm already making plenty of money doing what I do. And why would I ever wake up and not like what I'm doing when I can like what I'm doing?

04:08:19,618 --> 04:08:21,086
SPEAKER_1:  How do you guys find through that?

04:08:21,346 --> 04:08:21,822
SPEAKER_1:  given that.

04:08:22,722 --> 04:08:26,622
SPEAKER_1:  you love it and sometimes maybe lose yourself in the drug of it. How do you

04:08:26,850 --> 04:08:27,390
SPEAKER_1:  find.

04:08:27,714 --> 04:08:30,142
SPEAKER_1:  like work life balance together inside a relationship.

04:08:30,978 --> 04:08:31,902
SPEAKER_1:  like time for each other.

04:08:32,642 --> 04:08:34,517
SPEAKER_0:  I don't at all so I'm not a good person to ask.

04:08:34,517 --> 04:08:38,910
SPEAKER_1:  What do you love more, Mel or Fector?

04:08:39,074 --> 04:08:48,094
SPEAKER_0:  Factor is a really good game. That's like not a fair comparison, okay? You're talking about one of the best, cleanest games, best support ever made, cleanest code base. Yeah, this is.

04:08:48,770 --> 04:08:50,846
SPEAKER_0:  Yeah, it's more factorial time for me.

04:08:52,066 --> 04:08:57,691
SPEAKER_1:  starting to understand where the massaging comes from. By the way, is the Inspector legit a really good game? Yeah, of course.

04:08:57,691 --> 04:08:58,206
SPEAKER_0:  See you on call.

04:08:58,434 --> 04:09:00,254
SPEAKER_0:  If you're like, do you enjoy programming?

04:09:01,058 --> 04:09:02,846
SPEAKER_1:  Of course, that's all I do. That's all that's...

04:09:03,170 --> 04:09:04,830
SPEAKER_1:  Programming is...

04:09:05,218 --> 04:09:08,593
SPEAKER_1:  is the game in itself that I enjoy probably more than anything else. But yeah.

04:09:08,593 --> 04:09:22,647
SPEAKER_0:  very much a game like that. If you're into stuff like that, you can lose hundreds of hours very quickly too. You have a problem and then you think of a solution and then you iterate on that over and over and over again in larger, larger schemes. Sometimes you gotta redesign stuff, sometimes you gotta, it's very much like that kind of game. See us on video.

04:09:22,647 --> 04:09:26,046
SPEAKER_1:  building a factory like what on a foreign planet or something like that.

04:09:26,210 --> 04:09:33,150
SPEAKER_0:  Basically, it's like a bunch of you're trying to automate different problems so that you can build bigger things so that you can automate bigger problems. So you can build bigger things and automate bigger problems.

04:09:33,346 --> 04:09:37,694
SPEAKER_1:  So it's more complicated than like a city building game, like some city type of thing.

04:09:38,306 --> 04:09:42,782
SPEAKER_0:  I wouldn't say it's more complicated, it's more like, it's like, Factorio is like a game of like, logic.

04:09:43,138 --> 04:09:45,013
SPEAKER_0:  Like strictly like logic, like.

04:09:45,013 --> 04:09:46,513
SPEAKER_1:  almost like a building a circuit.

04:09:46,513 --> 04:09:52,513
SPEAKER_0:  Yes, yeah, there's like there's circuitry and you've got your an or exorga to like there's stuff like that It's very much like that like what are the enemies?

04:09:52,513 --> 04:09:53,054
SPEAKER_1:  in the game.

04:09:53,250 --> 04:09:55,038
SPEAKER_0:  Like what? Um, they're like, so

04:09:55,330 --> 04:10:02,814
SPEAKER_0:  try to bite you and you can get guns and shoot and kill them. But it's like, I saw there's like shooting going on. Yeah, but that's like a minor, just like another problem to solve in the game, basically. Okay.

04:10:03,074 --> 04:10:03,390
SPEAKER_1:  Alright.

04:10:03,842 --> 04:10:07,358
SPEAKER_1:  See what we do there? We just started talking about the game as we're trying.

04:10:07,586 --> 04:10:11,678
SPEAKER_1:  Oh my God, that's like a game. OK, that's horrible. Anyway, is there.

04:10:11,970 --> 04:10:14,910
SPEAKER_1:  Is that basically the struggle, not a thought struggle, how to get?

04:10:15,298 --> 04:10:15,966
SPEAKER_1:  human.

04:10:17,026 --> 04:10:18,526
SPEAKER_1:  like intimate human time.

04:10:19,394 --> 04:10:23,102
SPEAKER_0:  I feel like it was like that a little bit more in the past. I feel like it's been better.

04:10:23,746 --> 04:10:24,446
SPEAKER_0:  Lately?

04:10:24,866 --> 04:10:29,758
SPEAKER_0:  But I think it's because when we started dating, I wasn't streaming and I kind of just like.

04:10:29,986 --> 04:10:31,966
SPEAKER_0:  gave up like my trip to New Zealand.

04:10:32,226 --> 04:10:33,790
SPEAKER_0:  I give up. Okay.

04:10:34,274 --> 04:10:35,230
SPEAKER_0:  left Sweden.

04:10:35,586 --> 04:10:36,254
SPEAKER_0:  So it was just like.

04:10:36,706 --> 04:10:39,934
SPEAKER_0:  in LA, which I hate. I hate LA. I don't like LA at all.

04:10:40,386 --> 04:10:42,398
SPEAKER_0:  It's hard to make friends.

04:10:42,658 --> 04:10:51,838
SPEAKER_0:  that are like real, that are into the same stuff as you. It was just really hard for me to connect with anyone, especially also like being a European and like being around Americans was very strange.

04:10:52,258 --> 04:10:55,390
SPEAKER_0:  So the only thing I had when I came here was him.

04:10:56,162 --> 04:11:11,070
SPEAKER_0:  And I didn't expect because we had like two weeks of hanging out. And like he would be in his computer sometimes and like do emails and stuff. But I wasn't thinking that he would stream like 12 hours a day. And it was pretty like it was pretty intense like in the beginning of it as well.

04:11:11,458 --> 04:11:15,550
SPEAKER_0:  I realized it was really hard to get attention or get time because his...

04:11:15,778 --> 04:11:23,486
SPEAKER_0:  love meter would be like full if I was just in the house. And that's just kind of like the way he is. And for me back then when I didn't have anything else to do.

04:11:23,842 --> 04:11:24,446
SPEAKER_0:  Um...

04:11:25,090 --> 04:11:35,646
SPEAKER_0:  was kind of like a, it was kind of crazy for me. I feel like right now, because I do work as well and I have things going for me and I have other friends now that I'm made.

04:11:35,906 --> 04:11:44,158
SPEAKER_0:  I feel like it's a lot easier because I can definitely enjoy just being in separate rooms and just hearing them in the background is really nice. I can sit and paint.

04:11:44,418 --> 04:11:48,414
SPEAKER_0:  and like in my room and I will do that for hours while I'm just like hearing a scream in the background. It's kinda like-

04:11:48,866 --> 04:11:52,030
SPEAKER_0:  comforting that he's just there. It feels nice. I like it.

04:11:52,130 --> 04:11:54,005
SPEAKER_1:  to you that's the sound of happiness.

04:11:54,005 --> 04:12:00,382
SPEAKER_0:  Because I know he's right there. Yeah, it's nice and they'll come in and check on me sometimes. And it's kind of like, it's actually very comforting. It's very nice. I like it.

04:12:01,954 --> 04:12:06,590
SPEAKER_0:  I think that's kind of what a relationship is, like you do fun things together, you share moments together.

04:12:06,818 --> 04:12:09,886
SPEAKER_0:  but also just like having someone like around you is really, really nice.

04:12:10,402 --> 04:12:12,030
SPEAKER_0:  And I think that's probably.

04:12:12,386 --> 04:12:13,662
SPEAKER_0:  Maybe it's me growing up.

04:12:14,722 --> 04:12:24,035
SPEAKER_0:  Maybe that's what it is. And I start liking like the kind of, I feel like we're like an old couple. Like we're like 80 and we're just like around. We don't really have to talk much. It's nice.

04:12:24,035 --> 04:12:25,726
SPEAKER_1:  That fills your love meter.

04:12:26,210 --> 04:12:27,070
SPEAKER_1:  That's it.

04:12:27,170 --> 04:12:30,270
SPEAKER_0:  I think I need both. I need both. I mean, okay. I think I need both. I need both.

04:12:30,754 --> 04:12:40,894
SPEAKER_0:  You're making it sound like that I'm like craving like crazy time. I'm not saying anything. I haven't said a single thing at all. You're making face right now. I know exactly what you're thinking. There's so much judging going on. There's no judging.

04:12:41,154 --> 04:12:47,838
SPEAKER_0:  No, but like we, I think whenever we do plan something out, like if we go on a trip like every other month once a month.

04:12:48,290 --> 04:12:50,526
SPEAKER_0:  I feel like usually that's enough.

04:12:51,138 --> 04:12:57,118
SPEAKER_0:  as long as he's not playing Victoria the entire time. Like, if I feel like he's going on these trips with me and he's not...

04:12:57,922 --> 04:13:06,366
SPEAKER_0:  like doing things with me or he's not interested in like spending time or like being present with me, then I'll feel like, I just feel like I'm just wasting time right now and then I get kind of disappointed.

04:13:06,690 --> 04:13:13,815
SPEAKER_0:  But otherwise, I think this is fun. I think this is like spending time together. Cause we're doing something together. Yeah, it's fun. being apart of wonderful Halloween, and the candy and

04:13:13,815 --> 04:13:15,614
SPEAKER_1:  My love meters

04:13:15,842 --> 04:13:18,467
SPEAKER_1:  Your library is full. This is my social life.

04:13:18,467 --> 04:13:26,430
SPEAKER_0:  We like to think about it that way, that I need a little bit more of this one thing, quality time. And he needs like almost zero quality time.

04:13:27,042 --> 04:13:30,558
SPEAKER_0:  But like, let's say that we took away physical touch, you would probably not be very happy.

04:13:31,458 --> 04:13:33,950
SPEAKER_1:  So you need physical touch, so it's not just back to where you are.

04:13:34,210 --> 04:13:35,678
SPEAKER_0:  No, I'm a very cuddly person. I'm a good girl, with telly skin.

04:13:36,002 --> 04:13:40,830
SPEAKER_0:  And then you're like, I guess like acts of service. Like if I do something for you, you get really happy. Like hot chocolate.

04:13:41,858 --> 04:13:44,542
SPEAKER_0:  Like if I give him hot chocolate in the morning, he gets really happy.

04:13:44,738 --> 04:13:48,863
SPEAKER_1:  The actual, it's not the hot chocolate, it's the giving of the hot chocolate. No, it's just the hot chocolate.

04:13:48,863 --> 04:13:49,502
SPEAKER_0:  What?

04:13:49,730 --> 04:13:53,246
SPEAKER_0:  But if she gives it to me, I didn't have to get it myself. Maybe it's just physical touch that you like. That's really nice.

04:13:54,338 --> 04:13:57,374
SPEAKER_1:  Alright, well if you have to choose between Factorio and the drama.

04:13:58,146 --> 04:13:59,454
SPEAKER_1:  or political discourse.

04:14:00,162 --> 04:14:02,302
SPEAKER_0:  Probably political discourse, probably my calling.

04:14:02,882 --> 04:14:04,062
SPEAKER_0:  I am a good factorial player.

04:14:05,506 --> 04:14:09,374
SPEAKER_1:  What role exactly does factorial play in your streaming life?

04:14:09,986 --> 04:14:15,966
SPEAKER_0:  Well right now it's just usually there are like these games that I play in the background as I have conversation because it's hard for me to just sit on the computer and just talk.

04:14:16,418 --> 04:14:19,742
SPEAKER_0:  and not like be playing a game at the same time. So just something to keep me kind of like occupied.

04:14:19,970 --> 04:14:25,150
SPEAKER_0:  You know, I was gonna go buy like those little like widget things, I guess. Yeah, that's what yours is. Yeah, basically, yeah. It's like Minecraft or Factorio for me.

04:14:26,018 --> 04:14:26,366
SPEAKER_1:  Alright.

04:14:27,234 --> 04:14:36,638
SPEAKER_1:  Well, my love meter is full from this. Mel, thank you so much for joining us. Thank you for having me. This was really fun. You guys are fascinating human beings.

04:14:36,930 --> 04:14:38,014
SPEAKER_1:  Thank you for existing.

04:14:38,562 --> 04:14:43,326
SPEAKER_1:  I'm glad to live in a world where you exist. I can't wait to see what kind of beautiful.

04:14:43,714 --> 04:14:48,382
SPEAKER_1:  thing you create next and the crazy kind of art that you create.

04:14:48,610 --> 04:14:50,238
SPEAKER_1:  to the different people you interact with.

04:14:50,658 --> 04:14:54,494
SPEAKER_1:  Destiny Stephen, you're an amazing human. Thank you so much for talking to me. It's an honor.

04:14:54,754 --> 04:14:58,814
SPEAKER_1:  Hope to talk with you again. I'm talking to Ben Shapiro. You've given me a lot of inspiration.

04:14:59,074 --> 04:15:01,534
SPEAKER_1:  It's an honor to talk to the Ben Shapiro of the left.

04:15:01,762 --> 04:15:04,117
SPEAKER_0:  Yeah. Well, thanks a lot for having me. I appreciate it.

04:15:04,117 --> 04:15:05,022
SPEAKER_1:  Thank you.

04:15:06,050 --> 04:15:08,190
SPEAKER_1:  Thanks for listening to this conversation with Destiny.

04:15:08,802 --> 04:15:12,158
SPEAKER_1:  To support this podcast, please check out our sponsors in the description.

04:15:12,642 --> 04:15:15,294
SPEAKER_1:  And now, let me leave you with some words from Lewis Carroll.

04:15:16,098 --> 04:15:18,334
SPEAKER_1:  It's no use going back to yesterday.

04:15:18,882 --> 04:15:20,446
SPEAKER_1:  because I was a different person then.

04:15:22,018 --> 04:15:22,814
SPEAKER_1:  Thank you for listening.

04:15:23,138 --> 04:15:23,870
SPEAKER_1:  I hope to see you.

04:15:24,322 --> 04:15:24,798
SPEAKER_1:  next time.
